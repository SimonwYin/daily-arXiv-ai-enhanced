{"id": "2510.24242", "categories": ["cs.NI", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24242", "abs": "https://arxiv.org/abs/2510.24242", "authors": ["Zihan Li", "Jiahao Yang", "Yuxin Zhang", "Zhe Chen", "Yue Gao"], "title": "Enabling Near-realtime Remote Sensing via Satellite-Ground Collaboration of Large Vision-Language Models", "comment": "15 pages, 11 figures", "summary": "Large vision-language models (LVLMs) have recently demonstrated great\npotential in remote sensing (RS) tasks (e.g., disaster monitoring) conducted by\nlow Earth orbit (LEO) satellites. However, their deployment in real-world LEO\nsatellite systems remains largely unexplored, hindered by limited onboard\ncomputing resources and brief satellite-ground contacts. We propose Grace, a\nsatellite-ground collaborative system designed for near-realtime LVLM inference\nin RS tasks. Accordingly, we deploy compact LVLM on satellites for realtime\ninference, but larger ones on ground stations (GSs) to guarantee end-to-end\nperformance. Grace is comprised of two main phases that are asynchronous\nsatellite-GS Retrieval-Augmented Generation (RAG), and a task dispatch\nalgorithm. Firstly, we still the knowledge archive of GS RAG to satellite\narchive with tailored adaptive update algorithm during limited satellite-ground\ndata exchange period. Secondly, propose a confidence-based test algorithm that\neither processes the task onboard the satellite or offloads it to the GS.\nExtensive experiments based on real-world satellite orbital data show that\nGrace reduces the average latency by 76-95% compared to state-of-the-art\nmethods, without compromising inference accuracy.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faGrace\uff0c\u4e00\u79cd\u536b\u661f-\u5730\u9762\u534f\u4f5c\u7cfb\u7edf\uff0c\u5728\u4f4e\u8f68\u536b\u661f\u4e0a\u90e8\u7f72\u7cbe\u7b80\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u5b9e\u65f6\u63a8\u7406\uff0c\u5728\u5730\u9762\u7ad9\u90e8\u7f72\u66f4\u5927\u6a21\u578b\u3002\u7cfb\u7edf\u5305\u542b\u5f02\u6b65\u536b\u661f-\u5730\u9762\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\u4e0e\u4efb\u52a1\u8c03\u5ea6\u7b97\u6cd5\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u66f4\u65b0\u5c06\u5730\u9762\u77e5\u8bc6\u5e93\u90e8\u5206\u540c\u6b65\u5230\u536b\u661f\uff0c\u5e76\u7528\u7f6e\u4fe1\u5ea6\u6d4b\u8bd5\u51b3\u5b9a\u672c\u5730\u5904\u7406\u6216\u4e0b\u53d1\u5730\u9762\u3002\u5b9e\u6d4b\u8f68\u9053\u6570\u636e\u8868\u660eGrace\u5728\u4e0d\u964d\u4f4e\u7cbe\u5ea6\u4e0b\u5c06\u5e73\u5747\u5ef6\u8fdf\u964d\u4f4e76\u201395%\u3002", "motivation": "\u52a8\u673a\u662f\u5f53\u524d\u5927\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u9065\u611f\u4efb\u52a1\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u771f\u5b9eLEO\u536b\u661f\u90e8\u7f72\u53d7\u9650\u4e8e\u536b\u661f\u8ba1\u7b97\u80fd\u529b\u548c\u77ed\u6682\u7684\u536b\u661f-\u5730\u9762\u8054\u7edc\u7a97\u53e3\uff0c\u9700\u5728\u5ef6\u8fdf\u3001\u5e26\u5bbd\u548c\u51c6\u786e\u6027\u4e4b\u95f4\u627e\u5230\u5e73\u8861\u4ee5\u5b9e\u73b0\u8fd1\u5b9e\u65f6\u5e94\u7528\uff08\u5982\u707e\u5bb3\u76d1\u6d4b\uff09\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\uff1a(1) \u5728\u536b\u661f\u4e0a\u90e8\u7f72\u7d27\u51d1LVLM\u5e76\u7ef4\u62a4\u672c\u5730\u77e5\u8bc6\u5f52\u6863\uff0c\u5730\u9762\u90e8\u7f72\u5927\u6a21\u578b\u4e0e\u5b8c\u6574\u77e5\u8bc6\u5e93\uff1b(2) \u8bbe\u8ba1\u81ea\u9002\u5e94\u66f4\u65b0\u7b97\u6cd5\uff0c\u5728\u6709\u9650\u94fe\u8def\u7a97\u53e3\u5185\u5c06\u5730\u9762RAG\u77e5\u8bc6\u5e93\u7684\u5173\u952e\u90e8\u5206\u540c\u6b65\u5230\u536b\u661f\u5f52\u6863\uff1b(3) \u63d0\u51fa\u57fa\u4e8e\u7f6e\u4fe1\u5ea6\u7684\u6d4b\u8bd5\u7b97\u6cd5\u52a8\u6001\u51b3\u5b9a\u662f\u5426\u5728\u536b\u661f\u7aef\u5b8c\u6210\u4efb\u52a1\u6216\u5c06\u4efb\u52a1\u4e0b\u53d1\u81f3\u5730\u9762\u7ad9\uff1b(4) \u5f02\u6b65\u536b\u661f-\u5730\u9762RAG\u673a\u5236\u5b9e\u73b0\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u4ee5\u63d0\u5347\u63a8\u7406\u8d28\u91cf\u3002", "result": "\u57fa\u4e8e\u771f\u5b9e\u536b\u661f\u8f68\u9053\u6570\u636e\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u663e\u793a\uff0cGrace\u5728\u4e0d\u727a\u7272\u63a8\u7406\u7cbe\u5ea6\u7684\u60c5\u51b5\u4e0b\uff0c\u5c06\u5e73\u5747\u5ef6\u8fdf\u964d\u4f4e76\u201395%\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "Grace\u5b9e\u73b0\u4e86\u5728\u53d7\u9650\u8ba1\u7b97\u548c\u77ed\u65f6\u536b\u661f-\u5730\u9762\u94fe\u8def\u4e0b\u7684\u8fd1\u5b9e\u65f6LVLM\u63a8\u7406\uff0c\u663e\u8457\u964d\u4f4e\u5ef6\u8fdf\u4e14\u4fdd\u6301\u51c6\u786e\u6027\uff0c\u9002\u5408\u771f\u5b9eLEO\u9065\u611f\u573a\u666f\u90e8\u7f72\u3002"}}
{"id": "2510.24595", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2510.24595", "abs": "https://arxiv.org/abs/2510.24595", "authors": ["Azadeh Pourkabirian", "Kai Li", "Photios A. Stavrou", "Wei Ni"], "title": "A New Hybrid Precoding Approach for Multi-user Massive MIMO over Fading Channels", "comment": null, "summary": "Hybrid precoding is an indispensable technique to harness the full potential\nof a multi-user massive multiple-input, multiple-output (MU-MMIMO) system. In\nthis paper, we propose a new hybrid precoding approach that combines digital\nand analog precoding to optimize data transmission over multiple antennas. This\napproach steers signals in specific directions, leading to maximizing sum-rate\nand suppressing side-lobe interference. When dealing with complex signals,\nchanges in phase are naturally associated with changes in angle, and these\nvariations are inherently correlated. The correlation between the angle and\nphase is essential for accurately determining the channel characteristics. An\nimportant aspect of this approach is that we model the angle and phase as\ncorrelated variables following a bivariate Gaussian distribution, and for the\nfirst time, we define a joint angle and phase entropy to measure the\nuncertainty of angle and phase variations in wireless channels. This entropy is\ncrucial to adapt the proposed precoding method with variations. Simulation\nresult validate the accuracy of our analytical findings, demonstrating 18.31%\nincrease in sum-rate and an 11.47% improvement in robustness compared to other\nstate-of-the-art methods.", "AI": {"tldr": "\u6587\u7ae0\u5c06\u89d2\u5ea6\u4e0e\u76f8\u4f4d\u89c6\u4e3a\u76f8\u5173\u53d8\u91cf\uff0c\u4f7f\u7528\u4e8c\u5143\u9ad8\u65af\u5206\u5e03\u548c\u8054\u5408\u71b5\u6765\u6307\u5bfc\u6df7\u5408\u9884\u7f16\u7801\u8bbe\u8ba1\uff0c\u4eff\u771f\u663e\u793a\u6bd4\u73b0\u6709\u65b9\u6cd5\u63d0\u5347\u7ea618.31%\u603b\u901f\u7387\u548c11.47%\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u6709\u6df7\u5408\u9884\u7f16\u7801\u65b9\u6cd5\u672a\u5145\u5206\u5229\u7528\u89d2\u5ea6\u4e0e\u76f8\u4f4d\u95f4\u7684\u7edf\u8ba1\u76f8\u5173\u6027\uff0c\u672c\u6587\u901a\u8fc7\u8054\u5408\u5efa\u6a21\u4e0e\u4fe1\u606f\u71b5\u5ea6\u91cf\u6765\u63d0\u9ad8\u9884\u7f16\u7801\u7684\u6027\u80fd\u4e0e\u9c81\u68d2\u6027\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u6570\u5b57/\u6a21\u62df\u4e32\u8054\u7684\u6df7\u5408\u9884\u7f16\u7801\u67b6\u6784\uff0c\u6a21\u62df\u7aef\u7528\u6ce2\u675f\u5f62\u6210\u6307\u5411\u76ee\u6807\u65b9\u5411\u4ee5\u6700\u5927\u5316\u4e3b\u74e3\u5e76\u6291\u5236\u526f\u74e3\uff1b\u5c06\u89d2\u5ea6\u4e0e\u76f8\u4f4d\u5efa\u6a21\u4e3a\u4e8c\u5143\u9ad8\u65af\u5206\u5e03\uff0c\u5b9a\u4e49\u5e76\u5229\u7528\u8054\u5408\u89d2\u76f8\u4f4d\u71b5\u66f4\u65b0\u9884\u7f16\u7801\u53c2\u6570\u4ee5\u9002\u5e94\u4fe1\u9053\u53d8\u5316\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u6570\u5b57\u548c\u6a21\u62df\u9884\u7f16\u7801\u7684\u6df7\u5408\u9884\u7f16\u7801\u65b9\u6cd5\uff0c\u901a\u8fc7\u5bf9\u89d2\u5ea6\u548c\u76f8\u4f4d\u5efa\u6a21\u4e3a\u8054\u5408\u9ad8\u65af\u5206\u5e03\u5e76\u5b9a\u4e49\u8054\u5408\u89d2\u76f8\u4f4d\u71b5\uff0c\u81ea\u9002\u5e94\u6291\u5236\u526f\u74e3\u5e72\u6270\u5e76\u63d0\u5347\u603b\u901f\u7387\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "\u5c06\u89d2\u5ea6\u4e0e\u76f8\u4f4d\u7684\u76f8\u5173\u6027\u878d\u5165\u9884\u7f16\u7801\u8bbe\u8ba1\u5e76\u901a\u8fc7\u8054\u5408\u71b5\u8fdb\u884c\u9002\u914d\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8MU-MMIMO\u7cfb\u7edf\u7684\u603b\u901f\u7387\u4e0e\u6297\u5e72\u6270\u80fd\u529b\u3002"}}
{"id": "2510.24611", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2510.24611", "abs": "https://arxiv.org/abs/2510.24611", "authors": ["Azadeh Pourkabirian", "Amir Masoud Rahmani", "Kai Li", "Wei Ni"], "title": "Strategic Task Offloading for Delay-Sensitive IoT Applications: A Game-Theory-Based Demand-Supply Mechanism with Participation Incentives", "comment": null, "summary": "Delay-sensitive Internet of Things (IoT) applications have drawn significant\nattention. Running many of these applications on IoT devices is challenging due\nto the limited processing resources of these devices and the need for real-time\nresponses. Task offloading can minimize latency by transferring computationally\nintensive tasks from IoT devices to resource-rich edge servers, ensuring delay\nand performance guarantees. In this paper, we develop a task-offloading\napproach for delay-sensitive IoT applications in edge computing environments.\nUnlike existing schemes, we model the task offloading problem as an economic\ndemand and supply model to achieve market balance. The proposed model avoids\nunder- and over-supply, ensuring the computational resources at edge servers\n(supply) are allocated in a manner that best meets the processing and\ncomputational needs of user devices (demand). Given the multi-agent nature of\ntask offloading involving users and service providers with different\npreferences and objectives, we design a game-theoretic framework using a\nVickrey-Clarke-Groves (VCG) auction. This framework analyzes agent interactions\nand decision-making processes. Additionally, we develop an incentive mechanism\nto encourage both parties to participate in the auction. The mechanism\nmaximizes user task offloading to edge servers and motivates edge servers to\nshare their computational resources, achieving profitability for both IoT users\nand edge servers. Simulations demonstrate our method maximizes social welfare,\nensures truthfulness, maintains market balance, and provides latency guarantees\nfor delay-sensitive IoT applications.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8eVCG\u62cd\u5356\u7684\u8fb9\u7f18\u8ba1\u7b97\u4efb\u52a1\u5378\u8f7d\u65b9\u6cd5\uff0c\u5c06\u5378\u8f7d\u95ee\u9898\u5efa\u6a21\u4e3a\u4f9b\u9700\u5e02\u573a\uff0c\u901a\u8fc7\u6fc0\u52b1\u673a\u5236\u4fdd\u8bc1\u771f\u5b9e\u6027\u3001\u5e02\u573a\u5e73\u8861\u548c\u5ef6\u8fdf\u7ea6\u675f\uff0c\u6a21\u62df\u7ed3\u679c\u663e\u793a\u793e\u4f1a\u798f\u5229\u6700\u5927\u5316\u4e14\u5bf9\u7528\u6237\u548c\u8fb9\u7f18\u670d\u52a1\u5668\u6709\u5229", "motivation": "Address limited processing on IoT devices and need for latency guarantees by modeling offloading as market demand-supply to avoid under/over-supply", "method": "VCG auction-based task offloading in edge computing for delay-sensitive IoT", "result": "Game-theoretic VCG auction mechanism with incentive design that maximizes social welfare, truthfulness, market balance, latency guarantees; simulations confirm effectiveness and profitability for users and edge servers", "conclusion": "VCG\u62cd\u5356\u4e0e\u6fc0\u52b1\u673a\u5236\u80fd\u591f\u5728\u5ef6\u8fdf\u654f\u611fIoT\u573a\u666f\u4e0b\u5b9e\u73b0\u9ad8\u6548\u516c\u5e73\u7684\u8d44\u6e90\u5206\u914d\uff0c\u4fdd\u8bc1\u5ef6\u8fdf\u3001\u63d0\u9ad8\u793e\u4f1a\u798f\u5229\u5e76\u6fc0\u52b1\u53c2\u4e0e\u5404\u65b9"}}
{"id": "2510.23911", "categories": ["cs.DC", "cs.PF"], "pdf": "https://arxiv.org/pdf/2510.23911", "abs": "https://arxiv.org/abs/2510.23911", "authors": ["Arno Uhlig", "Iris Braun", "Matthias W\u00e4hlisch"], "title": "The SAP Cloud Infrastructure Dataset: A Reality Check of Scheduling and Placement of VMs in Cloud Computing", "comment": "15 pages", "summary": "Allocating resources in a distributed environment is a fundamental challenge.\nIn this paper, we analyze the scheduling and placement of virtual machines\n(VMs) in the cloud platform of SAP, the world's largest enterprise resource\nplanning software vendor. Based on data from roughly 1,800 hypervisors and\n48,000 VMs within a 30-day observation period, we highlight potential\nimprovements for workload management. The data was measured through\nobservability tooling that tracks resource usage and performance metrics across\nthe entire infrastructure. In contrast to existing datasets, ours uniquely\noffers fine-grained time-series telemetry data of fully virtualized\nenterprise-level workloads from both long-running and memory-intensive SAP\nS/4HANA and diverse, general-purpose applications. Our key findings include\nseveral suboptimal scheduling situations, such as CPU resource contention\nexceeding 40%, CPU ready times of up to 220 seconds, significantly imbalanced\ncompute hosts with a maximum CPU~utilization on intra-building block hosts of\nup to 99%, and overprovisioned CPU and memory resources resulting into over 80%\nof VMs using less than 70% of the provided resources. Bolstered by these\nfindings, we derive requirements for the design and implementation of novel\nplacement and scheduling algorithms and provide guidance to optimize resource\nallocations. We make the full dataset used in this study publicly available to\nenable data-driven evaluations of scheduling approaches for large-scale cloud\ninfrastructures in future research.", "AI": {"tldr": "\u901a\u8fc7\u5927\u89c4\u6a21\u4f01\u4e1a\u7ea7\u865a\u62df\u5316\u5de5\u4f5c\u8d1f\u8f7d\u7684\u7ec6\u7c92\u5ea6\u65f6\u5e8f\u9065\u6d4b\uff0c\u8bc1\u660e\u5f53\u524dVM\u8c03\u5ea6\u4e0e\u653e\u7f6e\u5b58\u5728\u663e\u8457\u4f4e\u6548\uff0c\u7ed9\u51fa\u6539\u8fdb\u9700\u6c42\u5e76\u516c\u5f00\u6570\u636e\u96c6\u4ee5\u652f\u6301\u540e\u7eed\u7814\u7a76\u3002", "motivation": "\u5206\u6790\u5728\u5206\u5e03\u5f0f\u73af\u5883\u4e2d\u5206\u914d\u8d44\u6e90\u7684\u6311\u6218\uff0c\u7279\u522b\u662f\u4e91\u5e73\u53f0\u4e2d\u865a\u62df\u673a\u8c03\u5ea6\u4e0e\u653e\u7f6e\u7684\u95ee\u9898\uff0c\u53d1\u73b0\u73b0\u6709\u5b9e\u8df5\u4e2d\u7684\u4f4e\u6548\u5e76\u63d0\u51fa\u4f18\u5316\u9700\u6c42\u3002", "method": "\u5229\u7528\u89c2\u6d4b\u5de5\u5177\u6536\u96c630\u5929\u3001\u8986\u76d61,800\u4e2ahypervisor\u548c48,000\u4e2aVM\u7684\u7ec6\u7c92\u5ea6\u65f6\u95f4\u5e8f\u5217\u8d44\u6e90\u4e0e\u6027\u80fd\u6307\u6807\uff0c\u5206\u6790CPU\u4e89\u7528\u3001CPU ready\u3001\u4e3b\u673a\u5229\u7528\u7387\u5206\u5e03\u548cVM\u8d44\u6e90\u4f7f\u7528\u7387\uff0c\u57fa\u4e8e\u53d1\u73b0\u63d0\u51fa\u9700\u6c42\u4e0e\u4f18\u5316\u6307\u5bfc\uff0c\u5e76\u53d1\u5e03\u6570\u636e\u96c6\u3002", "result": "\u57fa\u4e8e1,800\u53f0hypervisor\u548c48,000\u53f0VM\u768430\u5929\u65f6\u95f4\u5e8f\u5217\u9065\u6d4b\u6570\u636e\uff0c\u53d1\u73b0\u591a\u79cd\u6b21\u4f18\u8c03\u5ea6\u60c5\u5f62\uff1aCPU\u4e89\u7528>40%\uff0cCPU ready\u9ad8\u8fbe220s\uff0c\u4e3b\u673a\u5229\u7528\u7387\u6781\u5ea6\u4e0d\u5e73\u8861\uff08\u90e8\u5206\u8fbe99%\uff09\uff0c\u8d85\u8fc780%\u7684VM\u8fc7\u5ea6\u914d\u7f6e\uff08\u5b9e\u9645\u4f7f\u7528<70%\u5206\u914d\u8d44\u6e90\uff09\u3002\u5e76\u63d0\u4f9b\u5bf9\u8c03\u5ea6\u4e0e\u653e\u7f6e\u7b97\u6cd5\u8bbe\u8ba1\u7684\u9700\u6c42\u548c\u4f18\u5316\u5efa\u8bae\uff0c\u540c\u65f6\u516c\u5f00\u6570\u636e\u96c6\u3002", "conclusion": "\u73b0\u6709\u8d44\u6e90\u8c03\u5ea6\u5b58\u5728\u660e\u663e\u95ee\u9898\uff1a\u8d44\u6e90\u4e89\u7528\u3001\u957f\u7b49\u5f85\u3001\u4e3b\u673a\u8d1f\u8f7d\u4e0d\u5747\u4e0e\u8fc7\u5ea6\u914d\u7f6e\u3002\u9700\u8981\u65b0\u7684\u611f\u77e5\u5e76\u884c/\u5f02\u6784\u8d1f\u8f7d\u7684\u8c03\u5ea6\u4e0e\u653e\u7f6e\u7b97\u6cd5\uff0c\u5e76\u53ef\u901a\u8fc7\u516c\u5f00\u6570\u636e\u9a71\u52a8\u8bc4\u4f30\u6539\u8fdb\u6548\u679c\u3002"}}
{"id": "2510.24408", "categories": ["cs.CR", "cs.NI"], "pdf": "https://arxiv.org/pdf/2510.24408", "abs": "https://arxiv.org/abs/2510.24408", "authors": ["Yifan Wu", "Xuewei Feng", "Yuxiang Yang", "Ke Xu"], "title": "Uncovering Gaps Between RFC Updates and TCP/IP Implementations: LLM-Facilitated Differential Checks on Intermediate Representations", "comment": "15 pages, 7 figures", "summary": "As the core of the Internet infrastructure, the TCP/IP protocol stack\nundertakes the task of network data transmission. However, due to the\ncomplexity of the protocol and the uncertainty of cross-layer interaction,\nthere are often inconsistencies between the implementation of the protocol\nstack code and the RFC standard. This inconsistency may not only lead to\ndifferences in protocol functions but also cause serious security\nvulnerabilities. At present, with the continuous expansion of protocol stack\nfunctions and the rapid iteration of RFC documents, it is increasingly\nimportant to detect and fix these inconsistencies. With the rise of large\nlanguage models, researchers have begun to explore how to extract protocol\nspecifications from RFC documents through these models, including protocol\nstack modeling, state machine extraction, text ambiguity analysis, and other\nrelated content. However, existing methods rely on predefined patterns or\nrule-based approaches that fail to generalize across different protocol\nspecifications. Automated and scalable detection of these inconsistencies\nremains a significant challenge. In this study, we propose an automated\nanalysis framework based on LLM and differential models. By modeling the\niterative relationship of the protocol and based on the iterative update\nrelationship of the RFC standard, we perform incremental code function analysis\non different versions of kernel code implementations to automatically perform\ncode detection and vulnerability analysis. We conduct extensive evaluations to\nvalidate the effectiveness of our framework, demonstrating its effectiveness in\nidentifying potential vulnerabilities caused by RFC code inconsistencies.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u57fa\u4e8e\u5927\u6a21\u578b\u4e0e\u5dee\u5f02\u5316\u5206\u6790\u7684\u81ea\u52a8\u5316\u6846\u67b6\uff0c\u7528\u4e8e\u68c0\u6d4b\u5185\u6838TCP/IP\u534f\u8bae\u6808\u5b9e\u73b0\u4e0eRFC\u89c4\u8303\u95f4\u7684\u4e0d\u4e00\u81f4\uff0c\u4ece\u800c\u53d1\u73b0\u6f5c\u5728\u6f0f\u6d1e\u3002\u65b9\u6cd5\u901a\u8fc7\u5efa\u6a21\u534f\u8bae\u8fed\u4ee3\u5173\u7cfb\u3001\u57fa\u4e8eRFC\u8fed\u4ee3\u66f4\u65b0\u5bf9\u5185\u6838\u4e0d\u540c\u7248\u672c\u4ee3\u7801\u505a\u589e\u91cf\u529f\u80fd\u5206\u6790\u4e0e\u5dee\u5206\u68c0\u6d4b\u3002\u8bc4\u4f30\u663e\u793a\u8be5\u6846\u67b6\u80fd\u6709\u6548\u8bc6\u522b\u7531RFC\u4e0e\u5b9e\u73b0\u4e0d\u4e00\u81f4\u5f15\u53d1\u7684\u6f5c\u5728\u5b89\u5168\u95ee\u9898\u3002", "motivation": "\u534f\u8bae\u4e0e\u5b9e\u73b0\u4e4b\u95f4\u7531\u4e8e\u89c4\u8303\u590d\u6742\u3001\u8de8\u5c42\u4ea4\u4e92\u4e0d\u786e\u5b9a\u6027\u53caRFC\u9891\u7e41\u8fed\u4ee3\uff0c\u5bb9\u6613\u4ea7\u751f\u5b9e\u73b0\u4e0e\u89c4\u8303\u4e0d\u4e00\u81f4\uff0c\u8fdb\u800c\u5e26\u6765\u529f\u80fd\u504f\u5dee\u6216\u5b89\u5168\u6f0f\u6d1e\uff0c\u56e0\u6b64\u9700\u8981\u81ea\u52a8\u5316\u3001\u53ef\u6269\u5c55\u7684\u65b9\u6cd5\u68c0\u6d4b\u5e76\u5b9a\u4f4d\u8fd9\u4e9b\u4e0d\u4e00\u81f4\uff0c\u4ece\u800c\u63d0\u5347\u7f51\u7edc\u534f\u8bae\u6808\u7684\u5b89\u5168\u6027\u548c\u6b63\u786e\u6027\u3002", "method": "1) \u5229\u7528LLM\u4eceRFC\u4e2d\u62bd\u53d6\u534f\u8bae\u89c4\u8303\u4e0e\u72b6\u6001\u673a\u3001\u5e76\u5efa\u6a21\u89c4\u8303\u7684\u8fed\u4ee3\u66f4\u65b0\u5173\u7cfb\uff1b2) \u5bf9\u4e0d\u540c\u5185\u6838\u7248\u672c\u7684\u534f\u8bae\u6808\u4ee3\u7801\u505a\u589e\u91cf\u5dee\u5206\u5206\u6790\uff0c\u7ed3\u5408\u7b26\u53f7\u6267\u884c/\u9759\u6001\u5206\u6790\u83b7\u53d6\u51fd\u6570\u884c\u4e3a\u8bed\u4e49\uff1b3) \u5c06\u4ee3\u7801\u884c\u4e3a\u4e0e\u4eceRFC\u62bd\u53d6\u7684\u89c4\u8303\u8fdb\u884c\u5bf9\u9f50\u4e0e\u5dee\u5f02\u68c0\u6d4b\uff0c\u81ea\u52a8\u6807\u8bb0\u4e0d\u4e00\u81f4\u5e76\u63a8\u65ad\u6f5c\u5728\u5b89\u5168\u5f71\u54cd\u3002", "result": "\u901a\u8fc7\u5927\u89c4\u6a21\u5b9e\u9a8c\u8bc4\u4f30\uff0c\u6846\u67b6\u5728\u591a\u7248\u672c\u5185\u6838TCP/IP\u5b9e\u73b0\u4e0a\u6210\u529f\u68c0\u6d4b\u51fa\u82e5\u5e72\u4e0eRFC\u4e0d\u4e00\u81f4\u7684\u5b9e\u73b0\u70b9\uff0c\u5e76\u5b9a\u4f4d\u51fa\u5bf9\u5e94\u7684\u6f5c\u5728\u6f0f\u6d1e\u793a\u4f8b\uff0c\u5c55\u793a\u4e86\u826f\u597d\u7684\u68c0\u6d4b\u80fd\u529b\u548c\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "\u57fa\u4e8eLLM\u4e0e\u5dee\u5f02\u5316\u6a21\u578b\u7684\u81ea\u52a8\u5316\u5206\u6790\u6846\u67b6\u80fd\u5728\u6838\u5b9e\u73b0\u4e0eRFC\u89c4\u8303\u4e4b\u95f4\u53d1\u73b0\u4e0d\u4e00\u81f4\uff0c\u5e2e\u52a9\u5b9a\u4f4d\u6f5c\u5728\u6f0f\u6d1e\u5e76\u63d0\u5347\u534f\u8bae\u6808\u5b89\u5168\u6027\uff1b\u65b9\u6cd5\u5728\u591a\u7248\u672c\u5185\u6838\u4ee3\u7801\u4e0a\u7ecf\u8fc7\u8bc4\u4f30\uff0c\u8bc1\u660e\u5177\u6709\u6548\u9a8c\u5b9e\u7528\u6027\u4e0e\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2510.23993", "categories": ["cs.DC", "cs.CE"], "pdf": "https://arxiv.org/pdf/2510.23993", "abs": "https://arxiv.org/abs/2510.23993", "authors": ["Anthony Carreon", "Jagmohan Singh", "Shivank Sharma", "Shuzhi Zhang", "Venkat Raman"], "title": "A GPU-based Compressible Combustion Solver for Applications Exhibiting Disparate Space and Time Scales", "comment": "32 pages, 12 figures", "summary": "High-speed chemically active flows present significant computational\nchallenges due to their disparate space and time scales, where stiff chemistry\noften dominates simulation time. While modern supercomputing scientific codes\nachieve exascale performance by leveraging graphics processing units (GPUs),\nexisting GPU-based compressible combustion solvers face critical limitations in\nmemory management, load balancing, and handling the highly localized nature of\nchemical reactions. To this end, we present a high-performance compressible\nreacting flow solver built on the AMReX framework and optimized for multi-GPU\nsettings. Our approach addresses three GPU performance bottlenecks: memory\naccess patterns through column-major storage optimization, computational\nworkload variability via a bulk-sparse integration strategy for chemical\nkinetics, and multi-GPU load distribution for adaptive mesh refinement\napplications. The solver adapts existing matrix-based chemical kinetics\nformulations to multigrid contexts. Using representative combustion\napplications including hydrogen-air detonations and jet in supersonic crossflow\nconfigurations, we demonstrate $2-5\\times$ performance improvements over\ninitial GPU implementations with near-ideal weak scaling across $1-96$ NVIDIA\nH100 GPUs. Roofline analysis reveals substantial improvements in arithmetic\nintensity for both convection ($\\sim 10 \\times$) and chemistry ($\\sim 4\n\\times$) routines, confirming efficient utilization of GPU memory bandwidth and\ncomputational resources.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5185\u5b58\u5e03\u5c40\u4f18\u5316\u3001bulk-sparse\u5316\u5b66\u79ef\u5206\u548cAMR\u591aGPU\u8d1f\u8f7d\u5206\u914d\uff0c\u663e\u8457\u63d0\u5347\u4e86\u591aGPU\u73af\u5883\u4e0b\u53ef\u71c3\u6d41\u6c42\u89e3\u5668\u7684\u6027\u80fd\u4e0e\u6269\u5c55\u6027\u3002", "motivation": "\u5f53\u524d\u9ad8\u6027\u80fd\u8ba1\u7b97\u4e2dGPU\u4e0a\u53ef\u71c3\u6d41\u6c42\u89e3\u5668\u5728\u5185\u5b58\u7ba1\u7406\u3001\u8d1f\u8f7d\u5747\u8861\u548c\u5316\u5b66\u53cd\u5e94\u5c40\u90e8\u5316\u5904\u7406\u65b9\u9762\u5b58\u5728\u74f6\u9888\uff0c\u5f71\u54cd\u6536\u655b\u548c\u6269\u5c55\u6027\u3002\u4f5c\u8005\u5e0c\u671b\u901a\u8fc7\u7ed3\u6784\u4e0e\u7b97\u6cd5\u4f18\u5316\u63d0\u5347\u591aGPU\u4e0b\u7684\u5316\u5b66\u53cd\u5e94\u6d41\u6a21\u62df\u6027\u80fd\u3002", "method": "GPU\u4f18\u5316\u7684\u53ef\u71c3\u6d41\u6c42\u89e3\u5668\u5b9e\u73b0\u65b9\u6cd5", "result": "\u5728AMReX\u6846\u67b6\u4e0a\u5b9e\u73b0\u7684\u591aGPU\u53ef\u538b\u7f29\u53cd\u5e94\u6d41\u6c42\u89e3\u5668\uff0c\u901a\u8fc7\u5217\u4e3b\u5b58\u50a8\u3001bulk-sparse\u5316\u5b66\u79ef\u5206\u548c\u81ea\u9002\u5e94\u7f51\u683c\u591aGPU\u8d1f\u8f7d\u5206\u914d\u7b49\u7b56\u7565\uff0c\u5b9e\u73b0\u4e86\u6bd4\u521d\u59cbGPU\u5b9e\u73b02-5\u500d\u7684\u6027\u80fd\u63d0\u5347\uff0c\u5e76\u57281-96\u5757NVIDIA H100 GPU\u4e0a\u63a5\u8fd1\u7406\u60f3\u7684\u5f31\u6269\u5c55\u3002Roofline\u5206\u6790\u8868\u660e\u5bf9\u6d41\u7b97\u5b50\u548c\u5316\u5b66\u79ef\u5206\u7b97\u5b50\u7684\u7b97\u672f\u5f3a\u5ea6\u5206\u522b\u63d0\u9ad8\u7ea610\u500d\u548c4\u500d\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u6709\u6548\u7f13\u89e3\u4e86GPU\u4e0a\u7684\u5185\u5b58\u548c\u8d1f\u8f7d\u74f6\u9888\uff0c\u5728\u4ee3\u8868\u6027\u71c3\u70e7\u95ee\u9898\u4e0a\u5b9e\u73b0\u4e86\u4e9a\u7ebf\u6027\u5230\u63a5\u8fd1\u7406\u60f3\u7684\u6269\u5c55\u548c\u663e\u8457\u7684\u541e\u5410\u91cf\u63d0\u9ad8\uff0c\u9002\u5408\u5927\u89c4\u6a21\u5316\u5b66\u53cd\u5e94\u6d41\u6a21\u62df\u3002"}}
{"id": "2510.23617", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.23617", "abs": "https://arxiv.org/abs/2510.23617", "authors": ["Phuong Q. Dao", "Mark Roantree", "Vuong M. Ngo"], "title": "An Enhanced Dual Transformer Contrastive Network for Multimodal Sentiment Analysis", "comment": "The paper has been accepted for presentation at the MEDES 2025\n  conference", "summary": "Multimodal Sentiment Analysis (MSA) seeks to understand human emotions by\njointly analyzing data from multiple modalities typically text and images\noffering a richer and more accurate interpretation than unimodal approaches. In\nthis paper, we first propose BERT-ViT-EF, a novel model that combines powerful\nTransformer-based encoders BERT for textual input and ViT for visual input\nthrough an early fusion strategy. This approach facilitates deeper cross-modal\ninteractions and more effective joint representation learning. To further\nenhance the model's capability, we propose an extension called the Dual\nTransformer Contrastive Network (DTCN), which builds upon BERT-ViT-EF. DTCN\nincorporates an additional Transformer encoder layer after BERT to refine\ntextual context (before fusion) and employs contrastive learning to align text\nand image representations, fostering robust multimodal feature learning.\nEmpirical results on two widely used MSA benchmarks MVSA-Single and TumEmo\ndemonstrate the effectiveness of our approach. DTCN achieves best accuracy\n(78.4%) and F1-score (78.3%) on TumEmo, and delivers competitive performance on\nMVSA-Single, with 76.6% accuracy and 75.9% F1-score. These improvements\nhighlight the benefits of early fusion and deeper contextual modeling in\nTransformer-based multimodal sentiment analysis.", "AI": {"tldr": "\u63d0\u51faBERT-ViT-EF\uff08\u65e9\u671f\u878d\u5408BERT\u4e0eViT\uff09\u548c\u6269\u5c55\u7684\u5bf9\u6bd4\u5b66\u4e60\u6a21\u578bDTCN\uff0c\u901a\u8fc7\u6587\u672c\u9884\u7f16\u7801\u5c42\u4e0e\u5bf9\u6bd4\u5b66\u4e60\u63d0\u5347\u8de8\u6a21\u6001\u5bf9\u9f50\uff0c\u5728TumEmo\u4e0a\u8fbe78.4%\u51c6\u786e\u7387\u548c78.3% F1\u3002", "motivation": "\u901a\u8fc7\u66f4\u6df1\u7684\u6587\u672c\u4e0a\u4e0b\u6587\u5efa\u6a21\u548c\u65e9\u671f\u878d\u5408\u589e\u5f3a\u8de8\u6a21\u6001\u4e92\u52a8\u4ee5\u63d0\u9ad8\u591a\u6a21\u6001\u60c5\u611f\u5206\u6790\u7684\u6027\u80fd\u3002", "method": "\u4f7f\u7528BERT\u5904\u7406\u6587\u672c\u3001ViT\u5904\u7406\u56fe\u50cf\uff0c\u5148\u5c06\u6587\u672c\u7ecf\u989d\u5916Transformer\u5c42\u7cbe\u70bc\uff0c\u518d\u8fdb\u884c\u65e9\u671f\u878d\u5408\uff1b\u5f15\u5165\u5bf9\u6bd4\u5b66\u4e60\u5bf9\u9f50\u6587\u672c\u4e0e\u56fe\u50cf\u8868\u793a\uff0c\u5e76\u8054\u5408\u8bad\u7ec3\u5206\u7c7b\u635f\u5931\u4e0e\u5bf9\u6bd4\u635f\u5931\u3002", "result": "Proposed BERT-ViT-EF and DTCN models for MSA; DTCN achieves SOTA on TumEmo and competitive on MVSA-Single.", "conclusion": "\u65e9\u671f\u878d\u5408\u548c\u6587\u672c\u4e0a\u66f4\u6df1\u7684\u4e0a\u4e0b\u6587\u5efa\u6a21\u52a0\u4e0a\u5bf9\u6bd4\u5b66\u4e60\u80fd\u663e\u8457\u63d0\u5347Transformer\u591a\u6a21\u6001\u60c5\u611f\u5206\u6790\u6027\u80fd\u3002"}}
{"id": "2510.23619", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23619", "abs": "https://arxiv.org/abs/2510.23619", "authors": ["Yuyang Miao", "Huijun Xing", "Danilo P. Mandic", "Tony G. Constantinides"], "title": "Short Ticketing Detection Framework Analysis Report", "comment": null, "summary": "This report presents a comprehensive analysis of an unsupervised multi-expert\nmachine learning framework for detecting short ticketing fraud in railway\nsystems. The study introduces an A/B/C/D station classification system that\nsuccessfully identifies suspicious patterns across 30 high-risk stations. The\nframework employs four complementary algorithms: Isolation Forest, Local\nOutlier Factor, One-Class SVM, and Mahalanobis Distance. Key findings include\nthe identification of five distinct short ticketing patterns and potential for\nshort ticketing recovery in transportation systems.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e00\u79cd\u65e0\u76d1\u7763\u591a\u4e13\u5bb6\u68c0\u6d4b\u6846\u67b6\uff0c\u7ed3\u5408Isolation Forest\u3001LOF\u3001One-Class SVM\u548c\u9a6c\u6c0f\u8ddd\u79bb\u7b97\u6cd5\uff0c\u5bf930\u4e2a\u9ad8\u98ce\u9669\u8f66\u7ad9\u8fdb\u884cA/B/C/D\u5206\u7c7b\uff0c\u8bc6\u522b\u51fa5\u7c7b\u77ed\u7a0b\u9003\u7968\u6a21\u5f0f\u5e76\u6307\u51fa\u6f5c\u5728\u7684\u7968\u6b3e\u56de\u6536\u8def\u5f84\u3002", "motivation": "Short ticketing fraud harms revenue and operational integrity; unsupervised methods can detect anomalies without labeled fraud data and combining multiple algorithms improves robustness across diverse stations.", "method": "Unsupervised multi-expert framework for short ticketing fraud detection in railways", "result": "A/B/C/D station classification across 30 high-risk stations; four-algorithm ensemble (Isolation Forest, LOF, One-Class SVM, Mahalanobis Distance); five short ticketing patterns identified; potential for recovery of revenue.", "conclusion": "\u591a\u6a21\u578b\u65e0\u76d1\u7763\u65b9\u6cd5\u80fd\u5728\u7f3a\u4e4f\u6807\u6ce8\u6570\u636e\u60c5\u51b5\u4e0b\u6709\u6548\u8bc6\u522b\u591a\u6837\u5316\u77ed\u7968\u6b3a\u8bc8\u6a21\u5f0f\uff0c\u4e3a\u8f66\u7ad9\u5206\u7ea7\u7ba1\u7406\u548c\u7968\u6b3e\u56de\u6536\u63d0\u4f9b\u51b3\u7b56\u652f\u6301\u3002"}}
{"id": "2510.23691", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23691", "abs": "https://arxiv.org/abs/2510.23691", "authors": ["Zihao Wang", "Xujing Li", "Yining Ye", "Junjie Fang", "Haoming Wang", "Longxiang Liu", "Shihao Liang", "Junting Lu", "Zhiyong Wu", "Jiazhan Feng", "Wanjun Zhong", "Zili Li", "Yu Wang", "Yu Miao", "Bo Zhou", "Yuanfan Li", "Hao Wang", "Zhongkai Zhao", "Faming Wu", "Zhengxuan Jiang", "Weihao Tan", "Heyuan Yao", "Shi Yan", "Xiangyang Li", "Yitao Liang", "Yujia Qin", "Guang Shi"], "title": "Game-TARS: Pretrained Foundation Models for Scalable Generalist Multimodal Game Agents", "comment": null, "summary": "We present Game-TARS, a generalist game agent trained with a unified,\nscalable action space anchored to human-aligned native keyboard-mouse inputs.\nUnlike API- or GUI-based approaches, this paradigm enables large-scale\ncontinual pre-training across heterogeneous domains, including OS, web, and\nsimulation games. Game-TARS is pre-trained on over 500B tokens with diverse\ntrajectories and multimodal data. Key techniques include a decaying continual\nloss to reduce causal confusion and an efficient Sparse-Thinking strategy that\nbalances reasoning depth and inference cost. Experiments show that Game-TARS\nachieves about 2 times the success rate over the previous sota model on\nopen-world Minecraft tasks, is close to the generality of fresh humans in\nunseen web 3d games, and outperforms GPT-5, Gemini-2.5-Pro, and Claude-4-Sonnet\nin FPS benchmarks. Scaling results on training-time and test-time confirm that\nthe unified action space sustains improvements when scaled to cross-game and\nmultimodal data. Our results demonstrate that simple, scalable action\nrepresentations combined with large-scale pre-training provide a promising path\ntoward generalist agents with broad computer-use abilities.", "AI": {"tldr": "Game-TARS trains a generalist agent on a unified keyboard-mouse action space with 500B tokens, using decaying continual loss and Sparse-Thinking; it achieves strong cross-game performance and outperforms several LLMs in game benchmarks.", "motivation": "Develop a unified, scalable action space aligned to human keyboard-mouse inputs to enable large-scale continual pretraining across heterogeneous game domains and real computer use.", "method": "AnalyzeGame-TARS", "result": "2x success over previous SOTA in Minecraft, comparable to fresh humans in unseen web 3D games, outperforms GPT-5/Gemini-2.5-Pro/Claude-4-Sonnet in FPS benchmarks; scaling shows benefits preserved.", "conclusion": "Unified, human-aligned action representations plus large-scale pretraining enable scalable generalist game agents capable of broad computer-use abilities."}}
{"id": "2510.24175", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.24175", "abs": "https://arxiv.org/abs/2510.24175", "authors": ["Nitin Shukla", "Alessandro Romeo", "Caterina Caravita", "Michael Redenti", "Radim Vavrik", "Lubomir Riha", "Andrea Mignone", "Marco Rossazza", "Stefano Truzzi", "Luca Tornatore", "Antonio Ragagnin", "Tiago Castro", "Geray S. Karademir", "Klaus Dolag", "Pranab J. Deka", "Fabio Bacchini", "Rostislav-Paul Wilhelm", "Daniele Gregori", "Elisabetta Boella"], "title": "Towards Exascale Computing for Astrophysical Simulation Leveraging the Leonardo EuroHPC System", "comment": null, "summary": "Developing and redesigning astrophysical, cosmological, and space plasma\nnumerical codes for existing and next-generation accelerators is critical for\nenabling large-scale simulations. To address these challenges, the SPACE Center\nof Excellence (SPACE-CoE) fosters collaboration between scientists, code\ndevelopers, and high-performance computing experts to optimize applications for\nthe exascale era. This paper presents our strategy and initial results on the\nLeonardo system at CINECA for three flagship codes, namely gPLUTO, OpenGadget3\nand iPIC3D, using profiling tools to analyze performance on single and multiple\nnodes. Preliminary tests show all three codes scale efficiently, reaching 80%\nscalability up to 1,024 GPUs.", "AI": {"tldr": "SPACE-CoE\u5728Leonardo\u7cfb\u7edf\u4e0a\u4f18\u5316gPLUTO\u3001OpenGadget3\u548ciPIC3D\uff0c\u5229\u7528\u5256\u6790\u5de5\u5177\u8fdb\u884c\u5355/\u591a\u8282\u70b9\u6d4b\u8bd5\uff0c\u4e09\u8005\u5728\u6700\u591a1024 GPU\u4e0a\u5747\u8fbe\u7ea680%\u4f38\u7f29\u6548\u7387\uff0c\u8868\u660e\u5728\u52a0\u901f\u5668\u4e0a\u8fdb\u884c\u5927\u89c4\u6a21\u5929\u4f53\u4e0e\u7b49\u79bb\u5b50\u4f53\u6a21\u62df\u5177\u6709\u53ef\u884c\u6027\u3002", "motivation": "\u52a8\u673a\u662f\u4e3a\u5e94\u5bf9\u73b0\u6709\u4e0e\u4e0b\u4e00\u4ee3\u52a0\u901f\u5668\uff08\u5982\u5927\u578bGPU\u96c6\u7fa4\uff09\u5e26\u6765\u7684\u67b6\u6784\u53d8\u5316\uff0c\u4fdd\u8bc1\u5929\u4f53\u7269\u7406\u3001\u5b87\u5b99\u5b66\u4e0e\u7a7a\u95f4\u7b49\u79bb\u5b50\u4f53\u6570\u503c\u4ee3\u7801\u5728Exascale\u65f6\u4ee3\u4ecd\u80fd\u9ad8\u6548\u8fd0\u884c\uff0c\u4ece\u800c\u652f\u6301\u66f4\u5927\u89c4\u6a21\u3001\u66f4\u9ad8\u5206\u8fa8\u7387\u7684\u6a21\u62df\u7814\u7a76\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\uff1a\u4e0e\u79d1\u5b66\u5bb6\u548c\u4ee3\u7801\u5f00\u53d1\u8005\u534f\u4f5c\uff0c\u5bf9\u4e09\u6b3e\u4ee3\u7801\u8fdb\u884c\u9762\u5411\u52a0\u901f\u5668\u7684\u91cd\u6784\u4e0e\u4f18\u5316\uff1b\u4f7f\u7528\u5206\u6790/\u5256\u6790\u5de5\u5177\uff08profilers\uff09\u5728Leonardo\u7cfb\u7edf\u4e0a\u91c7\u96c6\u5355\u8282\u70b9\u4e0e\u591a\u8282\u70b9\u7684\u6027\u80fd\u6570\u636e\uff1b\u5f00\u5c55\u5f31/\u5f3a\u4f38\u7f29\u6027\u6d4b\u8bd5\u5e76\u8bc4\u4f30\u901a\u4fe1\u3001\u8ba1\u7b97\u4e0eI/O\u74f6\u9888\uff1b\u57fa\u4e8e\u5256\u6790\u7ed3\u679c\u9010\u6b65\u8c03\u6574\u5e76\u4f18\u5316\u5173\u952e\u5185\u6838\u4e0e\u5e76\u884c\u7b56\u7565\u3002", "result": "\u7ed3\u679c\uff1a\u4e09\u6b3e\u4ee3\u7801\u5728Leonardo\u4e0a\u5747\u5c55\u793a\u51fa\u826f\u597d\u6027\u80fd\u3002\u5256\u6790\u663e\u793a\u5173\u952e\u8ba1\u7b97\u5185\u6838\u5df2\u8f83\u597d\u8fc1\u79fb\u5230GPU\u5e76\u4e14\u901a\u4fe1\u7b56\u7565\u53ef\u6269\u5c55\uff1b\u521d\u6b65\u4f38\u7f29\u6d4b\u8bd5\u5728\u591a\u8fbe1024 GPUs\u65f6\u53ef\u8fbe\u7ea680%\u53ef\u6269\u5c55\u6548\u7387\u3002\u5177\u4f53\u7684\u5355\u8282\u70b9\u52a0\u901f\u6bd4\u3001\u901a\u4fe1\u4e0eI/O\u5f71\u54cd\u3001\u4ee5\u53ca\u4e0d\u540c\u95ee\u9898\u89c4\u6a21\u4e0b\u7684\u6027\u80fd\u7279\u5f81\u5728\u6b63\u6587\u4e2d\u6709\u8be6\u7ec6\u6570\u636e\uff08\u6458\u8981\u672a\u5b8c\u5168\u5217\u51fa\uff09\u3002", "conclusion": "\u672c\u6587\u603b\u7ed3\uff1aSPACE-CoE\u901a\u8fc7\u5728CINECA\u7684Leonardo\u7cfb\u7edf\u4e0a\u5bf9gPLUTO\u3001OpenGadget3\u548ciPIC3D\u4e09\u6b3e\u4ee3\u8868\u6027\u5929\u4f53\u4e0e\u7b49\u79bb\u5b50\u4f53\u4ee3\u7801\u8fdb\u884c\u91cd\u6784\u4e0e\u6027\u80fd\u5206\u6790\uff0c\u521d\u6b65\u7ed3\u679c\u663e\u793a\u5728\u5355\u8282\u70b9\u4e0e\u591a\u8282\u70b9\uff08\u591a\u8fbe1024 GPU\uff09\u4e0a\u5747\u6709\u826f\u597d\u4f38\u7f29\u6027\uff0c\u6700\u9ad8\u8fbe\u5230\u7ea680%\u7684\u53ef\u6269\u5c55\u6548\u7387\uff0c\u4e3a\u5728\u52a0\u901f\u5668\uff08GPU\uff09\u4e0a\u8fdb\u884c\u5927\u89c4\u6a21\u5929\u4f53\u7269\u7406\u4e0e\u7a7a\u95f4\u7b49\u79bb\u5b50\u4f53\u6a21\u62df\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2510.23621", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23621", "abs": "https://arxiv.org/abs/2510.23621", "authors": ["Alexandre Benoit"], "title": "Speeding Up MACE: Low-Precision Tricks for Equivarient Force Fields", "comment": "78 pages, 21 figures", "summary": "Machine-learning force fields can deliver accurate molecular dynamics (MD) at\nhigh computational cost. For SO(3)-equivariant models such as MACE, there is\nlittle systematic evidence on whether reduced-precision arithmetic and\nGPU-optimized kernels can cut this cost without harming physical fidelity. This\nthesis aims to make MACE cheaper and faster while preserving accuracy by\nidentifying computational bottlenecks and evaluating low-precision execution\npolicies. We profile MACE end-to-end and per block, compare the e3nn and NVIDIA\ncuEquivariance backends, and assess FP64/FP32/BF16/FP16 settings (with FP32\naccumulation) for inference, short NVT and long NPT water simulations, and toy\ntraining runs under reproducible, steady-state timing. cuEquivariance reduces\ninference latency by about $3\\times$. Casting only linear layers to BF16/FP16\nwithin an FP32 model yields roughly 4x additional speedups, while energies and\nthermodynamic observables in NVT/NPT MD remain within run-to-run variability.\nHalf-precision weights during training degrade force RMSE. Mixing e3nn and cuEq\nmodules without explicit adapters causes representation mismatches. Fused\nequivariant kernels and mixed-precision inference can substantially accelerate\nstate-of-the-art force fields with negligible impact on downstream MD. A\npractical policy is to use cuEquivariance with FP32 by default and enable\nBF16/FP16 for linear layers (keeping FP32 accumulations) for maximum\nthroughput, while training remains in FP32. Further gains are expected on\nAmpere/Hopper GPUs (TF32/BF16) and from kernel-level FP16/BF16 paths and\npipeline fusion.", "AI": {"tldr": "\u4f7f\u7528cuEquivariance\u5e76\u5bf9\u7ebf\u6027\u5c42\u5e94\u7528BF16/FP16\uff08FP32\u7d2f\u52a0\uff09\uff0c\u53ef\u5728\u4e0d\u663e\u8457\u635f\u5bb3MD\u4e0b\u5b9e\u73b0\u5927\u5e45\u52a0\u901f\uff1b\u8bad\u7ec3\u4ecd\u5e94\u4f7f\u7528FP32\u3002", "motivation": "\u964d\u4f4eSO(3)-\u7b49\u53d8\u673a\u5668\u5b66\u4e60\u529b\u573a\u7684\u8ba1\u7b97\u6210\u672c\uff0c\u4f7f\u9ad8\u7cbe\u5ea6MD\u66f4\u7ecf\u6d4e\u53ef\u884c\uff0c\u540c\u65f6\u9a8c\u8bc1\u4f4e\u7cbe\u5ea6\u548cGPU\u4f18\u5316\u5185\u6838\u662f\u5426\u5728\u4e0d\u635f\u5bb3\u7269\u7406\u4fdd\u771f\u5ea6\u4e0b\u5e26\u6765\u6027\u80fd\u63d0\u5347\u3002", "method": "\u5bf9MACE\u6a21\u578b\u8fdb\u884c\u7aef\u5230\u7aef\u53ca\u9010\u6a21\u5757\u6027\u80fd\u5256\u6790\uff0c\u6bd4\u8f83e3nn\u4e0eNVIDIA cuEquivariance\u5b9e\u73b0\uff0c\u8bc4\u4f30FP64/FP32/BF16/FP16\uff08FP32\u7d2f\u52a0\uff09\u7b49\u6570\u503c\u7cbe\u5ea6\u8bbe\u7f6e\uff0c\u57fa\u4e8e\u53ef\u590d\u73b0\u7684\u7a33\u6001\u8ba1\u65f6\u8fdb\u884c\u63a8\u7406\u3001\u77edNVT\u4e0e\u957fNPT\u6c34\u4f53\u7cfb\u6a21\u62df\u4ee5\u53ca\u7b80\u5355\u8bad\u7ec3\u4efb\u52a1\u7684\u6d4b\u91cf\u3002", "result": "cuEquivariance\u5c06\u63a8\u7406\u5ef6\u8fdf\u7ea6\u51cf\u5c113\u500d\uff1b\u5c06\u7ebf\u6027\u5c42\u7f6e\u4e3aBF16/FP16\uff08\u6a21\u578b\u5176\u4f59\u4fdd\u6301FP32\uff09\u53ef\u518d\u5e26\u6765\u7ea64\u500d\u52a0\u901f\uff1b\u5728NVT/NPT MD\u4e2d\u80fd\u91cf\u4e0e\u70ed\u529b\u5b66\u89c2\u6d4b\u91cf\u4fdd\u6301\u5728\u8fd0\u884c\u95f4\u53d8\u5f02\u8303\u56f4\u5185\uff1b\u8bad\u7ec3\u65f6\u82e5\u4f7f\u7528\u534a\u7cbe\u5ea6\u6743\u91cd\u4f1a\u5bfc\u81f4\u529bRMSE\u6076\u5316\uff1b\u6df7\u5408\u4f7f\u7528e3nn\u4e0ecuEq\u6a21\u5757\u4f1a\u56e0\u8868\u793a\u4e0d\u5339\u914d\u4ea7\u751f\u95ee\u9898\u3002", "conclusion": "\u5728\u4fdd\u6301\u7269\u7406\u7cbe\u5ea6\u524d\u63d0\u4e0b\uff0c\u901a\u8fc7\u4f7f\u7528GPU\u4e13\u7528\u540e\u7aef\u548c\u6df7\u5408\u4f4e\u7cbe\u5ea6\u6570\u503c\u7b56\u7565\uff0c\u80fd\u663e\u8457\u52a0\u901fSO(3)-\u7b49\u53d8\u529b\u573a\uff08\u4ee5MACE\u4e3a\u4f8b\uff09\u7684\u63a8\u7406\u4e0eMD\u6a21\u62df\u3002\u8bad\u7ec3\u9636\u6bb5\u4ecd\u5efa\u8bae\u4fdd\u7559FP32\u4ee5\u907f\u514d\u529b\u8bef\u5dee\u6076\u5316\u3002"}}
{"id": "2510.23643", "categories": ["cs.CR", "cs.AI", "cs.LG", "I.2.6; D.4.6"], "pdf": "https://arxiv.org/pdf/2510.23643", "abs": "https://arxiv.org/abs/2510.23643", "authors": ["Zhixin Pan", "Ziyu Shu", "Linh Nguyen", "Amberbir Alemayoh"], "title": "SAND: A Self-supervised and Adaptive NAS-Driven Framework for Hardware Trojan Detection", "comment": null, "summary": "The globalized semiconductor supply chain has made Hardware Trojans (HT) a\nsignificant security threat to embedded systems, necessitating the design of\nefficient and adaptable detection mechanisms. Despite promising machine\nlearning-based HT detection techniques in the literature, they suffer from ad\nhoc feature selection and the lack of adaptivity, all of which hinder their\neffectiveness across diverse HT attacks. In this paper, we propose SAND, a\nselfsupervised and adaptive NAS-driven framework for efficient HT detection.\nSpecifically, this paper makes three key contributions. (1) We leverage\nself-supervised learning (SSL) to enable automated feature extraction,\neliminating the dependency on manually engineered features. (2) SAND integrates\nneural architecture search (NAS) to dynamically optimize the downstream\nclassifier, allowing for seamless adaptation to unseen benchmarks with minimal\nfine-tuning. (3) Experimental results show that SAND achieves a significant\nimprovement in detection accuracy (up to 18.3%) over state-of-the-art methods,\nexhibits high resilience against evasive Trojans, and demonstrates strong\ngeneralization.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51faSAND\uff0c\u4e00\u79cd\u7ed3\u5408\u81ea\u76d1\u7763\u5b66\u4e60\u548c\u795e\u7ecf\u7ed3\u6784\u641c\u7d22\u7684\u786c\u4ef6\u6728\u9a6c\u68c0\u6d4b\u6846\u67b6\uff0c\u81ea\u52a8\u63d0\u53d6\u7279\u5f81\u5e76\u81ea\u9002\u5e94\u4f18\u5316\u5206\u7c7b\u5668\uff0c\u4ee5\u63d0\u9ad8\u68c0\u6d4b\u51c6\u786e\u7387\u548c\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u786c\u4ef6\u6728\u9a6c\u68c0\u6d4b\u4f9d\u8d56\u624b\u5de5\u7279\u5f81\u4e14\u7f3a\u4e4f\u81ea\u9002\u5e94\u6027\uff0c\u5bfc\u81f4\u5bf9\u4e0d\u540c\u6728\u9a6c\u653b\u51fb\u6548\u679c\u4e0d\u7a33\uff0c\u9700\u4e00\u79cd\u81ea\u52a8\u5316\u3001\u53ef\u8fc1\u79fb\u548c\u9c81\u68d2\u7684\u68c0\u6d4b\u6846\u67b6\u3002", "method": "\u5148\u7528\u81ea\u76d1\u7763\u5b66\u4e60\u5728\u5927\u91cf\u672a\u6807\u6ce8\u786c\u4ef6\u6570\u636e\u4e0a\u9884\u8bad\u7ec3\u7f16\u7801\u5668\u4ee5\u81ea\u52a8\u5b66\u4e60\u8868\u5f81\uff1b\u518d\u7528\u795e\u7ecf\u7ed3\u6784\u641c\u7d22\u5728\u76ee\u6807\u6570\u636e\u96c6\u4e0a\u641c\u7d22\u5e76\u5fae\u8c03\u4e0b\u6e38\u5206\u7c7b\u5668\u67b6\u6784\uff0c\u8fbe\u5230\u6700\u4f18\u5206\u7c7b\u6027\u80fd\uff1b\u6700\u540e\u5728\u6d4b\u8bd5\u96c6\u4e0a\u4e0e\u73b0\u6709\u65b9\u6cd5\u6bd4\u8f83\u5e76\u8fdb\u884c\u89c4\u907f\u653b\u51fb\u4e0e\u6cdb\u5316\u6027\u8bc4\u4f30\u3002", "result": "\u5b9e\u9a8c\u663e\u793aSAND\u5728\u591a\u4e2a\u57fa\u51c6\u4e0a\u5c06\u68c0\u6d4b\u7cbe\u5ea6\u6700\u591a\u63d0\u534718.3%\uff0c\u5728\u9762\u5bf9\u89c4\u907f\u7b56\u7565\u65f6\u6027\u80fd\u4e0b\u964d\u8f83\u5c0f\uff0c\u5e76\u5728\u65b0\u57fa\u51c6\u4e0a\u6709\u826f\u597d\u6cdb\u5316\u8868\u73b0\u3002", "conclusion": "SAND\u901a\u8fc7SSL\u81ea\u52a8\u62bd\u53d6\u9c81\u68d2\u7279\u5f81\u5e76\u501f\u52a9NAS\u5bf9\u4e0b\u6e38\u5206\u7c7b\u5668\u7ed3\u6784\u8fdb\u884c\u52a8\u6001\u4f18\u5316\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u786c\u4ef6\u6728\u9a6c\u68c0\u6d4b\u6027\u80fd\uff08\u6700\u5927\u63d0\u534718.3%\uff09\uff0c\u5bf9\u89c4\u907f\u653b\u51fb\u5177\u5907\u8f83\u5f3a\u9c81\u68d2\u6027\u4e14\u80fd\u5f88\u597d\u6cdb\u5316\u5230\u672a\u89c1\u57fa\u51c6\u3002"}}
{"id": "2510.23734", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23734", "abs": "https://arxiv.org/abs/2510.23734", "authors": ["Eamon Duede"], "title": "AI and the Decentering of Disciplinary Creativity", "comment": null, "summary": "This paper examines the role of artificial intelligence in scientific\nproblem-solving, with a focus on its implications for disciplinary creativity.\nDrawing on recent work in the philosophy of creativity, I distinguish between\ncreative approaches and creative products, and introduce the concept of\ndisciplinary creativity -the creative application of discipline-specific\nexpertise to a valued problem within that field. Through two cases in\nmathematics, I show that while computation can extend disciplinary creativity,\ncertain approaches involving AI can serve to displace it. This displacement has\nthe potential to alter (and, perhaps, diminish) the value of scientific\npursuit.", "AI": {"tldr": "\u7814\u7a76\u8868\u660eAI\u4e00\u65b9\u9762\u80fd\u589e\u5f3a\u5b66\u79d1\u5185\u90e8\u7684\u521b\u9020\u6027\u5b9e\u8df5\uff0c\u53e6\u4e00\u65b9\u9762\u67d0\u4e9bAI\u4ecb\u5165\u53ef\u80fd\u66ff\u4ee3\u4eba\u7c7b\u7684\u5b66\u79d1\u521b\u9020\u529b\uff0c\u5f71\u54cd\u79d1\u5b66\u4ef7\u503c\u3002", "motivation": "\u63a2\u8ba8\u4eba\u5de5\u667a\u80fd\u5728\u79d1\u5b66\u95ee\u9898\u89e3\u51b3\u4e2d\u7684\u4f5c\u7528\u53ca\u5176\u5bf9\u5b66\u79d1\u7279\u6709\u521b\u9020\u529b\u4e0e\u5b66\u672f\u4ef7\u503c\u7684\u5f71\u54cd\u3002", "method": "\u57fa\u4e8e\u521b\u9020\u529b\u54f2\u5b66\uff0c\u5c06\u521b\u9020\u6027\u65b9\u6cd5\u4e0e\u521b\u9020\u6027\u4ea7\u7269\u533a\u5206\uff0c\u5e76\u63d0\u51fa\u201c\u5b66\u79d1\u521b\u9020\u529b\u201d\u6982\u5ff5\u3002\u901a\u8fc7\u6570\u5b66\u9886\u57df\u7684\u4e24\u4e2a\u6848\u4f8b\u5206\u6790AI\u5982\u4f55\u6269\u5c55\u6216\u7f6e\u6362\u8be5\u521b\u9020\u529b\u3002", "result": "\u8bc1\u660e\u8ba1\u7b97\u53ef\u4ee5\u6269\u5c55\u5b66\u79d1\u521b\u9020\u529b\uff0c\u4f46\u67d0\u4e9bAI\u65b9\u6cd5\u4f1a\u7f6e\u6362\u5b83\uff0c\u4ece\u800c\u53ef\u80fd\u964d\u4f4e\u79d1\u5b66\u6d3b\u52a8\u7684\u4ef7\u503c\u3002", "conclusion": "\u4eba\u5de5\u667a\u80fd\u65e2\u80fd\u6269\u5c55\u4e5f\u80fd\u7f6e\u6362\u5b66\u79d1\u521b\u9020\u529b\uff0c\u53ef\u80fd\u6539\u53d8\u79d1\u5b66\u8ffd\u6c42\u7684\u4ef7\u503c\u3002"}}
{"id": "2510.24205", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.24205", "abs": "https://arxiv.org/abs/2510.24205", "authors": ["Telmo Ribeiro", "Jos\u00e9 Proen\u00e7a", "M\u00e1rio Florido"], "title": "CoMPSeT: A Framework for Comparing Multiparty Session Types", "comment": "In Proceedings EXPRESS/SOS 2025, arXiv:2510.23211", "summary": "Concurrent systems are often complex and difficult to design. Choreographic\nlanguages, such as Multiparty Session Types (MPST), allow the description of\nglobal protocols of interactions by capturing valid patterns of interactions\nbetween participants. Many variations of MPST exist, each one with its rather\nspecific features and idiosyncrasies. Here we propose a tool (CoMPSeT) that\nprovides clearer insights over different features in existing MPST. We select a\nrepresentative set of MPST examples and provide mechanisms to combine different\nfeatures and to animate and compare the semantics of concrete examples. CoMPSeT\nis open-source, compiled into JavaScript, and can be directly executed from any\nbrowser, becoming useful both for researchers who want to better understand the\nlandscape of MPST and for teachers who want to explain global choreographies.", "AI": {"tldr": "CoMPSeT: a browser-based, open-source tool that animates and composes MPST examples to clarify and compare semantics of different MPST variants.", "motivation": "MPST variants are numerous and idiosyncratic; designers and learners need clearer insights and interactive ways to compare and teach global choreographies.", "method": "Select representative MPST examples; provide mechanisms to combine features; animate and compare semantics of examples; implement tool in JavaScript as open-source browser app.", "result": "A tool (CoMPSeT) for exploring and comparing features of Multiparty Session Types (MPST) by animating and combining representative examples; open-source, runs in browser (compiled to JavaScript); useful for researchers and teachers.", "conclusion": "CoMPSeT effectively aids understanding of MPST variant features by enabling interactive combination, animation, and semantic comparison of concrete choreographies."}}
{"id": "2510.23622", "categories": ["cs.LG", "cs.CR"], "pdf": "https://arxiv.org/pdf/2510.23622", "abs": "https://arxiv.org/abs/2510.23622", "authors": ["Alyssa Gerhart", "Balaji Iyangar"], "title": "Adversarially-Aware Architecture Design for Robust Medical AI Systems", "comment": null, "summary": "Adversarial attacks pose a severe risk to AI systems used in healthcare,\ncapable of misleading models into dangerous misclassifications that can delay\ntreatments or cause misdiagnoses. These attacks, often imperceptible to human\nperception, threaten patient safety, particularly in underserved populations.\nOur study explores these vulnerabilities through empirical experimentation on a\ndermatological dataset, where adversarial methods significantly reduce\nclassification accuracy. Through detailed threat modeling, experimental\nbenchmarking, and model evaluation, we demonstrate both the severity of the\nthreat and the partial success of defenses like adversarial training and\ndistillation. Our results show that while defenses reduce attack success rates,\nthey must be balanced against model performance on clean data. We conclude with\na call for integrated technical, ethical, and policy-based approaches to build\nmore resilient, equitable AI in healthcare.", "AI": {"tldr": "Paper empirically shows adversarial attacks threaten dermatology AI, defenses help partly but harm clean accuracy; calls for combined technical, ethical, policy solutions", "motivation": "To assess vulnerability of healthcare AI (dermatology) to adversarial attacks and evaluate defenses, highlighting patient safety and equity concerns", "method": "Empirical experimentation with adversarial attacks on dermatology images, threat modeling, benchmarking defenses (adversarial training, distillation)", "result": "Adversarial attacks significantly reduce classification accuracy; defenses (adversarial training, distillation) partially mitigate attacks but trade off clean-data performance", "conclusion": "Defenses reduce attack success but require balancing robustness and accuracy; integrated technical, ethical, and policy measures needed for resilient, equitable healthcare AI"}}
{"id": "2510.23673", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23673", "abs": "https://arxiv.org/abs/2510.23673", "authors": ["Bin Wang", "Zexin Liu", "Hao Yu", "Ao Yang", "Yenan Huang", "Jing Guo", "Huangsheng Cheng", "Hui Li", "Huiyu Wu"], "title": "MCPGuard : Automatically Detecting Vulnerabilities in MCP Servers", "comment": null, "summary": "The Model Context Protocol (MCP) has emerged as a standardized interface\nenabling seamless integration between Large Language Models (LLMs) and external\ndata sources and tools. While MCP significantly reduces development complexity\nand enhances agent capabilities, its openness and extensibility introduce\ncritical security vulnerabilities that threaten system trustworthiness and user\ndata protection. This paper systematically analyzes the security landscape of\nMCP-based systems, identifying three principal threat categories: (1) agent\nhijacking attacks stemming from protocol design deficiencies; (2) traditional\nweb vulnerabilities in MCP servers; and (3) supply chain security. To address\nthese challenges, we comprehensively survey existing defense strategies,\nexamining both proactive server-side scanning approaches, ranging from layered\ndetection pipelines and agentic auditing frameworks to zero-trust registry\nsystems, and runtime interaction monitoring solutions that provide continuous\noversight and policy enforcement. Our analysis reveals that MCP security\nfundamentally represents a paradigm shift where the attack surface extends from\ntraditional code execution to semantic interpretation of natural language\nmetadata, necessitating novel defense mechanisms tailored to this unique threat\nmodel.", "AI": {"tldr": "MCP\u6269\u5c55\u4e86\u653b\u51fb\u9762\uff0c\u4ece\u4ee3\u7801\u6267\u884c\u5ef6\u4f38\u5230\u81ea\u7136\u8bed\u8a00\u5143\u6570\u636e\u7684\u8bed\u4e49\u89e3\u91ca\uff0c\u5e26\u6765\u4ee3\u7406\u52ab\u6301\u3001\u670d\u52a1\u5668\u6f0f\u6d1e\u548c\u4f9b\u5e94\u94fe\u98ce\u9669\u7b49\u5b89\u5168\u95ee\u9898\uff1b\u9700\u7ed3\u5408\u670d\u52a1\u5668\u7aef\u68c0\u6d4b\u548c\u8fd0\u884c\u65f6\u76d1\u63a7\u7b49\u65b0\u578b\u9632\u62a4\u63aa\u65bd\u3002", "motivation": "MCP\u4f5c\u4e3a\u8fde\u63a5LLM\u4e0e\u5916\u90e8\u5de5\u5177\u7684\u6570\u636e\u4ea4\u6362\u534f\u8bae\uff0c\u5176\u5f00\u653e\u6027\u4e0e\u53ef\u6269\u5c55\u6027\u867d\u63d0\u9ad8\u5f00\u53d1\u4fbf\u5229\u6027\uff0c\u5374\u5f15\u5165\u65b0\u578b\u5b89\u5168\u98ce\u9669\uff0c\u8feb\u5207\u9700\u8981\u7cfb\u7edf\u6027\u5b89\u5168\u5206\u6790\u4e0e\u9632\u62a4\u65b9\u6cd5\u3002", "method": "\u672c\u6587\u901a\u8fc7\u7cfb\u7edf\u6027\u5a01\u80c1\u5efa\u6a21\u3001\u5206\u7c7b\u73b0\u6709\u653b\u51fb\u573a\u666f\u3001\u68b3\u7406\u4e0e\u8bc4\u4f30\u73b0\u6709\u9632\u5fa1\u65b9\u6848\uff08\u5305\u62ec\u5206\u5c42\u68c0\u6d4b\u6d41\u6c34\u7ebf\u3001\u57fa\u4e8eagent\u7684\u5ba1\u8ba1\u6846\u67b6\u3001\u96f6\u4fe1\u4efb\u6ce8\u518c\u8868\u4ee5\u53ca\u8fd0\u884c\u65f6\u4ea4\u4e92\u76d1\u63a7\uff09\uff0c\u5e76\u4ece\u8bed\u4e49\u653b\u51fb\u89d2\u5ea6\u63d0\u51fa\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "result": "This paper identifies security vulnerabilities in MCP-based systems and categorizes threats into agent hijacking, web vulnerabilities, and supply chain risks. It surveys defense strategies including server-side scanning, layered detection pipelines, agentic auditing, zero-trust registries, and runtime monitoring; emphasizes the need for novel defenses due to semantic attack surface expansion.", "conclusion": "MCP\u5b89\u5168\u662f\u65b0\u8303\u5f0f\uff0c\u9700\u5f00\u53d1\u9488\u5bf9\u8bed\u4e49\u5c42\u9762\u653b\u51fb\u7684\u68c0\u6d4b\u4e0e\u9632\u5fa1\u673a\u5236\uff0c\u7ed3\u5408\u9884\u9632\u6027\u5ba1\u67e5\uff08\u6ce8\u518c\u8868\u4e0e\u626b\u63cf\uff09\u4e0e\u6301\u7eed\u7684\u8fd0\u884c\u65f6\u7b56\u7565\u6267\u884c\u4ee5\u4fdd\u969c\u7528\u6237\u6570\u636e\u4e0e\u7cfb\u7edf\u5b8c\u6574\u6027\u3002"}}
{"id": "2510.23744", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23744", "abs": "https://arxiv.org/abs/2510.23744", "authors": ["Eline M. Bovy", "Caleb Probine", "Marnix Suilen", "Ufuk Topcu", "Nils Jansen"], "title": "Multi-Environment POMDPs: Discrete Model Uncertainty Under Partial Observability", "comment": "Accepted at NeurIPS 2025", "summary": "Multi-environment POMDPs (ME-POMDPs) extend standard POMDPs with discrete\nmodel uncertainty. ME-POMDPs represent a finite set of POMDPs that share the\nsame state, action, and observation spaces, but may arbitrarily vary in their\ntransition, observation, and reward models. Such models arise, for instance,\nwhen multiple domain experts disagree on how to model a problem. The goal is to\nfind a single policy that is robust against any choice of POMDP within the set,\ni.e., a policy that maximizes the worst-case reward across all POMDPs. We\ngeneralize and expand on existing work in the following way. First, we show\nthat ME-POMDPs can be generalized to POMDPs with sets of initial beliefs, which\nwe call adversarial-belief POMDPs (AB-POMDPs). Second, we show that any\narbitrary ME-POMDP can be reduced to a ME-POMDP that only varies in its\ntransition and reward functions or only in its observation and reward\nfunctions, while preserving (optimal) policies. We then devise exact and\napproximate (point-based) algorithms to compute robust policies for AB-POMDPs,\nand thus ME-POMDPs. We demonstrate that we can compute policies for standard\nPOMDP benchmarks extended to the multi-environment setting.", "AI": {"tldr": "\u63d0\u51fa\u5c06ME-POMDP\u63a8\u5e7f\u5230\u5bf9\u6297\u6027\u521d\u59cb\u4fe1\u5ff5\u7684AB-POMDP\uff0c\u7ed9\u51fa\u6a21\u578b\u7b80\u5316\u7684\u5f52\u7ea6\uff0c\u5e76\u8bbe\u8ba1\u4e86\u7cbe\u786e\u4e0e\u57fa\u4e8e\u70b9\u7684\u8fd1\u4f3c\u7b97\u6cd5\u4ee5\u8ba1\u7b97\u5bf9\u6297\u9c81\u68d2\u7b56\u7565\uff0c\u4e14\u5728\u57fa\u51c6\u4e0a\u9a8c\u8bc1\u53ef\u884c\u6027\u3002", "motivation": "Address model uncertainty in POMDPs where multiple models exist; find policies robust to worst-case environment.", "method": "\u7406\u8bba\u5f52\u7ea6\u8bc1\u660e\u4e0e\u7b97\u6cd5\u8bbe\u8ba1\uff1a\u5c06ME-POMDP\u5f52\u7ea6\u4e3a\u53ea\u53d8\u52a8\u8f6c\u79fb/\u5956\u52b1\u6216\u53ea\u53d8\u52a8\u89c2\u6d4b/\u5956\u52b1\u7684\u60c5\u5f62\uff1b\u57fa\u4e8e\u503c\u8fed\u4ee3\u7684\u7cbe\u786e\u89e3\u6cd5\u4e0e\u57fa\u4e8e\u70b9\u7684\u8fd1\u4f3c\uff08point-based\uff09\u65b9\u6cd5\u8fdb\u884c\u6c42\u89e3\u3002", "result": "Introduced AB-POMDPs; reductions showing ME-POMDPs can be limited to varying only transitions/rewards or observations/rewards; developed exact and point-based approximate algorithms to compute robust policies; demonstrated on benchmarks.", "conclusion": "AB-POMDP\u4e3a\u5904\u7406\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u63d0\u4f9b\u4e86\u7b49\u4ef7\u4e14\u66f4\u4e00\u822c\u7684\u8868\u8ff0\uff1b\u7b97\u6cd5\u80fd\u6c42\u89e3\u6216\u8fd1\u4f3c\u6c42\u89e3\u9c81\u68d2\u7b56\u7565\uff1b\u6a21\u578b\u53ef\u7b80\u5316\u4ee5\u51cf\u5c11\u590d\u6742\u6027\u4e14\u4fdd\u7559\u6700\u4f18\u7b56\u7565\u3002"}}
{"id": "2510.24452", "categories": ["cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24452", "abs": "https://arxiv.org/abs/2510.24452", "authors": ["Xi Cheng", "Weijie Shen", "Haoming Chen", "Chaoyi Shen", "Jean Ortega", "Jiashang Liu", "Steve Thomas", "Honglin Zheng", "Haoyun Wu", "Yuxiang Li", "Casey Lichtendahl", "Jenny Ortiz", "Gang Liu", "Haiyang Qi", "Omid Fatemieh", "Chris Fry", "Jing Jing Long"], "title": "ARIMA_PLUS: Large-scale, Accurate, Automatic and Interpretable In-Database Time Series Forecasting and Anomaly Detection in Google BigQuery", "comment": null, "summary": "Time series forecasting and anomaly detection are common tasks for\npractitioners in industries such as retail, manufacturing, advertising and\nenergy. Two unique challenges stand out: (1) efficiently and accurately\nforecasting time series or detecting anomalies in large volumes automatically;\nand (2) ensuring interpretability of results to effectively incorporate\nbusiness insights. We present ARIMA_PLUS, a novel framework to overcome these\ntwo challenges by a unique combination of (a) accurate and interpretable time\nseries models and (b) scalable and fully managed system infrastructure. The\nmodel has a sequential and modular structure to handle different components of\nthe time series, including holiday effects, seasonality, trend, and anomalies,\nwhich enables high interpretability of the results. Novel enhancements are made\nto each module, and a unified framework is established to address both\nforecasting and anomaly detection tasks simultaneously. In terms of accuracy,\nits comprehensive benchmark on the 42 public datasets in the Monash forecasting\nrepository shows superior performance over not only well-established\nstatistical alternatives (such as ETS, ARIMA, TBATS, Prophet) but also newer\nneural network models (such as DeepAR, N-BEATS, PatchTST, TimeMixer). In terms\nof infrastructure, it is directly built into the query engine of BigQuery in\nGoogle Cloud. It uses a simple SQL interface and automates tedious\ntechnicalities such as data cleaning and model selection. It automatically\nscales with managed cloud computational and storage resources, making it\npossible to forecast 100 million time series using only 1.5 hours with a\nthroughput of more than 18000 time series per second. In terms of\ninterpretability, we present several case studies to demonstrate time series\ninsights it generates and customizability it offers.", "AI": {"tldr": "ARIMA_PLUS is a sequential, modular time series framework combining interpretable component models (holiday, seasonality, trend, anomalies) with scalable BigQuery integration, achieving superior accuracy to statistical and neural baselines and enabling massive parallel forecasting with high throughput and interpretability.", "motivation": "Need for accurate, interpretable, and scalable forecasting and anomaly detection for large volumes of time series in industry", "method": "Sequential modular ARIMA-like framework integrated with cloud infrastructure", "result": "Outperforms classical and neural models on Monash benchmark; scales to 100M series in 1.5 hours in BigQuery; provides interpretable component-level outputs", "conclusion": "ARIMA_PLUS successfully balances accuracy, interpretability, and scalability by modular modeling and managed cloud deployment, making it practical for large-scale industrial forecasting and anomaly detection."}}
{"id": "2510.23624", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.23624", "abs": "https://arxiv.org/abs/2510.23624", "authors": ["Tiago Mendon\u00e7a dos Santos", "Rafael Izbicki", "Lu\u00eds Gustavo Esteves"], "title": "DiNo and RanBu: Lightweight Predictions from Shallow Random Forests", "comment": null, "summary": "Random Forest ensembles are a strong baseline for tabular prediction tasks,\nbut their reliance on hundreds of deep trees often results in high inference\nlatency and memory demands, limiting deployment in latency-sensitive or\nresource-constrained environments. We introduce DiNo (Distance with Nodes) and\nRanBu (Random Bushes), two shallow-forest methods that convert a small set of\ndepth-limited trees into efficient, distance-weighted predictors. DiNo measures\ncophenetic distances via the most recent common ancestor of observation pairs,\nwhile RanBu applies kernel smoothing to Breiman's classical proximity measure.\nBoth approaches operate entirely after forest training: no additional trees are\ngrown, and tuning of the single bandwidth parameter $h$ requires only\nlightweight matrix-vector operations. Across three synthetic benchmarks and 25\npublic datasets, RanBu matches or exceeds the accuracy of full-depth random\nforests-particularly in high-noise settings-while reducing training plus\ninference time by up to 95\\%. DiNo achieves the best bias-variance trade-off in\nlow-noise regimes at a modest computational cost. Both methods extend directly\nto quantile regression, maintaining accuracy with substantial speed gains. The\nimplementation is available as an open-source R/C++ package at\nhttps://github.com/tiagomendonca/dirf. We focus on structured tabular random\nsamples (i.i.d.), leaving extensions to other modalities for future work.", "AI": {"tldr": "\u63d0\u51fa\u4e24\u79cd\u540e\u5904\u7406\u6d45\u5c42\u968f\u673a\u68ee\u6797\u65b9\u6cd5\uff08DiNo\u3001RanBu\uff09\uff0c\u7528\u6811\u7ed3\u6784\u8ddd\u79bb\u6216\u6838\u5e73\u6ed1\u63a5\u8fd1\u5ea6\u66ff\u4ee3\u6210\u767e\u4e0a\u5343\u68f5\u6df1\u6811\uff0c\u4fdd\u6301\u6216\u63d0\u5347\u7cbe\u5ea6\u540c\u65f6\u5927\u5e45\u964d\u4f4e\u5ef6\u8fdf\u4e0e\u5185\u5b58\uff1b\u53ea\u9700\u8bad\u7ec3\u540e\u64cd\u4f5c\u5e76\u8c03\u8282\u5355\u4e00\u5e26\u5bbd\u53c2\u6570h\u3002", "motivation": "\u51cf\u5c11\u968f\u673a\u68ee\u6797\u5728\u5ef6\u8fdf\u654f\u611f\u6216\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u7684\u63a8\u7406\u65f6\u5ef6\u548c\u5185\u5b58\u5f00\u9500\uff0c\u540c\u65f6\u5c3d\u91cf\u4fdd\u6301\u6216\u63d0\u5347\u9884\u6d4b\u7cbe\u5ea6\uff0c\u5c24\u5176\u5e0c\u671b\u5728\u9ad8\u566a\u58f0\u6570\u636e\u4e0b\u7528\u6d45\u6811\u96c6\u5408\u66ff\u4ee3\u5927\u91cf\u6df1\u6811\u8fbe\u5230\u66f4\u5feb\u66f4\u5c0f\u7684\u6a21\u578b\u3002", "method": "\u8bad\u7ec3\u5e38\u89c4\u6a21\u578b\uff1a\u5148\u8bad\u7ec3\u5c0f\u89c4\u6a21\u3001\u6df1\u5ea6\u53d7\u9650\u7684\u968f\u673a\u68ee\u6797\uff1b\u5728\u9884\u6d4b\u9636\u6bb5\u4e0d\u518d\u751f\u957f\u65b0\u6811\uff0c\u800c\u662f\u57fa\u4e8e\u6811\u53f6\u8282\u70b9\u4fe1\u606f\u6784\u5efa\u89c2\u5bdf\u95f4\u8ddd\u79bb\u6216\u63a5\u8fd1\u5ea6\u77e9\u9635\uff1aDiNo\u8ba1\u7b97\u901a\u8fc7\u6700\u8fd1\u516c\u5171\u7956\u5148\u7684cophenetic\u8ddd\u79bb\u5e76\u505a\u8ddd\u79bb\u52a0\u6743\u9884\u6d4b\uff1bRanBu\u5c06Breiman\u7684proximity\u77e9\u9635\u7528\u6838\u51fd\u6570\uff08\u5e26\u5bbdh\uff09\u5e73\u6ed1\uff0c\u5f97\u5230\u52a0\u6743\u9884\u6d4b\uff1b\u5e26\u5bbdh\u901a\u8fc7\u8f7b\u91cf\u7ea7\u77e9\u9635-\u5411\u91cf\u64cd\u4f5c\u8c03\u53c2\u3002", "result": "\u63d0\u51fa\u4e86\u4e24\u79cd\u6d45\u5c42\u68ee\u6797\u540e\u5904\u7406\u65b9\u6cd5DiNo\u548cRanBu\uff0c\u5c06\u5c11\u91cf\u6df1\u5ea6\u53d7\u9650\u7684\u6811\u8f6c\u4e3a\u9ad8\u6548\u7684\u8ddd\u79bb\u52a0\u6743\u9884\u6d4b\u5668\uff1bDiNo\u57fa\u4e8e\u89c2\u5bdf\u5bf9\u6700\u8fd1\u516c\u5171\u7956\u5148\u7684cophenetic\u8ddd\u79bb\uff0cRanBu\u5bf9Breiman\u63a5\u8fd1\u5ea6\u505a\u6838\u5e73\u6ed1\uff1b\u4e24\u65b9\u6cd5\u4ec5\u5728\u8bad\u7ec3\u540e\u64cd\u4f5c\uff0c\u53ea\u6709\u5355\u4e00\u5e26\u5bbd\u53c2\u6570h\u9700\u8c03\u8282\uff1b\u5728\u5408\u6210\u548c25\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u4e0aRanBu\u5728\u9ad8\u566a\u58f0\u4e0b\u80fd\u5339\u914d\u6216\u8d85\u8d8a\u5168\u6df1\u5ea6\u968f\u673a\u68ee\u6797\u5e76\u663e\u8457\u964d\u4f4e\u8bad\u7ec3+\u63a8\u7406\u65f6\u95f4\uff0cDiNo\u5728\u4f4e\u566a\u58f0\u60c5\u5f62\u6709\u66f4\u4f18\u504f\u5dee-\u65b9\u5dee\u5e73\u8861\uff1b\u4e24\u8005\u53ef\u6269\u5c55\u5230\u5206\u4f4d\u6570\u56de\u5f52\uff1b\u5b9e\u73b0\u5f00\u6e90R/C++\u5305\u3002", "conclusion": "RanBu\u9002\u7528\u4e8e\u9ad8\u566a\u58f0\u573a\u666f\u80fd\u5728\u901f\u5ea6\u4e0e\u7cbe\u5ea6\u4e0a\u4f18\u4e8e\u5168\u6df1\u968f\u673a\u68ee\u6797\uff1bDiNo\u5728\u4f4e\u566a\u58f0\u573a\u666f\u63d0\u4f9b\u66f4\u597d\u7684\u504f\u5dee-\u65b9\u5dee\u6743\u8861\u3002\u4e24\u65b9\u6cd5\u5747\u80fd\u663e\u8457\u51cf\u5c11\u8ba1\u7b97\u8d44\u6e90\u5e76\u652f\u6301\u5206\u4f4d\u6570\u56de\u5f52\uff0c\u9002\u5408i.i.d.\u8868\u683c\u6570\u636e\u3002"}}
{"id": "2510.23675", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23675", "abs": "https://arxiv.org/abs/2510.23675", "authors": ["Yuchong Xie", "Zesen Liu", "Mingyu Luo", "Zhixiang Zhang", "Kaikai Zhang", "Zongjie Li", "Ping Chen", "Shuai Wang", "Dongdong She"], "title": "QueryIPI: Query-agnostic Indirect Prompt Injection on Coding Agents", "comment": null, "summary": "Modern coding agents integrated into IDEs combine powerful tools and\nsystem-level actions, exposing a high-stakes attack surface. Existing Indirect\nPrompt Injection (IPI) studies focus mainly on query-specific behaviors,\nleading to unstable attacks with lower success rates. We identify a more\nsevere, query-agnostic threat that remains effective across diverse user\ninputs. This challenge can be overcome by exploiting a common vulnerability:\nleakage of the agent's internal prompt, which turns the attack into a\nconstrained white-box optimization problem. We present QueryIPI, the first\nquery-agnostic IPI method for coding agents. QueryIPI refines malicious tool\ndescriptions through an iterative, prompt-based process informed by the leaked\ninternal prompt. Experiments on five simulated agents show that QueryIPI\nachieves up to 87 percent success, outperforming baselines, and the generated\nmalicious descriptions also transfer to real-world systems, highlighting a\npractical security risk to modern LLM-based coding agents.", "AI": {"tldr": "QueryIPI is a query-agnostic IPI attack that uses leaked internal prompts to iteratively craft malicious tool descriptions, achieving high success and transferability.", "motivation": "Existing IPI attacks are query-specific and unstable; need a query-agnostic method exploiting internal prompt leakage to make attacks robust across inputs.", "method": "Query-based white-box optimization of tool descriptions", "result": "QueryIPI refines malicious tool descriptions iteratively using leaked internal prompt, achieving up to 87% success on five simulated agents and transferring to real-world systems.", "conclusion": "Leakage of internal prompts enables high-success, query-agnostic IPI attacks on coding agents; defenses must prevent prompt leakage and harden tool description handling."}}
{"id": "2510.23746", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.23746", "abs": "https://arxiv.org/abs/2510.23746", "authors": ["Laura Mismetti", "Marvin Alberts", "Andreas Krause", "Mara Graziani"], "title": "Test-Time Tuned Language Models Enable End-to-end De Novo Molecular Structure Generation from MS/MS Spectra", "comment": null, "summary": "Tandem Mass Spectrometry enables the identification of unknown compounds in\ncrucial fields such as metabolomics, natural product discovery and\nenvironmental analysis. However, current methods rely on database matching from\npreviously observed molecules, or on multi-step pipelines that require\nintermediate fragment or fingerprint prediction. This makes finding the correct\nmolecule highly challenging, particularly for compounds absent from reference\ndatabases. We introduce a framework that, by leveraging test-time tuning,\nenhances the learning of a pre-trained transformer model to address this gap,\nenabling end-to-end de novo molecular structure generation directly from the\ntandem mass spectra and molecular formulae, bypassing manual annotations and\nintermediate steps. We surpass the de-facto state-of-the-art approach DiffMS on\ntwo popular benchmarks NPLIB1 and MassSpecGym by 100% and 20%, respectively.\nTest-time tuning on experimental spectra allows the model to dynamically adapt\nto novel spectra, and the relative performance gain over conventional\nfine-tuning is of 62% on MassSpecGym. When predictions deviate from the ground\ntruth, the generated molecular candidates remain structurally accurate,\nproviding valuable guidance for human interpretation and more reliable\nidentification.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u9884\u8bad\u7ec3Transformer\u5e76\u7ed3\u5408test-time tuning\u7684\u7aef\u5230\u7aef\u4eceMS/MS\u4e0e\u5206\u5b50\u5f0f\u76f4\u63a5\u751f\u6210\u5206\u5b50\u7ed3\u6784\u7684\u65b9\u6cd5\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u7279\u522b\u80fd\u9002\u5e94\u5b9e\u9a8c\u8c31\u56fe", "motivation": "Overcome reliance on database matching and multi-step pipelines; enable de novo end-to-end structure generation from tandem MS and formula", "method": "Transformer with test-time tuning", "result": "Outperforms DiffMS by 100% on NPLIB1 and 20% on MassSpecGym; 62% gain of test-time tuning vs conventional fine-tuning on MassSpecGym; generated candidates remain structurally accurate even when incorrect", "conclusion": "Test-time tuning\u4f7f\u6a21\u578b\u80fd\u52a8\u6001\u9002\u914d\u65b0\u8c31\u56fe\uff0c\u63d0\u5347\u7ed3\u6784\u9884\u6d4b\u51c6\u786e\u6027\u5e76\u63d0\u4f9b\u6709\u7528\u7684\u7ed3\u6784\u5019\u9009\u7528\u4e8e\u4eba\u5de5\u5224\u65ad"}}
{"id": "2510.23931", "categories": ["cs.LG", "cs.CR", "cs.DC", "68T07 (Primary) 68M14, 68P27, 68Q32, 94A16, 62H35 (Secondary)", "I.2.11; I.2.6; C.2.4; D.4.6; K.4.1"], "pdf": "https://arxiv.org/pdf/2510.23931", "abs": "https://arxiv.org/abs/2510.23931", "authors": ["Miguel Fernandez-de-Retana", "Unai Zulaika", "Rub\u00e9n S\u00e1nchez-Corcuera", "Aitor Almeida"], "title": "Differential Privacy: Gradient Leakage Attacks in Federated Learning Environments", "comment": "17 pages, 12 figures", "summary": "Federated Learning (FL) allows for the training of Machine Learning models in\na collaborative manner without the need to share sensitive data. However, it\nremains vulnerable to Gradient Leakage Attacks (GLAs), which can reveal private\ninformation from the shared model updates. In this work, we investigate the\neffectiveness of Differential Privacy (DP) mechanisms - specifically, DP-SGD\nand a variant based on explicit regularization (PDP-SGD) - as defenses against\nGLAs. To this end, we evaluate the performance of several computer vision\nmodels trained under varying privacy levels on a simple classification task,\nand then analyze the quality of private data reconstructions obtained from the\nintercepted gradients in a simulated FL environment. Our results demonstrate\nthat DP-SGD significantly mitigates the risk of gradient leakage attacks,\nalbeit with a moderate trade-off in model utility. In contrast, PDP-SGD\nmaintains strong classification performance but proves ineffective as a\npractical defense against reconstruction attacks. These findings highlight the\nimportance of empirically evaluating privacy mechanisms beyond their\ntheoretical guarantees, particularly in distributed learning scenarios where\ninformation leakage may represent an unassumable critical threat to data\nsecurity and privacy.", "AI": {"tldr": "DP-SGD\u80fd\u6709\u6548\u7f13\u89e3\u68af\u5ea6\u91cd\u6784\u653b\u51fb\uff08\u6709\u7cbe\u5ea6\u4ee3\u4ef7\uff09\uff0cPDP-SGD\u4fdd\u7cbe\u5ea6\u4f46\u4e0d\u9632\u91cd\u6784\uff0c\u9700\u5728\u8054\u90a6\u5b66\u4e60\u4e2d\u5b9e\u8bc1\u8bc4\u4f30\u9690\u79c1\u673a\u5236\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u867d\u7136\u4e0d\u5171\u4eab\u539f\u59cb\u6570\u636e\uff0c\u4f46\u5171\u4eab\u7684\u68af\u5ea6\u4ecd\u53ef\u88ab\u7528\u4e8e\u91cd\u6784\u654f\u611f\u4fe1\u606f\u3002\u5c3d\u7ba1\u7406\u8bba\u4e0a\u5dee\u5206\u9690\u79c1\u80fd\u4fdd\u62a4\u9690\u79c1\uff0c\u9700\u5728\u5b9e\u9645\u5206\u5e03\u5f0f\u8bbe\u7f6e\u4e2d\u9a8c\u8bc1\u5176\u5bf9\u68af\u5ea6\u6cc4\u9732\u653b\u51fb\u7684\u5b9e\u6548\u6027\u3002", "method": "\u4f5c\u8005\u5728\u6a21\u62df\u8054\u90a6\u5b66\u4e60\u73af\u5883\u4e2d\uff0c\u5bf9\u6bd4\u4e86DP-SGD\u4e0ePDP-SGD\u4e24\u79cd\u5dee\u5206\u9690\u79c1\u673a\u5236\u3002\u5728\u4e0d\u540c\u9690\u79c1\u5f3a\u5ea6\uff08\u566a\u58f0\u548c\u88c1\u526a\u53c2\u6570\uff09\u4e0b\u8bad\u7ec3\u591a\u79cd\u8ba1\u7b97\u673a\u89c6\u89c9\u5206\u7c7b\u6a21\u578b\uff0c\u968f\u540e\u9488\u5bf9\u622a\u83b7\u7684\u68af\u5ea6\u6267\u884c\u91cd\u6784\u653b\u51fb\u4ee5\u8bc4\u4f30\u9690\u79c1\u6cc4\u9732\u7a0b\u5ea6\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff1a1\uff09DP-SGD\u5728\u591a\u6570\u8bbe\u7f6e\u4e0b\u80fd\u663e\u8457\u964d\u4f4e\u91cd\u6784\u56fe\u50cf\u8d28\u91cf\uff0c\u51cf\u8f7b\u4fe1\u606f\u6cc4\u9732\u98ce\u9669\uff0c\u4f46\u4f1a\u5bfc\u81f4\u4e00\u5b9a\u7684\u7cbe\u5ea6\u4e0b\u964d\uff1b2\uff09PDP-SGD\u5728\u4fdd\u6301\u6a21\u578b\u7cbe\u5ea6\u65b9\u9762\u8868\u73b0\u66f4\u597d\uff0c\u4f46\u5e76\u672a\u6709\u6548\u963b\u6b62\u57fa\u4e8e\u68af\u5ea6\u7684\u91cd\u6784\u653b\u51fb\uff1b3\uff09\u9700\u8981\u5728\u9690\u79c1\u4fdd\u62a4\u548c\u6a21\u578b\u6548\u7528\u4e4b\u95f4\u505a\u6743\u8861\uff0c\u5e76\u5f3a\u8c03\u4e86\u5bf9\u5b9e\u7528\u653b\u51fb\u7684\u7ecf\u9a8c\u8bc4\u4f30\u3002", "conclusion": "\u672c\u6587\u7ed3\u8bba\u662f\uff1aDP-SGD\u5728\u8054\u90a6\u5b66\u4e60\u573a\u666f\u4e0b\u80fd\u663e\u8457\u964d\u4f4e\u68af\u5ea6\u6cc4\u9732\u653b\u51fb\u6548\u679c\uff0c\u4f46\u4ee3\u4ef7\u662f\u9002\u5ea6\u7684\u6a21\u578b\u6027\u80fd\u4e0b\u964d\uff1b\u800c\u57fa\u4e8e\u663e\u5f0f\u6b63\u5219\u5316\u7684PDP-SGD\u5728\u4fdd\u6301\u8f83\u597d\u5206\u7c7b\u6027\u80fd\u7684\u540c\u65f6\uff0c\u5bf9\u62b5\u5fa1\u91cd\u6784\u653b\u51fb\u5b9e\u7528\u6027\u4e0d\u8db3\u3002"}}
{"id": "2510.23626", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.23626", "abs": "https://arxiv.org/abs/2510.23626", "authors": ["Shuang Geng", "Wenli Zhang", "Jiaheng Xie", "Rui Wang", "Sudha Ram"], "title": "From Detection to Discovery: A Closed-Loop Approach for Simultaneous and Continuous Medical Knowledge Expansion and Depression Detection on Social Media", "comment": "Presented at SWAIB2025 and HICSS2026", "summary": "Social media user-generated content (UGC) provides real-time, self-reported\nindicators of mental health conditions such as depression, offering a valuable\nsource for predictive analytics. While prior studies integrate medical\nknowledge to improve prediction accuracy, they overlook the opportunity to\nsimultaneously expand such knowledge through predictive processes. We develop a\nClosed-Loop Large Language Model (LLM)-Knowledge Graph framework that\nintegrates prediction and knowledge expansion in an iterative learning cycle.\nIn the knowledge-aware depression detection phase, the LLM jointly performs\ndepression detection and entity extraction, while the knowledge graph\nrepresents and weights these entities to refine prediction performance. In the\nknowledge refinement and expansion phase, new entities, relationships, and\nentity types extracted by the LLM are incorporated into the knowledge graph\nunder expert supervision, enabling continual knowledge evolution. Using\nlarge-scale UGC, the framework enhances both predictive accuracy and medical\nunderstanding. Expert evaluations confirmed the discovery of clinically\nmeaningful symptoms, comorbidities, and social triggers complementary to\nexisting literature. We conceptualize and operationalize\nprediction-through-learning and learning-through-prediction as mutually\nreinforcing processes, advancing both methodological and theoretical\nunderstanding in predictive analytics. The framework demonstrates the\nco-evolution of computational models and domain knowledge, offering a\nfoundation for adaptive, data-driven knowledge systems applicable to other\ndynamic risk monitoring contexts.", "AI": {"tldr": "\u63d0\u51fa\u95ed\u73afLLM-\u77e5\u8bc6\u56fe\u8c31\u6846\u67b6\uff0c\u5c06\u6291\u90c1\u9884\u6d4b\u4e0e\u77e5\u8bc6\u6269\u5c55\u8fed\u4ee3\u7ed3\u5408\uff0c\u5b9e\u73b0\u9884\u6d4b\u6027\u80fd\u4e0e\u533b\u5b66\u77e5\u8bc6\u5171\u540c\u6f14\u8fdb", "motivation": "\u73b0\u6709\u7814\u7a76\u4ec5\u5229\u7528\u533b\u5b66\u77e5\u8bc6\u6539\u8fdb\u9884\u6d4b\uff0c\u5374\u672a\u5229\u7528\u9884\u6d4b\u8fc7\u7a0b\u53bb\u6269\u5c55\u533b\u5b66\u77e5\u8bc6\uff1b\u5e0c\u671b\u6784\u5efa\u4e00\u4e2a\u80fd\u5728\u9884\u6d4b\u4e0e\u77e5\u8bc6\u6269\u5c55\u95f4\u5faa\u73af\u589e\u76ca\u7684\u4f53\u7cfb", "method": "Closed-Loop LLM-KG framework", "result": "\u5728\u5927\u578bUGC\u6570\u636e\u4e0a\uff0c\u6846\u67b6\u540c\u65f6\u63d0\u5347\u6291\u90c1\u68c0\u6d4b\u51c6\u786e\u7387\u5e76\u53d1\u73b0\u65b0\u7684\u4e34\u5e8a\u76f8\u5173\u5b9e\u4f53\uff08\u75c7\u72b6\u3001\u5171\u75c5\u3001\u793e\u4f1a\u89e6\u53d1\u56e0\u7d20\uff09\uff0c\u4e13\u5bb6\u8bc4\u4f30\u8bc1\u5b9e\u5176\u4e34\u5e8a\u610f\u4e49", "conclusion": "\u901a\u8fc7\u201cprediction-through-learning\u201d\u548c\u201clearning-through-prediction\u201d\u7684\u4e92\u4fc3\u673a\u5236\uff0c\u6846\u67b6\u63a8\u52a8\u6a21\u578b\u4e0e\u9886\u57df\u77e5\u8bc6\u5171\u8fdb\uff0c\u4e3a\u52a8\u6001\u98ce\u9669\u76d1\u6d4b\u7684\u81ea\u9002\u5e94\u77e5\u8bc6\u7cfb\u7edf\u63d0\u4f9b\u57fa\u7840"}}
{"id": "2510.23847", "categories": ["cs.CR", "eess.SP"], "pdf": "https://arxiv.org/pdf/2510.23847", "abs": "https://arxiv.org/abs/2510.23847", "authors": ["Joel Poncha Lemayian", "Ghyslain Gagnon", "Kaiwen Zhang", "Pascal Giard"], "title": "EthVault: A Secure and Resource-Conscious FPGA-Based Ethereum Cold Wallet", "comment": "Under review for publication", "summary": "Cryptocurrency blockchain networks safeguard digital assets using\ncryptographic keys, with wallets playing a critical role in generating,\nstoring, and managing these keys. Wallets, typically categorized as hot and\ncold, offer varying degrees of security and convenience. However, they are\ngenerally software-based applications running on microcontrollers.\nConsequently, they are vulnerable to malware and side-channel attacks, allowing\nperpetrators to extract private keys by targeting critical algorithms, such as\nECC, which processes private keys to generate public keys and authorize\ntransactions. To address these issues, this work presents EthVault, the first\nhardware architecture for an Ethereum hierarchically deterministic cold wallet,\nfeaturing hardware implementations of key algorithms for secure key generation.\nAlso, an ECC architecture resilient to side-channel and timing attacks is\nproposed. Moreover, an architecture of the child key derivation function, a\nfundamental component of cryptocurrency wallets, is proposed. The design\nminimizes resource usage, meeting market demand for small, portable\ncryptocurrency wallets. FPGA implementation results validate the feasibility of\nthe proposed approach. The ECC architecture exhibits uniform execution behavior\nacross varying inputs, while the complete design utilizes only 27%, 7%, and 6%\nof LUTs, registers, and RAM blocks, respectively, on a Xilinx Zynq UltraScale+\nFPGA.", "AI": {"tldr": "\u63d0\u51fa\u4e86EthVault\uff0c\u4e00\u79cd\u9488\u5bf9\u4ee5\u592a\u574a\u5206\u5c42\u786e\u5b9a\u6027\u51b7\u94b1\u5305\u7684\u786c\u4ef6\u67b6\u6784\uff0c\u5305\u542b\u786c\u4ef6\u5b9e\u73b0\u7684\u5bc6\u94a5\u751f\u6210\u3001\u5bf9\u4fa7\u4fe1\u9053\u548c\u65f6\u95f4\u653b\u51fb\u5177\u5907\u6297\u6027\u7684\u692d\u5706\u66f2\u7ebf\u52a0\u5bc6(ECC)\u67b6\u6784\uff0c\u4ee5\u53ca\u5b50\u5bc6\u94a5\u6d3e\u751f\u51fd\u6570\uff08CKD\uff09\u786c\u4ef6\u5b9e\u73b0\u3002\u8bbe\u8ba1\u8d44\u6e90\u5360\u7528\u4f4e\uff0c\u9002\u5408\u4fbf\u643a\u94b1\u5305\uff0cFPGA\u5b9e\u73b0\u9a8c\u8bc1\u53ef\u884c\u6027\u3002", "motivation": "\u8f6f\u4ef6\u94b1\u5305\u8fd0\u884c\u4e8e\u5fae\u63a7\u5236\u5668\u4e0a\uff0c\u6613\u53d7\u6076\u610f\u8f6f\u4ef6\u548c\u4fa7\u4fe1\u9053\u653b\u51fb\uff0c\u653b\u51fb\u8005\u53ef\u901a\u8fc7\u653b\u51fb\u5173\u952e\u7b97\u6cd5\uff08\u5982ECC\uff09\u63d0\u53d6\u79c1\u94a5\uff0c\u56e0\u6b64\u9700\u8981\u4e13\u95e8\u7684\u786c\u4ef6\u67b6\u6784\u63d0\u4f9b\u66f4\u9ad8\u7684\u5b89\u5168\u6027\u540c\u65f6\u4fdd\u6301\u4fbf\u643a\u6027\u3002", "method": "\u63d0\u51fa\u786c\u4ef6\u4f53\u7cfb\u7ed3\u6784\uff1a1\uff09\u786c\u4ef6\u5b9e\u73b0\u7684\u5bc6\u94a5\u751f\u6210\u6a21\u5757\u7528\u4e8e\u5206\u5c42\u786e\u5b9a\u6027\uff08HD\uff09\u4ee5\u592a\u574a\u94b1\u5305\uff1b2\uff09\u8bbe\u8ba1\u5e76\u5b9e\u73b0\u4fa7\u4fe1\u9053\u4e0e\u65f6\u95f4\u653b\u51fb\u6297\u6027\u7684ECC\u52a0\u901f\u5668\uff0c\u4fdd\u8bc1\u6267\u884c\u884c\u4e3a\u5728\u4e0d\u540c\u8f93\u5165\u4e0b\u7684\u5747\u4e00\u6027\uff1b3\uff09\u5b9e\u73b0\u5b50\u5bc6\u94a5\u6d3e\u751f\u51fd\u6570\u7684\u786c\u4ef6\u6a21\u5757\u4ee5\u652f\u6301HD\u94b1\u5305\u94fe\u5f0f\u5bc6\u94a5\u751f\u6210\uff1b\u6240\u6709\u6a21\u5757\u5728FPGA\u4e0a\u7efc\u5408\u4ee5\u6700\u5c0f\u5316\u8d44\u6e90\u5360\u7528\u3002", "result": "\u5728Xilinx Zynq UltraScale+ FPGA\u4e0a\u5b9e\u73b0\uff0c\u5b8c\u6574\u8bbe\u8ba1\u4ec5\u4f7f\u7528\u4e8627%\u7684LUT\u30017%\u7684\u5bc4\u5b58\u5668\u548c6%\u7684RAM\u5757\uff1bECC\u6a21\u5757\u5728\u4e0d\u540c\u8f93\u5165\u4e0b\u8868\u73b0\u51fa\u6267\u884c\u884c\u4e3a\u7684\u5747\u4e00\u6027\uff0c\u663e\u793a\u5bf9\u4fa7\u4fe1\u9053\u548c\u65f6\u95f4\u653b\u51fb\u7684\u6297\u6027\uff0c\u5e76\u8bc1\u660e\u6574\u4f53\u8bbe\u8ba1\u8d44\u6e90\u5360\u7528\u4f4e\u3001\u53ef\u884c\u3002", "conclusion": "EthVault\u5728FPGA\u4e0a\u5b9e\u73b0\u5e76\u9a8c\u8bc1\u4e86\u5c0f\u8d44\u6e90\u5360\u7528\u548c\u6297\u4fa7\u4fe1\u9053/\u65f6\u95f4\u653b\u51fb\u7684ECC\u4e0eCKD\u786c\u4ef6\u6a21\u5757\uff0c\u8bc1\u660e\u4e86\u5728\u4ee5\u592a\u574a\u51b7\u94b1\u5305\u4e2d\u7528\u5b9a\u5236\u786c\u4ef6\u63d0\u9ad8\u5b89\u5168\u6027\u548c\u53ef\u79fb\u690d\u6027\u7684\u53ef\u884c\u6027\u3002"}}
{"id": "2510.23772", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.23772", "abs": "https://arxiv.org/abs/2510.23772", "authors": ["Vivek Veeriah", "Federico Barbero", "Marcus Chiam", "Xidong Feng", "Michael Dennis", "Ryan Pachauri", "Thomas Tumiel", "Johan Obando-Ceron", "Jiaxin Shi", "Shaobo Hou", "Satinder Singh", "Nenad Toma\u0161ev", "Tom Zahavy"], "title": "Evaluating In Silico Creativity: An Expert Review of AI Chess Compositions", "comment": "Accepted at the Creative AI Track, NeurIPS 2025", "summary": "The rapid advancement of Generative AI has raised significant questions\nregarding its ability to produce creative and novel outputs. Our recent work\ninvestigates this question within the domain of chess puzzles and presents an\nAI system designed to generate puzzles characterized by aesthetic appeal,\nnovelty, counter-intuitive and unique solutions. We briefly discuss our method\nbelow and refer the reader to the technical paper for more details. To assess\nour system's creativity, we presented a curated booklet of AI-generated puzzles\nto three world-renowned experts: International Master for chess compositions\nAmatzia Avni, Grandmaster Jonathan Levitt, and Grandmaster Matthew Sadler. All\nthree are noted authors on chess aesthetics and the evolving role of computers\nin the game. They were asked to select their favorites and explain what made\nthem appealing, considering qualities such as their creativity, level of\nchallenge, or aesthetic design.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u751f\u6210\u5f0fAI\u5728\u56fd\u9645\u8c61\u68cb\u96be\u9898\u521b\u4f5c\u4e2d\u7684\u521b\u9020\u529b\u3002\u4f5c\u8005\u6784\u5efa\u7cfb\u7edf\u751f\u6210\u5177\u6709\u7f8e\u5b66\u3001\u65b0\u9896\u548c\u53cd\u76f4\u89c9\u89e3\u6cd5\u7684\u9898\u76ee\uff0c\u5e76\u8bf7\u4e09\u4f4d\u9876\u7ea7\u4e13\u5bb6\u4ece\u521b\u9020\u6027\u3001\u6311\u6218\u6027\u548c\u7f8e\u5b66\u89d2\u5ea6\u8bc4\u5ba1\u3002", "motivation": "\u68c0\u9a8c\u751f\u6210\u5f0fAI\u662f\u5426\u80fd\u5728\u5bcc\u6709\u521b\u610f\u7684\u827a\u672f\u6027\u4efb\u52a1\u4e2d\u4ea7\u751f\u771f\u6b63\u7684\u521b\u65b0\u4ea7\u51fa\uff0c\u4ee5\u53ca\u901a\u8fc7\u6743\u5a01\u4e13\u5bb6\u8bc4\u4f30\u6765\u9a8c\u8bc1\u8fd9\u4e9b\u6210\u679c\u3002", "method": "\u4f5c\u8005\u6784\u5efa\u57fa\u4e8e\u672a\u8be6\u8ff0\u7b97\u6cd5\u548c\u8bc4\u4f30\u51c6\u5219\u7684\u81ea\u52a8\u751f\u6210\u7cfb\u7edf\uff0c\u76ee\u6807\u4f18\u5316\u9898\u76ee\u7684\u7f8e\u611f\u3001\u65b0\u9896\u6027\u53ca\u53cd\u76f4\u89c9\u89e3\u6cd5\uff1b\u968f\u540e\u4eba\u5de5\u7b5b\u9009\u5e76\u5236\u4f5c\u9898\u96c6\u4f9b\u4e13\u5bb6\u8bc4\u5ba1\u3002\u5177\u4f53\u6280\u672f\u7ec6\u8282\u5728\u5b8c\u6574\u8bba\u6587\u4e2d\u5448\u73b0\u3002", "result": "AI\u7cfb\u7edf\u5728\u56fd\u9645\u8c61\u68cb\u96be\u9898\u751f\u6210\u9886\u57df\u63a2\u7d22\u751f\u6210\u6027\u521b\u9020\u529b\uff0c\u76ee\u6807\u751f\u6210\u5177\u6709\u7f8e\u611f\u3001\u65b0\u9896\u6027\u548c\u53cd\u76f4\u89c9\u89e3\u6cd5\u7684\u6b8b\u5c40\u9898\u76ee\u3002\u901a\u8fc7\u6280\u672f\u65b9\u6cd5\uff08\u6458\u8981\u4e2d\u672a\u8be6\u8ff0\uff09\u751f\u6210\u9898\u76ee\uff0c\u5e76\u5c06\u6574\u7406\u7684AI\u751f\u6210\u9898\u96c6\u63d0\u4f9b\u7ed9\u4e09\u4f4d\u56fd\u9645\u77e5\u540d\u4e13\u5bb6\u8bc4\u5ba1\uff1aAmatzia Avni\uff08\u56fd\u9645\u5927\u5e08\uff0c\u6784\u9898\u4e13\u5bb6\uff09\u3001Jonathan Levitt\uff08\u7279\u7ea7\u5927\u5e08\uff09\u548cMatthew Sadler\uff08\u7279\u7ea7\u5927\u5e08\uff09\u3002\u4e13\u5bb6\u88ab\u8981\u6c42\u9009\u51fa\u4ed6\u4eec\u7684\u6700\u7231\u5e76\u89e3\u91ca\u5438\u5f15\u529b\uff0c\u8bc4\u4f30\u7ef4\u5ea6\u5305\u62ec\u521b\u9020\u6027\u3001\u96be\u5ea6\u548c\u7f8e\u5b66\u8bbe\u8ba1\u3002", "conclusion": "\u4e13\u5bb6\u8bc4\u5ba1\u7528\u4e8e\u9a8c\u8bc1AI\u751f\u6210\u9898\u76ee\u7684\u521b\u9020\u6027\u548c\u7f8e\u5b66\u4ef7\u503c\uff1b\u901a\u8fc7\u4eba\u7c7b\u6743\u5a01\u8bc4\u4ef7\u6765\u8861\u91cfAI\u5728\u521b\u4f5c\u9886\u57df\u7684\u8868\u73b0\uff0c\u8868\u660eAI\u53ef\u751f\u6210\u5177\u5438\u5f15\u529b\u548c\u521b\u65b0\u6027\u7684\u8c61\u68cb\u9898\u76ee\u3002"}}
{"id": "2510.24200", "categories": ["cs.LG", "cs.CR", "cs.DC", "I.2.11"], "pdf": "https://arxiv.org/pdf/2510.24200", "abs": "https://arxiv.org/abs/2510.24200", "authors": ["Alexander Bakarsky", "Dimitar I. Dimitrov", "Maximilian Baader", "Martin Vechev"], "title": "SPEAR++: Scaling Gradient Inversion via Sparsely-Used Dictionary Learning", "comment": "Published at the Workshop on Regulatable ML at the 39th Conference on\n  Neural Information Processing Systems (NeurIPS 2025)", "summary": "Federated Learning has seen an increased deployment in real-world scenarios\nrecently, as it enables the distributed training of machine learning models\nwithout explicit data sharing between individual clients. Yet, the introduction\nof the so-called gradient inversion attacks has fundamentally challenged its\nprivacy-preserving properties. Unfortunately, as these attacks mostly rely on\ndirect data optimization without any formal guarantees, the vulnerability of\nreal-world systems remains in dispute and requires tedious testing for each new\nfederated deployment. To overcome these issues, recently the SPEAR attack was\nintroduced, which is based on a theoretical analysis of the gradients of linear\nlayers with ReLU activations. While SPEAR is an important theoretical\nbreakthrough, the attack's practicality was severely limited by its exponential\nruntime in the batch size b. In this work, we fill this gap by applying\nState-of-the-Art techniques from Sparsely-Used Dictionary Learning to make the\nproblem of gradient inversion on linear layers with ReLU activations tractable.\nOur experiments demonstrate that our new attack, SPEAR++, retains all desirable\nproperties of SPEAR, such as robustness to DP noise and FedAvg aggregation,\nwhile being applicable to 10x bigger batch sizes.", "AI": {"tldr": "SPEAR++\u901a\u8fc7\u5c06\u7a00\u758f\u5b57\u5178\u5b66\u4e60\u5f15\u5165SPEAR\u653b\u51fb\uff0c\u4f7f\u9488\u5bf9\u5e26ReLU\u7ebf\u6027\u5c42\u7684\u68af\u5ea6\u53cd\u6f14\u5728\u8ba1\u7b97\u4e0a\u53ef\u884c\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u53ef\u5904\u7406\u7684\u6279\u91cf\u5927\u5c0f\uff08\u7ea610\u500d\uff09\uff0c\u5e76\u4fdd\u6301\u5bf9DP\u566a\u58f0\u548cFedAvg\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u8be5\u8bba\u6587\u65e8\u5728\u89e3\u51b3\u8054\u90a6\u5b66\u4e60\u4e2d\u57fa\u4e8e\u68af\u5ea6\u53cd\u6f14\u653b\u51fb\u7684\u9690\u79c1\u98ce\u9669\u8bc4\u4f30\u56f0\u96be\uff0c\u7279\u522b\u662f\u5f53\u524dSPEAR\u65b9\u6cd5\u5bf9\u6279\u91cf\u5927\u5c0f\u5448\u6307\u6570\u7ea7\u65f6\u95f4\u590d\u6742\u5ea6\u5bfc\u81f4\u5b9e\u7528\u6027\u53d7\u9650\u7684\u95ee\u9898\u3002\u4f5c\u8005\u5e0c\u671b\u901a\u8fc7\u5f15\u5165\u7a00\u758f\u5b57\u5178\u5b66\u4e60\u9886\u57df\u7684\u5148\u8fdb\u6280\u672f\uff0c\u4f7f\u9488\u5bf9\u5e26ReLU\u6fc0\u6d3b\u7684\u7ebf\u6027\u5c42\u7684\u68af\u5ea6\u53cd\u6f14\u653b\u51fb\u5728\u66f4\u5927\u6279\u91cf\u4e0b\u4e5f\u80fd\u9ad8\u6548\u8fd0\u884c\uff0c\u4ece\u800c\u63d0\u4f9b\u53ef\u6269\u5c55\u5e76\u5177\u6709\u7406\u8bba\u652f\u6491\u7684\u9690\u79c1\u653b\u51fb\u5de5\u5177\u3002", "method": "\u5728\u539fSPEAR\u57fa\u4e8e\u68af\u5ea6\u89e3\u6790\u7684\u6846\u67b6\u4e0a\uff0c\u91c7\u7528\u7a00\u758f\u5b57\u5178\u5b66\u4e60\uff08Sparsely-Used Dictionary Learning\uff09\u6280\u672f\u6765\u6784\u9020\u548c\u6c42\u89e3\u7a00\u758f\u7f16\u7801\u95ee\u9898\uff0c\u51cf\u5c11\u5bf9\u6279\u91cf\u5927\u5c0f\u7684\u6307\u6570\u7ea7\u679a\u4e3e\uff0c\u7ed3\u5408\u4f18\u5316\u4e0e\u542f\u53d1\u5f0f\u7b56\u7565\u63d0\u5347\u53ef\u6269\u5c55\u6027\u548c\u9c81\u68d2\u6027\u3002", "result": "\u63d0\u51fa\u4e86SPEAR++\u653b\u51fb\u7b97\u6cd5\uff0c\u5c06\u7a00\u758f\u5b57\u5178\u5b66\u4e60\u6280\u672f\u5e94\u7528\u5230SPEAR\u6846\u67b6\uff0c\u4ece\u800c\u5c06\u539f\u672c\u5bf9\u6279\u91cf\u5927\u5c0f\u6307\u6570\u7ea7\u589e\u957f\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\u663e\u8457\u964d\u4f4e\uff0c\u4f7f\u5f97\u653b\u51fb\u53ef\u6269\u5c55\u5230\u5927\u7ea610\u500d\u66f4\u5927\u7684\u6279\u91cf\u3002\u5b9e\u9a8c\u663e\u793aSPEAR++\u4fdd\u7559\u4e86SPEAR\u5bf9\u5dee\u5206\u9690\u79c1\u566a\u58f0\u548cFedAvg\u805a\u5408\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "SPEAR++\u586b\u8865\u4e86SPEAR\u5728\u5b9e\u7528\u6027\u65b9\u9762\u7684\u7a7a\u767d\uff0c\u8bc1\u660e\u4e86\u7406\u8bba\u653b\u51fb\u53ef\u4ee5\u901a\u8fc7\u7a00\u758f\u8868\u793a\u65b9\u6cd5\u5728\u5b9e\u9645\u8054\u90a6\u5b66\u4e60\u8bbe\u7f6e\u4e2d\u9ad8\u6548\u8fd0\u884c\uff0c\u4ece\u800c\u5bf9\u90e8\u7f72\u7cfb\u7edf\u63d0\u51fa\u66f4\u5b9e\u9645\u7684\u9690\u79c1\u5a01\u80c1\u8bc4\u4f30\u9700\u6c42\u3002"}}
{"id": "2510.23629", "categories": ["cs.LG", "cs.AI", "cs.PL"], "pdf": "https://arxiv.org/pdf/2510.23629", "abs": "https://arxiv.org/abs/2510.23629", "authors": ["Nuo Chen", "Zehua Li", "Keqin Bao", "Junyang Lin", "Dayiheng Liu"], "title": "Chain of Execution Supervision Promotes General Reasoning in Large Language Models", "comment": null, "summary": "Building robust and general reasoning ability is a central goal in the\ndevelopment of large language models (LLMs). Recent efforts increasingly turn\nto code as a rich training source, given its inherent logical structure and\ndiverse reasoning paradigms such as divide-and-conquer, topological ordering,\nand enumeration. However, reasoning in code is often expressed implicitly and\nentangled with syntactic or implementation noise, making direct training on raw\ncode suboptimal.To address this, we introduce TracePile, a large-scale corpus\nof 2.6 million samples that transforms code execution into explicit,\nstep-by-step chain-of-thought-style rationales, which we call Chain of\nExecution (CoE). The corpus spans domains including mathematics, classical\nalgorithms and algorithmic competition, and is enriched with variable-tracing\nquestions and code rewritings to enhance logical granularity and code\ndiversity. We evaluate TracePile using three training setups:\ncontinue-pretraining, instruction tuning after pretraining, and two-stage\nfinetuning. Experiments across four base models (LLaMA 3, LLaMA 3.1, Qwen-2.5,\nand Qwen-2.5 Coder) and 20 benchmarks covering math, code, logic, and\nalgorithms demonstrate consistent improvements. Notably, TracePile boosts\nLLaMA3.1-8B by 7.1\\% on average across nine math datasets and delivers clear\ngains on LiveCodeBench, CRUX, and MMLU under two-stage fine-tuning.", "AI": {"tldr": "TracePile \u75282.6M\u6761\u4ee3\u7801\u6267\u884c\u5230\u5206\u6b65\u63a8\u7406\u7684\u8f6c\u6362\u8bed\u6599\uff08CoE\uff09\u8bad\u7ec3 LLM\uff0c\u663e\u8457\u63d0\u5347\u6570\u5b66\u4e0e\u7b97\u6cd5\u7c7b\u63a8\u7406\u80fd\u529b\uff0c\u6548\u679c\u5728\u591a\u6a21\u578b\u591a\u57fa\u51c6\u4e0a\u7a33\u5065\u3002", "motivation": "\u4ee3\u7801\u5305\u542b\u4e30\u5bcc\u7684\u903b\u8f91\u7ed3\u6784\u4e0e\u591a\u6837\u63a8\u7406\u8303\u5f0f\uff0c\u4f46\u539f\u59cb\u4ee3\u7801\u4e2d\u7684\u9690\u5f0f\u63a8\u7406\u4e0e\u5b9e\u73b0\u566a\u58f0\u9650\u5236\u4e86\u76f4\u63a5\u8bad\u7ec3\u6548\u679c\uff0c\u9700\u5c06\u9690\u542b\u7684\u6267\u884c\u6b65\u9aa4\u663e\u5f0f\u5316\u4ee5\u4fc3\u8fdb\u6a21\u578b\u5b66\u4e60\u63a8\u7406\u6d41\u7a0b\u3002", "method": "\u6784\u5efa\u5927\u89c4\u6a21 CoE \u8bed\u6599\uff1a\u5c06\u4ee3\u7801\u6267\u884c\u8f68\u8ff9\u8f6c\u6210\u9010\u6b65\u63a8\u7406\u94fe\uff0c\u5305\u542b\u53d8\u91cf\u8ddf\u8e2a\u95ee\u9898\u4e0e\u4ee3\u7801\u91cd\u5199\u4ee5\u589e\u5f3a\u903b\u8f91\u7c92\u5ea6\u548c\u591a\u6837\u6027\uff1b\u5728\u56db\u4e2a\u57fa\u7840\u6a21\u578b\u4e0a\u8fdb\u884c\u7ee7\u7eed\u9884\u8bad\u7ec3\u3001\u6307\u4ee4\u5fae\u8c03\u4e0e\u4e24\u9636\u6bb5\u5fae\u8c03\u8bc4\u4f30\u3002", "result": "\u572820\u4e2a\u57fa\u51c6\uff08\u6570\u5b66\u3001\u4ee3\u7801\u3001\u903b\u8f91\u3001\u7b97\u6cd5\uff09\u4e0a\u5747\u89c2\u5bdf\u5230\u4e00\u81f4\u63d0\u5347\uff1bLLaMA3.1-8B \u5728\u4e5d\u4e2a\u6570\u5b66\u6570\u636e\u96c6\u5e73\u5747\u63d0\u9ad87.1%\uff0c\u5728 LiveCodeBench\u3001CRUX\u3001MMLU \u7b49\u57fa\u51c6\u4e0a\u901a\u8fc7\u4e24\u9636\u6bb5\u5fae\u8c03\u4e5f\u6709\u660e\u663e\u589e\u76ca\u3002", "conclusion": "TracePile \u5c06\u4ee3\u7801\u6267\u884c\u8f6c\u6362\u4e3a\u663e\u5f0f\u5206\u6b65\u63a8\u7406\uff08Chain of Execution, CoE\uff09\uff0c\u901a\u8fc72.6M\u6837\u672c\u7684\u8bed\u6599\u63d0\u5347 LLM \u5728\u6570\u5b66\u3001\u7b97\u6cd5\u4e0e\u4ee3\u7801\u7406\u89e3\u4efb\u52a1\u4e0a\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4e09\u79cd\u8bad\u7ec3\u65b9\u5f0f\u5747\u8868\u73b0\u7a33\u5065\uff0c\u5c24\u5176\u5bf9 LLaMA3.1-8B \u5728\u6570\u5b66\u6570\u636e\u96c6\u6709\u663e\u8457\u63d0\u5347\u3002"}}
{"id": "2510.23891", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.23891", "abs": "https://arxiv.org/abs/2510.23891", "authors": ["Jiaqi Xue", "Yifei Zhao", "Mansour Al Ghanim", "Shangqian Gao", "Ruimin Sun", "Qian Lou", "Mengxin Zheng"], "title": "PRO: Enabling Precise and Robust Text Watermark for Open-Source LLMs", "comment": null, "summary": "Text watermarking for large language models (LLMs) enables model owners to\nverify text origin and protect intellectual property. While watermarking\nmethods for closed-source LLMs are relatively mature, extending them to\nopen-source models remains challenging, as developers cannot control the\ndecoding process. Consequently, owners of open-source LLMs lack practical means\nto verify whether text was generated by their models. A core difficulty lies in\nembedding watermarks directly into model weights without hurting detectability.\nA promising idea is to distill watermarks from a closed-source model into an\nopen one, but this suffers from (i) poor detectability due to mismatch between\nlearned and predefined patterns, and (ii) fragility to downstream modifications\nsuch as fine-tuning or model merging. To overcome these limitations, we propose\nPRO, a Precise and Robust text watermarking method for open-source LLMs. PRO\njointly trains a watermark policy model with the LLM, producing patterns that\nare easier for the model to learn and more consistent with detection criteria.\nA regularization term further simulates downstream perturbations and penalizes\ndegradation in watermark detectability, ensuring robustness under model edits.\nExperiments on open-source LLMs (e.g., LLaMA-3.2, LLaMA-3, Phi-2) show that PRO\nsubstantially improves both watermark detectability and resilience to model\nmodifications.", "AI": {"tldr": "PRO\u901a\u8fc7\u8054\u5408\u8bad\u7ec3\u6c34\u5370\u7b56\u7565\u5e76\u7528\u6270\u52a8\u6b63\u5219\u5316\uff0c\u5c06\u6c34\u5370\u5d4c\u5165\u5f00\u6e90LLM\u6743\u91cd\uff0c\u5b9e\u73b0\u7cbe\u786e\u4e14\u9c81\u68d2\u7684\u6587\u672c\u6c34\u5370\uff0c\u53ef\u5728\u6a21\u578b\u5fae\u8c03\u6216\u5408\u5e76\u540e\u4ecd\u88ab\u68c0\u6d4b\u3002", "motivation": "\u4fdd\u62a4\u5f00\u6e90LLM\u7684\u4ea7\u6743\u4e0e\u9a8c\u8bc1\u6587\u672c\u6765\u6e90\uff0c\u73b0\u6709\u6c34\u5370\u65b9\u6cd5\u5728\u4e0d\u5f00\u6e90\u6a21\u578b\u4e0a\u6210\u719f\uff0c\u4f46\u65e0\u6cd5\u76f4\u63a5\u7528\u4e8e\u5f00\u6e90\u6a21\u578b\u56e0\u65e0\u6cd5\u63a7\u5236\u89e3\u7801\u8fc7\u7a0b\u3002\u9700\u5c06\u6c34\u5370\u5d4c\u5165\u6a21\u578b\u6743\u91cd\u4e14\u4e0d\u635f\u5bb3\u53ef\u68c0\u6d4b\u6027\u3002", "method": "\u8054\u5408\u8bad\u7ec3\u4e00\u4e2a\u6c34\u5370\u7b56\u7565\u6a21\u578b\u4e0e\u5f00\u6e90LLM\uff0c\u4f7f\u751f\u6210\u7684\u6c34\u5370\u6a21\u5f0f\u66f4\u6613\u5b66\u4e60\u5e76\u4e0e\u68c0\u6d4b\u6807\u51c6\u4e00\u81f4\uff1b\u52a0\u5165\u6b63\u5219\u9879\u6a21\u62df\u4e0b\u6e38\u4fee\u6539\u5e76\u60e9\u7f5a\u53ef\u68c0\u6d4b\u6027\u4e0b\u964d\uff0c\u4ee5\u786e\u4fdd\u9c81\u68d2\u6027\u3002", "result": "\u63d0\u51faPRO\u65b9\u6cd5\uff0c\u901a\u8fc7\u8054\u5408\u8bad\u7ec3\u6c34\u5370\u7b56\u7565\u6a21\u578b\u4e0eLLM\u5e76\u5f15\u5165\u6b63\u5219\u5316\u6a21\u62df\u4e0b\u6e38\u6270\u52a8\uff0c\u663e\u8457\u63d0\u9ad8\u5728\u5f00\u6e90\u6a21\u578b\u4e0a\u7684\u6c34\u5370\u53ef\u68c0\u6d4b\u6027\u4e0e\u5bf9\u6a21\u578b\u4fee\u6539\u7684\u9c81\u68d2\u6027\uff0c\u5728LLaMA-3.2\u3001LLaMA-3\u3001Phi-2\u4e0a\u8868\u73b0\u826f\u597d\u3002", "conclusion": "PRO\u80fd\u6709\u6548\u5c06\u6c34\u5370\u5d4c\u5165\u5f00\u6e90LLM\uff0c\u89e3\u51b3\u4e86\u5339\u914d\u6027\u4e0e\u8106\u5f31\u6027\u95ee\u9898\uff0c\u4e3a\u5f00\u6e90\u6a21\u578b\u63d0\u4f9b\u53ef\u7528\u7684\u6765\u6e90\u9a8c\u8bc1\u624b\u6bb5\u3002"}}
{"id": "2510.23807", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.23807", "abs": "https://arxiv.org/abs/2510.23807", "authors": ["Hamid R. Tizhoosh"], "title": "Why Foundation Models in Pathology Are Failing", "comment": null, "summary": "In non-medical domains, foundation models (FMs) have revolutionized computer\nvision and language processing through large-scale self-supervised and\nmultimodal learning. Consequently, their rapid adoption in computational\npathology was expected to deliver comparable breakthroughs in cancer diagnosis,\nprognostication, and multimodal retrieval. However, recent systematic\nevaluations reveal fundamental weaknesses: low diagnostic accuracy, poor\nrobustness, geometric instability, heavy computational demands, and concerning\nsafety vulnerabilities. This short paper examines these shortcomings and argues\nthat they stem from deeper conceptual mismatches between the assumptions\nunderlying generic foundation modeling in mainstream AI and the intrinsic\ncomplexity of human tissue. Seven interrelated causes are identified:\nbiological complexity, ineffective self-supervision, overgeneralization,\nexcessive architectural complexity, lack of domain-specific innovation,\ninsufficient data, and a fundamental design flaw related to tissue patch size.\nThese findings suggest that current pathology foundation models remain\nconceptually misaligned with the nature of tissue morphology and call for a\nfundamental rethinking of the paradigm itself.", "AI": {"tldr": "Current foundation modeling assumptions clash with tissue complexity; seven causes outlined; need paradigm shift.", "motivation": "Assess why foundation models underperform in computational pathology despite success in other domains.", "method": "paper analysis", "result": "Identified seven interrelated causes explaining FM shortcomings in pathology.", "conclusion": "Pathology FMs are conceptually misaligned with tissue morphology; fundamental rethinking required."}}
{"id": "2510.24503", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.DC", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.24503", "abs": "https://arxiv.org/abs/2510.24503", "authors": ["Mortesa Hussaini", "Jan Thei\u00df", "Anthony Stein"], "title": "Local Performance vs. Out-of-Distribution Generalization: An Empirical Analysis of Personalized Federated Learning in Heterogeneous Data Environments", "comment": null, "summary": "In the context of Federated Learning with heterogeneous data environments,\nlocal models tend to converge to their own local model optima during local\ntraining steps, deviating from the overall data distributions. Aggregation of\nthese local updates, e.g., with FedAvg, often does not align with the global\nmodel optimum (client drift), resulting in an update that is suboptimal for\nmost clients. Personalized Federated Learning approaches address this challenge\nby exclusively focusing on the average local performances of clients' models on\ntheir own data distribution. Generalization to out-of-distribution samples,\nwhich is a substantial benefit of FedAvg and represents a significant component\nof robustness, appears to be inadequately incorporated into the assessment and\nevaluation processes. This study involves a thorough evaluation of Federated\nLearning approaches, encompassing both their local performance and their\ngeneralization capabilities. Therefore, we examine different stages within a\nsingle communication round to enable a more nuanced understanding of the\nconsidered metrics. Furthermore, we propose and incorporate a modified approach\nof FedAvg, designated as Federated Learning with Individualized Updates (FLIU),\nextending the algorithm by a straightforward individualization step with an\nadaptive personalization factor. We evaluate and compare the approaches\nempirically using MNIST and CIFAR-10 under various distributional conditions,\nincluding benchmark IID and pathological non-IID, as well as additional novel\ntest environments with Dirichlet distribution specifically developed to stress\nthe algorithms on complex data heterogeneity.", "AI": {"tldr": "Paper examines trade-off between personalization and generalization in FL, evaluates models at multiple stages per round, and introduces FLIU\u2014an easy individualized extension to FedAvg improving robustness under heterogeneity.", "motivation": "Federated Learning suffers from client drift in heterogeneous data; personalization focuses only on local performance and neglects generalization/out-of-distribution robustness.", "method": "Evaluation and proposal of FLIU", "result": "Thorough evaluation across stages within a communication round; propose FLIU (FedAvg + individualized update with adaptive personalization); empirical comparisons on MNIST/CIFAR-10 under IID, non-IID, and Dirichlet distributions.", "conclusion": "FLIU with adaptive personalization better balances local performance and OOD generalization across various heterogeneity settings; staging evaluations reveal nuances missed by single-metric assessments."}}
{"id": "2510.23630", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.23630", "abs": "https://arxiv.org/abs/2510.23630", "authors": ["Ninghui Feng", "Yiyan Qi"], "title": "NUM2EVENT: Interpretable Event Reasoning from Numerical time-series", "comment": null, "summary": "Large language models (LLMs) have recently demonstrated impressive multimodal\nreasoning capabilities, yet their understanding of purely numerical time-series\nsignals remains limited. Existing approaches mainly focus on forecasting or\ntrend description, without uncovering the latent events that drive numerical\nchanges or explaining the reasoning process behind them. In this work, we\nintroduce the task of number-to-event reasoning and decoding, which aims to\ninfer interpretable structured events from numerical inputs, even when current\ntext is unavailable. To address the data scarcity and semantic alignment\nchallenges, we propose a reasoning-aware framework that integrates an\nagent-guided event extractor (AGE), a marked multivariate Hawkes-based\nsynthetic generator (EveDTS), and a two-stage fine-tuning pipeline combining a\ntime-series encoder with a structured decoder. Our model explicitly reasons\nover numerical changes, generates intermediate explanations, and outputs\nstructured event hypotheses. Experiments on multi-domain datasets show that our\nmethod substantially outperforms strong LLM baselines in event-level precision\nand recall. These results suggest a new direction for bridging quantitative\nreasoning and semantic understanding, enabling LLMs to explain and predict\nevents directly from numerical dynamics.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5c06\u6570\u503c\u65f6\u95f4\u5e8f\u5217\u6620\u5c04\u4e3a\u53ef\u89e3\u91ca\u7684\u7ed3\u6784\u5316\u4e8b\u4ef6\uff08number-to-event reasoning\uff09\uff0c\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u5305\u542b\u4ee3\u7406\u5f15\u5bfc\u4e8b\u4ef6\u63d0\u53d6\u5668\uff08AGE\uff09\u3001\u57fa\u4e8e\u6807\u8bb0\u591a\u53d8\u91cf\u970d\u514b\u65af\u8fc7\u7a0b\u7684\u5408\u6210\u751f\u6210\u5668\uff08EveDTS\uff09\u548c\u4e24\u9636\u6bb5\u5fae\u8c03\u7684\u63a8\u7406\u611f\u77e5\u6846\u67b6\u3002\u6a21\u578b\u5bf9\u6570\u503c\u53d8\u5316\u8fdb\u884c\u663e\u5f0f\u63a8\u7406\uff0c\u751f\u6210\u4e2d\u95f4\u89e3\u91ca\u5e76\u8f93\u51fa\u4e8b\u4ef6\u5047\u8bbe\uff0c\u5728\u591a\u9886\u57df\u6570\u636e\u96c6\u4e0a\u5728\u4e8b\u4ef6\u7ea7\u7cbe\u786e\u7387\u548c\u53ec\u56de\u7387\u4e0a\u663e\u8457\u4f18\u4e8e\u5f3a\u57fa\u7ebf\u3002", "motivation": "\u73b0\u6709LLM\u5728\u591a\u6a21\u6001\u63a8\u7406\u4e0a\u8868\u73b0\u5f88\u597d\uff0c\u4f46\u5bf9\u7eaf\u6570\u503c\u65f6\u95f4\u5e8f\u5217\u7684\u7406\u89e3\u6709\u9650\uff0c\u73b0\u6709\u65b9\u6cd5\u4fa7\u91cd\u4e8e\u9884\u6d4b\u6216\u63cf\u8ff0\u8d8b\u52bf\uff0c\u7f3a\u4e4f\u53d1\u73b0\u9a71\u52a8\u6570\u503c\u53d8\u5316\u7684\u6f5c\u5728\u4e8b\u4ef6\u4e0e\u89e3\u91ca\u5176\u63a8\u7406\u8fc7\u7a0b\u7684\u80fd\u529b\u3002\u9700\u8981\u4e00\u79cd\u80fd\u5c06\u6570\u503c\u53d8\u5316\u6620\u5c04\u4e3a\u53ef\u89e3\u91ca\u4e8b\u4ef6\u7684\u673a\u5236\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7531\u4e09\u90e8\u5206\u7ec4\u6210\u7684\u6846\u67b6\uff1a1) \u4ee3\u7406\u5f15\u5bfc\u4e8b\u4ef6\u63d0\u53d6\u5668\uff08AGE\uff09\u7528\u4e8e\u4ece\u6570\u503c\u5e8f\u5217\u4e2d\u63d0\u53d6\u6f5c\u5728\u4e8b\u4ef6\u5019\u9009\u5e76\u751f\u6210\u89e3\u91ca\u6027\u63d0\u793a\uff1b2) EveDTS\u2014\u2014\u57fa\u4e8e\u6807\u8bb0\u591a\u53d8\u91cf\u970d\u514b\u65af\u8fc7\u7a0b\u7684\u5408\u6210\u6570\u636e\u751f\u6210\u5668\uff0c\u7528\u4e8e\u7f13\u89e3\u6570\u636e\u7a00\u7f3a\u5e76\u63d0\u9ad8\u8bed\u4e49\u5bf9\u9f50\uff1b3) \u4e24\u9636\u6bb5\u5fae\u8c03\u6d41\u7a0b\uff0c\u5c06\u65f6\u95f4\u5e8f\u5217\u7f16\u7801\u5668\u4e0e\u7ed3\u6784\u5316\u89e3\u7801\u5668\u7ed3\u5408\uff0c\u5148\u8bad\u7ec3\u6570\u503c\u63a8\u7406\u80fd\u529b\u518d\u7cbe\u8c03\u4e8b\u4ef6\u89e3\u7801\u3002\u6a21\u578b\u663e\u5f0f\u751f\u6210\u4e2d\u95f4\u63a8\u7406\u8fc7\u7a0b\u5e76\u8f93\u51fa\u7ed3\u6784\u5316\u4e8b\u4ef6\u3002", "result": "\u5728\u591a\u9886\u57df\u6570\u636e\u96c6\u4e0a\uff0c\u6240\u63d0\u65b9\u6cd5\u5728\u4e8b\u4ef6\u7ea7\u7cbe\u786e\u7387\u548c\u53ec\u56de\u7387\u4e0a\u660e\u663e\u4f18\u4e8e\u5f3aLLM\u57fa\u7ebf\uff0c\u8868\u660e\u5176\u5728\u89e3\u91ca\u548c\u9884\u6d4b\u6570\u503c\u9a71\u52a8\u4e8b\u4ef6\u65b9\u9762\u66f4\u6709\u6548\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u6865\u63a5\u5b9a\u91cf\u63a8\u7406\u4e0e\u8bed\u4e49\u7406\u89e3\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\uff0c\u4f7fLLM\u80fd\u591f\u76f4\u63a5\u4ece\u6570\u503c\u52a8\u6001\u4e2d\u89e3\u91ca\u548c\u9884\u6d4b\u9a71\u52a8\u4e8b\u4ef6\uff0c\u5e76\u5728\u591a\u9886\u57df\u5b9e\u9a8c\u4e2d\u53d6\u5f97\u4e86\u66f4\u9ad8\u7684\u4e8b\u4ef6\u8bc6\u522b\u6027\u80fd\u3002"}}
{"id": "2510.23927", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.23927", "abs": "https://arxiv.org/abs/2510.23927", "authors": ["Daniel Spokoyny", "Nikolai Vogler", "Xin Gao", "Tianyi Zheng", "Yufei Weng", "Jonghyun Park", "Jiajun Jiao", "Geoffrey M. Voelker", "Stefan Savage", "Taylor Berg-Kirkpatrick"], "title": "Victim as a Service: Designing a System for Engaging with Interactive Scammers", "comment": null, "summary": "Pig butchering, and similar interactive online scams, lower their victims'\ndefenses by building trust over extended periods of conversation - sometimes\nweeks or months. They have become increasingly public losses (at least $75B by\none recent study). However, because of their long-term conversational nature,\nthey are extremely challenging to investigate at scale. In this paper, we\ndescribe the motivation, design, implementation, and experience with\nCHATTERBOX, an LLM-based system that automates long-term engagement with online\nscammers, making large-scale investigations of their tactics possible. We\ndescribe the techniques we have developed to attract scam attempts, the system\nand LLM-engineering required to convincingly engage with scammers, and the\nnecessary capabilities required to satisfy or evade \"milestones\" in scammers'\nworkflow.", "AI": {"tldr": "CHATTERBOX uses LLMs to automate long-term conversational engagement with online scammers, making it possible to study and scale investigations of pig-butchering scams by attracting scammers, sustaining believable chats, and handling scam milestones.", "motivation": "Pig butchering scams cause major financial losses and are hard to study due to long-term conversational nature; automation can enable large-scale investigation.", "method": "Design and implement an LLM-based system that attracts scam attempts, uses engineered prompts and multi-step dialogue management to sustain believable conversations, and incorporates capabilities to meet or evade scammers' milestones.", "result": "Successfully deployed system that engaged scammers over extended periods, revealing tactics and enabling large-scale data collection for analysis.", "conclusion": "CHATTERBOX demonstrates that LLMs can automate long-term scam engagement, enabling scalable investigations and insights into scam workflows."}}
{"id": "2510.23822", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23822", "abs": "https://arxiv.org/abs/2510.23822", "authors": ["Zhenyu Zhang", "Tianyi Chen", "Weiran Xu", "Alex Pentland", "Jiaxin Pei"], "title": "ReCAP: Recursive Context-Aware Reasoning and Planning for Large Language Model Agents", "comment": null, "summary": "Long-horizon tasks requiring multi-step reasoning and dynamic re-planning\nremain challenging for large language models (LLMs). Sequential prompting\nmethods are prone to context drift, loss of goal information, and recurrent\nfailure cycles, while hierarchical prompting methods often weaken cross-level\ncontinuity or incur substantial runtime overhead. We introduce ReCAP (Recursive\nContext-Aware Reasoning and Planning), a hierarchical framework with shared\ncontext for reasoning and planning in LLMs. ReCAP combines three key\nmechanisms: (i) plan-ahead decomposition, in which the model generates a full\nsubtask list, executes the first item, and refines the remainder; (ii)\nstructured re-injection of parent plans, maintaining consistent multi-level\ncontext during recursive return; and (iii) memory-efficient execution, bounding\nthe active prompt so costs scale linearly with task depth. Together these\nmechanisms align high-level goals with low-level actions, reduce redundant\nprompting, and preserve coherent context updates across recursion. Experiments\ndemonstrate that ReCAP substantially improves subgoal alignment and success\nrates on various long-horizon reasoning benchmarks, achieving a 32% gain on\nsynchronous Robotouille and a 29% improvement on asynchronous Robotouille under\nthe strict pass@1 protocol.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aReCAP\u7684\u5c42\u7ea7\u9012\u5f52\u6846\u67b6\uff0c\u901a\u8fc7\u63d0\u524d\u89c4\u5212\u5b50\u4efb\u52a1\u3001\u5728\u9012\u5f52\u8fd4\u56de\u65f6\u7ed3\u6784\u5316\u5730\u6ce8\u5165\u7236\u7ea7\u8ba1\u5212\u3001\u4ee5\u53ca\u5185\u5b58\u9ad8\u6548\u7684\u6267\u884c\u7b56\u7565\uff0c\u5728\u4fdd\u6301\u8de8\u5c42\u7ea7\u4e0a\u4e0b\u6587\u4e00\u81f4\u6027\u7684\u540c\u65f6\u964d\u4f4e\u63d0\u793a\u6210\u672c\uff0c\u4ece\u800c\u63d0\u5347LLM\u5728\u957f\u65f6\u5e8f\u63a8\u7406\u4e0e\u52a8\u6001\u91cd\u89c4\u5212\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "motivation": "\u9488\u5bf9\u5e8f\u5217\u5f0f\u63d0\u793a\u6613\u53d1\u751f\u4e0a\u4e0b\u6587\u6f02\u79fb\u3001\u76ee\u6807\u4fe1\u606f\u4e22\u5931\u4e0e\u5931\u8d25\u5faa\u73af\uff0c\u5c42\u7ea7\u5f0f\u63d0\u793a\u53c8\u53ef\u80fd\u7834\u574f\u8de8\u5c42\u7ea7\u8fde\u7eed\u6027\u6216\u5e26\u6765\u9ad8\u8fd0\u884c\u65f6\u5f00\u9500\uff0c\u63d0\u51fa\u4e00\u79cd\u5728\u4fdd\u6301\u8de8\u5c42\u4e00\u81f4\u6027\u7684\u540c\u65f6\u964d\u4f4e\u63d0\u793a\u6210\u672c\u7684\u5c42\u7ea7\u9012\u5f52\u7b56\u7565\u3002", "method": "ReCAP\u7ed3\u5408\u4e09\u5927\u673a\u5236\uff1a1) plan-ahead decomposition\uff1a\u5148\u751f\u6210\u5b8c\u6574\u5b50\u4efb\u52a1\u5217\u8868\uff0c\u6267\u884c\u9996\u4e2a\u5b50\u4efb\u52a1\u540e\u5bf9\u5269\u4f59\u4efb\u52a1\u8fdb\u884c\u7ec6\u5316\uff1b2) \u7ed3\u6784\u5316\u7684\u7236\u8ba1\u5212\u91cd\u6ce8\u5165\uff1a\u5728\u9012\u5f52\u8fd4\u56de\u65f6\u4fdd\u7559\u591a\u5c42\u7ea7\u4e00\u81f4\u7684\u4e0a\u4e0b\u6587\uff0c\u5c06\u7236\u7ea7\u8ba1\u5212\u4fe1\u606f\u91cd\u65b0\u6ce8\u5165\u5b50\u6d41\u7a0b\uff1b3) \u5185\u5b58\u9ad8\u6548\u6267\u884c\uff1a\u9650\u5236\u6d3b\u52a8\u63d0\u793a\u957f\u5ea6\uff0c\u4f7f\u6210\u672c\u968f\u4efb\u52a1\u6df1\u5ea6\u7ebf\u6027\u589e\u957f\uff0c\u907f\u514d\u63d0\u793a\u5197\u4f59\u4e0e\u4e0a\u4e0b\u6587\u6f02\u79fb\u3002", "result": "\u5728\u591a\u4e2a\u957f\u65f6\u5e8f\u63a8\u7406\u4efb\u52a1\u4e0a\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u5c24\u5176\u5728Robotouille\u57fa\u51c6\u4e0b\u53d6\u5f97\u4e25\u683cpass@1\u768432%\uff08\u540c\u6b65\uff09\u548c29%\uff08\u5f02\u6b65\uff09\u589e\u76ca\u3002", "conclusion": "ReCAP\u5728\u591a\u4e2a\u957f\u65f6\u5e8f\u57fa\u51c6\u4e0a\u663e\u8457\u63d0\u9ad8\u4e86\u5b50\u76ee\u6807\u5bf9\u9f50\u548c\u4efb\u52a1\u6210\u529f\u7387\uff0c\u5728\u4e25\u683c\u7684pass@1\u8bc4\u4f30\u4e0b\u5728Robotouille\u540c\u6b65/\u5f02\u6b65\u4efb\u52a1\u4e0a\u5206\u522b\u63d0\u5347\u7ea632%\u548c29%\u3002"}}
{"id": "2510.23631", "categories": ["cs.LG", "cs.AI", "stat.ME", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.23631", "abs": "https://arxiv.org/abs/2510.23631", "authors": ["Yuxuan Tang", "Yifan Feng"], "title": "Beyond Pairwise: Empowering LLM Alignment With Ranked Choice Modeling", "comment": null, "summary": "Alignment of large language models (LLMs) has predominantly relied on\npairwise preference optimization, where annotators select the better of two\nresponses to a prompt. While simple, this approach overlooks the opportunity to\nlearn from richer forms of human feedback, such as multiwise comparisons and\ntop-$k$ rankings. We propose Ranked Choice Preference Optimization (RCPO), a\nunified framework that bridges preference optimization with (ranked) choice\nmodeling via maximum likelihood estimation. The framework is flexible,\nsupporting both utility-based and rank-based choice models. It subsumes several\nexisting pairwise methods (e.g., DPO, SimPO), while providing principled\ntraining objectives for richer feedback formats. We instantiate this framework\nwith two representative ranked choice models (Multinomial Logit and\nMallows-RMJ). Empirical studies on Llama-3-8B-Instruct and Gemma-2-9B-it across\nAlpacaEval 2 and Arena-Hard benchmarks show that RCPO consistently outperforms\ncompetitive baselines. RCPO shows how directly leveraging ranked preference\ndata, combined with the right choice models, yields more effective alignment.\nIt offers a versatile and extensible foundation for incorporating (ranked)\nchoice modeling into LLM training.", "AI": {"tldr": "RCPO \u662f\u4e00\u4e2a\u5c06\u504f\u597d\u4f18\u5316\u4e0e\u6392\u540d\u9009\u62e9\u6a21\u578b\u7ed3\u5408\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u53ef\u4ee5\u76f4\u63a5\u5229\u7528\u591a\u9879\u6bd4\u8f83\u4e0e top-k \u6392\u5e8f\u6570\u636e\u8fdb\u884c\u5bf9\u9f50\u8bad\u7ec3\uff0c\u5b9e\u9a8c\u8bc1\u660e\u6bd4\u4f20\u7edf\u6210\u5bf9\u65b9\u6cd5\u66f4\u6709\u6548\u3002", "motivation": "\u672c\u6587\u65e8\u5728\u5229\u7528\u66f4\u4e30\u5bcc\u7684\u4eba\u7c7b\u53cd\u9988\u5f62\u5f0f\uff08\u591a\u9879\u6bd4\u8f83\u3001top-k \u6392\u5e8f\uff09\u6539\u8fdb\u5927\u6a21\u578b\uff08LLMs\uff09\u7684\u5bf9\u9f50\u65b9\u6cd5\uff0c\u5f25\u8865\u4f20\u7edf\u6210\u5bf9\u504f\u597d\u4f18\u5316\u5ffd\u89c6\u6392\u5e8f\u4fe1\u606f\u7684\u7f3a\u9677\u3002", "method": "\u901a\u8fc7\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\u5c06\u504f\u597d\u5b66\u4e60\u95ee\u9898\u8868\u8ff0\u4e3a\u9009\u62e9\u6a21\u578b\u8bad\u7ec3\uff0c\u652f\u6301\u6548\u7528\u578b\uff08\u5982 Multinomial Logit\uff09\u548c\u57fa\u4e8e\u79e9\u7684\u6a21\u578b\uff08\u5982 Mallows-RMJ\uff09\uff0c\u5e76\u5c06\u82e5\u5e72\u73b0\u6709\u6210\u5bf9\u65b9\u6cd5\u4f5c\u4e3a\u7279\u4f8b\uff0c\u8bbe\u8ba1\u76f8\u5e94\u8bad\u7ec3\u76ee\u6807\u7528\u4e8e\u4e0d\u540c\u53cd\u9988\u683c\u5f0f\u3002", "result": "\u63d0\u51fa\u4e86 Ranked Choice Preference Optimization (RCPO) \u6846\u67b6\uff0c\u5c06\u504f\u597d\u4f18\u5316\u4e0e\uff08\u6392\u5e8f\uff09\u9009\u62e9\u6a21\u578b\u901a\u8fc7\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\u7edf\u4e00\u8d77\u6765\uff1bRCPO \u652f\u6301\u6548\u7528\u578b\u4e0e\u57fa\u4e8e\u79e9\u7684\u9009\u62e9\u6a21\u578b\uff0c\u5305\u542b Multinomial Logit \u4e0e Mallows-RMJ \u4e24\u79cd\u5b9e\u4f8b\uff0c\u5e76\u5728 Llama-3-8B-Instruct \u548c Gemma-2-9B-it \u4e0a\u7684 AlpacaEval 2 \u4e0e Arena-Hard \u57fa\u51c6\u4e0a\u4f18\u4e8e\u5bf9\u6bd4\u65b9\u6cd5\u3002", "conclusion": "\u76f4\u63a5\u5229\u7528\u6392\u5e8f\u504f\u597d\u6570\u636e\u5e76\u9009\u7528\u5408\u9002\u7684\u9009\u62e9\u6a21\u578b\u80fd\u66f4\u6709\u6548\u5730\u5bf9\u9f50 LLM\uff1bRCPO \u63d0\u4f9b\u4e86\u4e00\u4e2a\u7075\u6d3b\u53ef\u6269\u5c55\u7684\u57fa\u7840\uff0c\u53ef\u5c06\uff08\u6392\u540d\uff09\u9009\u62e9\u5efa\u6a21\u7eb3\u5165 LLM \u8bad\u7ec3\u3002"}}
{"id": "2510.23938", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23938", "abs": "https://arxiv.org/abs/2510.23938", "authors": ["Marcin Spoczynski", "Marcela S. Melara"], "title": "Scalable GPU-Based Integrity Verification for Large Machine Learning Models", "comment": null, "summary": "We present a security framework that strengthens distributed machine learning\nby standardizing integrity protections across CPU and GPU platforms and\nsignificantly reducing verification overheads. Our approach co-locates\nintegrity verification directly with large ML model execution on GPU\naccelerators, resolving the fundamental mismatch between how large ML workloads\ntypically run (primarily on GPUs) and how security verifications traditionally\noperate (on separate CPU-based processes), delivering both immediate\nperformance benefits and long-term architectural consistency. By performing\ncryptographic operations natively on GPUs using dedicated compute units (e.g.,\nIntel Arc's XMX units, NVIDIA's Tensor Cores), our solution eliminates the\npotential architectural bottlenecks that could plague traditional CPU-based\nverification systems when dealing with large models. This approach leverages\nthe same GPU-based high-memory bandwidth and parallel processing primitives\nthat power ML workloads ensuring integrity checks keep pace with model\nexecution even for massive models exceeding 100GB. This framework establishes a\ncommon integrity verification mechanism that works consistently across\ndifferent GPU vendors and hardware configurations. By anticipating future\ncapabilities for creating secure channels between trusted execution\nenvironments and GPU accelerators, we provide a hardware-agnostic foundation\nthat enterprise teams can deploy regardless of their underlying CPU and GPU\ninfrastructures.", "AI": {"tldr": "\u5728GPU\u4e0a\u672c\u5730\u6267\u884c\u52a0\u5bc6\u5b8c\u6574\u6027\u6821\u9a8c\uff0c\u5229\u7528\u4e13\u7528\u7b97\u529b\u5355\u5143\u5e76\u4e0e\u6a21\u578b\u6267\u884c\u5171\u7f6e\uff0c\u6d88\u9664CPU\u9a8c\u8bc1\u74f6\u9888\uff0c\u7edf\u4e00\u8de8\u5382\u5546\u673a\u5236\uff0c\u9002\u914d\u8d85\u5927\u6a21\u578b\u3002", "motivation": "Existing integrity verification runs on CPUs separate from GPU ML execution causing bottlenecks and mismatch; need standardized, efficient verification across CPUs/GPUs for large models.", "method": "GPU-native cryptographic integrity verification for distributed ML", "result": "Framework performs cryptographic ops on GPUs using dedicated units (XMX, Tensor Cores), co-locating verification with model execution, reducing overheads and supporting >100GB models; hardware-agnostic across vendors and anticipates secure channels/TEE-GPU integration.", "conclusion": "GPU\u672c\u5730\u5316\u7684\u5b8c\u6574\u6027\u9a8c\u8bc1\u53ef\u663e\u8457\u964d\u4f4e\u5206\u5e03\u5f0fML\u7684\u9a8c\u8bc1\u5f00\u9500\u5e76\u5b9e\u73b0\u8de8\u786c\u4ef6\u4e00\u81f4\u6027\uff0c\u4e3a\u4f01\u4e1a\u90e8\u7f72\u63d0\u4f9b\u53ef\u6269\u5c55\u3001\u786c\u4ef6\u65e0\u5173\u7684\u57fa\u7840\uff0c\u5c24\u5176\u5f53\u672a\u6765\u652f\u6301TEE\u4e0eGPU\u7684\u5b89\u5168\u901a\u9053\u65f6\u66f4\u5177\u957f\u671f\u4ef7\u503c\u3002"}}
{"id": "2510.23824", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23824", "abs": "https://arxiv.org/abs/2510.23824", "authors": ["Murad Ismayilov", "Edwin Meriaux", "Shuo Wen", "Gregory Dudek"], "title": "Decentralized Multi-Agent Goal Assignment for Path Planning using Large Language Models", "comment": "Accepted at MIT URTC 2025", "summary": "Coordinating multiple autonomous agents in shared environments under\ndecentralized conditions is a long-standing challenge in robotics and\nartificial intelligence. This work addresses the problem of decentralized goal\nassignment for multi-agent path planning, where agents independently generate\nranked preferences over goals based on structured representations of the\nenvironment, including grid visualizations and scenario data. After this\nreasoning phase, agents exchange their goal rankings, and assignments are\ndetermined by a fixed, deterministic conflict-resolution rule (e.g., agent\nindex ordering), without negotiation or iterative coordination. We\nsystematically compare greedy heuristics, optimal assignment, and large\nlanguage model (LLM)-based agents in fully observable grid-world settings. Our\nresults show that LLM-based agents, when provided with well-designed prompts\nand relevant quantitative information, can achieve near-optimal makespans and\nconsistently outperform traditional heuristics. These findings underscore the\npotential of language models for decentralized goal assignment in multi-agent\npath planning and highlight the importance of information structure in such\nsystems.", "AI": {"tldr": "LLMs can effectively generate goal preferences for decentralized multi-agent path planning, leading to near-optimal assignments under deterministic conflict resolution, outperforming greedy heuristics when given structured information.", "motivation": "Understand decentralized goal assignment in multi-agent path planning using agents that independently rank goals based on structured environment representations and then resolve conflicts deterministically without negotiation.", "method": "Paper analysis", "result": "LLM-based agents with good prompts and quantitative info achieve near-optimal makespans and outperform traditional heuristics in fully observable grid-worlds.", "conclusion": "Language models are promising for decentralized goal assignment; information structure and prompt design are critical for performance."}}
{"id": "2510.23632", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23632", "abs": "https://arxiv.org/abs/2510.23632", "authors": ["Guozhong Li", "Muhannad Alhumaidi", "Spiros Skiadopoulos", "Panos Kalnis"], "title": "LLMComp: A Language Modeling Paradigm for Error-Bounded Scientific Data Compression", "comment": null, "summary": "The rapid growth of high-resolution scientific simulations and observation\nsystems is generating massive spatiotemporal datasets, making efficient,\nerror-bounded compression increasingly important. Meanwhile, decoder-only large\nlanguage models (LLMs) have demonstrated remarkable capabilities in modeling\ncomplex sequential data. In this paper, we propose LLMCOMP, a novel lossy\ncompression paradigm that leverages decoder-only large LLMs to model scientific\ndata. LLMCOMP first quantizes 3D fields into discrete tokens, arranges them via\nZ-order curves to preserve locality, and applies coverage-guided sampling to\nenhance training efficiency. An autoregressive transformer is then trained with\nspatial-temporal embeddings to model token transitions. During compression, the\nmodel performs top-k prediction, storing only rank indices and fallback\ncorrections to ensure strict error bounds. Experiments on multiple reanalysis\ndatasets show that LLMCOMP consistently outperforms state-of-the-art\ncompressors, achieving up to 30% higher compression ratios under strict error\nbounds. These results highlight the potential of LLMs as general-purpose\ncompressors for high-fidelity scientific data.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u89e3\u7801\u5668\u578b\u5927\u6a21\u578b\u7684\u6709\u635f\u79d1\u5b66\u6570\u636e\u538b\u7f29\u65b9\u6cd5LLMCOMP\uff0c\u901a\u8fc7\u79bb\u6563\u5316\u3001Z\u66f2\u7ebf\u91cd\u6392\u548c\u81ea\u56de\u5f52Transformer\u5b9e\u73b0\uff0c\u5728\u4e25\u683c\u8bef\u5dee\u7ea6\u675f\u4e0b\u5bf9\u518d\u5206\u6790\u6570\u636e\u96c6\u538b\u7f29\u6bd4\u8f83\u73b0\u6709\u65b9\u6cd5\u63d0\u5347\u53ef\u8fbe30%\u3002", "motivation": "\u89e3\u51b3\u9ad8\u5206\u8fa8\u7387\u79d1\u5b66\u6a21\u62df\u548c\u89c2\u6d4b\u7cfb\u7edf\u4ea7\u751f\u7684\u5927\u89c4\u6a21\u65f6\u7a7a\u6570\u636e\u7684\u9ad8\u6548\u6709\u754c\u8bef\u5dee\u538b\u7f29\u95ee\u9898\uff0c\u5229\u7528\u89e3\u7801\u5668\u578b\u5927\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u5e8f\u5217\u5efa\u6a21\u65b9\u9762\u7684\u4f18\u52bf\uff0c\u63d0\u51fa\u901a\u7528\u538b\u7f29\u8303\u5f0f\u3002", "method": "\u91cf\u53163D\u5b57\u6bb5\u4e3a\u79bb\u6563token\uff1b\u6309Z-order\u91cd\u6392\u4fdd\u5b58\u7a7a\u95f4\u90bb\u8fd1\u6027\uff1b\u8986\u76d6\u5f15\u5bfc\u91c7\u6837\uff08coverage-guided sampling\uff09\u52a0\u901f\u8bad\u7ec3\u6570\u636e\u9009\u62e9\uff1b\u8bad\u7ec3\u5e26\u65f6\u7a7a\u5d4c\u5165\u7684\u81ea\u56de\u5f52Transformer\uff1b\u538b\u7f29\u65f6\u7528top-k\u9884\u6d4b\u53ea\u5b58\u79e9\u5e8f\u7d22\u5f15\u5e76\u7528\u56de\u9000\u4fee\u6b63\u4fdd\u8bc1\u8bef\u5dee\u754c\uff1b\u5728\u591a\u7ec4\u518d\u5206\u6790\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\u6bd4\u8f83\u3002", "result": "\u63d0\u51faLLMCOMP\uff1a\u5c063D\u573a\u91cf\u5316\u4e3a\u79bb\u6563token\u3001\u7528Z\u66f2\u7ebf\u4fdd\u5b58\u5c40\u90e8\u6027\u3001\u8986\u76d6\u5f15\u5bfc\u91c7\u6837\u63d0\u5347\u8bad\u7ec3\u6548\u7387\u3001\u7528\u81ea\u56de\u5f52Transformer\u5efa\u6a21\u65f6\u7a7a\u5d4c\u5165\u3002\u5728\u538b\u7f29\u65f6\u7528top-k\u9884\u6d4b\u4ec5\u5b58\u50a8\u79e9\u7d22\u5f15\u5e76\u8f85\u4ee5\u56de\u9000\u6821\u6b63\u4ee5\u4fdd\u8bc1\u4e25\u683c\u8bef\u5dee\u4e0a\u754c\u3002", "conclusion": "\u89e3\u7801\u5668\u578bLLMs\u53ef\u4ee5\u4f5c\u4e3a\u9ad8\u7cbe\u5ea6\u79d1\u5b66\u6570\u636e\u7684\u901a\u7528\u538b\u7f29\u5668\uff0c\u5728\u4fdd\u6301\u4e25\u683c\u8bef\u5dee\u754c\u9650\u4e0b\u663e\u8457\u63d0\u9ad8\u538b\u7f29\u6548\u7387\uff0c\u5c55\u793a\u4e86\u5c06\u5e8f\u5217\u5efa\u6a21\u80fd\u529b\u5e94\u7528\u4e8e\u79d1\u5b66\u6570\u636e\u538b\u7f29\u7684\u53ef\u884c\u6027\u4e0e\u6f5c\u529b\u3002"}}
{"id": "2510.24072", "categories": ["cs.CR", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2510.24072", "abs": "https://arxiv.org/abs/2510.24072", "authors": ["Austin Shouli", "Yulia Bobkova", "Ajay Kumar Shrestha"], "title": "Covert Surveillance in Smart Devices: A SCOUR Framework Analysis of Youth Privacy Implications", "comment": "To appear in the IEEE UEMCON 2025 proceedings", "summary": "This paper investigates how smart devices covertly capture private\nconversations and discusses in more in-depth the implications of this for youth\nprivacy. Using a structured review guided by the PRISMA methodology, the\nanalysis focuses on privacy concerns, data capture methods, data storage and\nsharing practices, and proposed technical mitigations. To structure and\nsynthesize findings, we introduce the SCOUR framework, encompassing\nSurveillance mechanisms, Consent and awareness, Operational data flow, Usage\nand exploitation, and Regulatory and technical safeguards. Findings reveal that\nsmart devices have been covertly capturing personal data, especially with smart\ntoys and voice-activated smart gadgets built for youth. These issues are\nworsened by unclear data collection practices and insufficient transparency in\nsmart device applications. Balancing privacy and utility in smart devices is\ncrucial, as youth are becoming more aware of privacy breaches and value their\npersonal data more. Strategies to improve regulatory and technical safeguards\nare also provided. The review identifies research gaps and suggests future\ndirections. The limitations of this literature review are also explained. The\nfindings have significant implications for policy development and the\ntransparency of data collection for smart devices.", "AI": {"tldr": "\u667a\u80fd\u8bbe\u5907\uff0c\u5c24\u5176\u662f\u9762\u5411\u9752\u5c11\u5e74\u7684\u667a\u80fd\u73a9\u5177\u4e0e\u8bed\u97f3\u8bbe\u5907\uff0c\u5b58\u5728\u6697\u4e2d\u5f55\u97f3\u4e0e\u6570\u636e\u6536\u96c6\u95ee\u9898\uff1b\u900f\u660e\u5ea6\u548c\u540c\u610f\u673a\u5236\u4e0d\u8db3\uff1b\u63d0\u51faSCOUR\u6846\u67b6\u5e76\u7ed9\u51fa\u76d1\u7ba1\u4e0e\u6280\u672f\u6539\u8fdb\u5efa\u8bae\u3002", "motivation": "\u63a2\u8ba8\u667a\u80fd\u8bbe\u5907\uff08\u5c24\u5176\u9762\u5411\u9752\u5c11\u5e74\u7684\u8bbe\u5907\uff09\u5982\u4f55\u6697\u4e2d\u6355\u83b7\u79c1\u4eba\u8c08\u8bdd\uff0c\u5206\u6790\u5bf9\u9752\u5c11\u5e74\u9690\u79c1\u7684\u6df1\u8fdc\u5f71\u54cd\u5e76\u63d0\u51fa\u53ef\u884c\u7684\u6280\u672f\u4e0e\u76d1\u7ba1\u5bf9\u7b56\u3002", "method": "\u91c7\u7528PRISMA\u7ed3\u6784\u5316\u6587\u732e\u56de\u987e\uff0c\u805a\u7126\u9690\u79c1\u5173\u5207\u3001\u6570\u636e\u6355\u83b7\u624b\u6bb5\u3001\u6570\u636e\u5b58\u50a8\u4e0e\u5171\u4eab\u5b9e\u8df5\u53ca\u6280\u672f\u7f13\u89e3\u65b9\u6848\uff1b\u901a\u8fc7SCOUR\u6846\u67b6\u7ec4\u7ec7\u4e0e\u7efc\u5408\u53d1\u73b0\u3002", "result": "\u667a\u80fd\u8bbe\u5907\u5728\u672a\u7ecf\u540c\u610f\u4e0b\u6355\u83b7\u79c1\u4eba\u8c08\u8bdd\uff1b\u5bf9\u9752\u5c11\u5e74\u9690\u79c1\u5f71\u54cd\u663e\u8457\uff1b\u63d0\u51faSCOUR\u6846\u67b6\uff08\u76d1\u63a7\u673a\u5236\u3001\u540c\u610f\u4e0e\u77e5\u60c5\u3001\u8fd0\u884c\u6570\u636e\u6d41\u3001\u4f7f\u7528\u4e0e\u6ee5\u7528\u3001\u76d1\u7ba1\u4e0e\u6280\u672f\u4fdd\u969c\uff09\uff1b\u8bc1\u636e\u4e3b\u8981\u6765\u81ea\u667a\u80fd\u73a9\u5177\u548c\u8bed\u97f3\u52a9\u624b\u7c7b\u8bbe\u5907\uff1b\u95ee\u9898\u6e90\u4e8e\u6a21\u7cca\u7684\u6570\u636e\u6536\u96c6\u5b9e\u8df5\u548c\u900f\u660e\u5ea6\u4e0d\u8db3\uff1b\u5efa\u8bae\u5728\u6cd5\u89c4\u4e0e\u6280\u672f\u4e0a\u52a0\u5f3a\u900f\u660e\u5ea6\u3001\u540c\u610f\u673a\u5236\u548c\u6570\u636e\u6700\u5c0f\u5316\uff1b\u8bc6\u522b\u7814\u7a76\u7a7a\u767d\u5e76\u63d0\u51fa\u672a\u6765\u65b9\u5411\uff1b\u6307\u51fa\u6587\u732e\u7efc\u8ff0\u7684\u5c40\u9650\u6027\u3002", "conclusion": "\u9700\u8981\u5728\u6cd5\u89c4\u3001\u4ea7\u54c1\u8bbe\u8ba1\u4e0e\u6280\u672f\u5b9e\u73b0\u5c42\u9762\u5f3a\u5316\u900f\u660e\u5ea6\u3001\u660e\u786e\u540c\u610f\u3001\u5b9e\u65bd\u6570\u636e\u6700\u5c0f\u5316\u4e0e\u672c\u5730\u5904\u7406\uff0c\u4ee5\u4fdd\u62a4\u9752\u5c11\u5e74\u9690\u79c1\uff0c\u5e76\u63a8\u52a8\u8fdb\u4e00\u6b65\u7814\u7a76\u586b\u8865\u65b9\u6cd5\u4e0e\u5b9e\u8df5\u8bc1\u636e\u7684\u7a7a\u767d\u3002"}}
{"id": "2510.23856", "categories": ["cs.AI", "68Txx"], "pdf": "https://arxiv.org/pdf/2510.23856", "abs": "https://arxiv.org/abs/2510.23856", "authors": ["Segev Shlomov", "Alon Oved", "Sami Marreed", "Ido Levy", "Offer Akrabi", "Avi Yaeli", "\u0141ukasz Str\u0105k", "Elizabeth Koumpan", "Yinon Goldshtein", "Eilam Shapira", "Nir Mashkif", "Asaf Adi"], "title": "From Benchmarks to Business Impact: Deploying IBM Generalist Agent in Enterprise Production", "comment": "AAAI Conference on Artificial Intelligence", "summary": "Agents are rapidly advancing in automating digital work, but enterprises face\na harder challenge: moving beyond prototypes to deployed systems that deliver\nmeasurable business value. This path is complicated by fragmented frameworks,\nslow development, and the absence of standardized evaluation practices.\nGeneralist agents have emerged as a promising direction, excelling on academic\nbenchmarks and offering flexibility across task types, applications, and\nmodalities. Yet, evidence of their use in production enterprise settings\nremains limited. This paper reports IBM's experience developing and piloting\nthe Computer Using Generalist Agent (CUGA), which has been open-sourced for the\ncommunity (https://github.com/cuga-project/cuga-agent). CUGA adopts a\nhierarchical planner--executor architecture with strong analytical foundations,\nachieving state-of-the-art performance on AppWorld and WebArena. Beyond\nbenchmarks, it was evaluated in a pilot within the Business-Process-Outsourcing\ntalent acquisition domain, addressing enterprise requirements for scalability,\nauditability, safety, and governance. To support assessment, we introduce\nBPO-TA, a 26-task benchmark spanning 13 analytics endpoints. In preliminary\nevaluations, CUGA approached the accuracy of specialized agents while\nindicating potential for reducing development time and cost. Our contribution\nis twofold: presenting early evidence of generalist agents operating at\nenterprise scale, and distilling technical and organizational lessons from this\ninitial pilot. We outline requirements and next steps for advancing\nresearch-grade architectures like CUGA into robust, enterprise-ready systems.", "AI": {"tldr": "CUGA\u91c7\u7528\u5206\u5c42planner\u2013executor\u67b6\u6784\uff0c\u5728AppWorld\u548cWebArena\u4e0a\u8868\u73b0\u4f18\u79c0\uff0c\u5e76\u5728BPO\u4eba\u624d\u62db\u52df\u9886\u57df\u7684\u4f01\u4e1a\u8bd5\u70b9\u4e2d\u63a5\u8fd1\u4e13\u7528\u4ee3\u7406\u7684\u51c6\u786e\u7387\uff0c\u540c\u65f6\u6539\u5584\u5f00\u53d1\u6548\u7387\u548c\u6cbb\u7406\u517c\u5bb9\u6027\u3002", "motivation": "\u4f01\u4e1a\u4ece\u539f\u578b\u5230\u53ef\u6295\u4ea7\u7cfb\u7edf\u9762\u4e34\u788e\u7247\u5316\u6846\u67b6\u3001\u5f00\u53d1\u6162\u548c\u8bc4\u4f30\u7f3a\u5931\u95ee\u9898\uff1b\u901a\u7528\u4ee3\u7406\u6709\u671b\u964d\u4f4e\u5f00\u53d1\u6210\u672c\u5e76\u63d0\u4f9b\u8de8\u4efb\u52a1/\u6a21\u6001\u7684\u7075\u6d3b\u6027\uff0c\u4f46\u9700\u5b9e\u8bc1\u5176\u5728\u4f01\u4e1a\u73af\u5883\u4e2d\u7684\u8868\u73b0\u3002", "method": "\u91c7\u7528\u6709\u7406\u8bba\u652f\u6491\u7684\u5206\u5c42planner\u2013executor\u67b6\u6784\uff0c\u7ed3\u5408\u5206\u6790\u5de5\u5177\u94fe\u4e0e\u8bc4\u4f30\u57fa\u51c6\uff08AppWorld\u3001WebArena\u3001BPO-TA\uff09\uff0c\u5e76\u5728\u771f\u5b9e\u4e1a\u52a1\u6d41\u7a0b\u5916\u5305\u4eba\u624d\u62db\u52df\u6d41\u7a0b\u4e2d\u8fdb\u884c\u8bd5\u70b9\u9a8c\u8bc1\u3002", "result": "IBM\u5f00\u53d1\u5e76\u5f00\u6e90\u4e86\u9762\u5411\u4f01\u4e1a\u7684\u901a\u7528\u4ee3\u7406CUGA\uff0c\u5e76\u5728\u57fa\u51c6\u548c\u4f01\u4e1a\u8bd5\u70b9\u4e2d\u53d6\u5f97\u6709\u524d\u666f\u7684\u7ed3\u679c\u3002", "conclusion": "CUGA\u5c55\u793a\u4e86\u901a\u7528\u4ee3\u7406\u5728\u751f\u4ea7\u4f01\u4e1a\u73af\u5883\u4e2d\u7684\u53ef\u884c\u6027\uff0c\u4f46\u4ecd\u9700\u89e3\u51b3\u6269\u5c55\u6027\u3001\u5b89\u5168\u3001\u5ba1\u8ba1\u548c\u8bc4\u4f30\u6807\u51c6\u5316\u7b49\u4f01\u4e1a\u7ea7\u6311\u6218\u3002"}}
{"id": "2510.23633", "categories": ["cs.LG", "cs.AI", "cs.CV", "eess.IV"], "pdf": "https://arxiv.org/pdf/2510.23633", "abs": "https://arxiv.org/abs/2510.23633", "authors": ["Xun Su", "Hiroyuki Kasai"], "title": "Noise is All You Need: Solving Linear Inverse Problems by Noise Combination Sampling with Diffusion Models", "comment": "9 pages", "summary": "Pretrained diffusion models have demonstrated strong capabilities in\nzero-shot inverse problem solving by incorporating observation information into\nthe generation process of the diffusion models. However, this presents an\ninherent dilemma: excessive integration can disrupt the generative process,\nwhile insufficient integration fails to emphasize the constraints imposed by\nthe inverse problem. To address this, we propose \\emph{Noise Combination\nSampling}, a novel method that synthesizes an optimal noise vector from a noise\nsubspace to approximate the measurement score, replacing the noise term in the\nstandard Denoising Diffusion Probabilistic Models process. This enables\nconditional information to be naturally embedded into the generation process\nwithout reliance on step-wise hyperparameter tuning. Our method can be applied\nto a wide range of inverse problem solvers, including image compression, and,\nparticularly when the number of generation steps $T$ is small, achieves\nsuperior performance with negligible computational overhead, significantly\nimproving robustness and stability.", "AI": {"tldr": "\u63d0\u51faNoise Combination Sampling\uff08\u566a\u58f0\u7ec4\u5408\u91c7\u6837\uff09\u65b9\u6cd5\uff0c\u5728\u6269\u6563\u6a21\u578b\u53bb\u566a\u8fc7\u7a0b\u4e2d\u4ece\u566a\u58f0\u5b50\u7a7a\u95f4\u5408\u6210\u6700\u4f18\u566a\u58f0\u5411\u91cf\u4ee5\u8fd1\u4f3c\u6d4b\u91cf\u5206\u6570\uff0c\u5c06\u5176\u66ff\u6362\u6807\u51c6DDPM\u7684\u566a\u58f0\u9879\uff0c\u4ece\u800c\u5728\u4e0d\u9700\u9010\u6b65\u8c03\u53c2\u4e0b\u5c06\u89c2\u6d4b\u4fe1\u606f\u81ea\u7136\u5d4c\u5165\u751f\u6210\u6d41\u7a0b\u3002\u9002\u7528\u4e8e\u591a\u79cd\u9006\u95ee\u9898\uff0c\u5c24\u5176\u5728\u6b65\u6570\u5c11\u65f6\u63d0\u5347\u6027\u80fd\u3001\u7a33\u5b9a\u6027\u548c\u9c81\u68d2\u6027\uff0c\u8ba1\u7b97\u5f00\u9500\u53ef\u5ffd\u7565\u3002", "motivation": "\u5728\u7528\u9884\u8bad\u7ec3\u6269\u6563\u6a21\u578b\u505a\u96f6\u6837\u672c\u9006\u95ee\u9898\u6c42\u89e3\u65f6\uff0c\u5982\u4f55\u5c06\u89c2\u6d4b\u4fe1\u606f\u878d\u5165\u751f\u6210\u8fc7\u7a0b\uff1a\u8fc7\u5ea6\u878d\u5165\u4f1a\u7834\u574f\u751f\u6210\u8fc7\u7a0b\uff0c\u878d\u5165\u4e0d\u8db3\u5219\u65e0\u6cd5\u6ee1\u8db3\u9006\u95ee\u9898\u7ea6\u675f\uff0c\u5f53\u524d\u65b9\u6cd5\u9700\u8981\u9010\u6b65\u8c03\u53c2\uff0c\u7f3a\u4e4f\u7a33\u5065\u6027\u548c\u901a\u7528\u6027\u3002", "method": "\u5b9a\u4e49\u4e00\u4e2a\u566a\u58f0\u5b50\u7a7a\u95f4\u5e76\u5728\u8be5\u5b50\u7a7a\u95f4\u5185\u641c\u7d22\u6216\u5408\u6210\u4e00\u4e2a\u6700\u4f18\u566a\u58f0\u5411\u91cf\u6765\u8fd1\u4f3c\u6d4b\u91cf\u5206\u6570\uff0c\u5c06\u8be5\u5411\u91cf\u66ff\u6362\u6807\u51c6DDPM\u6d41\u7a0b\u4e2d\u7684\u566a\u58f0\u9879\uff0c\u4ece\u800c\u5728\u6bcf\u4e00\u6b65\u81ea\u7136\u5f15\u5165\u6761\u4ef6\u4fe1\u606f\u3002\u8be5\u65b9\u6cd5\u907f\u514d\u4e86\u8fc7\u5ea6\u6216\u4e0d\u8db3\u6574\u5408\u89c2\u6d4b\u4fe1\u606f\u7684\u56f0\u5883\uff0c\u65e0\u9700\u9010\u6b65\u8c03\u53c2\u3002", "result": "\u5728\u591a\u79cd\u9006\u95ee\u9898\uff08\u5305\u62ec\u56fe\u50cf\u538b\u7f29\uff09\u4e0a\u9a8c\u8bc1\uff0c\u7279\u522b\u662f\u5728\u751f\u6210\u6b65\u6570T\u8f83\u5c11\u65f6\uff0cNoise Combination Sampling\u663e\u8457\u63d0\u9ad8\u6027\u80fd\uff0c\u540c\u65f6\u51e0\u4e4e\u4e0d\u589e\u52a0\u8ba1\u7b97\u5f00\u9500\uff0c\u63d0\u5347\u4e86\u9c81\u68d2\u6027\u548c\u7a33\u5b9a\u6027\u3002", "conclusion": "Noise Combination Sampling\u80fd\u5728\u4e0d\u4f9d\u8d56\u6b65\u7ea7\u8d85\u53c2\u6570\u8c03\u8282\u7684\u60c5\u51b5\u4e0b\uff0c\u628a\u89c2\u6d4b\u7ea6\u675f\u6709\u6548\u5730\u878d\u5165\u6269\u6563\u6a21\u578b\u751f\u6210\u8fc7\u7a0b\uff0c\u63d0\u5347\u5728\u5c0f\u6b65\u6570\u4e0b\u7684\u9006\u95ee\u9898\u6c42\u89e3\u6027\u80fd\u3001\u7a33\u5b9a\u6027\u4e0e\u9c81\u68d2\u6027\uff0c\u9002\u7528\u8303\u56f4\u5e7f\u6cdb\u4e14\u8ba1\u7b97\u6210\u672c\u4f4e\u3002"}}
{"id": "2510.24101", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.24101", "abs": "https://arxiv.org/abs/2510.24101", "authors": ["Nam Tran", "Khoa Nguyen", "Dongxi Liu", "Josef Pieprzyk", "Willy Susilo"], "title": "Traceable Signatures from Lattices", "comment": "45 pages", "summary": "Traceable signatures (Kiayas et al., EUROCRYPT 2004) is an anonymous digital\nsignature system that extends the tracing power of the opening authority in\ngroup signatures. There are many known constructions of traceable signatures,\nbut all are based on number-theoretic/pairing assumptions. For such reason,\nthey may not be secure in the presence of quantum computers. This work revisits\nthe notion of traceable signatures and presents a lattice-based construction\nprovably secure in the quantum random oracle model (QROM).", "AI": {"tldr": "\u63d0\u51fa\u7b2c\u4e00\u4e2a\u57fa\u4e8e\u683c\u7684\u53ef\u8ffd\u6eaf\u7b7e\u540d\uff08traceable signatures\uff09\u6784\u9020\uff0c\u5728\u91cf\u5b50\u968f\u673a\u9884\u8a00\u673a\u6a21\u578b\u4e0b\u53ef\u8bc1\u5b89\u5168\uff0c\u586b\u8865\u4e86\u73b0\u6709\u53ea\u57fa\u4e8e\u6570\u8bba\u5047\u8bbe\u7684\u7a7a\u767d", "motivation": "\u73b0\u6709\u53ef\u8ffd\u6eaf\u7b7e\u540d\u65b9\u6848\u4f9d\u8d56\u6570\u8bba/\u914d\u5bf9\u5047\u8bbe\uff0c\u9762\u5bf9\u91cf\u5b50\u653b\u51fb\u53ef\u80fd\u5931\u6548\uff0c\u9700\u6784\u9020\u540e\u91cf\u5b50\u5b89\u5168\u7684\u66ff\u4ee3\u65b9\u6848", "method": "\u91c7\u7528\u683c\u5bc6\u7801\u5b66\u5de5\u5177\uff08\u5982\u5b66\u4e60\u5e26\u566a\u58f0LWE/\u77ed\u6574\u6570\u89e3SIS\u6280\u672f\uff09\u3001\u8bbe\u8ba1\u9002\u914d\u7fa4\u7b7e\u4e0e\u5f00\u6743\u673a\u5236\u7684\u7b7e\u540d\u548c\u5f00\u8bc1\u6d41\u7a0b\uff0c\u5e76\u5728QROM\u4e2d\u7528\u7f16\u7a0b\u54c8\u5e0c/\u91cd\u7f16\u7a0b\u6280\u5de7\u8bc1\u660e\u4e0d\u53ef\u533a\u5206\u6027\u4e0e\u8ffd\u8e2a\u6027", "result": "A lattice-based traceable signature scheme secure in QROM", "conclusion": "\u4f5c\u8005\u6210\u529f\u6784\u5efa\u4e86\u57fa\u4e8e\u683c\u7684\u53ef\u8ffd\u6eaf\u7b7e\u540d\u65b9\u6848\uff0c\u5e76\u5728QROM\u4e0b\u7ed9\u51fa\u5f62\u5f0f\u5316\u5b89\u5168\u8bc1\u660e\uff0c\u8868\u660e\u5728\u91cf\u5b50\u8ba1\u7b97\u5a01\u80c1\u4e0b\u4ecd\u80fd\u4fdd\u6301\u533f\u540d\u6027\u4e0e\u53ef\u8ffd\u8e2a\u6027"}}
{"id": "2510.23881", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.23881", "abs": "https://arxiv.org/abs/2510.23881", "authors": ["Xidong Feng", "Vivek Veeriah", "Marcus Chiam", "Michael Dennis", "Ryan Pachauri", "Thomas Tumiel", "Federico Barbero", "Johan Obando-Ceron", "Jiaxin Shi", "Satinder Singh", "Shaobo Hou", "Nenad Toma\u0161ev", "Tom Zahavy"], "title": "Generating Creative Chess Puzzles", "comment": null, "summary": "While Generative AI rapidly advances in various domains, generating truly\ncreative, aesthetic, and counter-intuitive outputs remains a challenge. This\npaper presents an approach to tackle these difficulties in the domain of chess\npuzzles. We start by benchmarking Generative AI architectures, and then\nintroduce an RL framework with novel rewards based on chess engine search\nstatistics to overcome some of those shortcomings. The rewards are designed to\nenhance a puzzle's uniqueness, counter-intuitiveness, diversity, and realism.\nOur RL approach dramatically increases counter-intuitive puzzle generation by\n10x, from 0.22\\% (supervised) to 2.5\\%, surpassing existing dataset rates\n(2.1\\%) and the best Lichess-trained model (0.4\\%). Our puzzles meet novelty\nand diversity benchmarks, retain aesthetic themes, and are rated by human\nexperts as more creative, enjoyable, and counter-intuitive than composed book\npuzzles, even approaching classic compositions. Our final outcome is a curated\nbooklet of these AI-generated puzzles, which is acknowledged for creativity by\nthree world-renowned experts.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u57fa\u4e8e\u68cb\u5f15\u64ce\u641c\u7d22\u7edf\u8ba1\u7684\u65b0\u578b\u5956\u52b1\u51fd\u6570\u5c06\u5f3a\u5316\u5b66\u4e60\u5e94\u7528\u4e8e\u56fd\u9645\u8c61\u68cb\u9898\u76ee\u751f\u6210\uff0c\u663e\u8457\u63d0\u5347\u53cd\u76f4\u89c9\u6027\u4e0e\u521b\u9020\u6027\uff0c\u751f\u6210\u7ed3\u679c\u8d85\u8d8a\u73b0\u6709\u6a21\u578b\u5e76\u83b7\u5f97\u9876\u7ea7\u4e13\u5bb6\u8ba4\u53ef\u3002", "motivation": "\u89e3\u51b3\u751f\u6210\u5f0fAI\u5728\u521b\u9020\u6027\u3001\u7f8e\u5b66\u548c\u53cd\u76f4\u89c9\u8f93\u51fa\u65b9\u9762\u7684\u4e0d\u8db3\uff0c\u4e13\u6ce8\u4e8e\u56fd\u9645\u8c61\u68cb\u9898\u76ee\u751f\u6210\u9886\u57df\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u548c\u57fa\u4e8e\u68cb\u5c40\u5f15\u64ce\u641c\u7d22\u7edf\u8ba1\u7684\u65b0\u578b\u5956\u52b1\u8bbe\u8ba1\u6765\u63d0\u5347\u9898\u76ee\u7684\u72ec\u7279\u6027\u3001\u53cd\u76f4\u89c9\u6027\u3001\u591a\u6837\u6027\u548c\u771f\u5b9e\u6027\u3002", "method": "\u5148\u57fa\u51c6\u6d4b\u8bd5\u591a\u79cd\u751f\u6210\u5f0fAI\u67b6\u6784\uff0c\u968f\u540e\u6784\u5efa\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u5e76\u8bbe\u8ba1\u4e00\u7ec4\u57fa\u4e8e\u68cb\u5f15\u64ce\u641c\u7d22\u7edf\u8ba1\u7684\u5956\u52b1\uff08\u8861\u91cf\u552f\u4e00\u6027\u3001\u53cd\u76f4\u89c9\u6027\u3001\u591a\u6837\u6027\u3001\u771f\u5b9e\u6027\u7b49\uff09\uff0c\u8bad\u7ec3\u6a21\u578b\u5e76\u4e0e\u76d1\u7763\u5b66\u4e60/\u73b0\u6709\u6a21\u578b\u53ca\u4e66\u672c\u4f5c\u54c1\u8fdb\u884c\u6bd4\u8f83\uff0c\u6700\u540e\u901a\u8fc7\u4e13\u5bb6\u8bc4\u5ba1\u548c\u624b\u5de5\u7b56\u5212\u7684\u9898\u96c6\u5c55\u793a\u6210\u679c\u3002", "result": "\u63d0\u51fa\u5e76\u9a8c\u8bc1\u4e86\u4e00\u4e2a\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u4f7f\u7528\u57fa\u4e8e\u68cb\u5f15\u64ce\u641c\u7d22\u7edf\u8ba1\u7684\u5956\u52b1\uff0c\u5927\u5e45\u63d0\u9ad8\u53cd\u76f4\u89c9\u9898\u76ee\u751f\u6210\uff0c\u4ece\u76d1\u7763\u5b66\u4e60\u76840.22%\u63d0\u5347\u52302.5%\uff0c\u8d85\u8fc7\u73b0\u6709\u6570\u636e\u96c6(2.1%)\u548c\u6700\u4f73Lichess\u8bad\u7ec3\u6a21\u578b(0.4%)\uff1b\u751f\u6210\u7684\u9898\u76ee\u5728\u65b0\u9896\u6027\u3001\u591a\u6837\u6027\u548c\u7f8e\u5b66\u4e3b\u9898\u4e0a\u8fbe\u6807\uff0c\u5e76\u88ab\u4eba\u7c7b\u4e13\u5bb6\u8bc4\u4e3a\u66f4\u5177\u521b\u9020\u6027\u548c\u8da3\u5473\u6027\uff0c\u6700\u7ec8\u6574\u7406\u6210\u4e00\u672c\u7531\u4e09\u4f4d\u4e16\u754c\u7ea7\u4e13\u5bb6\u8ba4\u53ef\u7684AI\u751f\u6210\u4e60\u9898\u96c6\u3002", "conclusion": "\u57fa\u4e8e\u641c\u7d22\u7edf\u8ba1\u8bbe\u8ba1\u7684\u5956\u52b1\u80fd\u6709\u6548\u5f15\u5bfc\u5f3a\u5316\u5b66\u4e60\u751f\u6210\u66f4\u5177\u521b\u9020\u6027\u3001\u53cd\u76f4\u89c9\u6027\u4e0e\u591a\u6837\u6027\u7684\u68cb\u9898\uff0c\u751f\u6210\u8d28\u91cf\u63a5\u8fd1\u7ecf\u5178\u4f5c\u5e76\u83b7\u4e13\u5bb6\u8ba4\u53ef\uff0c\u5c55\u793a\u4e86\u5728\u521b\u9020\u6027\u751f\u6210\u4efb\u52a1\u4e2d\u7ed3\u5408\u9886\u57df\u6027\u4fe1\u53f7\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2510.23634", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23634", "abs": "https://arxiv.org/abs/2510.23634", "authors": ["Soutrik Sarangi", "Yonatan Sverdlov", "Nadav Dym", "Abir De"], "title": "Monotone and Separable Set Functions: Characterizations and Neural Models", "comment": null, "summary": "Motivated by applications for set containment problems, we consider the\nfollowing fundamental problem: can we design set-to-vector functions so that\nthe natural partial order on sets is preserved, namely $S\\subseteq T \\text{ if\nand only if } F(S)\\leq F(T) $. We call functions satisfying this property\nMonotone and Separating (MAS) set functions. % We establish lower and upper\nbounds for the vector dimension necessary to obtain MAS functions, as a\nfunction of the cardinality of the multisets and the underlying ground set. In\nthe important case of an infinite ground set, we show that MAS functions do not\nexist, but provide a model called our which provably enjoys a relaxed MAS\nproperty we name \"weakly MAS\" and is stable in the sense of Holder continuity.\nWe also show that MAS functions can be used to construct universal models that\nare monotone by construction and can approximate all monotone set functions.\nExperimentally, we consider a variety of set containment tasks. The experiments\nshow the benefit of using our our model, in comparison with standard set models\nwhich do not incorporate set containment as an inductive bias. Our code is\navailable in https://github.com/yonatansverdlov/Monotone-Embedding.", "AI": {"tldr": "Paper defines MAS functions that encode set inclusion via vector order, gives theoretical limits (no MAS for infinite ground sets), proposes a weakly MAS H\u00f6lder-stable model, proves universality for monotone functions, and demonstrates empirical gains on containment tasks.", "motivation": "Design set-to-vector functions preserving set partial order to solve set containment problems and provide inductive bias for models handling set inclusion.", "method": "The paper provides lower/upper bounds on embedding dimension, proves impossibility for infinite ground sets, constructs a \u2018weakly MAS\u2019 H\u00f6lder-continuous model, and uses MAS embeddings to create universal monotone approximators; experiments compare models on set containment datasets.", "result": "Introduces Monotone and Separating (MAS) set functions; proves nonexistence for infinite ground sets, introduces a \u2018weakly MAS\u2019 model stable under H\u00f6lder continuity; shows MAS can build universal monotone models approximating all monotone set functions; empirical results favor proposed model on containment tasks; code released.", "conclusion": "Finite-ground MAS embeddings possible with dimension bounds; no exact MAS for infinite ground sets but a practically useful weakly MAS continuous model exists; MAS embeddings enable universal monotone models and improve performance on containment tasks."}}
{"id": "2510.24141", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.24141", "abs": "https://arxiv.org/abs/2510.24141", "authors": ["Miao Zhang", "Shenao Wang", "Guilin Zheng", "Yanjie Zhao", "Haoyu Wang"], "title": "Demystifying Cookie Sharing Risks in WebView-based Mobile App-in-app Ecosystems", "comment": "To appear in the 40th IEEE/ACM International Conference on Automated\n  Software Engineering (ASE'25)", "summary": "Mini-programs, an emerging mobile application paradigm within super-apps,\noffer a seamless and installation-free experience. However, the adoption of the\nweb-view component has disrupted their isolation mechanisms, exposing new\nattack surfaces and vulnerabilities. In this paper, we introduce a novel\nvulnerability called Cross Mini-program Cookie Sharing (CMCS), which arises\nfrom the shared web-view environment across mini-programs. This vulnerability\nallows unauthorized data exchange across mini-programs by enabling one\nmini-program to access cookies set by another within the same web-view context,\nviolating isolation principles. As a preliminary step, we analyzed the web-view\nmechanisms of four major platforms, including WeChat, AliPay, TikTok, and\nBaidu, and found that all of them are affected by CMCS vulnerabilities.\nFurthermore, we demonstrate the collusion attack enabled by CMCS, where\nprivileged mini-programs exfiltrate sensitive user data via cookies accessible\nto unprivileged mini-programs. To measure the impact of collusion attacks\nenabled by CMCS vulnerabilities in the wild, we developed MiCoScan, a static\nanalysis tool that detects mini-programs affected by CMCS vulnerabilities.\nMiCoScan employs web-view context modeling to identify clusters of\nmini-programs sharing the same web-view domain and cross-webview data flow\nanalysis to detect sensitive data transmissions to/from web-views. Using\nMiCoScan, we conducted a large-scale analysis of 351,483 mini-programs,\nidentifying 45,448 clusters sharing web-view domains, 7,965 instances of\nprivileged data transmission, and 9,877 mini-programs vulnerable to collusion\nattacks. Our findings highlight the widespread prevalence and significant\nsecurity risks posed by CMCS vulnerabilities, underscoring the urgent need for\nimproved isolation mechanisms in mini-program ecosystems.", "AI": {"tldr": "Introduces CMCS vulnerability from shared web-views enabling cross-mini-program cookie access; builds MiCoScan static analyzer; finds widespread vulnerabilities and many potential collusion attacks in real-world mini-programs", "motivation": "Investigate security risks from shared web-view environments allowing cookie sharing across mini-programs (CMCS) and measure prevalence in major platforms' ecosystems", "method": "Static analysis of web-view isolation in mini-programs", "result": "Identified CMCS vulnerability across WeChat, AliPay, TikTok, Baidu; demonstrated collusion attacks; developed MiCoScan to detect affected mini-programs; analyzed 351,483 mini-programs and found extensive clusters and vulnerable apps", "conclusion": "CMCS is widespread across major mini-program platforms, enabling collusion attacks via shared cookies; urgent need for stronger isolation and mitigation techniques in mini-program ecosystems"}}
{"id": "2510.23882", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23882", "abs": "https://arxiv.org/abs/2510.23882", "authors": ["Adil Rasheed", "Oscar Ravik", "Omer San"], "title": "Hybrid Modeling, Sim-to-Real Reinforcement Learning, and Large Language Model Driven Control for Digital Twins", "comment": null, "summary": "This work investigates the use of digital twins for dynamical system modeling\nand control, integrating physics-based, data-driven, and hybrid approaches with\nboth traditional and AI-driven controllers. Using a miniature greenhouse as a\ntest platform, four predictive models Linear, Physics-Based Modeling (PBM),\nLong Short Term Memory (LSTM), and Hybrid Analysis and Modeling (HAM) are\ndeveloped and compared under interpolation and extrapolation scenarios. Three\ncontrol strategies Model Predictive Control (MPC), Reinforcement Learning (RL),\nand Large Language Model (LLM) based control are also implemented to assess\ntrade-offs in precision, adaptability, and implementation effort. Results show\nthat in modeling HAM provides the most balanced performance across accuracy,\ngeneralization, and computational efficiency, while LSTM achieves high\nprecision at greater resource cost. Among controllers, MPC delivers robust and\npredictable performance, RL demonstrates strong adaptability, and LLM-based\ncontrollers offer flexible human-AI interaction when coupled with predictive\ntools.", "AI": {"tldr": "\u5728\u5fae\u578b\u6e29\u5ba4\u6d4b\u8bd5\u4e2d\uff0cHAM\u6a21\u578b\u5728\u63d2\u503c\u4e0e\u5916\u63a8\u4efb\u52a1\u4e2d\u8868\u73b0\u6700\u5e73\u8861\uff0cLSTM\u7cbe\u5ea6\u6700\u4f73\u4f46\u4ee3\u4ef7\u9ad8\uff1bMPC\u662f\u7a33\u5065\u63a7\u5236\u9009\u62e9\uff0cRL\u66f4\u7075\u6d3b\uff0cLLM\u63a7\u5236\u4fa7\u91cd\u4eba\u673a\u4ea4\u4e92\u4e0e\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u63a2\u7d22\u6570\u5b57\u5b6a\u751f\u5728\u52a8\u529b\u7cfb\u7edf\u5efa\u6a21\u4e0e\u63a7\u5236\u4e2d\u7684\u5e94\u7528\uff0c\u8bc4\u4f30\u7269\u7406\u9a71\u52a8\u3001\u6570\u636e\u9a71\u52a8\u4e0e\u6df7\u5408\u6a21\u578b\u4ee5\u53ca\u4f20\u7edf\u4e0eAI\u63a7\u5236\u5668\u7684\u80fd\u529b\u4e0e\u6743\u8861\uff0c\u4e3a\u5de5\u7a0b\u5b9e\u8df5\u63d0\u4f9b\u6307\u5bfc\u3002", "method": "\u5f00\u53d1\u5e76\u6bd4\u8f83\u56db\u7c7b\u9884\u6d4b\u6a21\u578b\uff08\u7ebf\u6027\u3001PBM\u3001LSTM\u3001HAM\uff09\uff0c\u5728\u5fae\u578b\u6e29\u5ba4\u5e73\u53f0\u4e0a\u8fdb\u884c\u63d2\u503c\u4e0e\u5916\u63a8\u8bc4\u4f30\uff1b\u5b9e\u73b0\u5e76\u5bf9\u6bd4MPC\u3001RL\u3001LLM\u4e09\u79cd\u63a7\u5236\u7b56\u7565\uff0c\u57fa\u4e8e\u7cbe\u5ea6\u3001\u9002\u5e94\u6027\u3001\u5b9e\u73b0\u590d\u6742\u5ea6\u7b49\u6307\u6807\u5206\u6790\u6743\u8861\u3002", "result": "HAM\u5728\u51c6\u786e\u6027\u3001\u6cdb\u5316\u6027\u3001\u8ba1\u7b97\u6548\u7387\u65b9\u9762\u8868\u73b0\u5747\u8861\uff1bLSTM\u7cbe\u5ea6\u9ad8\u4f46\u8d44\u6e90\u5f00\u9500\u5927\uff1b\u7ebf\u6027\u4e0ePBM\u9002\u5408\u4f4e\u590d\u6742\u5ea6\u573a\u666f\u3002MPC\u7a33\u5065\u53ef\u9884\u6d4b\uff0cRL\u9002\u5e94\u6027\u5f3a\uff0cLLM\u63a7\u5236\u53ef\u4ea4\u4e92\u6027\u9ad8\u4f46\u9700\u914d\u5408\u9884\u6d4b\u5de5\u5177\u3002", "conclusion": "\u7efc\u5408\u5efa\u6a21\u4e0e\u63a7\u5236\u9700\u6c42\uff0c\u63a8\u8350HAM\u914d\u5408MPC\u4f5c\u4e3a\u9996\u9009\u65b9\u6848\uff1b\u5bf9\u9ad8\u7cbe\u5ea6\u8981\u6c42\u53ef\u9009LSTM\uff1b\u9700\u8981\u5b66\u4e60\u4e0e\u9002\u5e94\u6027\u573a\u666f\u53ef\u9009RL\uff1b\u6ce8\u91cd\u4ea4\u4e92\u4e0e\u53ef\u89e3\u91ca\u6027\u65f6\u53ef\u5f15\u5165LLM\u4f5c\u4e3a\u8f85\u52a9\u63a7\u5236\u5c42\u3002"}}
{"id": "2510.23635", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23635", "abs": "https://arxiv.org/abs/2510.23635", "authors": ["Andrea Bontempelli", "Matteo Busso", "Leonardo Javier Malcotti", "Fausto Giunchiglia"], "title": "Help the machine to help you: an evaluation in the wild of egocentric data cleaning via skeptical learning", "comment": null, "summary": "Any digital personal assistant, whether used to support task performance,\nanswer questions, or manage work and daily life, including fitness schedules,\nrequires high-quality annotations to function properly. However, user\nannotations, whether actively produced or inferred from context (e.g., data\nfrom smartphone sensors), are often subject to errors and noise. Previous\nresearch on Skeptical Learning (SKEL) addressed the issue of noisy labels by\ncomparing offline active annotations with passive data, allowing for an\nevaluation of annotation accuracy. However, this evaluation did not include\nconfirmation from end-users, the best judges of their own context. In this\nstudy, we evaluate SKEL's performance in real-world conditions with actual\nusers who can refine the input labels based on their current perspectives and\nneeds. The study involves university students using the iLog mobile application\non their devices over a period of four weeks. The results highlight the\nchallenges of finding the right balance between user effort and data quality,\nas well as the potential benefits of using SKEL, which include reduced\nannotation effort and improved quality of collected data.", "AI": {"tldr": "\u57284\u5468\u7684iLog\u771f\u5b9e\u7528\u6237\u5b9e\u9a8c\u4e2d\uff0cSKEL\u5728\u964d\u4f4e\u6807\u6ce8\u52b3\u52a8\u4e0e\u6539\u5584\u6570\u636e\u8d28\u91cf\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u9700\u66f4\u7cbe\u7ec6\u7684\u7528\u6237\u786e\u8ba4\u7b56\u7565\u6765\u5e73\u8861\u7528\u6237\u8d1f\u62c5\u4e0e\u6807\u6ce8\u51c6\u786e\u6027\u3002", "motivation": "\u8003\u8651\u5230\u4e2a\u4eba\u52a9\u624b\u548c\u751f\u6d3b\u7ba1\u7406\u5e94\u7528\u9ad8\u5ea6\u4f9d\u8d56\u9ad8\u8d28\u91cf\u6807\u7b7e\uff0c\u800c\u7528\u6237\u751f\u6210\u6216\u88ab\u52a8\u6536\u96c6\u7684\u6ce8\u91ca\u5e38\u542b\u566a\u58f0\uff0c\u7814\u7a76\u65e8\u5728\u6d4b\u8bd5SKEL\u5728\u73b0\u5b9e\u573a\u666f\u4e2d\u901a\u8fc7\u4e0e\u7528\u6237\u4ea4\u4e92\u6765\u63d0\u9ad8\u6807\u6ce8\u51c6\u786e\u6027\u4e0e\u964d\u4f4e\u6807\u6ce8\u8d1f\u62c5\u7684\u53ef\u884c\u6027\u3002", "method": "\u5728\u79fb\u52a8\u5e94\u7528iLog\u4e0a\u8fdb\u884c\u4e3a\u671f\u56db\u5468\u7684\u5b9e\u5730\u7528\u6237\u5b9e\u9a8c\uff0c\u62db\u52df\u5927\u5b66\u751f\u4f5c\u4e3a\u53c2\u4e0e\u8005\uff0c\u6536\u96c6\u5176\u4f20\u611f\u5668\u88ab\u52a8\u6570\u636e\u4e0e\u4e3b\u52a8\u6ce8\u91ca\uff0c\u5e76\u5141\u8bb8\u7528\u6237\u5bf9\u7cfb\u7edf\u63a8\u65ad\u7684\u6807\u7b7e\u8fdb\u884c\u5b9e\u65f6\u4fee\u6b63\uff0c\u4ee5\u8bc4\u4f30SKEL\u5728\u771f\u5b9e\u73af\u5883\u4e0b\u7684\u8868\u73b0\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cSKEL\u53ef\u663e\u8457\u51cf\u5c11\u7528\u6237\u4e3b\u52a8\u6ce8\u91ca\u7684\u5de5\u4f5c\u91cf\u5e76\u63d0\u5347\u6574\u4f53\u6807\u7b7e\u8d28\u91cf\uff0c\u4f46\u6548\u679c\u968f\u7528\u6237\u786e\u8ba4\u7387\u3001\u4efb\u52a1\u590d\u6742\u5ea6\u4e0e\u754c\u9762\u4ea4\u4e92\u8bbe\u8ba1\u53d8\u5316\u800c\u6ce2\u52a8\uff1b\u540c\u65f6\u53d1\u73b0\u9700\u8981\u5728\u7528\u6237\u6295\u5165\uff08\u8017\u65f6/\u9891\u7387\uff09\u4e0e\u6570\u636e\u8d28\u91cf\u4e4b\u95f4\u505a\u6743\u8861\u3002", "conclusion": "\u672c\u7814\u7a76\u8868\u660e\uff0c\u5728\u771f\u5b9e\u7528\u6237\u73af\u5883\u4e2d\uff0cSkeptical Learning (SKEL) \u80fd\u5728\u964d\u4f4e\u6807\u6ce8\u6210\u672c\u7684\u540c\u65f6\u63d0\u5347\u6570\u636e\u8d28\u91cf\uff0c\u4f46\u5176\u6548\u679c\u4f9d\u8d56\u4e8e\u7528\u6237\u53c2\u4e0e\u5ea6\u4e0e\u6807\u6ce8\u786e\u8ba4\u673a\u5236\u7684\u8bbe\u8ba1\u3002"}}
{"id": "2510.24317", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.24317", "abs": "https://arxiv.org/abs/2510.24317", "authors": ["Mar\u00eda Sanz-G\u00f3mez", "V\u00edctor Mayoral-Vilches", "Francesco Balassone", "Luis Javier Navarrete-Lozano", "Crist\u00f3bal R. J. Veas Chavez", "Maite del Mundo de Torres"], "title": "Cybersecurity AI Benchmark (CAIBench): A Meta-Benchmark for Evaluating Cybersecurity AI Agents", "comment": null, "summary": "Cybersecurity spans multiple interconnected domains, complicating the\ndevelopment of meaningful, labor-relevant benchmarks. Existing benchmarks\nassess isolated skills rather than integrated performance. We find that\npre-trained knowledge of cybersecurity in LLMs does not imply attack and\ndefense abilities, revealing a gap between knowledge and capability. To address\nthis limitation, we present the Cybersecurity AI Benchmark (CAIBench), a\nmodular meta-benchmark framework that allows evaluating LLM models and agents\nacross offensive and defensive cybersecurity domains, taking a step towards\nmeaningfully measuring their labor-relevance. CAIBench integrates five\nevaluation categories, covering over 10,000 instances: Jeopardy-style CTFs,\nAttack and Defense CTFs, Cyber Range exercises, knowledge benchmarks, and\nprivacy assessments. Key novel contributions include systematic simultaneous\noffensive-defensive evaluation, robotics-focused cybersecurity challenges\n(RCTF2), and privacy-preserving performance assessment (CyberPII-Bench).\nEvaluation of state-of-the-art AI models reveals saturation on security\nknowledge metrics (~70\\% success) but substantial degradation in multi-step\nadversarial (A\\&D) scenarios (20-40\\% success), or worse in robotic targets\n(22\\% success). The combination of framework scaffolding and LLM model choice\nsignificantly impacts performance; we find that proper matches improve up to\n2.6$\\times$ variance in Attack and Defense CTFs. These results demonstrate a\npronounced gap between conceptual knowledge and adaptive capability,\nemphasizing the need for a meta-benchmark.", "AI": {"tldr": "\u63d0\u51faCAIBench\u5143\u57fa\u51c6\uff0c\u8986\u76d6\u653b\u9632\u4e0e\u9690\u79c1\u8bc4\u4f30\uff0c\u63ed\u793a\u5927\u6a21\u578b\u5bf9\u5b89\u5168\u77e5\u8bc6\u638c\u63e1\u8f83\u597d\u4f46\u5728\u591a\u6b65\u653b\u9632\u548c\u673a\u5668\u4eba\u573a\u666f\u80fd\u529b\u4e0d\u8db3\uff0c\u6a21\u578b\u4e0e\u6846\u67b6\u5339\u914d\u4f1a\u6781\u5927\u5f71\u54cd\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u8fc7\u4e8e\u5b64\u7acb\u53ea\u6d4b\u5355\u4e00\u6280\u80fd\uff0c\u65e0\u6cd5\u8bc4\u4f30\u7f51\u7edc\u5b89\u5168\u4e2d\u8de8\u9886\u57df\u3001\u5bf9\u6297\u6027\u4e0e\u6267\u884c\u6027\u4efb\u52a1\u7684\u52b3\u52a8\u529b\u76f8\u5173\u80fd\u529b\uff1b\u9884\u8bad\u7ec3\u77e5\u8bc6\u4e0d\u7b49\u4e8e\u5b9e\u9645\u653b\u9632\u80fd\u529b\uff0c\u9700\u5143\u57fa\u51c6\u6765\u8861\u91cf\u7efc\u5408\u8868\u73b0\u3002", "method": "\u6784\u5efa\u4e94\u7c7b\u8bc4\u4f30\u6a21\u5757\uff08Jeopardy CTF\u3001Attack&Defense CTF\u3001Cyber Range\u3001\u77e5\u8bc6\u57fa\u51c6\u3001\u9690\u79c1\u8bc4\u4f30\uff09\uff0c\u751f\u62101\u4e07+\u5b9e\u4f8b\uff1b\u8bbe\u8ba1\u673a\u5668\u4eba\u805a\u7126\u6311\u6218RCTF2\u4e0e\u9690\u79c1\u57fa\u51c6CyberPII-Bench\uff1b\u5bf9\u591a\u79cdSOTA\u6a21\u578b\u4e0e\u4ee3\u7406\u8fdb\u884c\u7edf\u4e00\u8bc4\u6d4b\uff0c\u5e76\u5206\u6790\u4e0d\u540c\u6a21\u578b-\u6846\u67b6\u7ec4\u5408\u7684\u6027\u80fd\u5dee\u5f02\u3002", "result": "CAIBench\u63d0\u51fa\u4e00\u4e2a\u6a21\u5757\u5316\u7684\u5143\u57fa\u51c6\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u6a21\u578b\u5728\u7f51\u7edc\u653b\u9632\u4e24\u7aef\u7684\u80fd\u529b\uff0c\u6574\u5408\u4e86\u4e94\u7c7b\u8bc4\u4f30\uff1aCTF\u7c7b\u95ee\u7b54\u3001\u653b\u9632CTF\u3001\u7f51\u7edc\u6f14\u4e60\u3001\u77e5\u8bc6\u57fa\u51c6\u548c\u9690\u79c1\u8bc4\u4f30\uff0c\u5305\u542b1\u4e07\u591a\u6761\u6837\u672c\u3002\u5b9e\u9a8c\u53d1\u73b0\u6a21\u578b\u5728\u5b89\u5168\u77e5\u8bc6\u7c7b\u4e0a\u63a5\u8fd1\u9971\u548c\uff08\u7ea670%\u6210\u529f\u7387\uff09\uff0c\u4f46\u5728\u591a\u6b65\u5bf9\u6297\u573a\u666f\u548c\u673a\u5668\u4eba\u76f8\u5173\u653b\u51fb\u4e0a\u8868\u73b0\u663e\u8457\u4e0b\u964d\uff0820\u201340%\uff0c\u673a\u5668\u4eba\u7ea622%\uff09\u3002\u6846\u67b6\u4e0e\u6a21\u578b\u9009\u62e9\u7684\u5339\u914d\u4f1a\u5bfc\u81f4\u6027\u80fd\u53d8\u5316\u9ad8\u8fbe2.6\u500d\uff0c\u8868\u660e\u77e5\u8bc6\u4e0e\u5b9e\u9645\u80fd\u529b\u4e4b\u95f4\u5b58\u5728\u660e\u663e\u5dee\u8ddd\u3002", "conclusion": "CAIBench\u6709\u6548\u63ed\u793aLLM\u5728\u7f51\u7edc\u5b89\u5168\u4e2d\u77e5\u8bc6\u4e0e\u80fd\u529b\u7684\u5dee\u8ddd\uff0c\u5f3a\u8c03\u9700\u6784\u5efa\u7efc\u5408\u6027\u3001\u52b3\u52a8\u529b\u76f8\u5173\u7684\u6d4b\u8bc4\u4ee5\u8bc4\u4f30\u5b9e\u9645\u653b\u9632\u80fd\u529b\uff0c\u5e76\u63d0\u793a\u6a21\u578b\u4e0e\u4efb\u52a1\u6846\u67b6\u5339\u914d\u91cd\u8981\u6027\u3002"}}
{"id": "2510.23883", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23883", "abs": "https://arxiv.org/abs/2510.23883", "authors": ["Shrestha Datta", "Shahriar Kabir Nahin", "Anshuman Chhabra", "Prasant Mohapatra"], "title": "Agentic AI Security: Threats, Defenses, Evaluation, and Open Challenges", "comment": null, "summary": "Agentic AI systems powered by large language models (LLMs) and endowed with\nplanning, tool use, memory, and autonomy, are emerging as powerful, flexible\nplatforms for automation. Their ability to autonomously execute tasks across\nweb, software, and physical environments creates new and amplified security\nrisks, distinct from both traditional AI safety and conventional software\nsecurity. This survey outlines a taxonomy of threats specific to agentic AI,\nreviews recent benchmarks and evaluation methodologies, and discusses defense\nstrategies from both technical and governance perspectives. We synthesize\ncurrent research and highlight open challenges, aiming to support the\ndevelopment of secure-by-design agent systems.", "AI": {"tldr": "\u8be5\u7efc\u8ff0\u8ba8\u8bba\u4e86\u57fa\u4e8e\u5927\u6a21\u578b\u7684\u5177\u4ee3\u7406\u80fd\u529b\uff08planning\u3001tool use\u3001memory\u3001\u81ea\u4e3b\u6027\uff09\u7684AI\u7cfb\u7edf\u5e26\u6765\u7684\u72ec\u7279\u5b89\u5168\u5a01\u80c1\uff0c\u63d0\u51fa\u5a01\u80c1\u5206\u7c7b\u3001\u56de\u987e\u8bc4\u6d4b\u57fa\u51c6\u4e0e\u65b9\u6cd5\uff0c\u5e76\u8ba8\u8bba\u6280\u672f\u4e0e\u6cbb\u7406\u9632\u5fa1\u7b56\u7565\uff0c\u5f3a\u8c03\u5b89\u5168\u8bbe\u8ba1\u4e0e\u82e5\u5e72\u5f00\u653e\u6311\u6218\u3002", "motivation": "\u968f\u7740LLM\u9a71\u52a8\u7684\u4ee3\u7406\u7cfb\u7edf\u80fd\u591f\u81ea\u4e3b\u5728\u7f51\u7edc\u3001\u8f6f\u4ef6\u4e0e\u7269\u7406\u73af\u5883\u4e2d\u6267\u884c\u590d\u6742\u4efb\u52a1\uff0c\u5b83\u4eec\u5f15\u5165\u4e86\u65e2\u4e0d\u540c\u4e8e\u4f20\u7edfAI\u5b89\u5168\u4e5f\u4e0d\u540c\u4e8e\u8f6f\u4ef6\u5b89\u5168\u7684\u65b0\u98ce\u9669\uff0c\u9700\u8981\u7cfb\u7edf\u6027\u8bc4\u4f30\u4e0e\u9632\u62a4\u7b56\u7565\u3002", "method": "\u6587\u7ae0\u901a\u8fc7\u5f62\u6210\u9488\u5bf9\u4ee3\u7406AI\u7684\u5a01\u80c1\u5206\u7c7b\u6846\u67b6\uff0c\u7efc\u8ff0\u5f53\u524d\u57fa\u51c6\u4e0e\u8bc4\u4f30\u65b9\u6cd5\uff08\u653b\u51fb\u573a\u666f\u3001\u7ea2\u961f\u3001\u5bf9\u6297\u751f\u6210\u3001\u6a21\u62df\u73af\u5883\u6d4b\u8bd5\uff09\uff0c\u5e76\u8bc4\u4f30\u73b0\u6709\u9632\u5fa1\u65b9\u6cd5\uff08\u8bbf\u95ee\u63a7\u5236\u3001\u6c99\u7bb1\u3001\u9a8c\u8bc1\u3001\u6a21\u578b\u8c03\u6574\u3001\u89e3\u91ca\u6027\u5de5\u5177\u3001\u6cbb\u7406\u63aa\u65bd\uff09\uff1b\u6574\u5408\u6587\u732e\u5e76\u63d0\u51fa\u7814\u7a76\u8bae\u7a0b\u3002", "result": "\u603b\u7ed3\u4e86\u4ee3\u7406AI\u4e13\u6709\u7684\u5a01\u80c1\u7c7b\u578b\uff08\u6ee5\u7528\u3001\u88ab\u52ab\u6301\u3001\u7b56\u7565\u64cd\u7eb5\u3001\u8bb0\u5fc6\u6ee5\u7528\u3001\u4f9b\u5e94\u94fe\u4e0e\u5de5\u5177\u6ee5\u7528\u7b49\uff09\u3001\u73b0\u6709\u8bc4\u4f30\u57fa\u51c6\u7684\u8986\u76d6\u4e0d\u8db3\u4e0e\u5c40\u9650\u3001\u5e76\u68b3\u7406\u4e86\u4e00\u7cfb\u5217\u6280\u672f\u4e0e\u6cbb\u7406\u9632\u62a4\u624b\u6bb5\uff0c\u63d0\u51fa\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "conclusion": "\u9700\u5c06\u5b89\u5168\u6027\u5d4c\u5165\u4ee3\u7406\u7cfb\u7edf\u8bbe\u8ba1\uff0c\u7ed3\u5408\u591a\u5c42\u6b21\u9632\u62a4\uff08\u6743\u9650\u63a7\u5236\u3001\u53ef\u89e3\u91ca\u6027\u3001\u5ba1\u8ba1\u4e0e\u76d1\u63a7\u3001\u5bf9\u6297\u6027\u7a33\u5065\u6027\u3001\u9650\u5236\u5de5\u5177\u8bbf\u95ee\u3001\u5f3a\u5316\u8bad\u7ec3\u4e0e\u8bc4\u4f30\u57fa\u51c6\uff09\uff0c\u5e76\u901a\u8fc7\u6cbb\u7406\u4e0e\u6cd5\u89c4\u3001\u6807\u51c6\u5316\u6d41\u7a0b\u3001\u8de8\u5b66\u79d1\u5408\u4f5c\u6765\u7f13\u89e3\u98ce\u9669\u3002\u672a\u6765\u5de5\u4f5c\u5e94\u96c6\u4e2d\u5728\u7edf\u4e00\u8bc4\u4f30\u6307\u6807\u3001\u52a8\u6001\u9632\u62a4\u673a\u5236\u4e0e\u5b9e\u5730\u90e8\u7f72\u8bc4\u4f30\u3002"}}
{"id": "2510.23636", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.23636", "abs": "https://arxiv.org/abs/2510.23636", "authors": ["Thaweerath Phisannupawong", "Joshua Julian Damanik", "Han-Lim Choi"], "title": "Flight Delay Prediction via Cross-Modality Adaptation of Large Language Models and Aircraft Trajectory Representation", "comment": "Preprint submitted to Aerospace Science and Technology (Elsevier) for\n  possible publication", "summary": "Flight delay prediction has become a key focus in air traffic management, as\ndelays highlight inefficiencies that impact overall network performance. This\npaper presents a lightweight large language model-based multimodal flight delay\nprediction, formulated from the perspective of air traffic controllers\nmonitoring aircraft delay after entering the terminal area. The approach\nintegrates trajectory representations with textual aeronautical information,\nincluding flight information, weather reports, and aerodrome notices, by\nadapting trajectory data into the language modality to capture airspace\nconditions. Experimental results show that the model consistently achieves\nsub-minute prediction error by effectively leveraging contextual information\nrelated to the sources of delay. The framework demonstrates that linguistic\nunderstanding, when combined with cross-modality adaptation of trajectory\ninformation, enhances delay prediction. Moreover, the approach shows\npracticality and scalability for real-world operations, supporting real-time\nupdates that refine predictions upon receiving new operational information.", "AI": {"tldr": "LLM-based multimodal model fusing adapted trajectory text and aeronautical texts predicts flight delays with sub-minute error and real-time refinement.", "motivation": "Reduce flight delays and improve air traffic management by predicting delays with contextual multimodal data.", "method": "Adapt trajectory representations into language modality, fuse with textual flight info, weather, and notices, and use a lightweight LLM to produce real-time delay predictions.", "result": "A lightweight LLM-based multimodal model integrating trajectory data converted to language modality plus textual aeronautical information achieves sub-minute prediction error and supports real-time updates.", "conclusion": "Combining linguistic understanding with cross-modality trajectory adaptation improves delay prediction accuracy and is practical for operational deployment."}}
{"id": "2510.24393", "categories": ["cs.CR", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2510.24393", "abs": "https://arxiv.org/abs/2510.24393", "authors": ["Yan Meng", "Jiachun Li", "Matthew Pillari", "Arjun Deopujari", "Liam Brennan", "Hafsah Shamsie", "Haojin Zhu", "Yuan Tian"], "title": "Your Microphone Array Retains Your Identity: A Robust Voice Liveness Detection System for Smart Speakers", "comment": "This is a paper accepted by USENIX Security 2022. See:\n  https://www.usenix.org/conference/usenixsecurity22/presentation/meng", "summary": "Though playing an essential role in smart home systems, smart speakers are\nvulnerable to voice spoofing attacks. Passive liveness detection, which\nutilizes only the collected audio rather than the deployed sensors to\ndistinguish between live-human and replayed voices, has drawn increasing\nattention. However, it faces the challenge of performance degradation under the\ndifferent environmental factors as well as the strict requirement of the fixed\nuser gestures.\n  In this study, we propose a novel liveness feature, array fingerprint, which\nutilizes the microphone array inherently adopted by the smart speaker to\ndetermine the identity of collected audios. Our theoretical analysis\ndemonstrates that by leveraging the circular layout of microphones, compared\nwith existing schemes, array fingerprint achieves a more robust performance\nunder the environmental change and user's movement. Then, to leverage such a\nfingerprint, we propose ARRAYID, a lightweight passive detection scheme, and\nelaborate a series of features working together with array fingerprint. Our\nevaluation on the dataset containing 32,780 audio samples and 14 spoofing\ndevices shows that ARRAYID achieves an accuracy of 99.84%, which is superior to\nexisting passive liveness detection schemes.", "AI": {"tldr": "\u5229\u7528\u667a\u80fd\u97f3\u7bb1\u7684\u5706\u5f62\u9ea6\u514b\u98ce\u9635\u5217\u63d0\u53d6\u9635\u5217\u6307\u7eb9\uff0c\u6784\u5efaARRAYID\uff0c\u88ab\u52a8\u68c0\u6d4b\u56de\u653e\u653b\u51fb\uff0c\u5728\u5927\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02\uff0899.84%\uff09\u3002", "motivation": "\u667a\u80fd\u97f3\u7bb1\u6613\u53d7\u8bed\u97f3\u56de\u653e\u6b3a\u9a97\uff0c\u88ab\u52a8\u6d3b\u4f53\u68c0\u6d4b\u4e0d\u4f9d\u8d56\u989d\u5916\u4f20\u611f\u5668\u4f46\u5bf9\u73af\u5883\u53d8\u5316\u548c\u7528\u6237\u52a8\u4f5c\u654f\u611f\uff0c\u9700\u63d0\u9ad8\u9c81\u68d2\u6027\u5e76\u51cf\u5c11\u5bf9\u56fa\u5b9a\u7528\u6237\u59ff\u6001\u7684\u4f9d\u8d56\u3002", "method": "\u7406\u8bba\u5206\u6790\u9ea6\u514b\u98ce\u5706\u5f62\u5e03\u5c40\u5bf9\u9635\u5217\u7279\u5f81\u7684\u9c81\u68d2\u6027\uff0c\u8bbe\u8ba1\u9635\u5217\u6307\u7eb9\u5e76\u7ed3\u5408\u5176\u4ed6\u7279\u5f81\u6784\u5efa\u8f7b\u91cf\u7ea7\u5206\u7c7b\u5668\uff1b\u5728\u5305\u542b32780\u6761\u6837\u672c\u548c14\u79cd\u6b3a\u9a97\u8bbe\u5907\u7684\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u5728\u6240\u7528\u6570\u636e\u96c6\u4e0a\uff0cARRAYID\u8fbe\u523099.84%\u51c6\u786e\u7387\uff0c\u4f18\u4e8e\u73b0\u6709\u88ab\u52a8\u6d3b\u4f53\u68c0\u6d4b\u65b9\u6cd5\uff0c\u5bf9\u73af\u5883\u53d8\u5316\u4e0e\u7528\u6237\u79fb\u52a8\u66f4\u9c81\u68d2\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u9ea6\u514b\u98ce\u9635\u5217\u7684\u88ab\u52a8\u6d3b\u4f53\u68c0\u6d4b\u65b0\u7279\u5f81\u201c\u9635\u5217\u6307\u7eb9\u201d\uff0c\u5e76\u5b9e\u73b0\u4e86\u8f7b\u91cf\u7ea7\u68c0\u6d4b\u65b9\u6848ARRAYID\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5bf9\u56de\u653e\u653b\u51fb\u7684\u8bc6\u522b\u6027\u80fd\u3002"}}
{"id": "2510.23925", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.23925", "abs": "https://arxiv.org/abs/2510.23925", "authors": ["Guohao Sun", "Hang Hua", "Jian Wang", "Jiebo Luo", "Sohail Dianat", "Majid Rabbani", "Raghuveer Rao", "Zhiqiang Tao"], "title": "Latent Chain-of-Thought for Visual Reasoning", "comment": "NeurIPS 2025", "summary": "Chain-of-thought (CoT) reasoning is critical for improving the\ninterpretability and reliability of Large Vision-Language Models (LVLMs).\nHowever, existing training algorithms such as SFT, PPO, and GRPO may not\ngeneralize well across unseen reasoning tasks and heavily rely on a biased\nreward model. To address this challenge, we reformulate reasoning in LVLMs as\nposterior inference and propose a scalable training algorithm based on\namortized variational inference. By leveraging diversity-seeking reinforcement\nlearning algorithms, we introduce a novel sparse reward function for\ntoken-level learning signals that encourage diverse, high-likelihood latent\nCoT, overcoming deterministic sampling limitations and avoiding reward hacking.\nAdditionally, we implement a Bayesian inference-scaling strategy that replaces\ncostly Best-of-N and Beam Search with a marginal likelihood to efficiently rank\noptimal rationales and answers. We empirically demonstrate that the proposed\nmethod enhances the state-of-the-art LVLMs on seven reasoning benchmarks, in\nterms of effectiveness, generalization, and interpretability.", "AI": {"tldr": "\u628aCoT\u5f53\u4f5c\u540e\u9a8c\u63a8\u65ad\uff0c\u7528\u644a\u9500\u53d8\u5206\u63a8\u65ad+\u7a00\u758ftoken\u5956\u52b1+\u8d1d\u53f6\u65af\u8fb9\u7f18\u4f3c\u7136\u6392\u540d\uff0c\u63d0\u5347LVLM\u7684\u6cdb\u5316\u4e0e\u53ef\u89e3\u91ca\u6027\u5e76\u66ff\u4ee3\u6602\u8d35\u641c\u7d22\u7b56\u7565\u3002", "motivation": "\u73b0\u6709SFT/PPO/GRPO\u5728\u672a\u89c1\u63a8\u7406\u4efb\u52a1\u4e0a\u6cdb\u5316\u5dee\uff0c\u4e14\u4f9d\u8d56\u6709\u504f\u5956\u52b1\u6a21\u578b\uff1b\u9700\u907f\u514d\u786e\u5b9a\u6027\u91c7\u6837\u9650\u5236\u548c\u5956\u52b1\u6295\u673a\uff0c\u540c\u65f6\u63d0\u5347\u6548\u7387\u4e0e\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u4f7f\u7528\u644a\u9500\u53d8\u5206\u63a8\u65ad\u6846\u67b6\uff0c\u7ed3\u5408\u5bfb\u6c42\u591a\u6837\u6027\u7684\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u8bbe\u8ba1\u7a00\u758f\u7684token\u7ea7\u5956\u52b1\u4ee5\u9f13\u52b1\u591a\u6837\u9ad8\u4f3c\u7136\u7684\u9690\u542bCoT\uff0c\u5e76\u7528\u8d1d\u53f6\u65af\u63a8\u65ad\u7f29\u653e\u7b56\u7565\u4ee5\u8fb9\u7f18\u4f3c\u7136\u66ff\u4ee3\u6602\u8d35\u7684Best-of-N/Beam Search\u8fdb\u884c\u6392\u5e8f\u3002", "result": "\u5728\u4e03\u4e2a\u63a8\u7406\u57fa\u51c6\u4e0a\uff0c\u65b9\u6cd5\u5728\u6548\u679c\u3001\u6cdb\u5316\u4e0e\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u4f18\u4e8e\u6700\u5148\u8fdbLVLM\u3002", "conclusion": "\u672c\u6587\u5c06LVLM\u7684\u63a8\u7406\u89c6\u4f5c\u540e\u9a8c\u63a8\u65ad\uff0c\u63d0\u51fa\u57fa\u4e8e\u644a\u9500\u53d8\u5206\u63a8\u65ad\u7684\u53ef\u6269\u5c55\u8bad\u7ec3\u7b97\u6cd5\uff0c\u6539\u5584\u4e00\u822c\u5316\u4e0e\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2510.23637", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.LO"], "pdf": "https://arxiv.org/pdf/2510.23637", "abs": "https://arxiv.org/abs/2510.23637", "authors": ["Job Petrov\u010di\u010d", "David Eliecer Narvaez Denis", "Ljup\u010do Todorovski"], "title": "Combining Textual and Structural Information for Premise Selection in Lean", "comment": null, "summary": "Premise selection is a key bottleneck for scaling theorem proving in large\nformal libraries. Yet existing language-based methods often treat premises in\nisolation, ignoring the web of dependencies that connects them. We present a\ngraph-augmented approach that combines dense text embeddings of Lean\nformalizations with graph neural networks over a heterogeneous dependency graph\ncapturing both state--premise and premise--premise relations. On the LeanDojo\nBenchmark, our method outperforms the ReProver language-based baseline by over\n25% across standard retrieval metrics. These results demonstrate the power of\nrelational information for more effective premise selection.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u6587\u672c\u5d4c\u5165\u4e0e\u5f02\u6784\u4f9d\u8d56\u56fe\u4e0a\u7684\u56fe\u795e\u7ecf\u7f51\u7edc\u7ed3\u5408\u7684\u524d\u63d0\u9009\u62e9\u65b9\u6cd5\uff0c\u5728LeanDojo\u57fa\u51c6\u4e0a\u76f8\u6bd4ReProver\u63d0\u534725%\u4ee5\u4e0a\uff0c\u8bc1\u660e\u4e86\u5173\u7cfb\u4fe1\u606f\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u591a\u5c06\u524d\u63d0\u5355\u72ec\u5904\u7406\uff0c\u5ffd\u7565\u4e86\u8fde\u63a5\u524d\u63d0\u7684\u4f9d\u8d56\u7f51\u7edc\uff0c\u800c\u8fd9\u4e9b\u5173\u7cfb\u80fd\u63d0\u4f9b\u5173\u952e\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u5e2e\u52a9\u66f4\u597d\u5730\u9009\u62e9\u76f8\u5173\u524d\u63d0\u3002", "method": "\u5bf9Lean\u5f62\u5f0f\u5316\u7684\u6587\u672c\u4f7f\u7528\u5bc6\u96c6\u5d4c\u5165\uff0c\u540c\u65f6\u6784\u5efa\u5305\u542b\u72b6\u6001-\u524d\u63d0\u548c\u524d\u63d0-\u524d\u63d0\u5173\u7cfb\u7684\u5f02\u6784\u4f9d\u8d56\u56fe\uff0c\u5bf9\u8be5\u56fe\u5e94\u7528\u56fe\u795e\u7ecf\u7f51\u7edc\uff0c\u5c06\u8282\u70b9\u8868\u793a\u4e0e\u6587\u672c\u5d4c\u5165\u878d\u5408\u7528\u4e8e\u68c0\u7d22\u524d\u63d0\u3002", "result": "\u5728LeanDojo\u57fa\u51c6\u4e0a\uff0c\u6240\u63d0\u65b9\u6cd5\u5728\u6807\u51c6\u68c0\u7d22\u6307\u6807\u4e0a\u76f8\u6bd4ReProver\u63d0\u5347\u8d85\u8fc725%\u3002", "conclusion": "\u5728\u5927\u89c4\u6a21\u5f62\u5f0f\u5316\u5e93\u4e2d\uff0c\u878d\u5408\u4f9d\u8d56\u5173\u7cfb\u7684\u56fe\u589e\u5f3a\u65b9\u6cd5\u80fd\u663e\u8457\u63d0\u5347\u524d\u63d0\u9009\u62e9\u6548\u679c\uff0c\u4f18\u4e8e\u4ec5\u57fa\u4e8e\u8bed\u8a00\u7684\u65b9\u6cd5\u3002"}}
{"id": "2510.23942", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23942", "abs": "https://arxiv.org/abs/2510.23942", "authors": ["Sridhar Mahadevan"], "title": "Decentralized Causal Discovery using Judo Calculus", "comment": "54 pages", "summary": "We describe a theory and implementation of an intuitionistic decentralized\nframework for causal discovery using judo calculus, which is formally defined\nas j-stable causal inference using j-do-calculus in a topos of sheaves. In\nreal-world applications -- from biology to medicine and social science --\ncausal effects depend on regime (age, country, dose, genotype, or lab\nprotocol). Our proposed judo calculus formalizes this context dependence\nformally as local truth: a causal claim is proven true on a cover of regimes,\nnot everywhere at once. The Lawvere-Tierney modal operator j chooses which\nregimes are relevant; j-stability means the claim holds constructively and\nconsistently across that family. We describe an algorithmic and implementation\nframework for judo calculus, combining it with standard score-based,\nconstraint-based, and gradient-based causal discovery methods. We describe\nexperimental results on a range of domains, from synthetic to real-world\ndatasets from biology and economics. Our experimental results show the\ncomputational efficiency gained by the decentralized nature of sheaf-theoretic\ncausal discovery, as well as improved performance over classical causal\ndiscovery methods.", "AI": {"tldr": "introduces j-stable causal inference using j-do-calculus to handle context-dependent causal effects via Lawvere-Tierney modality; implements algorithms combining standard causal discovery methods and shows empirical gains", "motivation": "causal effects depend on regimes; need local/contextual causal claims", "method": "judo calculus in topos of sheaves", "result": "decentralized sheaf-theoretic causal discovery with improved efficiency and performance", "conclusion": "judo calculus enables constructive, regime-local causal claims and efficient decentralized discovery, outperforming classical methods on varied datasets"}}
{"id": "2510.23639", "categories": ["cs.LG", "cs.AI", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2510.23639", "abs": "https://arxiv.org/abs/2510.23639", "authors": ["Jonathan Amar", "Edward Liu", "Alessandra Breschi", "Liangliang Zhang", "Pouya Kheradpour", "Sylvia Li", "Lisa Soleymani Lehmann", "Alessandro Giulianelli", "Matt Edwards", "Yugang Jia", "David Nola", "Raghav Mani", "Pankaj Vats", "Jesse Tetreault", "T. J. Chen", "Cory Y. McLean"], "title": "Integrating Genomics into Multimodal EHR Foundation Models", "comment": null, "summary": "This paper introduces an innovative Electronic Health Record (EHR) foundation\nmodel that integrates Polygenic Risk Scores (PRS) as a foundational data\nmodality, moving beyond traditional EHR-only approaches to build more holistic\nhealth profiles. Leveraging the extensive and diverse data from the All of Us\n(AoU) Research Program, this multimodal framework aims to learn complex\nrelationships between clinical data and genetic predispositions. The\nmethodology extends advancements in generative AI to the EHR foundation model\nspace, enhancing predictive capabilities and interpretability. Evaluation on\nAoU data demonstrates the model's predictive value for the onset of various\nconditions, particularly Type 2 Diabetes (T2D), and illustrates the interplay\nbetween PRS and EHR data. The work also explores transfer learning for custom\nclassification tasks, showcasing the architecture's versatility and efficiency.\nThis approach is pivotal for unlocking new insights into disease prediction,\nproactive health management, risk stratification, and personalized treatment\nstrategies, laying the groundwork for more personalized, equitable, and\nactionable real-world evidence generation in healthcare.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u591a\u57fa\u56e0\u98ce\u9669\u8bc4\u5206(PRS)\u4f5c\u4e3a\u57fa\u7840\u6a21\u6001\uff0c\u878d\u5165\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55(EHR)\u57fa\u7840\u6a21\u578b\u7684\u591a\u6a21\u6001\u6846\u67b6\u3002\u57fa\u4e8eAll of Us\u6570\u636e\uff0c\u6a21\u578b\u5b66\u4e60\u4e34\u5e8a\u4e0e\u9057\u4f20\u98ce\u9669\u7684\u590d\u6742\u5173\u7cfb\uff0c\u63d0\u9ad8\u4e86\u9884\u6d4b\u6027\u80fd\u548c\u89e3\u91ca\u6027\uff0c\u5728\u7cd6\u5c3f\u75c5\u7b49\u75be\u75c5\u53d1\u75c5\u9884\u6d4b\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u5e76\u5c55\u793a\u4e86\u8fc1\u79fb\u5b66\u4e60\u7528\u4e8e\u5b9a\u5236\u5206\u7c7b\u4efb\u52a1\u7684\u53ef\u884c\u6027\u3002", "motivation": "\u4f20\u7edfEHR\u57fa\u7840\u6a21\u578b\u5ffd\u7565\u9057\u4f20\u4fe1\u606f\uff0c\u9650\u5236\u4e86\u5bf9\u75be\u75c5\u98ce\u9669\u7684\u5168\u9762\u5efa\u6a21\u3002\u5c06PRS\u7eb3\u5165\u53ef\u4ee5\u6355\u6349\u9057\u4f20\u6613\u611f\u6027\u4e0e\u4e34\u5e8a\u4e8b\u4ef6\u7684\u4ea4\u4e92\uff0c\u4ece\u800c\u63d0\u9ad8\u9884\u6d4b\u4e0e\u4e2a\u4f53\u5316\u7b56\u7565\u7684\u80fd\u529b\u3002", "method": "\u57fa\u4e8eAoU\u5927\u89c4\u6a21\u591a\u6837\u5316\u6570\u636e\uff0c\u4f5c\u8005\u6784\u5efa\u4e86\u4e00\u4e2a\u5c06PRS\u4f5c\u4e3a\u989d\u5916\u8f93\u5165\u6a21\u6001\u7684EHR\u57fa\u7840\u6a21\u578b\uff0c\u91c7\u7528\u751f\u6210\u5f0fAI\u7684\u6280\u672f\uff08\u53ef\u80fd\u5305\u542b\u81ea\u76d1\u7763\u9884\u8bad\u7ec3\u548c\u591a\u6a21\u6001\u878d\u5408\u67b6\u6784\uff09\uff0c\u5e76\u5728\u4e0b\u6e38\u5206\u7c7b\u4efb\u52a1\u4e0a\u901a\u8fc7\u5fae\u8c03/\u8fc1\u79fb\u5b66\u4e60\u9a8c\u8bc1\u3002", "result": "\u5728AoU\u6570\u636e\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0c\u8be5\u591a\u6a21\u6001\u6a21\u578b\u5728\u9884\u6d4b\u5305\u62ecT2D\u5728\u5185\u7684\u591a\u79cd\u75be\u75c5\u53d1\u75c5\u4e0a\u5177\u6709\u9884\u6d4b\u4ef7\u503c\uff0c\u63ed\u793a\u4e86PRS\u4e0e\u4e34\u5e8a\u6570\u636e\u7684\u4e92\u8865\u6027\uff0c\u5e76\u8bc1\u660e\u4e86\u8fc1\u79fb\u5b66\u4e60\u5728\u5b9a\u5236\u4efb\u52a1\u4e2d\u7684\u6548\u7387\u548c\u7075\u6d3b\u6027\u3002", "conclusion": "\u5c06PRS\u4e0eEHR\u5171\u540c\u5efa\u6a21\u80fd\u63d0\u5347\u75be\u75c5\u53d1\u75c5\u9884\u6d4b\u548c\u98ce\u9669\u5206\u5c42\u80fd\u529b\uff0c\u589e\u5f3a\u6a21\u578b\u89e3\u91ca\u6027\uff0c\u5e76\u80fd\u901a\u8fc7\u8fc1\u79fb\u5b66\u4e60\u9ad8\u6548\u9002\u914d\u4e0b\u6e38\u4efb\u52a1\uff0c\u6709\u52a9\u4e8e\u4e2a\u6027\u5316\u533b\u7597\u548c\u516c\u5171\u536b\u751f\u51b3\u7b56\u3002"}}
{"id": "2510.24422", "categories": ["cs.CR", "cs.AR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24422", "abs": "https://arxiv.org/abs/2510.24422", "authors": ["Bijeet Basak", "Nupur Patil", "Kurian Polachan", "Srinivas Vivek"], "title": "Attack on a PUF-based Secure Binary Neural Network", "comment": "Accepted at VLSID 2026. To be published in IEEE Xplore", "summary": "Binarized Neural Networks (BNNs) deployed on memristive crossbar arrays\nprovide energy-efficient solutions for edge computing but are susceptible to\nphysical attacks due to memristor nonvolatility. Recently, Rajendran et al.\n(IEEE Embedded Systems Letter 2025) proposed a Physical Unclonable Function\n(PUF)-based scheme to secure BNNs against theft attacks. Specifically, the\nweight and bias matrices of the BNN layers were secured by swapping columns\nbased on device's PUF key bits.\n  In this paper, we demonstrate that this scheme to secure BNNs is vulnerable\nto PUF-key recovery attack. As a consequence of our attack, we recover the\nsecret weight and bias matrices of the BNN. Our approach is motivated by\ndifferential cryptanalysis and reconstructs the PUF key bit-by-bit by observing\nthe change in model accuracy, and eventually recovering the BNN model\nparameters. Evaluated on a BNN trained on the MNIST dataset, our attack could\nrecover 85% of the PUF key, and recover the BNN model up to 93% classification\naccuracy compared to the original model's 96% accuracy. Our attack is very\nefficient and it takes a couple of minutes to recovery the PUF key and the\nmodel parameters.", "AI": {"tldr": "\u9488\u5bf9 Rajendran \u7b49\u4eba\u63d0\u51fa\u7684\u57fa\u4e8e PUF \u7684 BNN \u5217\u4ea4\u6362\u4fdd\u62a4\u65b9\u6848\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5dee\u5206\u5206\u6790\u7684 PUF \u5bc6\u94a5\u6062\u590d\u653b\u51fb\uff1a\u9010\u4f4d\u6062\u590d PUF \u5bc6\u94a5\u4ee5\u8fd8\u539f\u88ab\u4ea4\u6362\u7684\u6743\u91cd\u548c\u504f\u7f6e\u77e9\u9635\u3002\u5bf9 MNIST \u4e0a\u7684 BNN \u5b9e\u9a8c\u8868\u660e\u53ef\u6062\u590d\u7ea6 85% \u7684 PUF \u5bc6\u94a5\uff0c\u5e76\u5c06\u6a21\u578b\u5206\u7c7b\u7cbe\u5ea6\u6062\u590d\u5230 93%\u3002\u653b\u51fb\u9ad8\u6548\uff0c\u8017\u65f6\u6570\u5206\u949f\u3002", "motivation": "Memristive crossbar \u4e0a\u7684 BNN \u867d\u8282\u80fd\u4f46\u56e0\u5668\u4ef6\u975e\u6613\u5931\u6027\u6613\u906d\u7a83\u53d6\uff1b\u5148\u524d\u63d0\u51fa\u7684 PUF \u57fa\u4e8e\u5217\u4ea4\u6362\u65b9\u6848\u65e8\u5728\u4fdd\u62a4\u6a21\u578b\uff0c\u4f46\u9700\u9a8c\u8bc1\u5176\u6297\u653b\u51fb\u6027\u3002", "method": "\u53d7\u5dee\u5206\u5bc6\u7801\u5206\u6790\u542f\u53d1\uff0c\u653b\u51fb\u8005\u5bf9\u6bcf\u4e00\u4f4d PUF \u5bc6\u94a5\u5c1d\u8bd5\u7ffb\u8f6c\uff08\u6216\u9009\u62e9\uff09\uff0c\u901a\u8fc7\u6bd4\u8f83\u6a21\u578b\u5728\u653b\u51fb\u6837\u672c\u96c6\u5408\u4e0a\u7684\u51c6\u786e\u7387\u5dee\u5f02\u6765\u5224\u65ad\u8be5\u4f4d\u7684\u771f\u5b9e\u503c\uff0c\u4ece\u800c\u9010\u4f4d\u91cd\u5efa\u5b8c\u6574 PUF \u5bc6\u94a5\u5e76\u53cd\u5411\u4ea4\u6362\u5217\u4ee5\u6062\u590d\u6743\u91cd/\u504f\u7f6e\u3002", "result": "\u5728 MNIST \u7684\u5b9e\u9a8c\u4e2d\uff0c\u653b\u51fb\u6062\u590d\u4e86\u7ea6 85% \u7684 PUF \u5bc6\u94a5\uff0c\u5e76\u5c06\u88ab\u4fdd\u62a4 BNN \u6062\u590d\u5230 93% \u7684\u5206\u7c7b\u7cbe\u5ea6\uff08\u539f\u6a21\u578b 96%\uff09\uff0c\u653b\u51fb\u4ec5\u9700\u6570\u5206\u949f\u3002", "conclusion": "\u8be5 PUF \u5217\u4ea4\u6362\u4fdd\u62a4\u65b9\u6848\u5b58\u5728\u88ab\u52a8\u7684\u5bc6\u94a5\u6062\u590d\u6f0f\u6d1e\uff0c\u653b\u51fb\u8005\u4ec5\u901a\u8fc7\u67e5\u8be2\u6a21\u578b\u8f93\u51fa\u51c6\u786e\u7387\u53d8\u5316\u5373\u53ef\u9010\u4f4d\u91cd\u6784 PUF \u5bc6\u94a5\u5e76\u6062\u590d BNN \u53c2\u6570\uff0c\u663e\u793a\u9700\u8981\u66f4\u5f3a\u7684\u9632\u62a4\u673a\u5236\u3002"}}
{"id": "2510.23965", "categories": ["cs.AI", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.23965", "abs": "https://arxiv.org/abs/2510.23965", "authors": ["Aymane El Gadarri", "Ali Aouad", "Vivek F. Farias"], "title": "The Sign Estimator: LLM Alignment in the Face of Choice Heterogeneity", "comment": null, "summary": "Traditional LLM alignment methods are vulnerable to heterogeneity in human\npreferences. Fitting a na\\\"ive probabilistic model to pairwise comparison data\n(say over prompt-completion pairs) yields an inconsistent estimate of the\npopulation-average utility -a canonical measure of social welfare. We propose a\nnew method, dubbed the sign estimator, that provides a simple, provably\nconsistent, and efficient estimator by replacing cross-entropy with binary\nclassification loss in the aggregation step. This simple modification recovers\nconsistent ordinal alignment under mild assumptions and achieves the first\npolynomial finite-sample error bounds in this setting. In realistic simulations\nof LLM alignment using digital twins, the sign estimator substantially reduces\npreference distortion over a panel of simulated personas, cutting (angular)\nestimation error by nearly 35% and decreasing disagreement with true population\npreferences from 12% to 8% compared to standard RLHF. Our method also compares\nfavorably to panel data heuristics that explicitly model user heterogeneity and\nrequire tracking individual-level preference data-all while maintaining the\nimplementation simplicity of existing LLM alignment pipelines.", "AI": {"tldr": "\u63d0\u51fa\u7b26\u53f7\u4f30\u8ba1\u5668\uff0c\u7528\u4e8c\u5206\u7c7b\u635f\u5931\u66ff\u4ee3\u4ea4\u53c9\u71b5\uff0c\u5728\u5b58\u5728\u504f\u597d\u5f02\u8d28\u6027\u7684\u914d\u5bf9\u6bd4\u8f83\u6570\u636e\u4e0b\u63d0\u4f9b\u4e00\u81f4\u4e14\u9ad8\u6548\u7684\u5e8f\u6570\u5bf9\u9f50\u4f30\u8ba1\uff0c\u5177\u5907\u591a\u9879\u5f0f\u6709\u9650\u6837\u672c\u8bef\u5dee\u754c\uff0c\u5e76\u5728\u6a21\u62df\u5b9e\u9a8c\u4e2d\u663e\u8457\u6539\u5584\u5bf9\u9f50\u8d28\u91cf\u548c\u964d\u4f4e\u504f\u597d\u5931\u771f\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u914d\u5bf9\u6bd4\u8f83\u6570\u636e\u7684\u6734\u7d20\u6982\u7387\u6a21\u578b\u5728\u5b58\u5728\u504f\u597d\u5f02\u8d28\u6027\u65f6\u4f1a\u5bfc\u81f4\u5bf9\u4eba\u53e3\u5e73\u5747\u6548\u7528\u7684\u4f30\u8ba1\u4e0d\u4e00\u81f4\uff0c\u5f71\u54cdLLM\u7684\u793e\u4f1a\u798f\u5229\u4f18\u5316\uff1b\u9700\u8981\u4e00\u79cd\u65e2\u7b80\u5355\u53c8\u80fd\u5728\u7406\u8bba\u4e0a\u4fdd\u8bc1\u4e00\u81f4\u6027\u7684\u4f30\u8ba1\u65b9\u6cd5\u6765\u51cf\u5c11\u504f\u597d\u5931\u771f\u3002", "method": "\u6838\u5fc3\u65b9\u6cd5\u662f\u5728\u805a\u5408\u6b65\u9aa4\u7528\u4e8c\u5206\u7c7b\uff08\u7b26\u53f7\uff09\u635f\u5931\u66ff\u4ee3\u4ea4\u53c9\u71b5\uff0c\u6784\u5efa\u7b26\u53f7\u4f30\u8ba1\u5668\uff0c\u901a\u8fc7\u4e8c\u5143\u6392\u5e8f\u4fe1\u606f\u4f30\u8ba1\u7fa4\u4f53\u5e73\u5747\u6548\u7528\u7684\u65b9\u5411\uff08\u5e8f\u6570\u4fe1\u606f\uff09\uff0c\u5e76\u5728\u6b64\u57fa\u7840\u4e0a\u8bc1\u660e\u4e00\u81f4\u6027\u548c\u63d0\u4f9b\u591a\u9879\u5f0f\u6709\u9650\u6837\u672c\u8bef\u5dee\u754c\u3002", "result": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u89e3\u51b3\u4eba\u7c7b\u504f\u597d\u5f02\u8d28\u6027\u5bfc\u81f4\u7684LLM\u5bf9\u9f50\u95ee\u9898\u7684\u65b0\u4f30\u8ba1\u5668\u2014\u2014\u7b26\u53f7\u4f30\u8ba1\u5668\uff08sign estimator\uff09\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u5728\u805a\u5408\u6b65\u9aa4\u4e2d\u5c06\u4ea4\u53c9\u71b5\u66ff\u6362\u4e3a\u4e8c\u5206\u7c7b\u635f\u5931\uff0c\u80fd\u591f\u5728\u6e29\u548c\u5047\u8bbe\u4e0b\u6062\u590d\u4e00\u81f4\u7684\u5e8f\u6570\u5bf9\u9f50\uff0c\u5e76\u7ed9\u51fa\u591a\u9879\u5f0f\u6709\u9650\u6837\u672c\u8bef\u5dee\u754c\u3002\u6a21\u62df\u5b9e\u9a8c\u663e\u793a\uff0c\u7b26\u53f7\u4f30\u8ba1\u5668\u5728\u6570\u5b57\u5b6a\u751f\u9762\u677f\u4e0a\u663e\u8457\u964d\u4f4e\u4e86\u504f\u597d\u5931\u771f\uff0c\u89d2\u5ea6\u4f30\u8ba1\u8bef\u5dee\u964d\u4f4e\u7ea635%\uff0c\u4e0e\u771f\u5b9e\u4eba\u53e3\u504f\u597d\u4e0d\u4e00\u81f4\u7684\u6bd4\u4f8b\u4ece12%\u964d\u52308%\uff0c\u4e14\u5b9e\u73b0\u7b80\u5355\uff0c\u4e0d\u9700\u8981\u8ddf\u8e2a\u4e2a\u4f53\u7ea7\u504f\u597d\u6570\u636e\uff0c\u4f18\u4e8e\u4e00\u4e9b\u660e\u786e\u5efa\u6a21\u7528\u6237\u5f02\u8d28\u6027\u7684\u9762\u677f\u6570\u636e\u542f\u53d1\u5f0f\u65b9\u6cd5\u3002", "conclusion": "\u7b26\u53f7\u4f30\u8ba1\u5668\u5728\u7406\u8bba\u548c\u5b9e\u8df5\u4e0a\u90fd\u80fd\u66f4\u597d\u5730\u5e94\u5bf9\u4eba\u7c7b\u504f\u597d\u5f02\u8d28\u6027\u95ee\u9898\uff0c\u63d0\u4f9b\u4e00\u81f4\u7684\u5e8f\u6570\u5bf9\u9f50\u4f30\u8ba1\uff0c\u51cf\u5c11\u5bf9\u4e2a\u4f53\u504f\u597d\u8ffd\u8e2a\u9700\u6c42\uff0c\u5e76\u5728\u6709\u9650\u6837\u672c\u4e0b\u6709\u53ef\u63a7\u8bef\u5dee\u3002"}}
{"id": "2510.23640", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23640", "abs": "https://arxiv.org/abs/2510.23640", "authors": ["Zihao Jing", "Yan Sun", "Yan Yi Li", "Sugitha Janarthanan", "Alana Deng", "Pingzhao Hu"], "title": "Structure-Aware Fusion with Progressive Injection for Multimodal Molecular Representation Learning", "comment": "Accepted by NeurIPS 2025", "summary": "Multimodal molecular models often suffer from 3D conformer unreliability and\nmodality collapse, limiting their robustness and generalization. We propose\nMuMo, a structured multimodal fusion framework that addresses these challenges\nin molecular representation through two key strategies. To reduce the\ninstability of conformer-dependent fusion, we design a Structured Fusion\nPipeline (SFP) that combines 2D topology and 3D geometry into a unified and\nstable structural prior. To mitigate modality collapse caused by naive fusion,\nwe introduce a Progressive Injection (PI) mechanism that asymmetrically\nintegrates this prior into the sequence stream, preserving modality-specific\nmodeling while enabling cross-modal enrichment. Built on a state space\nbackbone, MuMo supports long-range dependency modeling and robust information\npropagation. Across 29 benchmark tasks from Therapeutics Data Commons (TDC) and\nMoleculeNet, MuMo achieves an average improvement of 2.7% over the\nbest-performing baseline on each task, ranking first on 22 of them, including a\n27% improvement on the LD50 task. These results validate its robustness to 3D\nconformer noise and the effectiveness of multimodal fusion in molecular\nrepresentation. The code is available at: github.com/selmiss/MuMo.", "AI": {"tldr": "MuMo\u901a\u8fc7\u5c062D\u62d3\u6251\u4e0e3D\u51e0\u4f55\u5408\u6210\u4e3a\u7a33\u5b9a\u5148\u9a8c\uff0c\u5e76\u4ee5\u6e10\u8fdb\u6ce8\u5165\u65b9\u5f0f\u975e\u5bf9\u79f0\u878d\u5408\u5230\u5e8f\u5217\u6d41\uff0c\u89e3\u51b3\u5171\u5f62\u4f53\u566a\u58f0\u548c\u6a21\u6001\u5d29\u584c\uff0c\u57fa\u4e8e\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u8868\u73b0\u4f18\u8d8a\u3002", "motivation": "\u73b0\u6709\u591a\u6a21\u6001\u5206\u5b50\u6a21\u578b\u53d73D\u6784\u578b\u4e0d\u53ef\u9760\u548c\u6a21\u6001\u95f4\u878d\u5408\u5bfc\u81f4\u7684\u4fe1\u606f\u4e22\u5931\u9650\u5236\uff0c\u9700\u4e00\u79cd\u65e2\u7a33\u5065\u53c8\u80fd\u4fdd\u7559\u6a21\u6001\u7279\u6027\u7684\u878d\u5408\u7b56\u7565\u3002", "method": "\u8bbe\u8ba1\u4e86\u7ed3\u6784\u5316\u878d\u5408\u7ba1\u9053\uff08SFP\uff09\u7528\u4e8e\u5408\u5e762D\u4e0e3D\u4fe1\u606f\u4ee5\u6784\u5efa\u7a33\u5b9a\u5148\u9a8c\uff1b\u91c7\u7528\u6e10\u8fdb\u6ce8\u5165\uff08PI\uff09\u673a\u5236\u975e\u5bf9\u79f0\u5730\u5c06\u5148\u9a8c\u878d\u5408\u5165\u5e8f\u5217\u6d41\uff1b\u91c7\u7528\u72b6\u6001\u7a7a\u95f4\u7f51\u7edc\u4f5c\u4e3a\u9aa8\u5e72\u4ee5\u652f\u6301\u957f\u7a0b\u5efa\u6a21\u3002", "result": "MuMo\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u6784\u5316\u591a\u6a21\u6001\u878d\u5408\u6846\u67b6\uff0c\u65e8\u5728\u89e3\u51b3\u5206\u5b50\u5efa\u6a21\u4e2d3D\u5171\u5f62\u4f53\u4e0d\u53ef\u9760\u6027\u548c\u6a21\u6001\u5d29\u584c\u95ee\u9898\u3002\u901a\u8fc7\u7ed3\u6784\u5316\u878d\u5408\u7ba1\u9053\uff08SFP\uff09\u5c062D\u62d3\u6251\u548c3D\u51e0\u4f55\u6574\u5408\u4e3a\u7a33\u5b9a\u7684\u7ed3\u6784\u5148\u9a8c\uff0c\u5e76\u901a\u8fc7\u6e10\u8fdb\u6ce8\u5165\uff08PI\uff09\u673a\u5236\u5c06\u8be5\u5148\u9a8c\u975e\u5bf9\u79f0\u5730\u6ce8\u5165\u5e8f\u5217\u6d41\uff0c\u4ee5\u4fdd\u6301\u6a21\u6001\u7279\u6709\u5efa\u6a21\u540c\u65f6\u5b9e\u73b0\u8de8\u6a21\u6001\u589e\u5f3a\u3002\u57fa\u4e8e\u72b6\u6001\u7a7a\u95f4\u9aa8\u5e72\u7f51\u7edc\uff0c\u652f\u6301\u957f\u8ddd\u79bb\u4f9d\u8d56\u548c\u9c81\u68d2\u7684\u4fe1\u606f\u4f20\u64ad\u3002\u5728TDC\u548cMoleculeNet\u768429\u4e2a\u57fa\u51c6\u4efb\u52a1\u4e0a\u5e73\u5747\u4f18\u4e8e\u6700\u4f73\u57fa\u7ebf2.7%\uff0c\u572822\u4e2a\u4efb\u52a1\u4e0a\u6392\u540d\u7b2c\u4e00\u3002", "conclusion": "MuMo\u80fd\u663e\u8457\u63d0\u5347\u591a\u6a21\u6001\u5206\u5b50\u8868\u793a\u7684\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u6027\uff0c\u7279\u522b\u5728\u542b\u566a3D\u5171\u5f62\u4f53\u573a\u666f\u4e0b\u6548\u679c\u660e\u663e\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5728\u591a\u4e2a\u57fa\u51c6\u4efb\u52a1\u4e0a\u53d6\u5f97\u9886\u5148\u6210\u7ee9\u3002"}}
{"id": "2510.24498", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24498", "abs": "https://arxiv.org/abs/2510.24498", "authors": ["Tejaswini Bollikonda"], "title": "Design and Optimization of Cloud Native Homomorphic Encryption Workflows for Privacy-Preserving ML Inference", "comment": "6 pages 2 figures, 2 tABLES", "summary": "As machine learning (ML) models become increasingly deployed through cloud\ninfrastructures, the confidentiality of user data during inference poses a\nsignificant security challenge. Homomorphic Encryption (HE) has emerged as a\ncompelling cryptographic technique that enables computation on encrypted data,\nallowing predictions to be generated without decrypting sensitive inputs.\nHowever, the integration of HE within large scale cloud native pipelines\nremains constrained by high computational overhead, orchestration complexity,\nand model compatibility issues.\n  This paper presents a systematic framework for the design and optimization of\ncloud native homomorphic encryption workflows that support privacy-preserving\nML inference. The proposed architecture integrates containerized HE modules\nwith Kubernetes-based orchestration, enabling elastic scaling and parallel\nencrypted computation across distributed environments. Furthermore,\noptimization strategies including ciphertext packing, polynomial modulus\nadjustment, and operator fusion are employed to minimize latency and resource\nconsumption while preserving cryptographic integrity. Experimental results\ndemonstrate that the proposed system achieves up to 3.2times inference\nacceleration and 40% reduction in memory utilization compared to conventional\nHE pipelines. These findings illustrate a practical pathway for deploying\nsecure ML-as-a-Service (MLaaS) systems that guarantee data confidentiality\nunder zero-trust cloud conditions.", "AI": {"tldr": "Proposes Kubernetes-orchestrated containerized HE modules with optimizations (ciphertext packing, polynomial modulus adjustment, operator fusion) to improve performance and resource use for privacy-preserving ML inference", "motivation": "Address confidentiality of user data during ML inference in cloud environments by enabling computation on encrypted inputs without decryption", "method": "Systematic framework integrating HE with cloud-native pipelines", "result": "Up to 3.2x inference acceleration and 40% memory reduction vs conventional HE pipelines", "conclusion": "Practical pathway for scalable, secure MLaaS under zero-trust clouds via optimized HE workflows"}}
{"id": "2510.23989", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23989", "abs": "https://arxiv.org/abs/2510.23989", "authors": ["Shangde Gao", "Zelin Xu", "Zhe Jiang"], "title": "Learning Individual Movement Shifts After Urban Disruptions with Social Infrastructure Reliance", "comment": null, "summary": "Shifts in individual movement patterns following disruptive events can reveal\nchanging demands for community resources. However, predicting such shifts\nbefore disruptive events remains challenging for several reasons. First,\nmeasures are lacking for individuals' heterogeneous social infrastructure\nresilience (SIR), which directly influences their movement patterns, and\ncommonly used features are often limited or unavailable at scale, e.g.,\nsociodemographic characteristics. Second, the complex interactions between\nindividual movement patterns and spatial contexts have not been sufficiently\ncaptured. Third, individual-level movement may be spatially sparse and not\nwell-suited to traditional decision-making methods for movement predictions.\nThis study incorporates individuals' SIR into a conditioned deep learning model\nto capture the complex relationships between individual movement patterns and\nlocal spatial context using large-scale, sparse individual-level data. Our\nexperiments demonstrate that incorporating individuals' SIR and spatial context\ncan enhance the model's ability to predict post-event individual movement\npatterns. The conditioned model can capture the divergent shifts in movement\npatterns among individuals who exhibit similar pre-event patterns but differ in\nSIR.", "AI": {"tldr": "\u5728\u53d7\u6270\u52a8\u4e8b\u4ef6\u540e\uff0c\u4e2a\u4f53\u51fa\u884c\u6a21\u5f0f\u4f1a\u53d1\u751f\u53d8\u5316\u3002\u8be5\u6587\u63d0\u51fa\u5c06\u4e2a\u4f53\u7684\u793e\u4f1a\u57fa\u7840\u8bbe\u65bd\u97e7\u6027\uff08SIR\uff09\u4f5c\u4e3a\u6761\u4ef6\uff0c\u7ed3\u5408\u6df1\u5ea6\u5b66\u4e60\u4e0e\u7a7a\u95f4\u4e0a\u4e0b\u6587\uff0c\u63d0\u9ad8\u5bf9\u4e8b\u4ef6\u540e\u4e2a\u4f53\u79fb\u52a8\u6a21\u5f0f\u53d8\u5316\u7684\u9884\u6d4b\u80fd\u529b\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u7f3a\u4e4f\u53ef\u89c4\u6a21\u5316\u83b7\u53d6\u7684\u4e2a\u4f53\u5f02\u8d28\u6027\u97e7\u6027\u5ea6\u91cf\uff0c\u4e14\u96be\u4ee5\u6355\u6349\u79fb\u52a8\u6a21\u5f0f\u4e0e\u7a7a\u95f4\u60c5\u5883\u7684\u590d\u6742\u4ea4\u4e92\uff0c\u5bfc\u81f4\u96be\u4ee5\u5728\u4e8b\u4ef6\u53d1\u751f\u524d\u9884\u6d4b\u4e2a\u4f53\u51fa\u884c\u6a21\u5f0f\u7684\u5206\u5316\u3002", "method": "\u6784\u5efa\u6761\u4ef6\u5316\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u8f93\u5165\u5305\u542b\u4e2a\u4f53\u7684\u9884\u4e8b\u4ef6\u79fb\u52a8\u5e8f\u5217\u3001SIR\u6307\u6807\u548c\u5c40\u90e8\u7a7a\u95f4\u7279\u5f81\uff1b\u4f7f\u7528\u5927\u89c4\u6a21\u7a00\u758f\u4e2a\u4f53\u7ea7\u79fb\u52a8\u6570\u636e\u8fdb\u884c\u8bad\u7ec3\u4e0e\u8bc4\u4f30\uff1b\u901a\u8fc7\u5bf9\u6bd4\u5b9e\u9a8c\u8bc1\u660e\u5f15\u5165SIR\u4e0e\u7a7a\u95f4\u4e0a\u4e0b\u6587\u7684\u589e\u76ca\u3002", "result": "The paper proposes incorporating social infrastructure resilience (SIR) into a conditioned deep learning model to predict individual movement pattern shifts after disruptive events, using large-scale sparse individual-level data and local spatial context.", "conclusion": "\u5c06SIR\u4e0e\u7a7a\u95f4\u4e0a\u4e0b\u6587\u5f15\u5165\u6761\u4ef6\u5316\u6df1\u5ea6\u6a21\u578b\u80fd\u66f4\u597d\u5730\u9884\u6d4b\u4e2a\u4f53\u5728\u6270\u52a8\u4e8b\u4ef6\u540e\u7684\u79fb\u52a8\u6a21\u5f0f\uff0c\u5e76\u533a\u5206\u5728\u4e8b\u4ef6\u524d\u6a21\u5f0f\u76f8\u4f3c\u4f46SIR\u4e0d\u540c\u7684\u4e2a\u4f53\u7684\u5dee\u5f02\u6027\u54cd\u5e94\u3002"}}
{"id": "2510.23641", "categories": ["cs.LG", "cs.AI", "hep-ex", "physics.ins-det"], "pdf": "https://arxiv.org/pdf/2510.23641", "abs": "https://arxiv.org/abs/2510.23641", "authors": ["Aaron Wang", "Zihan Zhao", "Subash Katel", "Vivekanand Gyanchand Sahu", "Elham E Khoda", "Abhijith Gandrakota", "Jennifer Ngadiuba", "Richard Cavanaugh", "Javier Duarte"], "title": "Spatially Aware Linear Transformer (SAL-T) for Particle Jet Tagging", "comment": null, "summary": "Transformers are very effective in capturing both global and local\ncorrelations within high-energy particle collisions, but they present\ndeployment challenges in high-data-throughput environments, such as the CERN\nLHC. The quadratic complexity of transformer models demands substantial\nresources and increases latency during inference. In order to address these\nissues, we introduce the Spatially Aware Linear Transformer (SAL-T), a\nphysics-inspired enhancement of the linformer architecture that maintains\nlinear attention. Our method incorporates spatially aware partitioning of\nparticles based on kinematic features, thereby computing attention between\nregions of physical significance. Additionally, we employ convolutional layers\nto capture local correlations, informed by insights from jet physics. In\naddition to outperforming the standard linformer in jet classification tasks,\nSAL-T also achieves classification results comparable to full-attention\ntransformers, while using considerably fewer resources with lower latency\nduring inference. Experiments on a generic point cloud classification dataset\n(ModelNet10) further confirm this trend. Our code is available at\nhttps://github.com/aaronw5/SAL-T4HEP.", "AI": {"tldr": "\u63d0\u51faSAL-T\uff1a\u5c06\u57fa\u4e8e\u8fd0\u52a8\u5b66\u7684\u7a7a\u95f4\u5206\u533a\u548c\u5c40\u90e8\u5377\u79ef\u6574\u5408\u8fdb\u7ebf\u6027Transformer\uff0c\u663e\u8457\u964d\u4f4e\u63a8\u7406\u8d44\u6e90\u4e0e\u5ef6\u8fdf\uff0c\u540c\u65f6\u4fdd\u6301\u6216\u63a5\u8fd1\u5168\u6ce8\u610f\u529b\u6027\u80fd\uff0c\u9002\u7528\u4e8e\u9ad8\u80fd\u7269\u7406\u548c\u70b9\u4e91\u5206\u7c7b\u3002", "motivation": "\u5168\u6ce8\u610f\u529bTransformer\u5728\u9ad8\u80fd\u7269\u7406\u6570\u636e\uff08\u5927\u91cf\u7c92\u5b50\u70b9\u4e91\uff09\u4e0a\u6548\u679c\u597d\u4f46\u63a8\u7406\u65f6\u8d44\u6e90\u548c\u5ef6\u8fdf\u9ad8\uff1b\u9700\u8981\u4e00\u79cd\u80fd\u4fdd\u7559\u6027\u80fd\u540c\u65f6\u964d\u4f4e\u8ba1\u7b97/\u5185\u5b58\u5f00\u9500\u3001\u9002\u7528\u4e8eLHC\u7b49\u9ad8\u541e\u5410\u573a\u666f\u7684\u65b9\u6cd5\u3002", "method": "\u5728Linformer\u6846\u67b6\u4e0a\u5f15\u5165\u57fa\u4e8e\u7c92\u5b50\u52a8\u5b66\u7279\u5f81\uff08\u5982\u89d2\u5ea6\u3001\u80fd\u91cf\u7b49\uff09\u7684\u7a7a\u95f4\u611f\u77e5\u5206\u533a\uff0c\u5bf9\u533a\u57df\u95f4\u8fdb\u884c\u7ebf\u6027\u6ce8\u610f\u529b\u8ba1\u7b97\uff1b\u5e76\u5728\u5206\u533a\u5185\u6216\u90bb\u8fd1\u533a\u57df\u52a0\u5165\u5377\u79ef\u5c42\u4ee5\u6355\u83b7\u5c40\u90e8\u76f8\u5173\u6027\uff0c\u7ed3\u5408\u7269\u7406\u76f4\u89c9\uff08\u55b7\u6ce8\u7269\u7406\uff09\u8bbe\u8ba1\u7f51\u7edc\u7ed3\u6784\u548c\u7279\u5f81\u7f16\u7801\u3002", "result": "\u5728\u55b7\u6ce8\u5206\u7c7b\u4efb\u52a1\u4e0a\uff0cSAL-T\u4f18\u4e8e\u6807\u51c6Linformer\uff0c\u5e76\u5728\u8d44\u6e90\u4e0e\u5ef6\u8fdf\u663e\u8457\u964d\u4f4e\u7684\u60c5\u51b5\u4e0b\u8fbe\u5230\u4e0e\u5168\u6ce8\u610f\u529bTransformer\u63a5\u8fd1\u7684\u5206\u7c7b\u6027\u80fd\uff1b\u5728ModelNet10\u70b9\u4e91\u5206\u7c7b\u4e0a\u4e5f\u9a8c\u8bc1\u4e86\u76f8\u540c\u8d8b\u52bf\u3002\u63d0\u4f9b\u4e86\u4ee3\u7801\u4ed3\u5e93\u3002", "conclusion": "SAL-T\u5728\u4fdd\u6301\u7ebf\u6027\u6ce8\u610f\u529b\u590d\u6742\u5ea6\u7684\u540c\u65f6\uff0c\u901a\u8fc7\u57fa\u4e8e\u8fd0\u52a8\u5b66\u7279\u5f81\u7684\u7a7a\u95f4\u611f\u77e5\u5206\u533a\u4e0e\u5377\u79ef\u5c42\u8865\u5145\u5c40\u90e8\u76f8\u5173\u6027\uff0c\u80fd\u5728\u8d44\u6e90\u53d7\u9650\u573a\u666f\u4e0b\u63a5\u8fd1\u5168\u6ce8\u610f\u529bTransformer\u7684\u6027\u80fd\uff0c\u5e76\u4f18\u4e8e\u6807\u51c6Linformer\u3002"}}
{"id": "2510.24013", "categories": ["cs.AI", "cs.LG", "cs.NE", "math.CO", "math.OC"], "pdf": "https://arxiv.org/pdf/2510.24013", "abs": "https://arxiv.org/abs/2510.24013", "authors": ["\u0130brahim O\u011fuz \u00c7etinkaya", "\u0130. Esra B\u00fcy\u00fcktahtak\u0131n", "Parshin Shojaee", "Chandan K. Reddy"], "title": "Discovering Heuristics with Large Language Models (LLMs) for Mixed-Integer Programs: Single-Machine Scheduling", "comment": null, "summary": "Our study contributes to the scheduling and combinatorial optimization\nliterature with new heuristics discovered by leveraging the power of Large\nLanguage Models (LLMs). We focus on the single-machine total tardiness (SMTT)\nproblem, which aims to minimize total tardiness by sequencing n jobs on a\nsingle processor without preemption, given processing times and due dates. We\ndevelop and benchmark two novel LLM-discovered heuristics, the EDD Challenger\n(EDDC) and MDD Challenger (MDDC), inspired by the well-known Earliest Due Date\n(EDD) and Modified Due Date (MDD) rules. In contrast to prior studies that\nemployed simpler rule-based heuristics, we evaluate our LLM-discovered\nalgorithms using rigorous criteria, including optimality gaps and solution time\nderived from a mixed-integer programming (MIP) formulation of SMTT. We compare\ntheir performance against state-of-the-art heuristics and exact methods across\nvarious job sizes (20, 100, 200, and 500 jobs). For instances with more than\n100 jobs, exact methods such as MIP and dynamic programming become\ncomputationally intractable. Up to 500 jobs, EDDC improves upon the classic EDD\nrule and another widely used algorithm in the literature. MDDC consistently\noutperforms traditional heuristics and remains competitive with exact\napproaches, particularly on larger and more complex instances. This study shows\nthat human-LLM collaboration can produce scalable, high-performing heuristics\nfor NP-hard constrained combinatorial optimization, even under limited\nresources when effectively configured.", "AI": {"tldr": "LLM-guided human-in-the-loop design produced two new heuristics (EDDC, MDDC) that outperform classical rules on SMTT, are scalable, and competitive with exact approaches on large instances.", "motivation": "Leverage LLMs to discover improved heuristics for NP-hard scheduling problem (SMTT) where exact methods are infeasible at scale.", "method": "Use LLMs to generate heuristics inspired by EDD and MDD; evaluate via MIP formulations measuring optimality gaps and runtimes across instance sizes (20,100,200,500 jobs).", "result": "EDDC improves over EDD and a common algorithm; MDDC outperforms traditional heuristics and competes with exact methods on larger instances; both scale to 500 jobs.", "conclusion": "LLM-assisted heuristics (EDDC and MDDC) improve upon classic rules for SMTT, scaling to larger instances and offering competitive performance vs. exact methods."}}
{"id": "2510.23649", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23649", "abs": "https://arxiv.org/abs/2510.23649", "authors": ["Tenghui Li", "Guoxu Zhou", "Xuyang Zhao", "Yuning Qiu", "Qibin Zhao"], "title": "Efficient Low Rank Attention for Long-Context Inference in Large Language Models", "comment": null, "summary": "As the length of input text grows, the key-value (KV) cache in LLMs imposes\nprohibitive GPU memory costs and limits long-context inference on resource\nconstrained devices. Existing approaches, such as KV quantization and pruning,\nreduce memory usage but suffer from numerical precision loss or suboptimal\nretention of key-value pairs. We introduce Low Rank Query and Key attention\n(LRQK), a two-stage framework that jointly decomposes the full-precision query\nand key matrices into compact rank-\\(r\\) factors during the prefill stage, and\nthen uses these low-dimensional projections to compute proxy attention scores\nin \\(\\mathcal{O}(lr)\\) time at each decode step. By selecting only the\ntop-\\(k\\) tokens and a small fixed set of recent tokens, LRQK employs a mixed\nGPU-CPU cache with a hit-and-miss mechanism that transfers only missing\nfull-precision KV pairs, thereby preserving exact attention outputs while\nreducing CPU-GPU data movement. Extensive experiments on the RULER and\nLongBench benchmarks with LLaMA-3-8B and Qwen2.5-7B demonstrate that LRQK\nmatches or surpasses leading sparse-attention methods in long context settings,\nwhile delivering significant memory savings with minimal loss in accuracy. Our\ncode is available at https://github.com/tenghuilee/LRQK.", "AI": {"tldr": "LRQK\u901a\u8fc7\u5728prefill\u65f6\u5bf9Q\u548cK\u505a\u4f4e\u79e9\u5206\u89e3\u5e76\u5728decode\u65f6\u57fa\u4e8e\u4f4e\u7ef4\u6295\u5f71\u5feb\u901f\u7b5b\u9009top-k\u548c\u8fd1\u671ftokens\uff0c\u53ea\u5728\u7f3a\u5931\u65f6\u4eceCPU\u4f20\u8f93\u5168\u7cbe\u5ea6KV\uff0c\u5b9e\u73b0\u957f\u4e0a\u4e0b\u6587\u4e0b\u7684\u663e\u8457\u5185\u5b58\u4e0e\u5e26\u5bbd\u8282\u7ea6\u4e14\u51e0\u4e4e\u4e0d\u635f\u5931\u51c6\u786e\u6027\u3002", "motivation": "\u5f53\u8f93\u5165\u957f\u5ea6\u589e\u957f\u65f6\uff0cKV\u7f13\u5b58\u7684GPU\u5185\u5b58\u4e0eCPU-GPU\u4f20\u8f93\u6210\u4e3a\u9650\u5236\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u7684\u74f6\u9888\u3002\u73b0\u6709\u91cf\u5316\u6216\u526a\u679d\u65b9\u6cd5\u5b58\u5728\u6570\u503c\u7cbe\u5ea6\u635f\u5931\u6216\u9009\u62e9\u5b50\u96c6\u4e0d\u7406\u60f3\u7684\u95ee\u9898\uff0c\u56e0\u800c\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u8282\u7ea6\u5185\u5b58\u53c8\u80fd\u4fdd\u6301\u6ce8\u610f\u529b\u7cbe\u786e\u6027\u7684\u65b9\u6848\u3002", "method": "\u4e24\u9636\u6bb5\uff1a1) Prefill\u9636\u6bb5\u5bf9\u5168\u7cbe\u5ea6Q\u548cK\u505a\u8054\u5408\u4f4e\u79e9\u5206\u89e3\uff0c\u5f97\u5230rank-r\u56e0\u5b50\u5e76\u5b58\u50a8\u4f4e\u7ef4\u6295\u5f71\uff1b2) Decode\u9636\u6bb5\u4f7f\u7528\u4f4e\u79e9\u6295\u5f71\u4ee5O(lr)\u590d\u6742\u5ea6\u8ba1\u7b97\u4ee3\u7406\u6ce8\u610f\u5206\u6570\u4ee5\u7b5b\u9009top-k tokens\u5e76\u7ed3\u5408\u56fa\u5b9a\u6570\u91cf\u7684\u8fd1\u671ftokens\uff1b\u91c7\u7528\u6df7\u5408GPU-CPU\u7f13\u5b58\uff0c\u9047\u5230miss\u518d\u6309\u9700\u4eceCPU\u4f20\u8f93\u5b8c\u6574KV\u4ee5\u4fdd\u6301\u7cbe\u786e\u6ce8\u610f\u529b\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u79cd\u79f0\u4e3aLRQK\u7684\u4e24\u9636\u6bb5\u6846\u67b6\uff0c\u5728\u9884\u586b\u5145\u9636\u6bb5\u5c06\u67e5\u8be2\uff08Q\uff09\u548c\u952e\uff08K\uff09\u77e9\u9635\u5206\u89e3\u4e3a\u4f4e\u79e9\u56e0\u5b50\uff0c\u5e76\u5728\u89e3\u7801\u9636\u6bb5\u7528\u4f4e\u7ef4\u6295\u5f71\u8ba1\u7b97\u4ee3\u7406\u6ce8\u610f\u5206\u6570\uff0c\u4ece\u800c\u663e\u8457\u964d\u4f4eKV\u7f13\u5b58\u7684GPU\u5185\u5b58\u5f00\u9500\u5e76\u51cf\u5c11CPU-GPU\u7684\u6570\u636e\u4f20\u8f93\uff0c\u540c\u65f6\u4fdd\u6301\u7cbe\u786e\u7684\u6ce8\u610f\u529b\u8f93\u51fa\u3002", "conclusion": "LRQK\u5728RULER\u548cLongBench\u4e0a\u5bf9LLaMA-3-8B\u4e0eQwen2.5-7B\u505a\u9a8c\u8bc1\uff0c\u80fd\u5728\u957f\u4e0a\u4e0b\u6587\u573a\u666f\u4e0b\u5339\u914d\u6216\u4f18\u4e8e\u73b0\u6709\u7a00\u758f\u6ce8\u610f\u65b9\u6cd5\uff0c\u540c\u65f6\u5e26\u6765\u663e\u8457\u5185\u5b58\u8282\u7ea6\u4e0e\u6781\u5c0f\u51c6\u786e\u6027\u635f\u5931\u3002"}}
{"id": "2510.24028", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24028", "abs": "https://arxiv.org/abs/2510.24028", "authors": ["Tingyue Pan", "Mingyue Cheng", "Shilong Zhang", "Zhiding Liu", "Xiaoyu Tao", "Yucong Luo", "Jintao Zhang", "Qi Liu"], "title": "OneCast: Structured Decomposition and Modular Generation for Cross-Domain Time Series Forecasting", "comment": null, "summary": "Cross-domain time series forecasting is a valuable task in various web\napplications. Despite its rapid advancement, achieving effective generalization\nacross heterogeneous time series data remains a significant challenge. Existing\nmethods have made progress by extending single-domain models, yet often fall\nshort when facing domain-specific trend shifts and inconsistent periodic\npatterns. We argue that a key limitation lies in treating temporal series as\nundifferentiated sequence, without explicitly decoupling their inherent\nstructural components. To address this, we propose OneCast, a structured and\nmodular forecasting framework that decomposes time series into seasonal and\ntrend components, each modeled through tailored generative pathways.\nSpecifically, the seasonal component is captured by a lightweight projection\nmodule that reconstructs periodic patterns via interpretable basis functions.\nIn parallel, the trend component is encoded into discrete tokens at segment\nlevel via a semantic-aware tokenizer, and subsequently inferred through a\nmasked discrete diffusion mechanism. The outputs from both branches are\ncombined to produce a final forecast that captures seasonal patterns while\ntracking domain-specific trends. Extensive experiments across eight domains\ndemonstrate that OneCast mostly outperforms state-of-the-art baselines.", "AI": {"tldr": "OneCast\u901a\u8fc7\u5b63\u8282/\u8d8b\u52bf\u5206\u89e3\u3001\u57fa\u51fd\u6570\u91cd\u5efa\u5b63\u8282\u6027\u548c\u79bb\u6563\u6269\u6563\u5efa\u6a21\u8d8b\u52bf\uff0c\u5b9e\u73b0\u8de8\u57df\u66f4\u9c81\u68d2\u7684\u65f6\u5e8f\u9884\u6d4b\uff0c\u5b9e\u9a8c\u5728\u516b\u4e2a\u57df\u4e0a\u4f18\u4e8e\u5927\u591a\u6570\u57fa\u7ebf\u3002", "motivation": "\u73b0\u6709\u8de8\u57df\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u65b9\u6cd5\u628a\u5e8f\u5217\u89c6\u4e3a\u65e0\u5dee\u522b\u7684\u4e00\u7ef4\u5e8f\u5217\uff0c\u672a\u80fd\u663e\u5f0f\u89e3\u8026\u65f6\u5e8f\u4e2d\u7684\u7ed3\u6784\u6210\u5206\uff08\u5b63\u8282\u6027\u4e0e\u8d8b\u52bf\uff09\uff0c\u56e0\u6b64\u96be\u4ee5\u5e94\u5bf9\u5404\u57df\u95f4\u7684\u8d8b\u52bf\u6f02\u79fb\u4e0e\u5468\u671f\u4e0d\u4e00\u81f4\u95ee\u9898\u3002", "method": "\u53cc\u5206\u652f\u6846\u67b6\uff1a1) \u5b63\u8282\u5206\u652f\uff1a\u8f7b\u91cf\u6295\u5f71\u6a21\u5757+\u53ef\u89e3\u91ca\u57fa\u51fd\u6570\u91cd\u6784\u5468\u671f\u6027\uff1b2) \u8d8b\u52bf\u5206\u652f\uff1a\u8bed\u4e49\u611f\u77e5\u5206\u6bb5tokenizer\u5c06\u8d8b\u52bf\u7f16\u7801\u4e3a\u79bb\u6563token\uff0c\u4f7f\u7528\u63a9\u7801\u79bb\u6563\u6269\u6563\u6a21\u578b\u63a8\u65ad\uff0c\u518d\u4e0e\u5b63\u8282\u5206\u91cf\u5408\u5e76\u8f93\u51fa\u3002", "result": "\u63d0\u51faOneCast\u2014\u2014\u4e00\u79cd\u7ed3\u6784\u5316\u6a21\u5757\u5316\u7684\u9884\u6d4b\u6846\u67b6\uff1a\u5c06\u65f6\u95f4\u5e8f\u5217\u5206\u89e3\u4e3a\u5b63\u8282\u6027\u4e0e\u8d8b\u52bf\u5206\u91cf\uff1b\u5b63\u8282\u6027\u7528\u8f7b\u91cf\u6295\u5f71\u6a21\u5757\u548c\u53ef\u89e3\u91ca\u57fa\u51fd\u6570\u91cd\u5efa\uff1b\u8d8b\u52bf\u7528\u8bed\u4e49\u611f\u77e5\u5206\u6bb5\u6807\u8bb0\u5668\u79bb\u6563\u5316\u4e3atoken\uff0c\u5e76\u7528\u63a9\u7801\u79bb\u6563\u6269\u6563\u673a\u5236\u63a8\u65ad\u3002\u4e24\u5206\u652f\u5408\u6210\u6700\u7ec8\u9884\u6d4b\u3002", "conclusion": "\u6309\u7ed3\u6784\u5206\u89e3\u65f6\u5e8f\u5e76\u5206\u522b\u7528\u9488\u5bf9\u6027\u751f\u6210\u8def\u5f84\u5efa\u6a21\u5b63\u8282\u4e0e\u8d8b\u52bf\uff0c\u53ef\u66f4\u597d\u517c\u987e\u8de8\u57df\u7684\u5468\u671f\u5dee\u5f02\u548c\u8d8b\u52bf\u6f02\u79fb\uff0c\u63d0\u9ad8\u9884\u6d4b\u6027\u80fd\u3002"}}
{"id": "2510.23650", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23650", "abs": "https://arxiv.org/abs/2510.23650", "authors": ["Wei Xia"], "title": "Beyond Hidden-Layer Manipulation: Semantically-Aware Logit Interventions for Debiasing LLMs", "comment": null, "summary": "We proposed Static and Dynamic -- two zero-shot logits-layer debiasing\nmethods. Dynamic reduces bias by up to 70% with minimal fluency loss. Logits\nintervention outperforms hidden-layer approaches. We show semantic-aware logits\nintervention is stable and effective for debiasing aligned LLMs.", "AI": {"tldr": "\u63d0\u51fa\u4e24\u79cd\u96f6-shot logits\u5c42\u53bb\u504f\u65b9\u6cd5\uff1aStatic\u4e0eDynamic\u3002Dynamic\u5728\u4fdd\u6301\u6d41\u7545\u6027\u7684\u540c\u65f6\uff0c\u504f\u89c1\u964d\u4f4e\u6700\u9ad8\u8fbe70%\uff1b\u603b\u4f53\u4e0alogits\u5c42\u5e72\u9884\u4f18\u4e8e\u9690\u85cf\u5c42\u65b9\u6cd5\uff1b\u8bed\u4e49\u611f\u77e5\u7684logits\u5e72\u9884\u5728\u5df2\u5bf9\u9f50\u7684\u5927\u6a21\u578b\u4e0a\u7a33\u5b9a\u6709\u6548\u3002", "motivation": "\u9488\u5bf9\u9690\u85cf\u5c42\u53bb\u504f\u65b9\u6cd5\u590d\u6742\u3001\u6548\u679c\u4e0d\u7a33\u5b9a\u6216\u5f71\u54cd\u751f\u6210\u8d28\u91cf\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u5728logits\u5c42\u76f4\u63a5\u3001\u96f6-shot\u5730\u8fdb\u884c\u8bed\u4e49\u611f\u77e5\u8c03\u63a7\uff0c\u4ee5\u5b9e\u73b0\u9ad8\u6548\u3001\u7a33\u5b9a\u7684\u53bb\u504f\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u7684\u751f\u6210\u6d41\u7545\u6027\u3002", "method": "\u63d0\u51faStatic\uff08\u9759\u6001\uff09\u4e0eDynamic\uff08\u52a8\u6001\uff09\u4e24\u79cd\u65b9\u6cd5\uff0c\u5747\u5728logits\u5c42\u8fdb\u884c\u5e72\u9884\u4ee5\u8c03\u6574\u6a21\u578b\u8f93\u51fa\u5206\u5e03\uff1bDynamic\u65b9\u6cd5\u6839\u636e\u8f93\u5165\u8bed\u4e49/\u4e0a\u4e0b\u6587\u52a8\u6001\u8c03\u6574logits\uff0c\u5bfc\u81f4\u66f4\u5f3a\u7684\u53bb\u504f\u6548\u679c\u4e14\u5bf9\u6d41\u7545\u6027\u5f71\u54cd\u8f83\u5c0f\u3002", "result": "Proposed two logits-layer, zero-shot debiasing methods: Static and Dynamic. Dynamic achieved up to 70% bias reduction with minimal fluency loss. Empirically, logits intervention outperforms hidden-layer methods. Semantic-aware logits intervention is stable and effective for aligned LLMs.", "conclusion": "Logits\u5c42\u76f4\u63a5\u5e72\u9884\u5728\u96f6-shot\u8bbe\u5b9a\u4e0b\u662f\u9ad8\u6548\u4e14\u7a33\u5b9a\u7684\u53bb\u504f\u7b56\u7565\uff0c\u5c24\u5176\u662f\u8bed\u4e49\u611f\u77e5\u7684Dynamic\u65b9\u6cd5\uff0c\u5728\u4e0d\u663e\u8457\u727a\u7272\u751f\u6210\u8d28\u91cf\u7684\u524d\u63d0\u4e0b\u663e\u8457\u964d\u4f4e\u504f\u89c1\uff0c\u4f18\u4e8e\u9690\u85cf\u5c42\u7b56\u7565\u3002"}}
{"id": "2510.24031", "categories": ["cs.AI", "cs.CR", "H.3.3, I.2.7, I.5.3, I.2.5,"], "pdf": "https://arxiv.org/pdf/2510.24031", "abs": "https://arxiv.org/abs/2510.24031", "authors": ["Peng Cai", "Reza Ryan", "Nickson M. Karie"], "title": "LLMLogAnalyzer: A Clustering-Based Log Analysis Chatbot using Large Language Models", "comment": "33 pages, 10 figures", "summary": "System logs are a cornerstone of cybersecurity, supporting proactive breach\nprevention and post-incident investigations. However, analyzing vast amounts of\ndiverse log data remains significantly challenging, as high costs, lack of\nin-house expertise, and time constraints make even basic analysis difficult for\nmany organizations. This study introduces LLMLogAnalyzer, a clustering-based\nlog analysis chatbot that leverages Large Language Models (LLMs) and Machine\nLearning (ML) algorithms to simplify and streamline log analysis processes.\nThis innovative approach addresses key LLM limitations, including context\nwindow constraints and poor structured text handling capabilities, enabling\nmore effective summarization, pattern extraction, and anomaly detection tasks.\nLLMLogAnalyzer is evaluated across four distinct domain logs and various tasks.\nResults demonstrate significant performance improvements over state-of-the-art\nLLM-based chatbots, including ChatGPT, ChatPDF, and NotebookLM, with consistent\ngains ranging from 39% to 68% across different tasks. The system also exhibits\nstrong robustness, achieving a 93% reduction in interquartile range (IQR) when\nusing ROUGE-1 scores, indicating significantly lower result variability. The\nframework's effectiveness stems from its modular architecture comprising a\nrouter, log recognizer, log parser, and search tools. This design enhances LLM\ncapabilities for structured text analysis while improving accuracy and\nrobustness, making it a valuable resource for both cybersecurity experts and\nnon-technical users.", "AI": {"tldr": "\u63d0\u51faLLMLogAnalyzer\u2014\u2014\u57fa\u4e8e\u805a\u7c7b\u7684\u65e5\u5fd7\u5206\u6790\u804a\u5929\u673a\u5668\u4eba\uff0c\u5229\u7528\u6a21\u5757\u5316\u67b6\u6784\u548c\u68c0\u7d22/\u89e3\u6790\u7ec4\u4ef6\u63d0\u5347LLM\u5bf9\u7ed3\u6784\u5316\u65e5\u5fd7\u7684\u5904\u7406\u80fd\u529b\uff0c\u57284\u7c7b\u65e5\u5fd7\u4e0e\u591a\u4efb\u52a1\u8bc4\u6d4b\u4e2d\u8f83\u73b0\u6709LLM\u804a\u5929\u5de5\u5177\u63d0\u534739%\u201368%\uff0c\u5e76\u663e\u8457\u964d\u4f4e\u7ed3\u679c\u6ce2\u52a8\uff08ROUGE-1 IQR\u4e0b\u964d93%\uff09\u3002", "motivation": "\u5927\u591a\u6570\u7ec4\u7ec7\u7f3a\u4e4f\u5904\u7406\u5927\u91cf\u3001\u591a\u6837\u5316\u65e5\u5fd7\u7684\u6570\u636e\u4e0e\u4eba\u624d\uff0c\u4e14LLM\u5728\u957f\u6587\u548c\u7ed3\u6784\u5316\u6587\u672c\u4e0a\u8868\u73b0\u6709\u9650\uff1b\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u53ef\u6269\u5c55\u3001\u9c81\u68d2\u4e14\u5bf9\u975e\u6280\u672f\u7528\u6237\u53cb\u597d\u7684\u65e5\u5fd7\u5206\u6790\u65b9\u6848\u3002", "method": "\u7cfb\u7edf\u5148\u7528router\u5206\u6d41\u3001log recognizer\u8bc6\u522b\u65e5\u5fd7\u7c7b\u578b\uff0c\u518d\u7528parser\u5c06\u7ed3\u6784\u5316\u5b57\u6bb5\u63d0\u53d6\u5e76\u805a\u7c7b\uff0c\u7ed3\u5408\u641c\u7d22\u5de5\u5177\u5bf9\u805a\u7c7b\u7ed3\u679c\u548c\u539f\u59cb\u65e5\u5fd7\u8fdb\u884c\u4e0a\u4e0b\u6587\u68c0\u7d22\uff0c\u6700\u540e\u7531LLM\u751f\u6210\u6458\u8981\u3001\u6a21\u5f0f\u6216\u5f02\u5e38\u62a5\u544a\u3002\u8bc4\u4f30\u91c7\u75284\u7c7b\u771f\u5b9e\u65e5\u5fd7\u4e0e\u591a\u4efb\u52a1\u5bf9\u6bd4ChatGPT/ChatPDF/NotebookLM\uff0c\u4f7f\u7528ROUGE\u7b49\u6307\u6807\u8861\u91cf\u8d28\u91cf\u4e0e\u7a33\u5b9a\u6027\u3002", "result": "LLMLogAnalyzer\u901a\u8fc7\u7ed3\u5408\u805a\u7c7b\u3001LLM\u4e0e\u4f20\u7edfML\u65b9\u6cd5\uff0c\u6784\u5efa\u6a21\u5757\u5316\u6d41\u6c34\u7ebf\uff08router\u3001log recognizer\u3001parser\u3001search\uff09\u4ee5\u514b\u670dLLM\u4e0a\u4e0b\u6587\u7a97\u53e3\u4e0e\u7ed3\u6784\u5316\u6587\u672c\u5904\u7406\u5f31\u70b9\uff0c\u5b9e\u73b0\u65e5\u5fd7\u6458\u8981\u3001\u6a21\u5f0f\u63d0\u53d6\u4e0e\u5f02\u5e38\u68c0\u6d4b\u7b49\u4efb\u52a1\u3002", "conclusion": "\u672c\u6587\u8bc1\u660e\u5c06\u805a\u7c7b\u4e0e\u68c0\u7d22\u5f0f\u6d41\u6c34\u7ebf\u4e0eLLM\u7ed3\u5408\u80fd\u663e\u8457\u63d0\u9ad8\u65e5\u5fd7\u5206\u6790\u7684\u51c6\u786e\u6027\u4e0e\u7a33\u5b9a\u6027\uff0c\u4f7f\u590d\u6742\u65e5\u5fd7\u4efb\u52a1\u5bf9\u975e\u4e13\u5bb6\u66f4\u53ef\u884c\u3002"}}
{"id": "2510.23652", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23652", "abs": "https://arxiv.org/abs/2510.23652", "authors": ["Yao Lu", "Yuqi Li", "Wenbin Xie", "Shanqing Yu", "Qi Xuan", "Zhaowei Zhu", "Shiping Wen"], "title": "The Structural Scalpel: Automated Contiguous Layer Pruning for Large Language Models", "comment": null, "summary": "Although large language models (LLMs) have achieved revolutionary\nbreakthroughs in many fields, their large model size and high computational\ncost pose significant challenges for practical deployment on\nresource-constrained edge devices. To this end, layer pruning has been proposed\nto reduce the computational overhead by directly removing redundant layers.\nHowever, existing layer pruning methods typically rely on hand-crafted metrics\nto evaluate and remove individual layers, while ignoring the dependencies\nbetween layers. This can disrupt the model's information flow and severely\ndegrade performance. To address these issues, we propose CLP, a novel\ncontinuous layer pruning framework that introduces two key innovations: a\ndifferentiable concave gate algorithm that automatically identifies the best\ncontinuous layer segments for pruning via gradient-based optimization; and a\ncutoff endpoint tuning strategy that effectively restores model performance by\nfine-tuning only the layers adjacent to the pruned segments. Extensive\nexperiments across multiple model architectures (including LLaMA2, LLaMA3 and\nQwen) and sizes (from $7$B to $70$B parameters) show that CLP significantly\noutperforms existing state-of-the-art baselines. For example, at a pruning rate\nof $20\\%$, CLP achieves an average performance retention of $95.34\\%$ on\nLLaMA3-70B, outperforming baselines by $4.29\\%$-$30.52\\%$. Furthermore, CLP can\nbe seamlessly combined with quantization to further compress the model with\nonly a slight performance loss.", "AI": {"tldr": "\u63d0\u51faCLP\uff0c\u4e00\u79cd\u53ef\u5fae\u5206\u7684\u8fde\u7eed\u5c42\u526a\u679d\u65b9\u6cd5\uff0c\u901a\u8fc7\u51f9\u95e8\u63a7\u786e\u5b9a\u526a\u679d\u8fde\u7eed\u6bb5\u5e76\u5fae\u8c03\u526a\u679d\u6bb5\u76f8\u90bb\u5c42\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u4e14\u53ef\u4e0e\u91cf\u5316\u7ed3\u5408\u8fdb\u4e00\u6b65\u538b\u7f29\u6a21\u578b\u3002", "motivation": "Edge devices cannot run large LLMs due to size and compute; need pruning to reduce cost, but existing layer pruning ignores inter-layer dependencies leading to degraded performance.", "method": "\u4f7f\u7528\u53ef\u5fae\u5206\u51f9\u95e8\u63a7\u7b97\u6cd5\u8fdb\u884c\u68af\u5ea6\u4f18\u5316\u4ee5\u8bc6\u522b\u6700\u4f73\u8fde\u7eed\u5c42\u6bb5\uff1b\u91c7\u7528cutoff endpoint tuning\u7b56\u7565\u53ea\u5fae\u8c03\u88ab\u526a\u5207\u6bb5\u76f8\u90bb\u7684\u5c42\u4ee5\u6062\u590d\u6027\u80fd\uff1b\u5728\u591a\u6a21\u578b\u591a\u5c3a\u5ea6\u4e0a\u8bc4\u4f30\u5e76\u4e0e\u91cf\u5316\u7ed3\u5408\u3002", "result": "CLP, a continuous layer pruning framework with a differentiable concave gate to identify prune segments via gradients and a cutoff endpoint tuning strategy to fine-tune adjacent layers. Achieves strong retention across LLaMA2/3 and Qwen, e.g., 95.34% retention at 20% pruning on LLaMA3-70B, outperforms baselines, and compatible with quantization.", "conclusion": "CLP effectively prunes continuous layer segments while preserving performance via gradient-based selection and localized finetuning; it's broadly applicable across large LLMs and compatible with quantization."}}
{"id": "2510.24085", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24085", "abs": "https://arxiv.org/abs/2510.24085", "authors": ["Md. Shihab Uddin", "Md Nazmus Shakib", "Rahul Bhadani"], "title": "Modeling Electric Vehicle Car-Following Behavior: Classical vs Machine Learning Approach", "comment": null, "summary": "The increasing adoption of electric vehicles (EVs) necessitates an\nunderstanding of their driving behavior to enhance traffic safety and develop\nsmart driving systems. This study compares classical and machine learning\nmodels for EV car following behavior. Classical models include the Intelligent\nDriver Model (IDM), Optimum Velocity Model (OVM), Optimal Velocity Relative\nVelocity (OVRV), and a simplified CACC model, while the machine learning\napproach employs a Random Forest Regressor. Using a real world dataset of an EV\nfollowing an internal combustion engine (ICE) vehicle under varied driving\nconditions, we calibrated classical model parameters by minimizing the RMSE\nbetween predictions and real data. The Random Forest model predicts\nacceleration using spacing, speed, and gap type as inputs. Results demonstrate\nthe Random Forest's superior accuracy, achieving RMSEs of 0.0046 (medium gap),\n0.0016 (long gap), and 0.0025 (extra long gap). Among physics based models,\nCACC performed best, with an RMSE of 2.67 for long gaps. These findings\nhighlight the machine learning model's performance across all scenarios. Such\nmodels are valuable for simulating EV behavior and analyzing mixed autonomy\ntraffic dynamics in EV integrated environments.", "AI": {"tldr": "\u5728 EV \u8ddf\u8f66\u4efb\u52a1\u4e0a\uff0cRandom Forest \u56de\u5f52\u4f18\u4e8e IDM\u3001OVM\u3001OVRV \u4e0e\u7b80\u5316 CACC\uff1bCACC \u5728\u7269\u7406\u6a21\u578b\u4e2d\u8868\u73b0\u6700\u4f73\uff0c\u4f46\u4e0e\u968f\u673a\u68ee\u6797\u5dee\u8ddd\u660e\u663e\u3002", "motivation": "\u968f\u7740\u7535\u52a8\u6c7d\u8f66\u666e\u53ca\uff0c\u4e86\u89e3\u5176\u8ddf\u8f66\u884c\u4e3a\u5bf9\u63d0\u5347\u4ea4\u901a\u5b89\u5168\u4e0e\u667a\u80fd\u9a7e\u9a76\u7cfb\u7edf\u5f00\u53d1\u81f3\u5173\u91cd\u8981\uff0c\u672c\u7814\u7a76\u65e8\u5728\u6bd4\u8f83\u7ecf\u5178\u52a8\u529b\u5b66\u6a21\u578b\u4e0e\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728 EV \u8ddf\u8f66\u5efa\u6a21\u4e2d\u7684\u8868\u73b0\u3002", "method": "\u4f7f\u7528\u771f\u5b9e\u4e16\u754c EV \u8ddf\u968f ICE \u8f66\u8f86\u6570\u636e\u3002\u5bf9 IDM\u3001OVM\u3001OVRV \u4e0e\u7b80\u5316 CACC\uff0c\u901a\u8fc7\u6700\u5c0f\u5316 RMSE \u6807\u5b9a\u53c2\u6570\u3002\u968f\u673a\u68ee\u6797\u4ee5\u95f4\u8ddd\u3001\u901f\u5ea6\u3001\u95f4\u9699\u7c7b\u578b\u4e3a\u8f93\u5165\uff0c\u9884\u6d4b\u52a0\u901f\u5ea6\uff0c\u5e76\u8bc4\u4f30\u4e0d\u540c\u95f4\u9699\uff08\u4e2d\u3001\u957f\u3001\u8d85\u957f\uff09\u4e0b\u7684 RMSE\u3002", "result": "Random Forest \u56de\u5f52\u5728\u6240\u7ed9 EV \u8ddf\u8f66\u6570\u636e\u4e0a\u8868\u73b0\u6700\u597d\uff0c\u663e\u8457\u4f18\u4e8e\u7ecf\u5178\u7269\u7406\u6a21\u578b\u3002\u7ecf\u5178\u6a21\u578b\u4e2d\uff0c\u7b80\u5316\u7684 CACC \u5728\u957f\u8ddd\u79bb\u95f4\u9699\u4e0b\u8868\u73b0\u6700\u4f18\uff0c\u4f46\u5176 RMSE \u4ecd\u8fdc\u9ad8\u4e8e\u673a\u5668\u5b66\u4e60\u6a21\u578b\u3002\u7814\u7a76\u57fa\u4e8e\u5b9e\u8f66 EV \u8ddf\u968f ICE \u8f66\u8f86\u7684\u771f\u5b9e\u6570\u636e\uff0c\u901a\u8fc7\u6700\u5c0f\u5316 RMSE \u8fdb\u884c\u7ecf\u5178\u6a21\u578b\u53c2\u6570\u6807\u5b9a\uff0c\u4e14\u968f\u673a\u68ee\u6797\u4f7f\u7528\u95f4\u8ddd\u3001\u901f\u5ea6\u548c\u95f4\u9699\u7c7b\u578b\u4f5c\u4e3a\u8f93\u5165\u6765\u9884\u6d4b\u52a0\u901f\u5ea6\u3002", "conclusion": "\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff08Random Forest\uff09\u5728\u5efa\u6a21 EV \u8ddf\u8f66\u884c\u4e3a\u65f6\u80fd\u63d0\u4f9b\u66f4\u4f4e\u7684\u9884\u6d4b\u8bef\u5dee\uff0c\u9002\u7528\u4e8e\u4eff\u771f EV \u884c\u4e3a\u4e0e\u6df7\u5408\u81ea\u4e3b\u4ea4\u901a\u5206\u6790\uff1b\u7ecf\u5178\u6a21\u578b\u5c3d\u7ba1\u53ef\u89e3\u91ca\u6027\u5f3a\uff0c\u4f46\u9700\u6539\u8fdb\u4ee5\u5339\u914d\u6570\u636e\u9a71\u52a8\u6a21\u578b\u7684\u7cbe\u5ea6\u3002"}}
{"id": "2510.23656", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23656", "abs": "https://arxiv.org/abs/2510.23656", "authors": ["Fuqiang Liu", "Weiping Ding", "Luis Miranda-Moreno", "Lijun Sun"], "title": "Error Adjustment Based on Spatiotemporal Correlation Fusion for Traffic Forecasting", "comment": "12 pages, 7 figures, 3 tables", "summary": "Deep neural networks (DNNs) play a significant role in an increasing body of\nresearch on traffic forecasting due to their effectively capturing\nspatiotemporal patterns embedded in traffic data. A general assumption of\ntraining the said forecasting models via mean squared error estimation is that\nthe errors across time steps and spatial positions are uncorrelated. However,\nthis assumption does not really hold because of the autocorrelation caused by\nboth the temporality and spatiality of traffic data. This gap limits the\nperformance of DNN-based forecasting models and is overlooked by current\nstudies. To fill up this gap, this paper proposes Spatiotemporally\nAutocorrelated Error Adjustment (SAEA), a novel and general framework designed\nto systematically adjust autocorrelated prediction errors in traffic\nforecasting. Unlike existing approaches that assume prediction errors follow a\nrandom Gaussian noise distribution, SAEA models these errors as a\nspatiotemporal vector autoregressive (VAR) process to capture their intrinsic\ndependencies. First, it explicitly captures both spatial and temporal error\ncorrelations by a coefficient matrix, which is then embedded into a newly\nformulated cost function. Second, a structurally sparse regularization is\nintroduced to incorporate prior spatial information, ensuring that the learned\ncoefficient matrix aligns with the inherent road network structure. Finally, an\ninference process with test-time error adjustment is designed to dynamically\nrefine predictions, mitigating the impact of autocorrelated errors in real-time\nforecasting. The effectiveness of the proposed approach is verified on\ndifferent traffic datasets. Results across a wide range of traffic forecasting\nmodels show that our method enhances performance in almost all cases.", "AI": {"tldr": "\u63d0\u51faSAEA\uff1a\u5c06\u9884\u6d4b\u8bef\u5dee\u5efa\u6a21\u4e3a\u65f6\u7a7aVAR\u8fc7\u7a0b\uff0c\u901a\u8fc7\u7cfb\u6570\u77e9\u9635\u4e0e\u7a00\u758f\u6b63\u5219\u5316\u5d4c\u5165\u8bad\u7ec3\uff0c\u5e76\u5728\u6d4b\u8bd5\u65f6\u52a8\u6001\u6821\u6b63\u8bef\u5dee\uff0c\u4ece\u800c\u63d0\u5347\u4ea4\u901a\u9884\u6d4b\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u7528MSE\u8bad\u7ec3\u5047\u8bbe\u8bef\u5dee\u72ec\u7acb\uff0c\u4f46\u4ea4\u901a\u6570\u636e\u5448\u663e\u8457\u65f6\u7a7a\u81ea\u76f8\u5173\uff0c\u5ffd\u7565\u6b64\u70b9\u9650\u5236\u4e86DNN\u9884\u6d4b\u6027\u80fd\uff0c\u9700\u5bf9\u8bef\u5dee\u81ea\u76f8\u5173\u5efa\u6a21\u4e0e\u6821\u6b63\u3002", "method": "1) \u5c06\u9884\u6d4b\u8bef\u5dee\u5efa\u6a21\u4e3a\u65f6\u7a7aVAR\u8fc7\u7a0b\uff1b2) \u5b66\u4e60\u8bef\u5dee\u7cfb\u6570\u77e9\u9635\u5e76\u5c06\u5176\u5d4c\u5165\u65b0\u7684\u635f\u5931\u51fd\u6570\uff1b3) \u7528\u7ed3\u6784\u7a00\u758f\u6b63\u5219\u5316\u7ed3\u5408\u8def\u7f51\u5148\u9a8c\uff1b4) \u5728\u63a8\u7406\u65f6\u8fdb\u884c\u52a8\u6001\u8bef\u5dee\u8c03\u6574\uff08\u6d4b\u8bd5\u65f6\u6821\u6b63\uff09\u3002", "result": "The paper proposes SAEA, a framework that models DNN forecasting residuals as a spatiotemporal VAR process, embeds the learned coefficient matrix into training via a new loss, uses structured sparse regularization aligned with road networks, and applies test-time error adjustment inference. It improves various traffic forecasting models across datasets.", "conclusion": "\u5c06\u8bef\u5dee\u7684\u65f6\u7a7a\u81ea\u76f8\u5173\u5efa\u6a21\u5e76\u5728\u8bad\u7ec3\u4e0e\u63a8\u7406\u9636\u6bb5\u6821\u6b63\uff0c\u80fd\u6709\u6548\u63d0\u5347DNN\u4ea4\u901a\u9884\u6d4b\u6a21\u578b\u7684\u51c6\u786e\u6027\u5e76\u4e0e\u8def\u7f51\u5148\u9a8c\u5bf9\u9f50\u3002"}}
{"id": "2510.24598", "categories": ["cs.LG", "cs.CR"], "pdf": "https://arxiv.org/pdf/2510.24598", "abs": "https://arxiv.org/abs/2510.24598", "authors": ["Sathwik Narkedimilli", "N V Saran Kumar", "Aswath Babu H", "Manjunath K Vanahalli", "Manish M", "Vinija Jain", "Aman Chadha"], "title": "A Novel XAI-Enhanced Quantum Adversarial Networks for Velocity Dispersion Modeling in MaNGA Galaxies", "comment": null, "summary": "Current quantum machine learning approaches often face challenges balancing\npredictive accuracy, robustness, and interpretability. To address this, we\npropose a novel quantum adversarial framework that integrates a hybrid quantum\nneural network (QNN) with classical deep learning layers, guided by an\nevaluator model with LIME-based interpretability, and extended through quantum\nGAN and self-supervised variants. In the proposed model, an adversarial\nevaluator concurrently guides the QNN by computing feedback loss, thereby\noptimizing both prediction accuracy and model explainability. Empirical\nevaluations show that the Vanilla model achieves RMSE = 0.27, MSE = 0.071, MAE\n= 0.21, and R^2 = 0.59, delivering the most consistent performance across\nregression metrics compared to adversarial counterparts. These results\ndemonstrate the potential of combining quantum-inspired methods with classical\narchitectures to develop lightweight, high-performance, and interpretable\npredictive models, advancing the applicability of QML beyond current\nlimitations.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u5e26\u6709LIME\u53ef\u89e3\u91ca\u6027\u8bc4\u4f30\u7684\u6df7\u5408QNN\u5bf9\u6297\u6846\u67b6\uff0cVanilla\u57fa\u7ebf\u5728\u56de\u5f52\u4efb\u52a1\u4e0a\u8868\u73b0\u6700\u7a33\u5b9a\uff0c\u8bc1\u660e\u91cf\u5b50-\u7ecf\u5178\u6df7\u5408\u65b9\u6cd5\u53ef\u5b9e\u73b0\u9ad8\u6027\u80fd\u4e0e\u53ef\u89e3\u91ca\u6027\u7684\u6298\u4e2d", "motivation": "\u89e3\u51b3\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u5728\u9884\u6d4b\u7cbe\u5ea6\u3001\u9c81\u68d2\u6027\u548c\u53ef\u89e3\u91ca\u6027\u4e4b\u95f4\u96be\u4ee5\u5e73\u8861\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e00\u79cd\u7ed3\u5408\u6df7\u5408\u91cf\u5b50\u795e\u7ecf\u7f51\u7edc\u4e0e\u7ecf\u5178\u6df1\u5ea6\u5b66\u4e60\u5c42\u7684\u5bf9\u6297\u6846\u67b6\uff0c\u5e76\u878d\u5165\u57fa\u4e8eLIME\u7684\u53ef\u89e3\u91ca\u6027\u8bc4\u4f30\u5668", "method": "\u6784\u5efa\u4e00\u4e2a\u6df7\u5408\u91cf\u5b50-\u7ecf\u5178\u7f51\u7edc\uff0c\u8bbe\u8ba1\u4e00\u4e2a\u57fa\u4e8eLIME\u7684\u5bf9\u6297\u8bc4\u4f30\u5668\u6765\u8ba1\u7b97\u53cd\u9988\u635f\u5931\u4ee5\u5f15\u5bfcQNN\u8bad\u7ec3\uff0c\u6269\u5c55\u4e3a\u91cf\u5b50GAN\u4e0e\u81ea\u76d1\u7763\u53d8\u4f53\uff0c\u5e76\u5728\u56de\u5f52\u4efb\u52a1\u4e0a\u8fdb\u884c\u6307\u6807\u6bd4\u8f83", "result": "\u63d0\u51fa\u7684\u6846\u67b6\u5305\u62ec\u5bf9\u6297\u8bc4\u4f30\u5668\u4e3aQNN\u63d0\u4f9b\u53cd\u9988\u635f\u5931\uff0c\u7ed3\u5408\u91cf\u5b50GAN\u548c\u81ea\u76d1\u7763\u53d8\u4f53\uff0c\u5b9e\u9a8c\u8bc1\u660eVanilla\u6a21\u578b\u5728\u56de\u5f52\u6307\u6807\u4e0a\u8868\u73b0\u6700\u7a33\u5b9a\uff08RMSE=0.27,MSE=0.071,MAE=0.21,R^2=0.59\uff09\uff0c\u8868\u660e\u8be5\u65b9\u6cd5\u80fd\u5728\u8f7b\u91cf\u7ea7\u53ef\u89e3\u91ca\u6a21\u578b\u4e2d\u53d6\u5f97\u6f5c\u529b", "conclusion": "\u7ed3\u5408\u91cf\u5b50\u542f\u53d1\u65b9\u6cd5\u4e0e\u7ecf\u5178\u67b6\u6784\u7684\u6df7\u5408\u5bf9\u6297\u6846\u67b6\uff0c\u5728\u63d0\u9ad8\u9884\u6d4b\u6027\u80fd\u7684\u540c\u65f6\u589e\u5f3a\u53ef\u89e3\u91ca\u6027\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u663e\u793aVanilla\u6a21\u578b\u8868\u73b0\u6700\u7a33\u5b9a\uff1b\u8be5\u65b9\u5411\u6709\u671b\u63a8\u52a8QML\u5728\u5b9e\u9645\u4efb\u52a1\u4e2d\u7684\u5e94\u7528"}}
{"id": "2510.24115", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24115", "abs": "https://arxiv.org/abs/2510.24115", "authors": ["Sandeep Vissapragada", "Vikrant Sahu", "Gagan Raj Gupta", "Vandita Singh"], "title": "HistoLens: An Interactive XAI Toolkit for Verifying and Mitigating Flaws in Vision-Language Models for Histopathology", "comment": null, "summary": "For doctors to truly trust artificial intelligence, it can't be a black box.\nThey need to understand its reasoning, almost as if they were consulting a\ncolleague. We created HistoLens1 to be that transparent, collaborative partner.\nIt allows a pathologist to simply ask a question in plain English about a\ntissue slide--just as they would ask a trainee. Our system intelligently\ntranslates this question into a precise query for its AI engine, which then\nprovides a clear, structured report. But it doesn't stop there. If a doctor\never asks, \"Why?\", HistoLens can instantly provide a 'visual proof' for any\nfinding--a heatmap that points to the exact cells and regions the AI used for\nits analysis. We've also ensured the AI focuses only on the patient's tissue,\njust like a trained pathologist would, by teaching it to ignore distracting\nbackground noise. The result is a workflow where the pathologist remains the\nexpert in charge, using a trustworthy AI assistant to verify their insights and\nmake faster, more confident diagnoses.", "AI": {"tldr": "HistoLens \u662f\u9762\u5411\u75c5\u7406\u5b66\u7684\u53ef\u89e3\u91ca AI \u52a9\u624b\uff0c\u652f\u6301\u81ea\u7136\u8bed\u8a00\u63d0\u95ee\u3001\u5c06\u95ee\u9898\u8f6c\u4e3a\u7cbe\u786e\u67e5\u8be2\u3001\u751f\u6210\u7ed3\u6784\u5316\u62a5\u544a\uff0c\u5e76\u80fd\u901a\u8fc7\u70ed\u56fe\u7b49\u201c\u53ef\u89c6\u5316\u8bc1\u636e\u201d\u5c55\u793a AI \u63a8\u7406\uff0c\u540c\u65f6\u53bb\u9664\u80cc\u666f\u566a\u58f0\uff0c\u4fdd\u6301\u75c5\u7406\u533b\u751f\u4e3b\u5bfc\u7684\u5de5\u4f5c\u6d41\u7a0b\u3002", "motivation": "\u4e3a\u6253\u6d88\u533b\u751f\u5bf9\u9ed1\u7bb1 AI \u7684\u4e0d\u4fe1\u4efb\uff0c\u63d0\u4f9b\u7c7b\u4f3c\u4e0e\u540c\u4e8b\u8ba8\u8bba\u7684\u4ea4\u4e92\u65b9\u5f0f\u548c\u53ef\u8ffd\u6eaf\u7684\u8bc1\u636e\uff0c\u786e\u4fdd\u4e34\u5e8a\u91c7\u7eb3\u65f6\u533b\u751f\u4ecd\u4e3a\u6700\u7ec8\u51b3\u7b56\u8005\u3002", "method": "\u7cfb\u7edf\u5c06\u81ea\u7136\u8bed\u8a00\u95ee\u9898\u8f6c\u6362\u4e3a\u5bf9 AI \u5f15\u64ce\u7684\u7cbe\u786e\u67e5\u8be2\uff0cAI \u8f93\u51fa\u7ed3\u6784\u5316\u62a5\u544a\uff1b\u82e5\u9700\u89e3\u91ca\uff0c\u7cfb\u7edf\u751f\u6210\u70ed\u56fe\u6307\u793a\u5173\u952e\u7ec6\u80de\u4e0e\u533a\u57df\uff1b\u8bad\u7ec3\u65f6\u52a0\u5165\u80cc\u666f\u566a\u58f0\u5ffd\u7565\u673a\u5236\u4ee5\u805a\u7126\u75c5\u53d8\u7ec4\u7ec7\u3002", "result": "\u5b9e\u73b0\u4e86\u53ef\u7528\u7684\u75c5\u7406\u5b66\u4ea4\u4e92\u5f0f AI \u52a9\u624b\uff0c\u652f\u6301\u95ee\u7b54\u5f0f\u5de5\u4f5c\u6d41\u3001\u53ef\u89c6\u5316\u8bc1\u636e\u5c55\u793a\u53ca\u80cc\u666f\u566a\u58f0\u6291\u5236\uff0c\u4ece\u800c\u6539\u8fdb\u8bca\u65ad\u6548\u7387\u4e0e\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "HistoLens \u63d0\u5347\u4e86\u75c5\u7406\u8bca\u65ad\u7684\u900f\u660e\u5ea6\u4e0e\u53ef\u4fe1\u5ea6\uff0c\u4f7f\u533b\u751f\u80fd\u5728\u4fdd\u6301\u4e3b\u5bfc\u6743\u7684\u540c\u65f6\u501f\u52a9\u53ef\u89e3\u91ca\u7684 AI \u63d0\u9ad8\u8bca\u65ad\u901f\u5ea6\u4e0e\u4fe1\u5fc3\u3002"}}
{"id": "2510.23657", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.23657", "abs": "https://arxiv.org/abs/2510.23657", "authors": ["Saklain Niam", "Tashfiqur Rahman", "Md. Amjad Patwary", "Mukarram Hossain"], "title": "A machine learning framework integrating seed traits and plasma parameters for predicting germination uplift in crops", "comment": null, "summary": "Cold plasma (CP) is an eco-friendly method to enhance seed germination, yet\noutcomes remain difficult to predict due to complex seed--plasma--environment\ninteractions. This study introduces the first machine learning framework to\nforecast germination uplift in soybean, barley, sunflower, radish, and tomato\nunder dielectric barrier discharge (DBD) plasma. Among the models tested (GB,\nXGB, ET, and hybrids), Extra Trees (ET) performed best (R\\textsuperscript{2} =\n0.919; RMSE = 3.21; MAE = 2.62), improving to R\\textsuperscript{2} = 0.925\nafter feature reduction. Engineering analysis revealed a hormetic response:\nnegligible effects at $<$7 kV or $<$200 s, maximum germination at 7--15 kV for\n200--500 s, and reduced germination beyond 20 kV or prolonged exposures.\nDischarge power was also a dominant factor, with germination rate maximizing at\n$\\geq$100 W with low exposure time. Species and cultivar-level predictions\nshowed radish (MAE = 1.46) and soybean (MAE = 2.05) were modeled with high\nconsistency, while sunflower remained slightly higher variable (MAE = 3.80).\nAmong cultivars, Williams (MAE = 1.23) and Sari (1.33) were well predicted,\nwhile Arian (2.86) and Ny\\'{\\i}rs\\'{e}gi fekete (3.74) were comparatively\npoorly captured. This framework was also embedded into MLflow, providing a\ndecision-support tool for optimizing CP seed germination in precision\nagriculture.", "AI": {"tldr": "First ML framework predicting germination uplift from DBD cold plasma; Extra Trees best; hormesis with optimal 7\u201315 kV and 200\u2013500 s; power >=100 W beneficial; species/cultivar variation; integrated into MLflow for decision support", "motivation": "Predict and optimize cold plasma treatment effects on seed germination across species and cultivars where outcomes are hard to predict due to complex interactions", "method": "Machine learning + engineering analysis", "result": "Extra Trees model achieved best performance (R^2=0.919, RMSE=3.21, MAE=2.62), improved to R^2=0.925 after feature reduction; identified hormetic response and key variables like discharge power", "conclusion": "ML model (ET) successfully predicts germination uplift and provides a decision-support tool; feature reduction improves performance; treatment windows and dominant factors identified, enabling precision optimization"}}
{"id": "2510.24145", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24145", "abs": "https://arxiv.org/abs/2510.24145", "authors": ["Yu Luo", "Jiamin Jiang", "Jingfei Feng", "Lei Tao", "Qingliang Zhang", "Xidao Wen", "Yongqian Sun", "Shenglin Zhang", "Jielong Huang", "Nan Qi", "Dan Pei"], "title": "From Observability Data to Diagnosis: An Evolving Multi-agent System for Incident Management in Cloud Systems", "comment": null, "summary": "Incident management (IM) is central to the reliability of large-scale cloud\nsystems. Yet manual IM, where on-call engineers examine metrics, logs, and\ntraces is labor-intensive and error-prone in the face of massive and\nheterogeneous observability data. Existing automated IM approaches often\nstruggle to generalize across systems, provide limited interpretability, and\nincur high deployment costs, which hinders adoption in practice. In this paper,\nwe present OpsAgent, a lightweight, self-evolving multi-agent system for IM\nthat employs a training-free data processor to convert heterogeneous\nobservability data into structured textual descriptions, along with a\nmulti-agent collaboration framework that makes diagnostic inference transparent\nand auditable. To support continual capability growth, OpsAgent also introduces\na dual self-evolution mechanism that integrates internal model updates with\nexternal experience accumulation, thereby closing the deployment loop.\nComprehensive experiments on the OPENRCA benchmark demonstrate state-of-the-art\nperformance and show that OpsAgent is generalizable, interpretable,\ncost-efficient, and self-evolving, making it a practically deployable and\nsustainable solution for long-term operation in real-world cloud systems.", "AI": {"tldr": "OpsAgent\u662f\u4e00\u4e2a\u8bad\u7ec3-\u514d\u8d39\u3001\u53ef\u89e3\u91ca\u3001\u4f4e\u6210\u672c\u3001\u53ef\u81ea\u6211\u8fdb\u5316\u7684\u591a\u667a\u80fd\u4f53\u4e8b\u6545\u7ba1\u7406\u7cfb\u7edf\uff0c\u901a\u8fc7\u628a\u89c2\u6d4b\u6570\u636e\u8f6c\u4e3a\u7ed3\u6784\u5316\u6587\u672c\u5e76\u7528\u534f\u4f5c\u4ee3\u7406\u8fdb\u884c\u8bca\u65ad\uff0c\u9002\u914d\u6027\u5f3a\u4e14\u4fbf\u4e8e\u90e8\u7f72\u3002", "motivation": "\u624b\u5de5\u4e8b\u6545\u7ba1\u7406\u5728\u5927\u89c4\u6a21\u4e91\u7cfb\u7edf\u4e2d\u8017\u65f6\u4e14\u6613\u9519\uff0c\u73b0\u6709\u81ea\u52a8\u5316\u65b9\u6cd5\u96be\u4ee5\u6cdb\u5316\u3001\u89e3\u91ca\u6027\u5dee\u5e76\u4e14\u90e8\u7f72\u6210\u672c\u9ad8\uff0c\u56e0\u800c\u9700\u8981\u4e00\u79cd\u53ef\u90e8\u7f72\u3001\u53ef\u89e3\u91ca\u4e14\u80fd\u957f\u671f\u81ea\u6211\u6f14\u5316\u7684\u8f7b\u91cf\u7ea7\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u6838\u5fc3\u65b9\u6cd5\u5305\u62ec\uff1a1) \u8bad\u7ec3-\u514d\u8d39\u6570\u636e\u5904\u7406\u5668\uff1a\u5c06\u6307\u6807\u3001\u65e5\u5fd7\u3001\u8ffd\u8e2a\u7b49\u5f02\u6784\u89c2\u6d4b\u6570\u636e\u8f6c\u4e3a\u7ed3\u6784\u5316\u6587\u672c\u63cf\u8ff0\uff1b2) \u591a\u667a\u80fd\u4f53\u534f\u4f5c\u6846\u67b6\uff1a\u5206\u5de5\u660e\u786e\u7684\u4ee3\u7406\u95f4\u900f\u660e\u4ea4\u4e92\u4ee5\u751f\u6210\u53ef\u5ba1\u8ba1\u8bca\u65ad\uff1b3) \u53cc\u91cd\u81ea\u6211\u8fdb\u5316\u673a\u5236\uff1a\u5185\u90e8\u6a21\u578b\u66f4\u65b0\u4e0e\u5916\u90e8\u7ecf\u9a8c\u79ef\u7d2f\u8054\u5408\u95ed\u73af\u4ee5\u6301\u7eed\u63d0\u5347\u80fd\u529b\u3002", "result": "OpsAgent\u63d0\u51fa\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u3001\u81ea\u6211\u8fdb\u5316\u7684\u591a\u667a\u80fd\u4f53\u4e8b\u6545\u7ba1\u7406\u7cfb\u7edf\uff0c\u901a\u8fc7\u8bad\u7ec3-\u514d\u8d39\u6570\u636e\u5904\u7406\u5668\u5c06\u5f02\u6784\u89c2\u6d4b\u6570\u636e\u8f6c\u4e3a\u7ed3\u6784\u5316\u6587\u672c\u63cf\u8ff0\uff0c\u5e76\u91c7\u7528\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u6846\u67b6\u5b9e\u73b0\u53ef\u5ba1\u8ba1\u7684\u8bca\u65ad\u63a8\u7406\uff1b\u5f15\u5165\u53cc\u91cd\u81ea\u6211\u8fdb\u5316\u673a\u5236\u6574\u5408\u5185\u90e8\u6a21\u578b\u66f4\u65b0\u4e0e\u5916\u90e8\u7ecf\u9a8c\u79ef\u7d2f\u4ee5\u5b9e\u73b0\u6301\u7eed\u80fd\u529b\u63d0\u5347\u3002", "conclusion": "\u5b9e\u9a8c\u8868\u660eOpsAgent\u5728OPENRCA\u57fa\u51c6\u4e0a\u8fbe\u5230\u4e86SOTA\u6027\u80fd\uff0c\u4e14\u5728\u53ef\u6cdb\u5316\u6027\u3001\u53ef\u89e3\u91ca\u6027\u3001\u6210\u672c\u6548\u7387\u4e0e\u81ea\u6211\u8fdb\u5316\u80fd\u529b\u65b9\u9762\u8868\u73b0\u826f\u597d\uff0c\u9002\u5408\u957f\u671f\u90e8\u7f72\u4e8e\u771f\u5b9e\u4e91\u7cfb\u7edf\u3002"}}
{"id": "2510.23658", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23658", "abs": "https://arxiv.org/abs/2510.23658", "authors": ["Vaibhav Jindal", "Hejian Sang", "Chun-Mao Lai", "Yanning Chen", "Zhipeng Wang"], "title": "Aligning Diffusion Language Models via Unpaired Preference Optimization", "comment": null, "summary": "Diffusion language models (dLLMs) are an emerging alternative to\nautoregressive (AR) generators, but aligning them to human preferences is\nchallenging because sequence log-likelihoods are intractable and pairwise\npreference data are costly to collect. We introduce ELBO-KTO, which combines an\nELBO surrogate for diffusion log-likelihoods with a prospect-theoretic,\nunpaired preference objective (Kahneman Tversky Optimization, KTO). We analyze\nthe bias and variance induced by the ELBO substitution and employ\nvariance-reduction practices that stabilize gradients during training. Applied\nto LLaDA-8B-Instruct, ELBO-KTO yields \\textbf{65.9\\%} and \\textbf{62.3\\%}\nadjusted win rates on kto-mix-14k and UltraFeedback-Binary, respectively,\nversus the base model under an automatic LLM judge. Across downstream tasks,\nincluding GSM8K, MMLU, and additional reasoning/knowledge benchmarks, ELBO-KTO\ntrained on UltraFeedback-Binary performs on par with or better than the base\nmodel under identical decoding. This establishes unpaired preference\noptimization as a viable alternative to pairwise alignment in diffusion LLMs.", "AI": {"tldr": "\u63d0\u51faELBO-KTO\uff1a\u7528ELBO\u66ff\u4ee3\u6269\u6563\u5bf9\u6570\u4f3c\u7136\u5e76\u7ed3\u5408KTO\u65e0\u914d\u5bf9\u504f\u597d\u4f18\u5316\uff0c\u5728\u81ea\u52a8Judge\u8bc4\u6d4b\u4e0b\u663e\u8457\u63d0\u5347\u4e86LLaDA-8B-Instruct\u7684\u76f8\u5bf9\u80dc\u7387\uff0c\u540c\u65f6\u5728\u4e0b\u6e38\u4efb\u52a1\u4e0a\u4fdd\u6301\u6216\u63d0\u5347\u6027\u80fd\uff0c\u8bc1\u660e\u4e86\u5bf9\u6269\u6563LLM\u8fdb\u884c\u65e0\u914d\u5bf9\u504f\u597d\u4f18\u5316\u7684\u53ef\u884c\u6027\u3002", "motivation": "\u6269\u6563\u8bed\u8a00\u6a21\u578b\u7684\u5e8f\u5217\u5bf9\u6570\u4f3c\u7136\u4e0d\u53ef\u6613\u5f97\uff0c\u800c\u914d\u5bf9\u504f\u597d\u6570\u636e\u6602\u8d35\uff1b\u56e0\u800c\u9700\u8981\u4e00\u79cd\u80fd\u5728\u65e0\u914d\u5bf9\u504f\u597d\u6570\u636e\u4e0b\u5bf9\u9f50dLLMs\u4e14\u53ef\u8ba1\u7b97\u8fd1\u4f3c\u5bf9\u6570\u4f3c\u7136\u7684\u53ef\u884c\u65b9\u6cd5\uff0c\u4ece\u800c\u964d\u4f4e\u6570\u636e\u4e0e\u8ba1\u7b97\u6210\u672c\u5e76\u4f7f\u5f97dLLMs\u80fd\u66f4\u597d\u5730\u6ee1\u8db3\u4eba\u7c7b\u504f\u597d\u3002", "method": "\u7528ELBO\u4f5c\u4e3a\u6269\u6563\u6a21\u578b\u7684\u5bf9\u6570\u4f3c\u7136\u8fd1\u4f3c\uff0c\u5e76\u7ed3\u5408Kahneman-Tversky Optimization\uff08KTO\uff09\u7684\u65e0\u914d\u5bf9\u524d\u666f\u7406\u8bba\u5f0f\u504f\u597d\u76ee\u6807\uff1b\u5206\u6790ELBO\u66ff\u4ee3\u5f15\u5165\u7684\u504f\u5dee/\u65b9\u5dee\uff0c\u91c7\u7528\u65b9\u5dee\u51cf\u5c11\u4e0e\u68af\u5ea6\u7a33\u5b9a\u5316\u5b9e\u8df5\u6765\u8bad\u7ec3\uff1b\u5728LLaDA-8B-Instruct\u4e0a\u7528kto-mix-14k\u4e0eUltraFeedback-Binary\u6570\u636e\u96c6\u8bad\u7ec3\u5e76\u7528\u81ea\u52a8LLM\u5224\u5b98\u8bc4\u4f30\u80dc\u7387\u4e0e\u4e0b\u6e38\u4efb\u52a1\u8868\u73b0\u3002", "result": "ELBO-KTO\u662f\u4e00\u79cd\u7528\u4e8e\u6269\u6563\u8bed\u8a00\u6a21\u578b\uff08dLLMs\uff09\u7684\u4eba\u7c7b\u504f\u597d\u5bf9\u9f50\u65b9\u6cd5\uff0c\u7ed3\u5408\u4e86ELBO\u66ff\u4ee3\u9879\u4e0e\u57fa\u4e8e\u524d\u666f\u7406\u8bba\u7684\u65e0\u914d\u5bf9\u504f\u597d\u76ee\u6807\uff08KTO\uff09\uff0c\u5e76\u5728LLaDA-8B-Instruct\u4e0a\u663e\u793a\u51fa\u663e\u8457\u6539\u8fdb\u3002", "conclusion": "ELBO\u66ff\u4ee3\u4f1a\u5f15\u5165\u504f\u5dee\u4e0e\u65b9\u5dee\uff0c\u4f46\u901a\u8fc7\u65b9\u5dee\u51cf\u5c0f\u6280\u5de7\u548c\u7a33\u5b9a\u5316\u8bad\u7ec3\u53ef\u6709\u6548\u63a7\u5236\uff1bELBO-KTO\u80fd\u5728\u65e0\u914d\u5bf9\u504f\u597d\u6570\u636e\u4e0b\u663e\u8457\u63d0\u5347\u6269\u6563LLM\u7684\u5bf9\u9f50\u8868\u73b0\uff0c\u5e76\u5728\u591a\u9879\u4efb\u52a1\u4e0a\u4e0e\u57fa\u7ebf\u6301\u5e73\u6216\u66f4\u4f18\uff0c\u8868\u660e\u65e0\u914d\u5bf9\u504f\u597d\u4f18\u5316\u662f\u5bf9\u6297\u6602\u8d35\u6210\u5bf9\u504f\u597d\u6570\u636e\u7684\u4e00\u79cd\u53ef\u884c\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2510.24151", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24151", "abs": "https://arxiv.org/abs/2510.24151", "authors": ["Bingsen Qiu", "Zijian Liu", "Xiao Liu", "Haoshen Yang", "Zeren Gao", "Bingjie Wang", "Feier Zhang", "Yixuan Qin", "Chunyan Li"], "title": "BMGQ: A Bottom-up Method for Generating Complex Multi-hop Reasoning Questions from Semi-structured Data", "comment": null, "summary": "Building training-ready multi-hop question answering (QA) datasets that truly\nstress a model's retrieval and reasoning abilities remains highly challenging\nrecently. While there have been a few recent evaluation datasets that capture\nthe characteristics of hard-to-search but easy-to-verify problems -- requiring\nthe integration of ambiguous, indirect, and cross-domain cues -- these data\nresources remain scarce and are mostly designed for evaluation, making them\nunsuitable for supervised fine-tuning (SFT) or reinforcement learning (RL).\nMeanwhile, manually curating non-trivially retrievable questions -- where\nanswers cannot be found through a single direct query but instead require\nmulti-hop reasoning over oblique and loosely connected evidence -- incurs\nprohibitive human costs and fails to scale, creating a critical data bottleneck\nfor training high-capability retrieval-and-reasoning agents.\n  To address this, we present an automated framework for generating\nhigh-difficulty, training-ready multi-hop questions from semi-structured\nknowledge sources. The system (i) grows diverse, logically labeled evidence\nclusters through Natural Language Inference (NLI)-based relation typing and\ndiversity-aware expansion; (ii) applies reverse question construction to\ncompose oblique cues so that isolated signals are underinformative but their\ncombination uniquely identifies the target entity; and (iii) enforces quality\nwith a two-step evaluation pipeline that combines multi-model consensus\nfiltering with structured constraint decomposition and evidence-based matching.\nThe result is a scalable process that yields complex, retrieval-resistant yet\nverifiable questions suitable for SFT/RL training as well as challenging\nevaluation, substantially reducing human curation effort while preserving the\ndifficulty profile of strong evaluation benchmarks.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u81ea\u52a8\u5316\u6846\u67b6\uff0c\u4ece\u534a\u7ed3\u6784\u5316\u77e5\u8bc6\u6e90\u751f\u6210\u8bad\u7ec3\u4e0e\u8bc4\u4f30\u7686\u9002\u7528\u7684\u9ad8\u96be\u5ea6\u591a\u8df3\u95ee\u7b54\u6570\u636e\uff0c\u5305\u542bNLI\u5173\u7cfb\u6253\u6807\u3001\u9006\u5411\u95ee\u9898\u6784\u9020\u548c\u591a\u6a21\u578b\u4e00\u81f4\u6027+\u8bc1\u636e\u8fc7\u6ee4\u6765\u4fdd\u8bc1\u8d28\u91cf\u4e0e\u53ef\u6269\u5c55\u6027\u3002", "motivation": "Address scarcity of training-ready multi-hop QA datasets that are hard-to-retrieve and require reasoning, by automating generation from semi-structured knowledge to avoid high human costs.", "method": "(i) \u901a\u8fc7NLI\u5173\u7cfb\u7c7b\u578b\u5316\u4e0e\u591a\u6837\u6027\u6269\u5c55\u6784\u5efa\u8bc1\u636e\u7c07\uff1b(ii) \u9006\u5411\u6784\u9020\u95ee\u9898\u4f7f\u5355\u6761\u7ebf\u7d22\u4e0d\u5145\u5206\u4f46\u7ec4\u5408\u552f\u4e00\u6307\u5411\u76ee\u6807\uff1b(iii) \u4f7f\u7528\u591a\u6a21\u578b\u5171\u8bc6\u8fc7\u6ee4\u52a0\u7ed3\u6784\u5316\u7ea6\u675f\u5206\u89e3\u4e0e\u8bc1\u636e\u5339\u914d\u7684\u4e24\u6b65\u8bc4\u4f30\u786e\u4fdd\u8d28\u91cf\u3002", "result": "A scalable framework that generates high-difficulty, retrieval-resistant but verifiable multi-hop questions via NLI-based relation typing, reverse question construction, and a two-step multi-model/evidence filtering pipeline, producing data suitable for SFT/RL and evaluation while reducing human effort.", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u5927\u5e45\u964d\u4f4e\u4eba\u5de5\u6210\u672c\uff0c\u751f\u6210\u4fdd\u6301\u9ad8\u96be\u5ea6\u7279\u6027\u7684\u53ef\u8bad\u7ec3\u4e0e\u8bc4\u4f30\u6570\u636e\uff0c\u9002\u4e8e\u8bad\u7ec3\u68c0\u7d22-\u63a8\u7406\u4ee3\u7406\u5e76\u7528\u4e8e\u6311\u6218\u6027\u8bc4\u4f30\u3002"}}
{"id": "2510.23659", "categories": ["cs.LG", "cs.CV", "cs.ET"], "pdf": "https://arxiv.org/pdf/2510.23659", "abs": "https://arxiv.org/abs/2510.23659", "authors": ["Md. Farhan Shahriyar", "Gazi Tanbhir", "Abdullah Md Raihan Chy"], "title": "Quantum Machine Learning for Image Classification: A Hybrid Model of Residual Network with Quantum Support Vector Machine", "comment": null, "summary": "Recently, there has been growing attention on combining quantum machine\nlearning (QML) with classical deep learning approaches, as computational\ntechniques are key to improving the performance of image classification tasks.\nThis study presents a hybrid approach that uses ResNet-50 (Residual Network)\nfor feature extraction and Quantum Support Vector Machines (QSVM) for\nclassification in the context of potato disease detection. Classical machine\nlearning as well as deep learning models often struggle with high-dimensional\nand complex datasets, necessitating advanced techniques like quantum computing\nto improve classification efficiency. In our research, we use ResNet-50 to\nextract deep feature representations from RGB images of potato diseases. These\nfeatures are then subjected to dimensionality reduction using Principal\nComponent Analysis (PCA). The resulting features are processed through QSVM\nmodels which apply various quantum feature maps such as ZZ, Z, and Pauli-X to\ntransform classical data into quantum states. To assess the model performance,\nwe compared it with classical machine learning algorithms such as Support\nVector Machine (SVM) and Random Forest (RF) using five-fold stratified\ncross-validation for comprehensive evaluation. The experimental results\ndemonstrate that the Z-feature map-based QSVM outperforms classical models,\nachieving an accuracy of 99.23 percent, surpassing both SVM and RF models. This\nresearch highlights the advantages of integrating quantum computing into image\nclassification and provides a potential disease detection solution through\nhybrid quantum-classical modeling.", "AI": {"tldr": "ResNet-50 extracts features from potato disease images; PCA reduces dimensionality; QSVM with Z-feature map classifies data achieving 99.23% accuracy, outperforming classical SVM and RF.", "motivation": "Classical ML/DL struggle with high-dimensional complex image data; quantum computing may improve classification efficiency for potato disease detection.", "method": "Hybrid QML with ResNet-50 + QSVM", "result": "Using ResNet-50 features reduced by PCA and classified by QSVM with Z-feature map achieved 99.23% accuracy, outperforming classical SVM and RF under five-fold stratified CV.", "conclusion": "Hybrid quantum-classical pipeline shows promise for image-based disease detection; Z-feature map QSVM outperforms classical baselines in this study."}}
{"id": "2510.24161", "categories": ["cs.AI", "cs.MM", "cs.RO"], "pdf": "https://arxiv.org/pdf/2510.24161", "abs": "https://arxiv.org/abs/2510.24161", "authors": ["Wentao Tan", "Bowen Wang", "Heng Zhi", "Chenyu Liu", "Zhe Li", "Jian Liu", "Zengrong Lin", "Yukun Dai", "Yipeng Chen", "Wenjie Yang", "Enci Xie", "Hao Xue", "Baixu Ji", "Chen Xu", "Zhibin Wang", "Tianshi Wang", "Lei Zhu", "Heng Tao Shen"], "title": "BLM$_1$: A Boundless Large Model for Cross-Space, Cross-Task, and Cross-Embodiment Learning", "comment": null, "summary": "Multimodal large language models (MLLMs) have advanced vision-language\nreasoning and are increasingly deployed in embodied agents. However,\nsignificant limitations remain: MLLMs generalize poorly across digital-physical\nspaces and embodiments; vision-language-action models (VLAs) produce low-level\nactions yet lack robust high-level embodied reasoning; and most embodied large\nlanguage models (ELLMs) are constrained to digital-space with poor\ngeneralization to the physical world. Thus, unified models that operate\nseamlessly across digital and physical spaces while generalizing across\nembodiments and tasks remain absent. We introduce the \\textbf{Boundless Large\nModel (BLM$_1$)}, a multimodal spatial foundation model that preserves\ninstruction following and reasoning, incorporates embodied knowledge, and\nsupports robust cross-embodiment control. BLM$_1$ integrates three key\ncapabilities -- \\textit{cross-space transfer, cross-task learning, and\ncross-embodiment generalization} -- via a two-stage training paradigm. Stage I\ninjects embodied knowledge into the MLLM through curated digital corpora while\nmaintaining language competence. Stage II trains a policy module through an\nintent-bridging interface that extracts high-level semantics from the MLLM to\nguide control, without fine-tuning the MLLM backbone. This process is supported\nby a self-collected cross-embodiment demonstration suite spanning four robot\nembodiments and six progressively challenging tasks. Evaluations across digital\nand physical benchmarks show that a single BLM$_1$ instance outperforms four\nmodel families -- MLLMs, ELLMs, VLAs, and GMLMs -- achieving\n$\\sim\\!\\textbf{6%}$ gains in digital tasks and $\\sim\\!\\textbf{3%}$ in physical\ntasks.", "AI": {"tldr": "BLM1 is a multimodal spatial foundation model using two-stage training to inject embodied knowledge and train a policy via intent-bridging, achieving better cross-space and cross-embodiment performance.", "motivation": "Current models fail to generalize across digital/physical spaces and embodiments; need unified model for cross-space, cross-task, cross-embodiment control.", "method": "Two-stage training: Stage I injects embodied knowledge into MLLM via curated digital corpora while preserving language competence; Stage II trains a policy module via intent-bridging interface extracting high-level semantics without fine-tuning backbone.", "result": "BLM1 integrates cross-space transfer, cross-task learning, cross-embodiment generalization; trained with cross-embodiment demos; outperforms MLLMs, ELLMs, VLAs, GMLMs by ~6% digital and ~3% physical.", "conclusion": "A single BLM1 can robustly operate across digital and physical environments and multiple robot embodiments, improving task success over existing model families."}}
{"id": "2510.23660", "categories": ["cs.LG", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.23660", "abs": "https://arxiv.org/abs/2510.23660", "authors": ["Gazi Tanbhir", "Md. Farhan Shahriyar", "Abdullah Md Raihan Chy"], "title": "Quanvolutional Neural Networks for Pneumonia Detection: An Efficient Quantum-Assisted Feature Extraction Paradigm", "comment": null, "summary": "Pneumonia poses a significant global health challenge, demanding accurate and\ntimely diagnosis. While deep learning, particularly Convolutional Neural\nNetworks (CNNs), has shown promise in medical image analysis for pneumonia\ndetection, CNNs often suffer from high computational costs, limitations in\nfeature representation, and challenges in generalizing from smaller datasets.\nTo address these limitations, we explore the application of Quanvolutional\nNeural Networks (QNNs), leveraging quantum computing for enhanced feature\nextraction. This paper introduces a novel hybrid quantum-classical model for\npneumonia detection using the PneumoniaMNIST dataset. Our approach utilizes a\nquanvolutional layer with a parameterized quantum circuit (PQC) to process 2x2\nimage patches, employing rotational Y-gates for data encoding and entangling\nlayers to generate non-classical feature representations. These\nquantum-extracted features are then fed into a classical neural network for\nclassification. Experimental results demonstrate that the proposed QNN achieves\na higher validation accuracy of 83.33 percent compared to a comparable\nclassical CNN which achieves 73.33 percent. This enhanced convergence and\nsample efficiency highlight the potential of QNNs for medical image analysis,\nparticularly in scenarios with limited labeled data. This research lays the\nfoundation for integrating quantum computing into deep-learning-driven medical\ndiagnostic systems, offering a computationally efficient alternative to\ntraditional approaches.", "AI": {"tldr": "\u8be5\u5de5\u4f5c\u63d0\u51fa\u5c06quanvolutional\u5c42\uff08\u57fa\u4e8ePQC\u3001Y\u65cb\u8f6c\u53ca\u7ea0\u7f20\uff09\u4e0e\u7ecf\u5178\u5206\u7c7b\u7f51\u7edc\u7ed3\u5408\u7528\u4e8ePneumoniaMNIST\u80ba\u708e\u68c0\u6d4b\uff0c\u5b9e\u9a8c\u663e\u793aQNN\u5728\u9a8c\u8bc1\u51c6\u786e\u7387\u3001\u6536\u655b\u901f\u5ea6\u53ca\u5c0f\u6837\u672c\u8868\u73b0\u4e0a\u4f18\u4e8e\u76f8\u5e94\u7ecf\u5178CNN\uff0c\u9a8c\u8bc1\u4e86\u91cf\u5b50\u7279\u5f81\u63d0\u53d6\u7684\u6f5c\u5728\u4f18\u52bf\u3002", "motivation": "\u52a8\u673a\u662f\u514b\u670d\u4f20\u7edfCNN\u5728\u8ba1\u7b97\u5f00\u9500\u5927\u3001\u7279\u5f81\u8868\u793a\u53d7\u9650\u548c\u5728\u5c0f\u6570\u636e\u96c6\u4e0a\u6cdb\u5316\u80fd\u529b\u5dee\u7684\u7f3a\u70b9\uff0c\u63a2\u7d22\u91cf\u5b50\u8ba1\u7b97\u589e\u5f3a\u7279\u5f81\u63d0\u53d6\u4ee5\u63d0\u5347\u80ba\u708e\u68c0\u6d4b\u6027\u80fd\u3002", "method": "\u8bba\u6587\u65b9\u6cd5\u662f\u5728\u8f93\u5165\u56fe\u50cf\u4e0a\u4f7f\u75282x2\u8865\u4e01\u7684quanvolutional\u5c42\uff0c\u91c7\u7528\u53c2\u6570\u5316\u91cf\u5b50\u7535\u8def(PQC)\u8fdb\u884c\u6570\u636e\u7f16\u7801\uff0c\u4f7f\u7528\u65cb\u8f6cY\u95e8\u548c\u7ea0\u7f20\u5c42\u751f\u6210\u975e\u7ecf\u5178\u7279\u5f81\uff0c\u5e76\u5c06\u91cf\u5b50\u63d0\u53d6\u7684\u7279\u5f81\u8f93\u5165\u5230\u7ecf\u5178\u795e\u7ecf\u7f51\u7edc\u8fdb\u884c\u5206\u7c7b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793aQNN\u5728\u9a8c\u8bc1\u96c6\u4e0a\u8fbe\u523083.33%\u51c6\u786e\u7387\uff0c\u9ad8\u4e8e\u4f20\u7edfCNN\u768473.33%\uff1b\u4f5c\u8005\u8fd8\u62a5\u544a\u4e86\u66f4\u597d\u7684\u6536\u655b\u6027\u548c\u6837\u672c\u6548\u7387\uff0c\u652f\u6301QNN\u5728\u6709\u9650\u6807\u6ce8\u6570\u636e\u60c5\u5883\u4e0b\u7684\u6f5c\u529b\u3002", "conclusion": "\u8bba\u6587\u7ed3\u8bba\u79f0\u57fa\u4e8e\u91cf\u5b50-\u7ecf\u5178\u6df7\u5408\u7684Quanvolutional Neural Network (QNN) \u5728PneumoniaMNIST\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u4f20\u7edfCNN\uff0c\u9a8c\u8bc1\u96c6\u51c6\u786e\u738783.33%\u4f18\u4e8e\u7ecf\u5178CNN\u768473.33%\uff0c\u5e76\u5f3a\u8c03QNN\u5728\u5c0f\u6837\u672c\u573a\u666f\u4e0b\u7684\u6536\u655b\u901f\u5ea6\u548c\u6837\u672c\u6548\u7387\u4f18\u52bf\u3002"}}
{"id": "2510.24166", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24166", "abs": "https://arxiv.org/abs/2510.24166", "authors": ["Xin Yang", "Yuhang Zhang", "Wei Li", "Xin Lin", "Wenbin Zou", "Chen Xu"], "title": "UniPlanner: A Unified Motion Planning Framework for Autonomous Vehicle Decision-Making Systems via Multi-Dataset Integration", "comment": null, "summary": "Motion planning is a critical component of autonomous vehicle decision-making\nsystems, directly determining trajectory safety and driving efficiency. While\ndeep learning approaches have advanced planning capabilities, existing methods\nremain confined to single-dataset training, limiting their robustness in\nplanning.\n  Through systematic analysis, we discover that vehicular trajectory\ndistributions and history-future correlations demonstrate remarkable\nconsistency across different datasets. Based on these findings, we propose\nUniPlanner, the first planning framework designed for multi-dataset integration\nin autonomous vehicle decision-making. UniPlanner achieves unified\ncross-dataset learning through three synergistic innovations.\n  First, the History-Future Trajectory Dictionary Network (HFTDN) aggregates\nhistory-future trajectory pairs from multiple datasets, using historical\ntrajectory similarity to retrieve relevant futures and generate cross-dataset\nplanning guidance.\n  Second, the Gradient-Free Trajectory Mapper (GFTM) learns robust\nhistory-future correlations from multiple datasets, transforming historical\ntrajectories into universal planning priors. Its gradient-free design ensures\nthe introduction of valuable priors while preventing shortcut learning, making\nthe planning knowledge safely transferable. Third, the Sparse-to-Dense (S2D)\nparadigm implements adaptive dropout to selectively suppress planning priors\nduring training for robust learning, while enabling full prior utilization\nduring inference to maximize planning performance.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faUniPlanner\uff0c\u4e00\u4e2a\u7528\u4e8e\u591a\u6570\u636e\u96c6\u878d\u5408\u7684\u81ea\u52a8\u9a7e\u9a76\u89c4\u5212\u6846\u67b6\uff0c\u901a\u8fc7HFTDN\u3001GFTM\u548cS2D\u4e09\u9879\u521b\u65b0\u5b9e\u73b0\u8de8\u6570\u636e\u96c6\u7edf\u4e00\u5b66\u4e60\uff0c\u63d0\u9ad8\u89c4\u5212\u9c81\u68d2\u6027\u4e0e\u6027\u80fd\u3002", "motivation": "\u89c2\u5bdf\u5230\u4e0d\u540c\u6570\u636e\u96c6\u95f4\u8f66\u8f86\u8f68\u8ff9\u5206\u5e03\u4e0e\u5386\u53f2-\u672a\u6765\u76f8\u5173\u6027\u5177\u6709\u4e00\u81f4\u6027\uff0c\u56e0\u800c\u53ef\u4ee5\u901a\u8fc7\u591a\u6570\u636e\u96c6\u5b66\u4e60\u63d0\u5347\u89c4\u5212\u9c81\u68d2\u6027\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\uff1a1\uff09HFTDN\uff1a\u6784\u5efa\u5386\u53f2-\u672a\u6765\u8f68\u8ff9\u5b57\u5178\u5e76\u57fa\u4e8e\u5386\u53f2\u76f8\u4f3c\u6027\u68c0\u7d22\u76f8\u5173\u672a\u6765\u8f68\u8ff9\uff1b2\uff09GFTM\uff1a\u65e0\u68af\u5ea6\u8bbe\u8ba1\u5c06\u5386\u53f2\u8f68\u8ff9\u6620\u5c04\u4e3a\u901a\u7528\u89c4\u5212\u5148\u9a8c\uff0c\u9632\u6b62\u5b66\u4e60\u6377\u5f84\uff1b3\uff09S2D\uff1a\u8bad\u7ec3\u65f6\u901a\u8fc7\u81ea\u9002\u5e94dropout\u6291\u5236\u90e8\u5206\u5148\u9a8c\uff0c\u63a8\u7406\u65f6\u6062\u590d\u5168\u91cf\u5148\u9a8c\u4ee5\u63d0\u5347\u6027\u80fd\u3002", "result": "\u6587\u4e2d\u5c55\u793a\u4e86\u8de8\u6570\u636e\u96c6\u8bad\u7ec3\u80fd\u5e26\u6765\u66f4\u7a33\u5b9a\u7684\u89c4\u5212\u8868\u73b0\uff0cUniPlanner\u5728\u6574\u5408\u591a\u6570\u636e\u96c6\u540e\u5728\u89c4\u5212\u8d28\u91cf\u548c\u9c81\u68d2\u6027\u4e0a\u5747\u6709\u663e\u8457\u63d0\u5347\u3002", "conclusion": "UniPlanner\u901a\u8fc7\u5386\u53f2-\u672a\u6765\u8f68\u8ff9\u5b57\u5178\u68c0\u7d22\u3001\u65e0\u68af\u5ea6\u8f68\u8ff9\u6620\u5c04\u548c\u7a00\u758f\u5230\u7a20\u5bc6\u8303\u5f0f\uff0c\u6709\u6548\u6574\u5408\u4e0d\u540c\u6570\u636e\u96c6\u7684\u89c4\u5212\u77e5\u8bc6\uff0c\u907f\u514d\u6377\u5f84\u5b66\u4e60\u5e76\u5728\u63a8\u7406\u65f6\u5145\u5206\u5229\u7528\u5148\u9a8c\uff0c\u5b9e\u73b0\u66f4\u7a33\u5065\u7684\u89c4\u5212\u3002"}}
{"id": "2510.23663", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.23663", "abs": "https://arxiv.org/abs/2510.23663", "authors": ["Padmanabhan Jagannathan Prajesh", "Kaliaperumal Ragunath", "Miriam Gordon", "Bruce Rathgeber", "Suresh Neethirajan"], "title": "AI-Driven Carbon Monitoring: Transformer-Based Reconstruction of Atmospheric CO2 in Canadian Poultry Regions", "comment": null, "summary": "Accurate mapping of column-averaged CO2 (XCO2) over agricultural landscapes\nis essential for guiding emission mitigation strategies. We present a\nSpatiotemporal Vision Transformer with Wavelets (ST-ViWT) framework that\nreconstructs continuous, uncertainty-quantified XCO2 fields from OCO-2 across\nsouthern Canada, emphasizing poultry-intensive regions. The model fuses wavelet\ntime-frequency representations with transformer attention over meteorology,\nvegetation indices, topography, and land cover. On 2024 OCO-2 data, ST-ViWT\nattains R2 = 0.984 and RMSE = 0.468 ppm; 92.3 percent of gap-filled predictions\nlie within +/-1 ppm. Independent validation with TCCON shows robust\ngeneralization (bias = -0.14 ppm; r = 0.928), including faithful reproduction\nof the late-summer drawdown. Spatial analysis across 14 poultry regions reveals\na moderate positive association between facility density and XCO2 (r = 0.43);\nhigh-density areas exhibit larger seasonal amplitudes (9.57 ppm) and enhanced\nsummer variability. Compared with conventional interpolation and standard\nmachine-learning baselines, ST-ViWT yields seamless 0.25 degree CO2 surfaces\nwith explicit uncertainties, enabling year-round coverage despite sparse\nobservations. The approach supports integration of satellite constraints with\nnational inventories and precision livestock platforms to benchmark emissions,\nrefine region-specific factors, and verify interventions. Importantly,\ntransformer-based Earth observation enables scalable, transparent, spatially\nexplicit carbon accounting, hotspot prioritization, and policy-relevant\nmitigation assessment.", "AI": {"tldr": "ST-ViWT combines wavelet time-frequency features with transformer attention over meteorology and land data to gap-fill OCO-2 XCO2, producing continuous 0.25\u00b0 maps with uncertainties and demonstrating good generalization and correlation with poultry facility density.", "motivation": "Need for accurate, continuous, uncertainty-quantified XCO2 maps over agricultural/poultry-intensive regions to guide emission mitigation and verify interventions.", "method": "Fusion of wavelet time-frequency representations and transformer attention applied to multi-source inputs (meteorology, vegetation indices, topography, land cover) to gap-fill OCO-2 XCO2; validation against TCCON and regional spatial analysis.", "result": "High-fidelity reconstruction of XCO2 fields over southern Canada, achieving R2 0.984 and RMSE 0.468 ppm with uncertainty quantification and strong TCCON validation.", "conclusion": "ST-ViWT reliably reconstructs year-round XCO2 fields, offers explicit uncertainties, outperforms conventional baselines, and is useful for integrating satellite data with inventories to prioritize mitigation and verify interventions."}}
{"id": "2510.24168", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24168", "abs": "https://arxiv.org/abs/2510.24168", "authors": ["Weihua Cheng", "Ersheng Ni", "Wenlong Wang", "Yifei Sun", "Junming Liu", "Wangyu Shen", "Yirong Chen", "Botian Shi", "Ding Wang"], "title": "MGA: Memory-Driven GUI Agent for Observation-Centric Interaction", "comment": "Submitted to WWW2025", "summary": "The rapid progress of Large Language Models (LLMs) and their multimodal\nextensions (MLLMs) has enabled agentic systems capable of perceiving and acting\nacross diverse environments. A challenging yet impactful frontier is the\ndevelopment of GUI agents, which must navigate complex desktop and web\ninterfaces while maintaining robustness and generalization. Existing paradigms\ntypically model tasks as long-chain executions, concatenating historical\ntrajectories into the context. While approaches such as Mirage and GTA1 refine\nplanning or introduce multi-branch action selection, they remain constrained by\ntwo persistent issues: Dependence on historical trajectories, which amplifies\nerror propagation. And Local exploration bias, where \"decision-first,\nobservation-later\" mechanisms overlook critical interface cues. We introduce\nthe Memory-Driven GUI Agent (MGA), which reframes GUI interaction around the\nprinciple of observe first, then decide. MGA models each step as an\nindependent, context-rich environment state represented by a triad: current\nscreenshot, task-agnostic spatial information, and a dynamically updated\nstructured memory. Experiments on OSworld benchmarks, real desktop applications\n(Chrome, VSCode, VLC), and cross-task transfer demonstrate that MGA achieves\nsubstantial gains in robustness, generalization, and efficiency compared to\nstate-of-the-art baselines. The code is publicly available at:\n{https://anonymous.4open.science/r/MGA-3571}.", "AI": {"tldr": "MGA\u901a\u8fc7\u5c06\u4ea4\u4e92\u5efa\u6a21\u4e3a\u201c\u622a\u56fe+\u7a7a\u95f4\u4fe1\u606f+\u52a8\u6001\u8bb0\u5fc6\u201d\u4e09\u5143\u7ec4\u5e76\u91c7\u7528\u5148\u89c2\u5bdf\u540e\u51b3\u7b56\u7b56\u7565\uff0c\u6709\u6548\u51cf\u5c11\u5386\u53f2\u4f9d\u8d56\u4e0e\u5c40\u90e8\u504f\u5dee\uff0c\u5728\u591a\u9879\u57fa\u51c6\u4e0e\u771f\u5b9e\u5e94\u7528\u4e0a\u663e\u8457\u63d0\u5347GUI\u4ee3\u7406\u6027\u80fd\u3002", "motivation": "\u73b0\u6709GUI\u4ee3\u7406\u4f9d\u8d56\u5386\u53f2\u8f68\u8ff9\u5bfc\u81f4\u8bef\u5dee\u653e\u5927\uff0c\u4e14\u51b3\u7b56\u4f18\u5148\u7684\u673a\u5236\u5ffd\u89c6\u754c\u9762\u5173\u952e\u4fe1\u606f\uff0c\u9650\u5236\u4e86\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u3002\u9700\u8981\u4e00\u79cd\u51cf\u5c11\u5386\u53f2\u4f9d\u8d56\u5e76\u66f4\u6ce8\u91cd\u5f53\u524d\u89c2\u5bdf\u7684\u4ea4\u4e92\u5efa\u6a21\u65b9\u5f0f\u3002", "method": "\u63d0\u51faMemory-Driven GUI Agent (MGA)\uff0c\u91c7\u7528\u201c\u5148\u89c2\u5bdf\u540e\u51b3\u7b56\u201d\u8303\u5f0f\uff1b\u6bcf\u6b65\u8f93\u5165\u4e3a\uff08\u5f53\u524d\u622a\u56fe\u3001\u7a7a\u95f4\u4fe1\u606f\u3001\u53ef\u66f4\u65b0\u7ed3\u6784\u5316\u8bb0\u5fc6\uff09\uff1b\u7528\u52a8\u6001\u8bb0\u5fc6\u66ff\u4ee3\u957f\u94fe\u5386\u53f2\u62fc\u63a5\uff1b\u5728OSworld\u548c\u771f\u5b9e\u684c\u9762\u5e94\u7528\u4e0a\u8fdb\u884c\u5bf9\u6bd4\u5b9e\u9a8c\u3002", "result": "\u5728OSworld\u57fa\u51c6\u3001Chrome\u3001VSCode\u3001VLC\u7b49\u771f\u5b9e\u5e94\u7528\u4e0e\u8de8\u4efb\u52a1\u8fc1\u79fb\u573a\u666f\u4e2d\uff0cMGA\u5728\u6210\u529f\u7387\u3001\u9c81\u68d2\u6027\u4e0e\u6548\u7387\u4e0a\u5747\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\uff08\u5982Mirage\u4e0eGTA1\uff09\u3002", "conclusion": "MGA\u901a\u8fc7\u5c06\u6bcf\u4e2a\u4ea4\u4e92\u6b65\u9aa4\u5efa\u6a21\u4e3a\u4ee5\u5f53\u524d\u622a\u56fe\u3001\u4efb\u52a1\u65e0\u5173\u7684\u7a7a\u95f4\u4fe1\u606f\u548c\u52a8\u6001\u7ed3\u6784\u5316\u8bb0\u5fc6\u4e3a\u4e09\u5143\u7ec4\u7684\u72ec\u7acb\u72b6\u6001\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u5386\u53f2\u8f68\u8ff9\u4f9d\u8d56\u548c\u5c40\u90e8\u63a2\u7d22\u504f\u5411\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u9c81\u68d2\u6027\u3001\u6cdb\u5316\u6027\u548c\u6548\u7387\u3002"}}
{"id": "2510.23665", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23665", "abs": "https://arxiv.org/abs/2510.23665", "authors": ["Juan C. Leon Alcazar", "Mattia Soldan", "Mohammad Saatialsoruji", "Alejandro Pardo", "Hani Itani", "Juan Camilo Perez", "Bernard Ghanem"], "title": "Transformers from Compressed Representations", "comment": null, "summary": "Compressed file formats are the corner stone of efficient data storage and\ntransmission, yet their potential for representation learning remains largely\nunderexplored. We introduce TEMPEST (TransformErs froM comPressed\nrEpreSenTations), a method that exploits the inherent byte-stream structure of\ncompressed files to design an effective tokenization and encoding strategy. By\nleveraging this compact encoding, a standard transformer can directly learn\nsemantic representations from compressed data streams, bypassing the need for\nraw byte-level processing or full media decoding. Our proposal substantially\nreduces the number of tokens required for semantic classification, thereby\nlowering both computational complexity and memory usage. Through extensive\nexperiments across diverse datasets, coding schemes, and modalities, we show\nthat TEMPEST achieves accuracy competitive wit the state-of-the-art while\ndelivering efficiency gains in memory and compute.", "AI": {"tldr": "TEMPEST \u5229\u7528\u538b\u7f29\u6587\u4ef6\u7684\u5b57\u8282\u6d41\u7ed3\u6784\u8fdb\u884c\u9ad8\u6548\u5206\u8bcd\u4e0e\u7f16\u7801\uff0c\u4f7fTransformer\u80fd\u76f4\u63a5\u4ece\u538b\u7f29\u6570\u636e\u5b66\u4e60\u8bed\u4e49\u8868\u793a\uff0c\u4ece\u800c\u964d\u4f4etoken\u6570\u4e0e\u8d44\u6e90\u6d88\u8017\uff0c\u4e14\u4fdd\u6301\u7ade\u4e89\u6027\u51c6\u786e\u5ea6\u3002", "motivation": "\u538b\u7f29\u6587\u4ef6\u5e7f\u6cdb\u5b58\u5728\u4e14\u5728\u5b58\u50a8/\u4f20\u8f93\u4e2d\u5360\u4e3b\u5bfc\u5730\u4f4d\uff0c\u4f46\u5176\u5728\u8868\u793a\u5b66\u4e60\u9886\u57df\u7684\u6f5c\u529b\u672a\u88ab\u5145\u5206\u5229\u7528\u3002\u901a\u8fc7\u76f4\u63a5\u5229\u7528\u538b\u7f29\u8868\u793a\u53ef\u4ee5\u51cf\u5c11token\u6570\u91cf\u548c\u8ba1\u7b97/\u5185\u5b58\u5f00\u9500\uff0c\u540c\u65f6\u4fdd\u6301\u6216\u63a5\u8fd1\u6700\u5148\u8fdb\u65b9\u6cd5\u7684\u51c6\u786e\u6027\u3002", "method": "\u6784\u5efa\u9488\u5bf9\u538b\u7f29\u6587\u4ef6\u56fa\u6709\u5b57\u8282\u6d41\u7ed3\u6784\u7684\u5206\u8bcd\u4e0e\u7f16\u7801\u65b9\u6cd5\uff0c\u5c06\u538b\u7f29\u6570\u636e\u6620\u5c04\u4e3a\u7d27\u51d1\u7684token\u5e8f\u5217\uff0c\u8f93\u5165\u5e38\u89c4\u6a21\u578b\uff08Transformer\uff09\u5b66\u4e60\u8bed\u4e49\u8868\u793a\uff0c\u7701\u53bb\u5b8c\u6574\u89e3\u7801\u6216\u539f\u59cb\u5b57\u8282\u7ea7\u522b\u5904\u7406\u3002", "result": "\u5728\u591a\u79cd\u6570\u636e\u96c6\u3001\u7f16\u7801\u65b9\u6848\u548c\u6a21\u6001\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0cTEMPEST \u5728\u51c6\u786e\u7387\u4e0a\u4e0e\u6700\u5148\u8fdb\u65b9\u6cd5\u76f8\u5f53\uff0c\u540c\u65f6\u5728\u5185\u5b58\u548c\u8ba1\u7b97\u6548\u7387\u4e0a\u6709\u663e\u8457\u63d0\u5347\u3002", "conclusion": "TEMPEST \u63d0\u51fa\u4e86\u4e00\u79cd\u76f4\u63a5\u4ece\u538b\u7f29\u6570\u636e\u6d41\u5b66\u4e60\u8bed\u4e49\u8868\u793a\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u8bbe\u8ba1\u9762\u5411\u538b\u7f29\u5b57\u8282\u6d41\u7684\u5206\u8bcd\u548c\u7f16\u7801\u7b56\u7565\uff0c\u4f7f\u6807\u51c6Transformer\u80fd\u5728\u4e0d\u89e3\u7801\u6216\u9010\u5b57\u8282\u5904\u7406\u539f\u59cb\u6570\u636e\u7684\u60c5\u51b5\u4e0b\u8fdb\u884c\u8bed\u4e49\u5206\u7c7b\u3002"}}
{"id": "2510.24284", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24284", "abs": "https://arxiv.org/abs/2510.24284", "authors": ["Wenhao Wang", "Peizhi Niu", "Zhao Xu", "Zhaoyu Chen", "Jian Du", "Yaxin Du", "Xianghe Pang", "Keduan Huang", "Yanfeng Wang", "Qiang Yan", "Siheng Chen"], "title": "MCP-Flow: Facilitating LLM Agents to Master Real-World, Diverse and Scaling MCP Tools", "comment": null, "summary": "Large Language Models (LLMs) increasingly rely on external tools to perform\ncomplex, realistic tasks, yet their ability to utilize the rapidly expanding\nModel Contextual Protocol (MCP) ecosystem remains limited. Existing MCP\nresearch covers few servers, depends on costly manual curation, and lacks\ntraining support, hindering progress toward real-world deployment. To overcome\nthese limitations, we introduce MCP-Flow, an automated web-agent-driven\npipeline for large-scale server discovery, data synthesis, and model training.\nMCP-Flow collects and filters data from 1166 servers and 11536 tools, producing\n68733 high-quality instruction-function call pairs and 6439 trajectories, far\nexceeding prior work in scale and diversity. Extensive experiments demonstrate\nMCP-Flow's effectiveness in driving superior MCP tool selection, function-call\ngeneration, and enhanced agentic task performance. MCP-Flow thus provides a\nscalable foundation for advancing LLM agents' proficiency in real-world MCP\nenvironments. MCP-Flow is publicly available at\n\\href{https://github.com/wwh0411/MCP-Flow}{https://github.com/wwh0411/MCP-Flow}.", "AI": {"tldr": "MCP-Flow: an automated pipeline that collects large-scale MCP data (1166 servers, 11536 tools) to produce 68733 instruction-function pairs and 6439 trajectories, enabling better LLM agent tool use and improved task performance.", "motivation": "Existing MCP research is limited in server coverage, relies on manual curation, and lacks training data, which hampers LLMs' real-world MCP deployment. MCP-Flow aims to provide automated large-scale data collection and training to fill this gap.", "method": "Developed an automated web-agent pipeline for server discovery, data synthesis, and model training; collected data from 1166 servers and 11536 tools; filtered to produce 68733 instruction-function call pairs and 6439 trajectories; trained models and ran extensive evaluations on tool selection, function-call generation, and agentic tasks.", "result": "MCP-Flow outperforms prior approaches, demonstrating superior tool selection, function-call generation, and improved agentic task performance, providing a public resource for future research.", "conclusion": "MCP-Flow successfully builds a scalable, automated pipeline that expands MCP dataset scale and diversity, improving LLM agents' ability to select and call external tools in realistic settings."}}
{"id": "2510.23667", "categories": ["cs.LG", "cs.AI", "cs.CE"], "pdf": "https://arxiv.org/pdf/2510.23667", "abs": "https://arxiv.org/abs/2510.23667", "authors": ["Amin Heyrani Nobari", "Lyle Regenwetter", "Cyril Picard", "Ligong Han", "Faez Ahmed"], "title": "Optimize Any Topology: A Foundation Model for Shape- and Resolution-Free Structural Topology Optimization", "comment": null, "summary": "Structural topology optimization (TO) is central to engineering design but\nremains computationally intensive due to complex physics and hard constraints.\nExisting deep-learning methods are limited to fixed square grids, a few\nhand-coded boundary conditions, and post-hoc optimization, preventing general\ndeployment. We introduce Optimize Any Topology (OAT), a foundation-model\nframework that directly predicts minimum-compliance layouts for arbitrary\naspect ratios, resolutions, volume fractions, loads, and fixtures. OAT combines\na resolution- and shape-agnostic autoencoder with an implicit neural-field\ndecoder and a conditional latent-diffusion model trained on OpenTO, a new\ncorpus of 2.2 million optimized structures covering 2 million unique\nboundary-condition configurations. On four public benchmarks and two\nchallenging unseen tests, OAT lowers mean compliance up to 90% relative to the\nbest prior models and delivers sub-1 second inference on a single GPU across\nresolutions from 64 x 64 to 256 x 256 and aspect ratios as high as 10:1. These\nresults establish OAT as a general, fast, and resolution-free framework for\nphysics-aware topology optimization and provide a large-scale dataset to spur\nfurther research in generative modeling for inverse design. Code & data can be\nfound at https://github.com/ahnobari/OptimizeAnyTopology.", "AI": {"tldr": "OAT\u662f\u4e00\u4e2a\u901a\u7528\u3001\u5feb\u901f\u3001\u65e0\u5206\u8fa8\u7387\u9650\u5236\u7684\u62d3\u6251\u4f18\u5316\u57fa\u7840\u6a21\u578b\uff1a\u7ed3\u5408\u81ea\u7f16\u7801\u5668\u3001\u9690\u5f0f\u795e\u7ecf\u573a\u4e0e\u6f5c\u5728\u6269\u6563\uff1b\u7528\u5927\u89c4\u6a21OpenTO\u6570\u636e\u8bad\u7ec3\uff1b\u663e\u8457\u964d\u4f4e\u5408\u89c4\u6027\u5e76\u5b9e\u73b0\u4e9a\u79d2\u63a8\u7406\uff0c\u652f\u6301\u591a\u6837\u8fb9\u754c\u6761\u4ef6\u4e0e\u5206\u8fa8\u7387\u3002", "motivation": "\u89e3\u51b3\u7ed3\u6784\u62d3\u6251\u4f18\u5316(TO)\u8ba1\u7b97\u5f00\u9500\u5927\u3001\u7269\u7406\u590d\u6742\u548c\u7ea6\u675f\u96be\u5904\u7406\u7684\u95ee\u9898\uff0c\u5e76\u6269\u5c55\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u4ee5\u652f\u6301\u4efb\u610f\u5206\u8fa8\u7387\u3001\u7eb5\u6a2a\u6bd4\u3001\u4f53\u79ef\u5206\u6570\u3001\u8f7d\u8377\u548c\u7ea6\u675f\u6761\u4ef6\uff0c\u4ece\u800c\u5b9e\u73b0\u901a\u7528\u90e8\u7f72\u3002", "method": "\u6784\u5efa\u5206\u8fa8\u7387/\u5f62\u72b6\u65e0\u5173\u7684\u81ea\u7f16\u7801\u5668\u4e0e\u9690\u5f0f\u795e\u7ecf\u573a\u89e3\u7801\u5668\uff0c\u5e76\u5728\u6f5c\u5728\u7a7a\u95f4\u4e2d\u8bad\u7ec3\u6761\u4ef6\u6269\u6563\u6a21\u578b\uff1b\u7528OpenTO\u5927\u89c4\u6a21\u6570\u636e\u96c6\u8fdb\u884c\u8bad\u7ec3\uff1b\u5728\u591a\u9879\u57fa\u51c6\u4e0e\u672a\u89c1\u6761\u4ef6\u4e0b\u8bc4\u4f30\u6027\u80fd\u4e0e\u63a8\u7406\u901f\u5ea6\u3002", "result": "\u63d0\u51faOAT(Optimize Any Topology)\uff0c\u7ed3\u5408\u5206\u8fa8\u7387\u548c\u5f62\u72b6\u65e0\u5173\u7684\u81ea\u7f16\u7801\u5668\u3001\u9690\u5f0f\u795e\u7ecf\u573a\u89e3\u7801\u5668\u548c\u6761\u4ef6\u6f5c\u5728\u6269\u6563\u6a21\u578b\uff0c\u5e76\u6784\u5efa\u4e86\u5305\u542b220\u4e07\u4f18\u5316\u7ed3\u6784\u3001\u8986\u76d6200\u4e07\u552f\u4e00\u8fb9\u754c\u6761\u4ef6\u7684\u65b0\u6570\u636e\u96c6OpenTO\u3002\u5728\u591a\u4e2a\u57fa\u51c6\u548c\u672a\u89c1\u6d4b\u8bd5\u4e2d\uff0c\u76f8\u6bd4\u6700\u4f18\u73b0\u6709\u6a21\u578b\u5e73\u5747\u964d\u4f4e\u6700\u9ad8\u8fbe90%\u5408\u89c4\u6027\uff0c\u652f\u630164x64\u5230256x256\u5206\u8fa8\u7387\u548c\u6700\u9ad810:1\u7eb5\u6a2a\u6bd4\u7684\u5355GPU\u4e9a\u79d2\u7ea7\u63a8\u7406\u3002", "conclusion": "OAT\u8bc1\u660e\u4e86\u901a\u8fc7\u5927\u89c4\u6a21\u6570\u636e\u548c\u9002\u914d\u6027\u7f51\u7edc\u67b6\u6784\u53ef\u5b9e\u73b0\u901a\u7528\u4e14\u9ad8\u6548\u7684\u7269\u7406\u611f\u77e5\u62d3\u6251\u4f18\u5316\uff0c\u4e3a\u9006\u5411\u8bbe\u8ba1\u7684\u751f\u6210\u6a21\u578b\u7814\u7a76\u63d0\u4f9b\u4e86\u6570\u636e\u548c\u65b9\u6cd5\u57fa\u7840\u3002"}}
{"id": "2510.24297", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24297", "abs": "https://arxiv.org/abs/2510.24297", "authors": ["Robin Schm\u00f6cker", "Alexander Dockhorn", "Bodo Rosenhahn"], "title": "Investigating Intra-Abstraction Policies For Non-exact Abstraction Algorithms", "comment": null, "summary": "One weakness of Monte Carlo Tree Search (MCTS) is its sample efficiency which\ncan be addressed by building and using state and/or action abstractions in\nparallel to the tree search such that information can be shared among nodes of\nthe same layer. The primary usage of abstractions for MCTS is to enhance the\nUpper Confidence Bound (UCB) value during the tree policy by aggregating visits\nand returns of an abstract node. However, this direct usage of abstractions\ndoes not take the case into account where multiple actions with the same parent\nmight be in the same abstract node, as these would then all have the same UCB\nvalue, thus requiring a tiebreak rule. In state-of-the-art abstraction\nalgorithms such as pruned On the Go Abstractions (pruned OGA), this case has\nnot been noticed, and a random tiebreak rule was implicitly chosen. In this\npaper, we propose and empirically evaluate several alternative\nintra-abstraction policies, several of which outperform the random policy\nacross a majority of environments and parameter settings.", "AI": {"tldr": "MCTS\u4e2d\u5c06\u52a8\u4f5c\u805a\u5408\u5230\u62bd\u8c61\u8282\u70b9\u4f1a\u9020\u6210\u540c\u7236\u52a8\u4f5cUCB\u76f8\u540c\u7684\u95ee\u9898\uff1b\u4f5c\u8005\u63d0\u51fa\u5e76\u6d4b\u8bd5\u591a\u79cd\u5185\u90e8\u9009\u62e9\u7b56\u7565\uff0c\u82e5\u5e72\u7b56\u7565\u4f18\u4e8e\u73b0\u6709\u968f\u673a\u5e73\u5c40\u89c4\u5219\u3002", "motivation": "\u63d0\u9ad8MCTS\u7684\u6837\u672c\u6548\u7387\uff0c\u901a\u8fc7\u5728\u6811\u641c\u7d22\u4e2d\u5e76\u884c\u6784\u5efa\u548c\u4f7f\u7528\u72b6\u6001/\u52a8\u4f5c\u62bd\u8c61\u4ee5\u5728\u540c\u4e00\u5c42\u8282\u70b9\u4e4b\u95f4\u5171\u4eab\u4fe1\u606f\u3002", "method": "\u5206\u6790\u62bd\u8c61\u589e\u5f3aUCB\u5e26\u6765\u7684\u540c\u503c\u51b2\u7a81\uff0c\u8bbe\u8ba1\u591a\u79cd\u62bd\u8c61\u5185\u7b56\u7565\uff08\u66ff\u4ee3\u968f\u673a\u5e73\u5c40\uff09\uff0c\u5e76\u5728\u591a\u4e2a\u73af\u5883\u4e0e\u53c2\u6570\u96c6\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u6bd4\u8f83\u3002", "result": "\u63d0\u51fa\u5e76\u5b9e\u8bc1\u8bc4\u4f30\u4e86\u591a\u79cd\u66ff\u4ee3\u6027\u7684\u62bd\u8c61\u5185\u7b56\u7565\uff0c\u7528\u4e8e\u5904\u7406\u4e00\u7ec4\u5177\u6709\u76f8\u540c\u7236\u8282\u70b9\u4e14\u843d\u5728\u540c\u4e00\u62bd\u8c61\u8282\u70b9\u7684\u52a8\u4f5c\u5bfc\u81f4\u76f8\u540cUCB\u503c\u7684\u95ee\u9898\uff0c\u53d1\u73b0\u82e5\u5e72\u7b56\u7565\u5728\u591a\u6570\u73af\u5883\u548c\u53c2\u6570\u8bbe\u7f6e\u4e2d\u4f18\u4e8e\u968f\u673a\u6253\u7834\u5e73\u5c40\u7b56\u7565\u3002", "conclusion": "\u5728\u4f7f\u7528\u62bd\u8c61\u589e\u5f3aMCTS\u65f6\uff0c\u5e94\u4f7f\u7528\u66f4\u597d\u7684\u62bd\u8c61\u5185\u9009\u62e9\u7b56\u7565\u800c\u975e\u968f\u673a\u5e73\u5c40\uff1b\u8fd9\u4e9b\u7b56\u7565\u53ef\u4ee5\u63d0\u9ad8\u6027\u80fd\u4e14\u5728\u591a\u79cd\u73af\u5883\u548c\u53c2\u6570\u4e0b\u8868\u73b0\u66f4\u7a33\u5b9a\u3002"}}
{"id": "2510.23668", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23668", "abs": "https://arxiv.org/abs/2510.23668", "authors": ["Fujiang Yuan", "Yangrui Fan", "Xiaohuan Bing", "Zhen Tian", "Chunhong Yuan", "Yankang Li"], "title": "Traffic flow forecasting, STL decomposition, Hybrid model, LSTM, ARIMA, XGBoost, Intelligent transportation systems", "comment": null, "summary": "Accurate traffic flow forecasting is essential for intelligent transportation\nsystems and urban traffic management. However, single model approaches often\nfail to capture the complex, nonlinear, and multi scale temporal patterns in\ntraffic flow data. This study proposes a decomposition driven hybrid framework\nthat integrates Seasonal Trend decomposition using Loess (STL) with three\ncomplementary predictive models. STL first decomposes the original time series\ninto trend, seasonal, and residual components. Then, a Long Short Term Memory\n(LSTM) network models long term trends, an Autoregressive Integrated Moving\nAverage (ARIMA) model captures seasonal periodicity, and an Extreme Gradient\nBoosting (XGBoost) algorithm predicts nonlinear residual fluctuations. The\nfinal forecast is obtained through multiplicative integration of the sub model\npredictions. Using 998 traffic flow records from a New York City intersection\nbetween November and December 2015, results show that the LSTM ARIMA XGBoost\nhybrid model significantly outperforms standalone models including LSTM, ARIMA,\nand XGBoost across MAE, RMSE, and R squared metrics. The decomposition strategy\neffectively isolates temporal characteristics, allowing each model to\nspecialize, thereby improving prediction accuracy, interpretability, and\nrobustness.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u57fa\u4e8e STL \u5206\u89e3\u7684\u6df7\u5408\u9884\u6d4b\u6846\u67b6\uff1aLSTM \u9884\u6d4b\u8d8b\u52bf\uff0cARIMA \u6355\u6349\u5b63\u8282\u6027\uff0cXGBoost \u9884\u6d4b\u6b8b\u5dee\uff0c\u4e09\u8005\u4e58\u6cd5\u878d\u5408\uff0c\u5b9e\u9a8c\u8bc1\u660e\u4f18\u4e8e\u5355\u6a21\u578b\u3002", "motivation": "\u89e3\u51b3\u5355\u4e00\u6a21\u578b\u96be\u4ee5\u6355\u6349\u4ea4\u901a\u6d41\u590d\u6742\u975e\u7ebf\u6027\u548c\u591a\u5c3a\u5ea6\u65f6\u95f4\u6a21\u5f0f\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u5c06 STL \u5206\u89e3\u4e0e\u591a\u4e2a\u6a21\u578b\u7ed3\u5408\uff0c\u4f7f\u6bcf\u4e2a\u6a21\u578b\u4e13\u6ce8\u4e8e\u4e0d\u540c\u6210\u5206\uff0c\u63d0\u9ad8\u9884\u6d4b\u7cbe\u5ea6\u4e0e\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u5148\u7528 STL \u5c06\u539f\u5e8f\u5217\u5206\u89e3\u4e3a\u8d8b\u52bf\u3001\u5b63\u8282\u548c\u6b8b\u5dee\uff1b\u7528 LSTM \u62df\u5408\u8d8b\u52bf\uff0cARIMA \u62df\u5408\u5b63\u8282\uff0cXGBoost \u62df\u5408\u6b8b\u5dee\uff1b\u6700\u540e\u901a\u8fc7\u4e58\u6cd5\u6574\u5408\u5b50\u6a21\u578b\u9884\u6d4b\u5f97\u5230\u6700\u7ec8\u9884\u6d4b\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a STL+LSTM+ARIMA+XGBoost \u7684\u6df7\u5408\u6846\u67b6\uff0c\u5e76\u5728\u7ebd\u7ea6\u67d0\u8def\u53e3 998 \u6761\u8bb0\u5f55\u4e0a\u5b9e\u9a8c\uff0c\u6df7\u5408\u6a21\u578b\u5728 MAE\u3001RMSE\u3001R\u00b2 \u4e0a\u663e\u8457\u4f18\u4e8e\u5355\u6a21\u578b\u3002", "conclusion": "\u5206\u89e3\u7b56\u7565\u4f7f\u5404\u6a21\u578b\u4e13\u6ce8\u4e8e\u4e0d\u540c\u65f6\u95f4\u7279\u5f81\uff0c\u63d0\u5347\u4e86\u9884\u6d4b\u51c6\u786e\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u9c81\u68d2\u6027\uff1b\u6df7\u5408\u6a21\u578b\u5728\u6240\u7528\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e LSTM\u3001ARIMA\u3001XGBoost \u5355\u72ec\u6a21\u578b\u3002"}}
{"id": "2510.24299", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24299", "abs": "https://arxiv.org/abs/2510.24299", "authors": ["Jiayu Liu", "Wei Dai", "Zhenya Huang", "Ning Miao", "Enhong Chen"], "title": "Verifying Large Language Models' Reasoning Paths via Correlation Matrix Rank", "comment": null, "summary": "Despite the strong reasoning ability of large language models~(LLMs), they\nare prone to errors and hallucinations. As a result, how to check their outputs\neffectively and efficiently has become a critical problem in their\napplications. Existing checking methods heavily rely on external resources,\nsuch as trained verifiers (e.g., process/outcome reward models) or elaborate\nprompts, which lead to high computational overhead and are only applicable to\nspecific domains. In this paper, we investigate whether the internal behaviors\nof LLMs have already implied the credibility of their reasoning paths.\nSpecifically, we find that the rank of the correlation matrix between the input\nproblem and the output reasoning path is a robust indicator of reasoning\ncorrectness. Different from other correctness indicators for LLMs, the\ncalculation of the correlation matrix only relies on the LLM itself, which\navoids the hassle of training a separate model or designing complicated\nprompts. Based on it, we design a simple, plug-and-play Self-Indicator method\nto reweight candidate reasoning paths, which achieves significant performance\nimprovements than other voting and verification methods with very few\ncomputational overhead. Our experiments across multiple LLMs of varying scales\nand model families have further shown the effectiveness of Self-Indicator. It\nachieves over 75% accuracy in distinguishing correct reasoning paths from\nincorrect ones, and, in turn, improves the accuracies on three reasoning\nbenchmarks by more than 8%.", "AI": {"tldr": "\u8be5\u5de5\u4f5c\u63d0\u51fa\u4e00\u79cd\u65e0\u9700\u5916\u90e8\u8d44\u6e90\u3001\u57fa\u4e8e\u6a21\u578b\u5185\u90e8\u884c\u4e3a\u7684\u81ea\u68c0\u65b9\u6cd5\uff08Self-Indicator\uff09\uff0c\u901a\u8fc7\u8ba1\u7b97\u8f93\u5165\u4e0e\u63a8\u7406\u8def\u5f84\u4e4b\u95f4\u7684\u76f8\u5173\u77e9\u9635\u7684\u79e9\u6765\u5224\u65ad\u63a8\u7406\u662f\u5426\u6b63\u786e\uff0c\u5e76\u636e\u6b64\u91cd\u52a0\u6743\u5019\u9009\u63a8\u7406\u8def\u5f84\uff0c\u4ece\u800c\u663e\u8457\u63d0\u5347\u591a\u79cd\u5927\u6a21\u578b\u5728\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u51c6\u786e\u7387\u3002", "motivation": "\u73b0\u6709\u68c0\u67e5LLM\u8f93\u51fa\u7684\u65b9\u6cd5\u4f9d\u8d56\u5916\u90e8\u8d44\u6e90\uff08\u8bad\u7ec3\u7684\u9a8c\u8bc1\u5668\u6216\u590d\u6742\u63d0\u793a\uff09\uff0c\u6210\u672c\u9ad8\u4e14\u9886\u57df\u9002\u5e94\u6027\u5dee\u3002\u4f5c\u8005\u5047\u8bbe\u5e76\u9a8c\u8bc1LLM\u5185\u90e8\u884c\u4e3a\u5df2\u9690\u542b\u53ef\u4fe1\u5ea6\u4fe1\u606f\uff0c\u5bfb\u627e\u4e00\u79cd\u53ea\u4f9d\u8d56\u6a21\u578b\u81ea\u8eab\u7684\u9ad8\u6548\u53ef\u4fe1\u5ea6\u4f30\u8ba1\u65b9\u6cd5\u3002", "method": "\u5bf9\u6bcf\u4e2a\u5019\u9009\u63a8\u7406\u8def\u5f84\uff0c\u8ba1\u7b97\u8f93\u5165\u95ee\u9898\u4e0e\u8be5\u8def\u5f84\u4e4b\u95f4\u7684\u76f8\u5173\u77e9\u9635\uff08\u53ef\u80fd\u901a\u8fc7token/\u8868\u793a\u76f8\u5173\u6027\uff09\uff0c\u63d0\u53d6\u77e9\u9635\u7684\u79e9\u4f5c\u4e3a\u6b63\u786e\u6027\u6307\u793a\u5668\uff0c\u7136\u540e\u6309\u8be5\u6307\u6807\u4e3a\u5019\u9009\u8def\u5f84\u91cd\u52a0\u6743\u5e76\u9009\u53d6\u6700\u7ec8\u7b54\u6848\u3002\u8be5\u65b9\u6cd5\u65e0\u9700\u5916\u90e8\u9a8c\u8bc1\u5668\u6216\u7279\u6b8a\u63d0\u793a\uff0c\u5c5e\u4e8e\u63d2\u62d4\u5f0f\u540e\u5904\u7406\u3002", "result": "\u5728\u591a\u79cd\u89c4\u6a21\u548c\u5bb6\u65cf\u7684LLM\u4e0a\uff0cSelf-Indicator\u5728\u533a\u5206\u6b63\u786e/\u9519\u8bef\u63a8\u7406\u8def\u5f84\u4e0a\u51c6\u786e\u7387\u8d85\u8fc775%\uff0c\u5e76\u5728\u4e09\u4e2a\u63a8\u7406\u57fa\u51c6\u4e0a\u5c06\u6700\u7ec8\u51c6\u786e\u7387\u63d0\u5347\u8d85\u8fc78%\u3002", "conclusion": "\u76f8\u5173\u77e9\u9635\u7684\u79e9\u662f\u5224\u65adLLM\u63a8\u7406\u8def\u5f84\u6b63\u786e\u6027\u7684\u7a33\u5065\u6307\u6807\uff1b\u57fa\u4e8e\u8be5\u6307\u6807\u7684Self-Indicator\u65b9\u6cd5\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u6216\u590d\u6742\u63d0\u793a\uff0c\u8ba1\u7b97\u5f00\u9500\u4f4e\uff0c\u4e0e\u591a\u6570\u6295\u7968\u6216\u9a8c\u8bc1\u65b9\u6cd5\u76f8\u6bd4\u80fd\u660e\u663e\u63d0\u5347\u63a8\u7406\u6b63\u786e\u7387\uff0c\u5728\u591a\u4e2a\u6a21\u578b\u4e0e\u57fa\u51c6\u4e0a\u53d6\u5f978%\u4ee5\u4e0a\u7684\u6027\u80fd\u63d0\u5347\u3002"}}
{"id": "2510.23671", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23671", "abs": "https://arxiv.org/abs/2510.23671", "authors": ["Marmik Chaudhari", "Jeremi Nuer", "Rome Thorstenson"], "title": "Sparsity and Superposition in Mixture of Experts", "comment": null, "summary": "Mixture of Experts (MoE) models have become central to scaling large language\nmodels, yet their mechanistic differences from dense networks remain poorly\nunderstood. Previous work has explored how dense models use\n\\textit{superposition} to represent more features than dimensions, and how\nsuperposition is a function of feature sparsity and feature importance. MoE\nmodels cannot be explained mechanistically through the same lens. We find that\nneither feature sparsity nor feature importance cause discontinuous phase\nchanges, and that network sparsity (the ratio of active to total experts)\nbetter characterizes MoEs. We develop new metrics for measuring superposition\nacross experts. Our findings demonstrate that models with greater network\nsparsity exhibit greater \\emph{monosemanticity}. We propose a new definition of\nexpert specialization based on monosemantic feature representation rather than\nload balancing, showing that experts naturally organize around coherent feature\ncombinations when initialized appropriately. These results suggest that network\nsparsity in MoEs may enable more interpretable models without sacrificing\nperformance, challenging the common assumption that interpretability and\ncapability are fundamentally at odds.", "AI": {"tldr": "MoEs differ from dense nets: network sparsity\u2014not feature sparsity/importance\u2014drives monosemantic representations across experts; new metrics and a redefined specialization show sparse MoEs are more interpretable without losing performance.", "motivation": "Understand mechanistic differences between MoE and dense models, especially superposition and interpretability.", "method": "Analysis of methods", "result": "Network sparsity (ratio of active to total experts) better characterizes MoE behavior; greater sparsity leads to monosemanticity; experts specialize into coherent feature combinations when initialized appropriately.", "conclusion": "Network sparsity enables more interpretable expert specialization in MoEs via monosemantic feature representation, challenging the trade-off between interpretability and capability."}}
{"id": "2510.24303", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24303", "abs": "https://arxiv.org/abs/2510.24303", "authors": ["Deniz Gorur", "Antoni Rago", "Francesca Toni"], "title": "Retrieval and Argumentation Enhanced Multi-Agent LLMs for Judgmental Forecasting", "comment": null, "summary": "Judgmental forecasting is the task of making predictions about future events\nbased on human judgment. This task can be seen as a form of claim verification,\nwhere the claim corresponds to a future event and the task is to assess the\nplausibility of that event. In this paper, we propose a novel multi-agent\nframework for claim verification, whereby different agents may disagree on\nclaim veracity and bring specific evidence for and against the claims,\nrepresented as quantitative bipolar argumentation frameworks (QBAFs). We then\ninstantiate the framework for supporting claim verification, with a variety of\nagents realised with Large Language Models (LLMs): (1) ArgLLM agents, an\nexisting approach for claim verification that generates and evaluates QBAFs;\n(2) RbAM agents, whereby LLM-empowered Relation-based Argument Mining (RbAM)\nfrom external sources is used to generate QBAFs; (3) RAG-ArgLLM agents,\nextending ArgLLM agents with a form of Retrieval-Augmented Generation (RAG) of\narguments from external sources. Finally, we conduct experiments with two\nstandard judgmental forecasting datasets, with instances of our framework with\ntwo or three agents, empowered by six different base LLMs. We observe that\ncombining evidence from agents can improve forecasting accuracy, especially in\nthe case of three agents, while providing an explainable combination of\nevidence for claim verification.", "AI": {"tldr": "\u672c\u6587\u628a\u5224\u65ad\u6027\u9884\u6d4b\u5f53\u4f5c\u89c2\u70b9\u9a8c\u8bc1\uff0c\u63d0\u51fa\u57fa\u4e8eQBAF\u7684\u591a\u4ee3\u7406\u8bba\u8bc1\u6846\u67b6\uff0c\u7528\u4e0d\u540c\u7c7b\u578b\u7684LLM\u4ee3\u7406\u751f\u6210\u4e0e\u8bc4\u4f30\u652f\u6301/\u53cd\u5bf9\u8bc1\u636e\uff0c\u5b9e\u9a8c\u8bc1\u660e\u591a\u4ee3\u7406\u6574\u5408\u80fd\u63d0\u9ad8\u51c6\u786e\u6027\u5e76\u589e\u5f3a\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u63d0\u51fa\u4e00\u79cd\u591a\u4ee3\u7406\u6846\u67b6\uff0c\u5c06\u5224\u65ad\u6027\u9884\u6d4b\u89c6\u4e3a\u9488\u5bf9\u672a\u6765\u4e8b\u4ef6\u7684\u89c2\u70b9\u9a8c\u8bc1\uff0c\u901a\u8fc7\u4ee3\u7406\u4e4b\u95f4\u7684\u8bc1\u636e\u8fa9\u8bba\u6765\u8bc4\u4f30\u4e8b\u4ef6\u7684\u53ef\u4fe1\u5ea6\u3002", "method": "\u63d0\u51faQBAF\u591a\u4ee3\u7406\u5f62\u5f0f\u5316\u6846\u67b6\uff1b\u5b9e\u73b0\u4e09\u7c7bLLM\u4ee3\u7406\uff08ArgLLM\u3001RbAM\u3001RAG-ArgLLM\uff09\uff1b\u5728\u4e24\u4e2a\u5224\u65ad\u6027\u9884\u6d4b\u6570\u636e\u96c6\u4e0a\uff0c\u7528\u516d\u79cd\u57fa\u7840LLM\u8fdb\u884c\u4e24/\u4e09\u4ee3\u7406\u7ec4\u5408\u5b9e\u9a8c\uff0c\u6bd4\u8f83\u51c6\u786e\u7387\u4e0e\u53ef\u89e3\u91ca\u6027\u3002", "result": "\u8bbe\u8ba1\u5e76\u5b9e\u4f8b\u5316\u4e86\u57fa\u4e8e\u5b9a\u91cf\u53cc\u6781\u8bba\u8bc1\u6846\u67b6(QBAF)\u7684\u591a\u4ee3\u7406\u4f53\u7cfb\uff0c\u5305\u542b\u4e09\u7c7b\u7531\u5927\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u7684\u4ee3\u7406\uff08ArgLLM\u3001RbAM\u3001RAG-ArgLLM\uff09\uff0c\u5e76\u5728\u4e24\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0c\u663e\u793a\u591a\u4ee3\u7406\u7ec4\u5408\uff08\u5c24\u5176\u4e09\u4ee3\u7406\uff09\u80fd\u63d0\u5347\u9884\u6d4b\u51c6\u786e\u6027\u5e76\u63d0\u4f9b\u53ef\u89e3\u91ca\u8bc1\u636e\u7ec4\u5408\u3002", "conclusion": "\u591a\u4ee3\u7406\u6846\u67b6\u80fd\u901a\u8fc7\u6574\u5408\u6765\u81ea\u4e0d\u540cLLM\u4ee3\u7406\u7684\u8bc1\u636e\u63d0\u5347\u5224\u65ad\u6027\u9884\u6d4b\u7684\u8868\u73b0\uff0c\u5e76\u63d0\u4f9b\u900f\u660e\u7684\u8bba\u8bc1\u7ed3\u6784\uff1b\u5f15\u5165\u68c0\u7d22\u6216\u5173\u7cfb\u578b\u8bba\u8bc1\u6316\u6398\u53ef\u8fdb\u4e00\u6b65\u4e30\u5bcc\u8bc1\u636e\u6765\u6e90\u3002"}}
{"id": "2510.23672", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.23672", "abs": "https://arxiv.org/abs/2510.23672", "authors": ["Xiangfei Qiu", "Xingjian Wu", "Hanyin Cheng", "Xvyuan Liu", "Chenjuan Guo", "Jilin Hu", "Bin Yang"], "title": "DBLoss: Decomposition-based Loss Function for Time Series Forecasting", "comment": "Accepted by NeurIPS 2025", "summary": "Time series forecasting holds significant value in various domains such as\neconomics, traffic, energy, and AIOps, as accurate predictions facilitate\ninformed decision-making. However, the existing Mean Squared Error (MSE) loss\nfunction sometimes fails to accurately capture the seasonality or trend within\nthe forecasting horizon, even when decomposition modules are used in the\nforward propagation to model the trend and seasonality separately. To address\nthese challenges, we propose a simple yet effective Decomposition-Based Loss\nfunction called DBLoss. This method uses exponential moving averages to\ndecompose the time series into seasonal and trend components within the\nforecasting horizon, and then calculates the loss for each of these components\nseparately, followed by weighting them. As a general loss function, DBLoss can\nbe combined with any deep learning forecasting model. Extensive experiments\ndemonstrate that DBLoss significantly improves the performance of\nstate-of-the-art models across diverse real-world datasets and provides a new\nperspective on the design of time series loss functions.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5206\u89e3\u7684\u635f\u5931DBLoss\uff0c\u5229\u7528EMA\u5206\u89e3\u9884\u6d4b\u533a\u95f4\u7684\u8d8b\u52bf\u4e0e\u5b63\u8282\u6027\u5e76\u5206\u522b\u52a0\u6743\u8ba1\u7b97\u635f\u5931\uff0c\u63d0\u5347\u591a\u79cd\u6a21\u578b\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u9884\u6d4b\u6548\u679c\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709MSE\u635f\u5931\u5728\u6355\u6349\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u533a\u95f4\u5185\u5b63\u8282\u6027\u548c\u8d8b\u52bf\u65b9\u9762\u7684\u4e0d\u8db3\uff0c\u5373\u4f7f\u4f7f\u7528\u524d\u5411\u4f20\u64ad\u4e2d\u7684\u5206\u89e3\u6a21\u5757\u4e5f\u65e0\u6cd5\u5145\u5206\u53cd\u6620\u3002", "method": "\u5728\u635f\u5931\u51fd\u6570\u4e2d\u4f7f\u7528\u6307\u6570\u79fb\u52a8\u5e73\u5747(EMA)\u5bf9\u9884\u6d4b\u548c\u771f\u5b9e\u5e8f\u5217\u5728\u9884\u6d4b\u7a97\u53e3\u5185\u8fdb\u884c\u5206\u89e3\uff0c\u5f97\u5230\u8d8b\u52bf\u548c\u5b63\u8282\u6027\u5206\u91cf\uff1b\u5206\u522b\u8ba1\u7b97\u4e24\u9879\u7684\u8bef\u5dee\uff08\u4f8b\u5982MSE\uff09\u5e76\u6309\u6743\u91cd\u5408\u6210\u6700\u7ec8\u635f\u5931\uff0c\u53ef\u4e0e\u4efb\u610f\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u914d\u5408\u4f7f\u7528\u3002", "result": "\u63d0\u51faDBLoss\uff1a\u4f7f\u7528\u6307\u6570\u79fb\u52a8\u5e73\u5747\u5728\u9884\u6d4b\u533a\u95f4\u5185\u5c06\u5e8f\u5217\u5206\u89e3\u4e3a\u5b63\u8282\u6027\u548c\u8d8b\u52bf\u6210\u5206\uff0c\u5206\u522b\u8ba1\u7b97\u635f\u5931\u5e76\u52a0\u6743\uff0c\u4f5c\u4e3a\u901a\u7528\u635f\u5931\u51fd\u6570\u53ef\u4ee5\u4e0e\u4efb\u610f\u6df1\u5ea6\u5b66\u4e60\u9884\u6d4b\u6a21\u578b\u7ed3\u5408\uff0c\u5b9e\u9a8c\u8bc1\u660e\u80fd\u663e\u8457\u63d0\u5347SOTA\u6a21\u578b\u6027\u80fd\u3002", "conclusion": "DBLoss\u662f\u4e00\u79cd\u7b80\u5355\u901a\u7528\u7684\u635f\u5931\u8bbe\u8ba1\uff0c\u901a\u8fc7\u5728\u635f\u5931\u5c42\u9762\u663e\u5f0f\u5206\u89e3\u5e76\u5206\u522b\u8861\u91cf\u8d8b\u52bf\u4e0e\u5b63\u8282\u6027\u8bef\u5dee\uff0c\u80fd\u63d0\u9ad8\u65f6\u95f4\u5e8f\u5217\u6a21\u578b\u5bf9\u8fd9\u4e24\u7c7b\u4fe1\u53f7\u7684\u62df\u5408\uff0c\u4ece\u800c\u63d0\u5347\u9884\u6d4b\u6027\u80fd\u3002"}}
{"id": "2510.24337", "categories": ["cs.AI", "cs.SI"], "pdf": "https://arxiv.org/pdf/2510.24337", "abs": "https://arxiv.org/abs/2510.24337", "authors": ["Daria Kravets-Meinke", "Hannah Schmid-Petri", "Sonja Niemann", "Ute Schmid"], "title": "Generative Large Language Models (gLLMs) in Content Analysis: A Practical Guide for Communication Research", "comment": null, "summary": "Generative Large Language Models (gLLMs), such as ChatGPT, are increasingly\nbeing used in communication research for content analysis. Studies show that\ngLLMs can outperform both crowd workers and trained coders, such as research\nassistants, on various coding tasks relevant to communication science, often at\na fraction of the time and cost. Additionally, gLLMs can decode implicit\nmeanings and contextual information, be instructed using natural language,\ndeployed with only basic programming skills, and require little to no annotated\ndata beyond a validation dataset - constituting a paradigm shift in automated\ncontent analysis. Despite their potential, the integration of gLLMs into the\nmethodological toolkit of communication research remains underdeveloped. In\ngLLM-assisted quantitative content analysis, researchers must address at least\nseven critical challenges that impact result quality: (1) codebook development,\n(2) prompt engineering, (3) model selection, (4) parameter tuning, (5)\niterative refinement, (6) validation of the model's reliability, and\noptionally, (7) performance enhancement. This paper synthesizes emerging\nresearch on gLLM-assisted quantitative content analysis and proposes a\ncomprehensive best-practice guide to navigate these challenges. Our goal is to\nmake gLLM-based content analysis more accessible to a broader range of\ncommunication researchers and ensure adherence to established disciplinary\nquality standards of validity, reliability, reproducibility, and research\nethics.", "AI": {"tldr": "gLLM\u80fd\u986f\u8457\u63d0\u5347\u5167\u5bb9\u5206\u6790\u7684\u6548\u7387\u8207\u6548\u679c\uff0c\u4f46\u9700\u4f9d\u5faa\u4ee3\u78bc\u7c3f\u3001\u63d0\u793a\u8a2d\u8a08\u3001\u6a21\u578b\u8207\u53c3\u6578\u9078\u64c7\u3001\u8fed\u4ee3\u3001\u9a57\u8b49\u7b49\u4e03\u5927\u6b65\u9a5f\uff0c\u4e26\u517c\u9867\u502b\u7406\u8207\u5b78\u79d1\u54c1\u8cea\u6a19\u6e96\u3002", "motivation": "\u52d5\u6a5f\u5728\u65bc\u5c07\u5feb\u901f\u666e\u53ca\u7684gLLM\u5de5\u5177\u5316\uff0c\u586b\u88dc\u65b9\u6cd5\u8ad6\u4e0a\u53ef\u7528\u6027\u8207\u8cea\u91cf\u4fdd\u8b49\u4e4b\u9593\u7684\u843d\u5dee\uff0c\u8b93\u50b3\u64ad\u5b78\u8005\u80fd\u5728\u7dad\u6301\u6548\u5ea6\u3001\u4fe1\u5ea6\u3001\u53ef\u91cd\u73fe\u6027\u8207\u502b\u7406\u6027\u7684\u524d\u63d0\u4e0b\uff0c\u5ee3\u6cdb\u63a1\u7528gLLM\u9032\u884c\u5167\u5bb9\u5206\u6790\u3002", "method": "\u672c\u8ad6\u6587\u900f\u904e\u7d9c\u8ff0\u73fe\u6709\u7814\u7a76\uff0c\u6574\u5408gLLM\u5728\u5167\u5bb9\u5206\u6790\u4e2d\u7684\u61c9\u7528\u8b49\u64da\uff0c\u4e26\u63d0\u51fa\u4e00\u5957\u6db5\u84cb\u4e03\u5927\u6311\u6230\u7684\u5be6\u52d9\u6307\u5f15\uff0c\u793a\u7bc4\u5982\u4f55\u900f\u904e\u81ea\u7136\u8a9e\u8a00\u63d0\u793a\u3001\u5c11\u91cf\u9a57\u8b49\u8cc7\u6599\u53ca\u57fa\u672c\u7a0b\u5f0f\u90e8\u7f72\u4f86\u5be6\u65bdgLLM\u8f14\u52a9\u7684\u5b9a\u91cf\u5167\u5bb9\u5206\u6790\u3002", "result": "\u7d50\u679c\u70ba\uff1a\u63d0\u51fa\u4e00\u5957\u7cfb\u7d71\u5316\u7684\u6700\u4f73\u5be6\u52d9\u6307\u5357\uff0c\u8aaa\u660e\u5982\u4f55\u5728\u4e03\u500b\u95dc\u9375\u6b65\u9a5f\u4e2d\u64cd\u4f5c\u8207\u9a57\u8b49\uff0c\u4e26\u5f37\u8abf\u5728\u4e0d\u540c\u7814\u7a76\u60c5\u5883\u4e0b\u7684\u53d6\u6368\u8207\u6ce8\u610f\u4e8b\u9805\uff0c\u4ee5\u63d0\u5347\u7814\u7a76\u7684\u53ef\u7528\u6027\u8207\u54c1\u8cea\u3002", "conclusion": "\u672c\u6587\u7d50\u8ad6\u662f\uff1a\u751f\u6210\u5f0f\u5927\u578b\u8a9e\u8a00\u6a21\u578b\uff08gLLMs\uff09\u5728\u5b9a\u91cf\u5167\u5bb9\u5206\u6790\u4e2d\u5177\u5099\u985b\u8986\u6027\u6f5b\u529b\uff0c\u53ef\u5728\u6210\u672c\u3001\u901f\u5ea6\u8207\u6e96\u78ba\u6027\u4e0a\u8d85\u8d8a\u50b3\u7d71\u4eba\u529b\u7de8\u78bc\uff0c\u4f46\u8981\u9054\u5230\u53ef\u63a5\u53d7\u7684\u5b78\u8853\u54c1\u8cea\uff0c\u7814\u7a76\u8005\u5fc5\u9808\u9075\u5faa\u5305\u62ec\u4ee3\u78bc\u7c3f\u5236\u5b9a\u3001\u63d0\u793a\u5de5\u7a0b\u3001\u6a21\u578b\u9078\u64c7\u3001\u53c3\u6578\u8abf\u6574\u3001\u8fed\u4ee3\u6539\u9032\u3001\u53ef\u9760\u6027\u9a57\u8b49\u53ca\uff08\u53ef\u9078\u7684\uff09\u6027\u80fd\u589e\u5f37\u5728\u5167\u7684\u4e03\u9805\u95dc\u9375\u6d41\u7a0b\u3002"}}
{"id": "2510.23681", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.23681", "abs": "https://arxiv.org/abs/2510.23681", "authors": ["Carl Hvarfner", "David Eriksson", "Eytan Bakshy", "Max Balandat"], "title": "Informed Initialization for Bayesian Optimization and Active Learning", "comment": "28 pages", "summary": "Bayesian Optimization is a widely used method for optimizing expensive\nblack-box functions, relying on probabilistic surrogate models such as Gaussian\nProcesses. The quality of the surrogate model is crucial for good optimization\nperformance, especially in the few-shot setting where only a small number of\nbatches of points can be evaluated. In this setting, the initialization plays a\ncritical role in shaping the surrogate's predictive quality and guiding\nsubsequent optimization. Despite this, practitioners typically rely on\n(quasi-)random designs to cover the input space. However, such approaches\nneglect two key factors: (a) space-filling designs may not be desirable to\nreduce predictive uncertainty, and (b) efficient hyperparameter learning during\ninitialization is essential for high-quality prediction, which may conflict\nwith space-filling designs. To address these limitations, we propose\nHyperparameter-Informed Predictive Exploration (HIPE), a novel acquisition\nstrategy that balances predictive uncertainty reduction with hyperparameter\nlearning using information-theoretic principles. We derive a closed-form\nexpression for HIPE in the Gaussian Process setting and demonstrate its\neffectiveness through extensive experiments in active learning and few-shot BO.\nOur results show that HIPE outperforms standard initialization strategies in\nterms of predictive accuracy, hyperparameter identification, and subsequent\noptimization performance, particularly in large-batch, few-shot settings\nrelevant to many real-world Bayesian Optimization applications.", "AI": {"tldr": "\u63d0\u51faHIPE\u65b9\u6cd5\uff0c\u901a\u8fc7\u4fe1\u606f\u8bba\u539f\u5219\u5728\u521d\u59cb\u5316\u4e2d\u5e73\u8861\u51cf\u5c11\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u4e0e\u5b66\u4e60\u8d85\u53c2\u6570\uff0c\u9488\u5bf9GP\u6a21\u578b\u7ed9\u51fa\u95ed\u5f0f\u8868\u8fbe\uff0c\u5e76\u5728\u4e3b\u52a8\u5b66\u4e60\u4e0e\u5c11\u6837\u672cBO\u4e2d\u9a8c\u8bc1\u4f18\u4e8e\u968f\u673a\u8bbe\u8ba1\uff0c\u5c24\u5176\u5728\u5927\u6279\u6b21\u5c11\u6837\u672c\u573a\u666f\u6548\u679c\u663e\u8457\u3002", "motivation": "\u5728\u5c11\u6837\u672c\u8d1d\u53f6\u65af\u4f18\u5316\u4e2d\uff0c\u521d\u59cb\u8bbe\u8ba1\u5bf9\u4ee3\u7406\u6a21\u578b\u8d28\u91cf\u4e0e\u8d85\u53c2\u6570\u5b66\u4e60\u81f3\u5173\u91cd\u8981\uff0c\u800c\u5e38\u7528\u7684\u7a7a\u95f4\u586b\u5145\u968f\u673a\u8bbe\u8ba1\u5ffd\u89c6\u4e86\u964d\u4f4e\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u53ca\u4fc3\u8fdb\u8d85\u53c2\u6570\u5b66\u4e60\u7684\u9700\u6c42\uff0c\u53ef\u80fd\u5bfc\u81f4\u540e\u7eed\u4f18\u5316\u6027\u80fd\u53d7\u635f\u3002", "method": "\u57fa\u4e8e\u4fe1\u606f\u7406\u8bba\u6784\u5efa\u7684\u91c7\u96c6\u51fd\u6570\uff0c\u517c\u987e\u51cf\u5c11\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u4e0e\u83b7\u53d6\u5173\u4e8eGP\u8d85\u53c2\u6570\u7684\u4fe1\u606f\uff1b\u5bf9\u9ad8\u65af\u8fc7\u7a0b\u63a8\u5bfc\u51fa\u95ed\u5f0f\u91c7\u96c6\u51fd\u6570\u8868\u8fbe\uff0c\u5e76\u5728\u4e3b\u52a8\u5b66\u4e60\u548c\u5c11\u6837\u672c\u8d1d\u53f6\u65af\u4f18\u5316\u4efb\u52a1\u4e2d\u8fdb\u884c\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "\u5b9e\u9a8c\u663e\u793aHIPE\u5728\u9884\u6d4b\u8bef\u5dee\u3001\u8d85\u53c2\u6570\u8bc6\u522b\u7387\u548c\u4f18\u5316\u76ee\u6807\u503c\u4e0a\u5747\u4f18\u4e8e\uff08\u62df\uff09\u968f\u673a\u521d\u59cb\u7b56\u7565\uff0c\u5c24\u5176\u5728\u5927\u6279\u91cf\u3001\u5c11\u8f6e\u6b21\u8bc4\u4f30\u60c5\u5883\u4e0b\u63d0\u5347\u660e\u663e\u3002", "conclusion": "HIPE\u80fd\u5728\u5c11\u6837\u672c\u3001\u5927\u6279\u91cf\u8bbe\u7f6e\u4e0b\u63d0\u9ad8\u9884\u6d4b\u7cbe\u5ea6\u3001\u8d85\u53c2\u6570\u8bc6\u522b\u53ca\u968f\u540e\u7684\u4f18\u5316\u8868\u73b0\uff0c\u4f18\u4e8e\u6807\u51c6\uff08\u62df\uff09\u968f\u673a\u521d\u59cb\u5316\u7b56\u7565\u3002"}}
{"id": "2510.24339", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24339", "abs": "https://arxiv.org/abs/2510.24339", "authors": ["Yunxuan Jiang", "Silan Hu", "Xiaoning Wang", "Yuanyuan Zhang", "Xiangyu Chang"], "title": "VDSAgents: A PCS-Guided Multi-Agent System for Veridical Data Science Automation", "comment": "29 pages, 6 figures. Yunxuan Jiang and Silan Hu contributed equally.\n  Code available at https://github.com/fengzer/VDSAgents", "summary": "Large language models (LLMs) become increasingly integrated into data science\nworkflows for automated system design. However, these LLM-driven data science\nsystems rely solely on the internal reasoning of LLMs, lacking guidance from\nscientific and theoretical principles. This limits their trustworthiness and\nrobustness, especially when dealing with noisy and complex real-world datasets.\nThis paper provides VDSAgents, a multi-agent system grounded in the\nPredictability-Computability-Stability (PCS) principles proposed in the\nVeridical Data Science (VDS) framework. Guided by PCS principles, the system\nimplements a modular workflow for data cleaning, feature engineering, modeling,\nand evaluation. Each phase is handled by an elegant agent, incorporating\nperturbation analysis, unit testing, and model validation to ensure both\nfunctionality and scientific auditability. We evaluate VDSAgents on nine\ndatasets with diverse characteristics, comparing it with state-of-the-art\nend-to-end data science systems, such as AutoKaggle and DataInterpreter, using\nDeepSeek-V3 and GPT-4o as backends. VDSAgents consistently outperforms the\nresults of AutoKaggle and DataInterpreter, which validates the feasibility of\nembedding PCS principles into LLM-driven data science automation.", "AI": {"tldr": "VDSAgents embeds Predictability-Computability-Stability (PCS) principles into a multi-agent LLM system for data science automation, improving robustness and auditability; outperforms state-of-the-art baselines on nine datasets.", "motivation": "This paper aims to improve trustworthiness and robustness of LLM-driven data science systems by integrating scientific principles (PCS from VDS) into multi-agent automation, addressing weaknesses when handling noisy/complex real-world data.", "method": "Design a modular multi-agent pipeline\u2014agents for data cleaning, feature engineering, modeling, evaluation\u2014each using perturbation analysis, unit tests, and model validation; evaluate against AutoKaggle and DataInterpreter across nine datasets with DeepSeek-V3 and GPT-4o backends.", "result": "Proposed VDSAgents: a PCS-grounded multi-agent system modularizing cleaning, feature engineering, modeling, evaluation; includes perturbation analysis, unit testing, model validation; outperforms AutoKaggle and DataInterpreter on nine diverse datasets using DeepSeek-V3 and GPT-4o backends.", "conclusion": "Embedding PCS principles into LLM-driven automation is feasible and beneficial, yielding better performance and scientific auditability compared to existing end-to-end systems."}}
{"id": "2510.23682", "categories": ["cs.LG", "cs.AI", "cs.LO", "cs.SE", "I.2.11; I.2.6; I.2.8"], "pdf": "https://arxiv.org/pdf/2510.23682", "abs": "https://arxiv.org/abs/2510.23682", "authors": ["Gokturk Aytug Akarlar"], "title": "Beyond Prompt Engineering: Neuro-Symbolic-Causal Architecture for Robust Multi-Objective AI Agents", "comment": "35 pages, 15 figures, 2 tables. Keywords: Large Language Models,\n  Autonomous Agents, Neuro-Symbolic AI, Causal Inference, Formal Verification,\n  Multi-Objective Optimization. Open-source code and interactive demo available", "summary": "Large language models show promise as autonomous decision-making agents, yet\ntheir deployment in high-stakes domains remains fraught with risk. Without\narchitectural safeguards, LLM agents exhibit catastrophic brittleness:\nidentical capabilities produce wildly different outcomes depending solely on\nprompt framing. We present Chimera, a neuro-symbolic-causal architecture that\nintegrates three complementary components - an LLM strategist, a formally\nverified symbolic constraint engine, and a causal inference module for\ncounterfactual reasoning. We benchmark Chimera against baseline architectures\n(LLM-only, LLM with symbolic constraints) across 52-week simulations in a\nrealistic e-commerce environment featuring price elasticity, trust dynamics,\nand seasonal demand. Under organizational biases toward either volume or margin\noptimization, LLM-only agents fail catastrophically (total loss of \\$99K in\nvolume scenarios) or destroy brand trust (-48.6% in margin scenarios). Adding\nsymbolic constraints prevents disasters but achieves only 43-87% of Chimera's\nprofit. Chimera consistently delivers the highest returns (\\$1.52M and \\$1.96M\nrespectively, some cases +\\$2.2M) while improving brand trust (+1.8% and\n+10.8%, some cases +20.86%), demonstrating prompt-agnostic robustness. Our TLA+\nformal verification proves zero constraint violations across all scenarios.\nThese results establish that architectural design not prompt engineering\ndetermines the reliability of autonomous agents in production environments. We\nprovide open-source implementations and interactive demonstrations for\nreproducibility.", "AI": {"tldr": "Chimera combines LLM strategist, verified symbolic constraint engine, and causal counterfactual module to achieve prompt-agnostic, high-return, trust-preserving decisions in e-commerce; verified safe and reproducible", "motivation": "Mitigate catastrophic brittleness of LLM agents due to prompt framing and ensure safe, robust decisions in high-stakes deployment", "method": "Neuro-symbolic-causal architecture with LLM + symbolic constraints + causal module", "result": "Chimera outperforms LLM-only and LLM+constraints across 52-week e-commerce simulations, yielding higher profit and improved brand trust; TLA+ verifies zero constraint violations", "conclusion": "Architectural design (neuro-symbolic-causal) is crucial for reliable autonomous agents; Chimera provides robust, verifiable performance improvements over baselines and is reproducible with open-source code."}}
{"id": "2510.24342", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24342", "abs": "https://arxiv.org/abs/2510.24342", "authors": ["Silin Chen", "Yuzhong Chen", "Zifan Wang", "Junhao Wang", "Zifeng Jia", "Keith M Kendrick", "Tuo Zhang", "Lin Zhao", "Dezhong Yao", "Tianming Liu", "Xi Jiang"], "title": "A Unified Geometric Space Bridging AI Models and the Human Brain", "comment": null, "summary": "For decades, neuroscientists and computer scientists have pursued a shared\nambition: to understand intelligence and build it. Modern artificial neural\nnetworks now rival humans in language, perception, and reasoning, yet it is\nstill largely unknown whether these artificial systems organize information as\nthe brain does. Existing brain-AI alignment studies have shown the striking\ncorrespondence between the two systems, but such comparisons remain bound to\nspecific inputs and tasks, offering no common ground for comparing how AI\nmodels with different kinds of modalities-vision, language, or multimodal-are\nintrinsically organized. Here we introduce a groundbreaking concept of\nBrain-like Space: a unified geometric space in which every AI model can be\nprecisely situated and compared by mapping its intrinsic spatial attention\ntopological organization onto canonical human functional brain networks,\nregardless of input modality, task, or sensory domain. Our extensive analysis\nof 151 Transformer-based models spanning state-of-the-art large vision models,\nlarge language models, and large multimodal models uncovers a continuous\narc-shaped geometry within this space, reflecting a gradual increase of\nbrain-likeness; different models exhibit distinct distribution patterns within\nthis geometry associated with different degrees of brain-likeness, shaped not\nmerely by their modality but by whether the pretraining paradigm emphasizes\nglobal semantic abstraction and whether the positional encoding scheme\nfacilitates deep fusion across different modalities. Moreover, the degree of\nbrain-likeness for a model and its downstream task performance are not\n\"identical twins\". The Brain-like Space provides the first unified framework\nfor situating, quantifying, and comparing intelligence across domains,\nrevealing the deep organizational principles that bridge machines and the\nbrain.", "AI": {"tldr": "\u628a\u4e0d\u540c\u6a21\u6001\u6a21\u578b\u7684\u5185\u90e8\u7a7a\u95f4\u6ce8\u610f\u529b\u7ed3\u6784\u6620\u5c04\u5230\u4eba\u8111\u529f\u80fd\u7f51\u7edc\uff0c\u5f97\u5230\u4e00\u4e2a\u7edf\u4e00\u7684\u201cBrain-like Space\u201d\uff0c\u63ed\u793a\u6a21\u578b\u6309\u201c\u8111\u76f8\u4f3c\u6027\u201d\u6cbf\u5f27\u5f62\u8fde\u7eed\u5206\u5e03\uff0c\u53d7\u9884\u8bad\u7ec3\u76ee\u6807\u4e0e\u4f4d\u7f6e\u7f16\u7801\u5f71\u54cd\uff0c\u4f46\u4e0e\u4efb\u52a1\u6027\u80fd\u975e\u540c\u4e49\u3002", "motivation": "\u5f25\u5408\u8111\u79d1\u5b66\u4e0e\u4eba\u5de5\u667a\u80fd\u4e4b\u95f4\u7684\u6bd4\u8f83\u9e3f\u6c9f\uff0c\u521b\u9020\u4e00\u4e2a\u4e0e\u8f93\u5165\u3001\u4efb\u52a1\u65e0\u5173\u7684\u901a\u7528\u6846\u67b6\uff0c\u6765\u6bd4\u8f83\u4e0d\u540c\u6a21\u6001\u6a21\u578b\u7684\u5185\u90e8\u7ec4\u7ec7\u7ed3\u6784\uff0c\u4ece\u800c\u7406\u89e3AI\u4e0e\u5927\u8111\u7ec4\u7ec7\u4e4b\u95f4\u7684\u5171\u6027\u4e0e\u5dee\u5f02\u3002", "method": "\u57fa\u4e8e151\u4e2aTransformer\u6a21\u578b\uff0c\u8ba1\u7b97\u5e76\u63d0\u53d6\u6a21\u578b\u7684\u7a7a\u95f4\u6ce8\u610f\u529b\u62d3\u6251\u7ec4\u7ec7\uff08\u53ef\u80fd\u4f7f\u7528\u6ce8\u610f\u529b\u77e9\u9635\u7684\u62d3\u6251\u5b66\u6216\u56fe\u5d4c\u5165\u65b9\u6cd5\uff09\uff0c\u5c06\u8fd9\u4e9b\u7ec4\u7ec7\u6620\u5c04\u5230\u6807\u51c6\u5316\u7684\u4eba\u7c7b\u529f\u80fd\u8111\u7f51\u7edc\uff0c\u6784\u5efa\u7edf\u4e00\u51e0\u4f55\u8868\u793a\u5e76\u5206\u6790\u6a21\u578b\u5728\u8be5\u7a7a\u95f4\u4e2d\u7684\u5206\u5e03\u4e0e\u5c5e\u6027\u76f8\u5173\u6027\uff08\u5982\u6a21\u6001\u3001\u9884\u8bad\u7ec3\u8303\u5f0f\u3001\u4f4d\u7f6e\u7f16\u7801\u3001\u4e0b\u6e38\u6027\u80fd\uff09\u3002", "result": "\u63d0\u51fa\u201cBrain-like Space\u201d\u6982\u5ff5\uff0c\u5c06\u4e0d\u540c\u6a21\u6001\u7684Transformer\u6a21\u578b\u901a\u8fc7\u5176\u7a7a\u95f4\u6ce8\u610f\u529b\u7684\u62d3\u6251\u7ec4\u7ec7\u6620\u5c04\u5230\u4eba\u7c7b\u529f\u80fd\u7f51\u7edc\uff0c\u6784\u5efa\u4e00\u4e2a\u7edf\u4e00\u7684\u51e0\u4f55\u7a7a\u95f4\u4ee5\u6bd4\u8f83\u6a21\u578b\u7684\u8111\u76f8\u4f3c\u6027\uff1b\u5728151\u4e2aTransformer\u6a21\u578b\u4e0a\u53d1\u73b0\u5f27\u5f62\u8fde\u7eed\u51e0\u4f55\u5206\u5e03\uff0c\u8111\u76f8\u4f3c\u6027\u968f\u6cbf\u5f27\u589e\u52a0\uff0c\u5e76\u53d7\u9884\u8bad\u7ec3\u8303\u5f0f\uff08\u5f3a\u8c03\u5168\u5c40\u8bed\u4e49\u62bd\u8c61\uff09\u548c\u4f4d\u7f6e\u7f16\u7801\u673a\u5236\u5f71\u54cd\uff1b\u6a21\u578b\u7684\u8111\u76f8\u4f3c\u6027\u4e0e\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd\u5e76\u4e0d\u4e00\u81f4\u3002", "conclusion": "Brain-like Space\u63d0\u4f9b\u4e86\u4e00\u4e2a\u8de8\u6a21\u6001\u3001\u65e0\u4efb\u52a1\u4f9d\u8d56\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u7528\u4ee5\u91cf\u5316\u548c\u6bd4\u8f83AI\u6a21\u578b\u4e0e\u4eba\u8111\u7684\u7ec4\u7ec7\u76f8\u4f3c\u6027\uff0c\u53d1\u73b0\u9884\u8bad\u7ec3\u8303\u5f0f\u4e0e\u4f4d\u7f6e\u7f16\u7801\u662f\u5f71\u54cd\u8111\u76f8\u4f3c\u6027\u7684\u5173\u952e\u56e0\u7d20\uff0c\u4e14\u8111\u76f8\u4f3c\u6027\u4e0e\u5b9e\u9645\u4efb\u52a1\u8868\u73b0\u5e76\u4e0d\u5b8c\u5168\u76f8\u5173\u3002"}}
{"id": "2510.23685", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23685", "abs": "https://arxiv.org/abs/2510.23685", "authors": ["Junwen Ma", "Mingyu Ge", "Yisen Wang", "Yong Zhang", "Weicheng Fu"], "title": "Parallel BiLSTM-Transformer networks for forecasting chaotic dynamics", "comment": "9 pages,7 figures", "summary": "The nonlinear nature of chaotic systems results in extreme sensitivity to\ninitial conditions and highly intricate dynamical behaviors, posing fundamental\nchallenges for accurately predicting their evolution. To overcome the\nlimitation that conventional approaches fail to capture both local features and\nglobal dependencies in chaotic time series simultaneously, this study proposes\na parallel predictive framework integrating Transformer and Bidirectional Long\nShort-Term Memory (BiLSTM) networks. The hybrid model employs a dual-branch\narchitecture, where the Transformer branch mainly captures long-range\ndependencies while the BiLSTM branch focuses on extracting local temporal\nfeatures. The complementary representations from the two branches are fused in\na dedicated feature-fusion layer to enhance predictive accuracy. As\nillustrating examples, the model's performance is systematically evaluated on\ntwo representative tasks in the Lorenz system. The first is autonomous\nevolution prediction, in which the model recursively extrapolates system\ntrajectories from the time-delay embeddings of the state vector to evaluate\nlong-term tracking accuracy and stability. The second is inference of\nunmeasured variable, where the model reconstructs the unobserved states from\nthe time-delay embeddings of partial observations to assess its\nstate-completion capability. The results consistently indicate that the\nproposed hybrid framework outperforms both single-branch architectures across\ntasks, demonstrating its robustness and effectiveness in chaotic system\nprediction.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u5e76\u884c\u6df7\u5408\u6a21\u578b\uff08Transformer + BiLSTM\uff09\uff0cTransformer \u6355\u6349\u957f\u7a0b\u4f9d\u8d56\uff0cBiLSTM \u62bd\u53d6\u5c40\u90e8\u65f6\u5e8f\u7279\u5f81\uff0c\u4e24\u5206\u652f\u7279\u5f81\u5728\u878d\u5408\u5c42\u5408\u5e76\uff0c\u7528\u4e8e Lorenz \u7cfb\u7edf\u7684\u4e24\u9879\u4efb\u52a1\uff1a\u81ea\u4e3b\u6f14\u5316\u9884\u6d4b\u4e0e\u672a\u89c2\u6d4b\u53d8\u91cf\u63a8\u65ad\uff0c\u7ed3\u679c\u4f18\u4e8e\u5355\u4e00\u5206\u652f\u6a21\u578b\u3002", "motivation": "\u6df7\u6c8c\u7cfb\u7edf\u65e2\u6709\u5c40\u90e8\u590d\u6742\u975e\u7ebf\u6027\u53c8\u6709\u5168\u5c40\u957f\u671f\u4f9d\u8d56\uff0c\u5355\u4e00\u6a21\u578b\u96be\u4ee5\u540c\u65f6\u6355\u6349\u4e24\u8005\uff1b\u56e0\u6b64\u63d0\u51fa\u5c06 Transformer \u7684\u957f\u7a0b\u5efa\u6a21\u80fd\u529b\u4e0e BiLSTM \u7684\u5c40\u90e8\u65f6\u5e8f\u80fd\u529b\u5e76\u884c\u878d\u5408\u4ee5\u63d0\u9ad8 chaotic \u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e0e\u72b6\u6001\u91cd\u5efa\u6027\u80fd\u3002", "method": "\u6784\u5efa\u53cc\u5206\u652f\u5e76\u884c\u7f51\u7edc\uff1a\u4e00\u5206\u652f\u4e3a Transformer\uff08\u957f\u7a0b\u4f9d\u8d56\u5efa\u6a21\uff09\uff0c\u53e6\u4e00\u5206\u652f\u4e3a BiLSTM\uff08\u5c40\u90e8\u65f6\u5e8f\u7279\u5f81\u63d0\u53d6\uff09\uff1b\u4e24\u5206\u652f\u8f93\u51fa\u5728\u7279\u5f81\u878d\u5408\u5c42\u5408\u5e76\uff0c\u968f\u540e\u7528\u4e8e\u9012\u5f52\u9884\u6d4b\uff08\u7528\u4e8e\u81ea\u4e3b\u6f14\u5316\uff09\u6216\u7528\u4e8e\u76f4\u63a5\u56de\u5f52\u672a\u89c2\u6d4b\u53d8\u91cf\uff08\u7528\u4e8e\u72b6\u6001\u63a8\u65ad\uff09\uff1b\u8bad\u7ec3\u4f7f\u7528\u5ef6\u8fdf\u5d4c\u5165\u7684\u65f6\u95f4\u5e8f\u5217\u6570\u636e\uff0c\u8bc4\u4f30\u6307\u6807\u5305\u62ec\u957f\u671f\u8ddf\u8e2a\u7cbe\u5ea6\u4e0e\u7a33\u5b9a\u6027\u3001\u91cd\u6784\u8bef\u5dee\u7b49\u3002", "result": "\u5728 Lorenz \u7cfb\u7edf\u7684\u4e24\u9879\u4efb\u52a1\u4e0a\uff0c\u6df7\u5408\u6a21\u578b\u5728\u957f\u671f\u9884\u6d4b\u7cbe\u5ea6\u3001\u7a33\u5b9a\u6027\u548c\u672a\u89c2\u6d4b\u53d8\u91cf\u91cd\u6784\u8bef\u5dee\u65b9\u9762\u5747\u4f18\u4e8e\u5355\u5206\u652f Transformer \u6216 BiLSTM\uff0c\u663e\u793a\u51fa\u66f4\u5f3a\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "\u5e76\u884c Transformer\u2013BiLSTM \u6df7\u5408\u6846\u67b6\u5728 Lorenz \u7cfb\u7edf\u7684\u957f\u671f\u8f68\u8ff9\u9884\u6d4b\u548c\u90e8\u5206\u89c2\u6d4b\u72b6\u6001\u91cd\u5efa\u4efb\u52a1\u4e2d\u5747\u4f18\u4e8e\u5355\u4e00\u6a21\u578b\uff0c\u663e\u793a\u51fa\u66f4\u597d\u7684\u51c6\u786e\u6027\u4e0e\u7a33\u5b9a\u6027\uff0c\u5177\u6709\u8f83\u5f3a\u7684\u9c81\u68d2\u6027\u548c\u6709\u6548\u6027\u3002"}}
{"id": "2510.24359", "categories": ["cs.AI", "cs.SY", "eess.SY", "q-bio.QM", "stat.AP"], "pdf": "https://arxiv.org/pdf/2510.24359", "abs": "https://arxiv.org/abs/2510.24359", "authors": ["Pedram Fard", "Alaleh Azhir", "Neguine Rezaii", "Jiazi Tian", "Hossein Estiri"], "title": "An N-of-1 Artificial Intelligence Ecosystem for Precision Medicine", "comment": "This study has been supported by grants from the National Institutes\n  of Health: The National Institute on Aging R01AG074372 and The National\n  Institute of Allergy and Infectious Diseases R01AI165535", "summary": "Artificial intelligence in medicine is built to serve the average patient. By\nminimizing error across large datasets, most systems deliver strong aggregate\naccuracy yet falter at the margins: patients with rare variants,\nmultimorbidity, or underrepresented demographics. This average patient fallacy\nerodes both equity and trust. We propose a different design: a multi-agent\necosystem for N-of-1 decision support. In this environment, agents clustered by\norgan systems, patient populations, and analytic modalities draw on a shared\nlibrary of models and evidence synthesis tools. Their results converge in a\ncoordination layer that weighs reliability, uncertainty, and data density\nbefore presenting the clinician with a decision-support packet: risk estimates\nbounded by confidence ranges, outlier flags, and linked evidence. Validation\nshifts from population averages to individual reliability, measured by error in\nlow-density regions, calibration in the small, and risk--coverage trade-offs.\nAnticipated challenges include computational demands, automation bias, and\nregulatory fit, addressed through caching strategies, consensus checks, and\nadaptive trial frameworks. By moving from monolithic models to orchestrated\nintelligence, this approach seeks to align medical AI with the first principle\nof medicine: care that is transparent, equitable, and centered on the\nindividual.", "AI": {"tldr": "\u4ece\u5355\u4e00\u5927\u6a21\u578b\u8f6c\u5411\u591a\u4ee3\u7406\u534f\u540c\uff0c\u8bc4\u4f30\u4e2a\u4f53\u53ef\u9760\u6027\uff08\u4f4e\u6570\u636e\u533a\u8bef\u5dee\u3001\u5c0f\u6837\u672c\u6821\u51c6\u3001\u98ce\u9669-\u8986\u76d6\u6743\u8861\uff09\uff0c\u4ee5\u5b9e\u73b0\u66f4\u900f\u660e\u4e0e\u516c\u5e73\u7684\u4e2a\u4f53\u5316\u533b\u7597AI", "motivation": "\u5f53\u524d\u533b\u5b66AI\u9488\u5bf9\u5e73\u5747\u60a3\u8005\u4f18\u5316\uff0c\u5ffd\u89c6\u7f55\u89c1\u53d8\u4f53\u3001\u591a\u91cd\u5171\u75c5\u548c\u5f31\u52bf\u7fa4\u4f53\uff0c\u524a\u5f31\u516c\u5e73\u4e0e\u4fe1\u4efb\uff0c\u6545\u9700\u4ee5N-of-1\u4e3a\u4e2d\u5fc3\u8bbe\u8ba1", "method": "\u6784\u5efa\u6309\u5668\u5b98\u7cfb/\u4eba\u7fa4/\u6a21\u6001\u805a\u7c7b\u7684\u4ee3\u7406\u5e93\uff1b\u5171\u4eab\u6a21\u578b\u4e0e\u8bc1\u636e\u5408\u6210\u5de5\u5177\uff1b\u534f\u8c03\u5c42\u57fa\u4e8e\u53ef\u9760\u6027\u3001\u4e0d\u786e\u5b9a\u6027\u548c\u6570\u636e\u5bc6\u5ea6\u878d\u5408\u7ed3\u679c\uff1b\u8f93\u51fa\u51b3\u7b56\u652f\u6301\u5305\u5e76\u7528\u4e2a\u4f53\u5316\u9a8c\u8bc1\u6307\u6807\u8bc4\u4f30", "result": "\u63d0\u51fa\u4e00\u4e2a\u591a\u4ee3\u7406\u751f\u6001\u7cfb\u7edf\u7528\u4e8eN-of-1\u51b3\u7b56\u652f\u6301\uff0c\u901a\u8fc7\u5668\u5b98\u7cfb\u3001\u60a3\u8005\u7fa4\u4f53\u548c\u5206\u6790\u6a21\u6001\u805a\u7c7b\u7684\u4ee3\u7406\u5171\u4eab\u6a21\u578b\u4e0e\u8bc1\u636e\u5408\u6210\u5de5\u5177\uff0c\u534f\u8c03\u5c42\u6743\u8861\u53ef\u9760\u6027\u3001\u4e0d\u786e\u5b9a\u6027\u4e0e\u6570\u636e\u5bc6\u5ea6\uff0c\u8f93\u51fa\u5305\u542b\u7f6e\u4fe1\u533a\u95f4\u3001\u5f02\u5e38\u6807\u8bb0\u548c\u8bc1\u636e\u94fe\u63a5\u7684\u51b3\u7b56\u5305", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u63d0\u5347\u5bf9\u8fb9\u7f18\u75c5\u4f8b\u7684\u53ef\u9760\u6027\u4e0e\u4fe1\u4efb\uff0c\u4f46\u9762\u4e34\u8ba1\u7b97\u3001\u81ea\u52a8\u5316\u504f\u89c1\u4e0e\u76d1\u7ba1\u6311\u6218\uff0c\u9700\u8981\u7f13\u5b58\u3001\u5171\u8bc6\u68c0\u67e5\u548c\u81ea\u9002\u5e94\u8bd5\u9a8c\u7b49\u7f13\u89e3\u7b56\u7565"}}
{"id": "2510.23693", "categories": ["cs.LG", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2510.23693", "abs": "https://arxiv.org/abs/2510.23693", "authors": ["Joachim Baumann"], "title": "On the Societal Impact of Machine Learning", "comment": "PhD thesis", "summary": "This PhD thesis investigates the societal impact of machine learning (ML). ML\nincreasingly informs consequential decisions and recommendations, significantly\naffecting many aspects of our lives. As these data-driven systems are often\ndeveloped without explicit fairness considerations, they carry the risk of\ndiscriminatory effects. The contributions in this thesis enable more\nappropriate measurement of fairness in ML systems, systematic decomposition of\nML systems to anticipate bias dynamics, and effective interventions that reduce\nalgorithmic discrimination while maintaining system utility. I conclude by\ndiscussing ongoing challenges and future research directions as ML systems,\nincluding generative artificial intelligence, become increasingly integrated\ninto society. This work offers a foundation for ensuring that ML's societal\nimpact aligns with broader social values.", "AI": {"tldr": "\u8be5\u535a\u58eb\u8bba\u6587\u7814\u7a76\u673a\u5668\u5b66\u4e60\uff08ML\uff09\u7684\u793e\u4f1a\u5f71\u54cd\uff0c\u91cd\u70b9\u5728\u516c\u5e73\u6027\u5ea6\u91cf\u3001\u7cfb\u7edf\u5206\u89e3\u4ee5\u9884\u6d4b\u504f\u89c1\u52a8\u6001\uff0c\u53ca\u5728\u4fdd\u6301\u6548\u7528\u7684\u540c\u65f6\u51cf\u8f7b\u7b97\u6cd5\u6b67\u89c6\u7684\u5e72\u9884\u63aa\u65bd\uff0c\u5e76\u8ba8\u8bba\u672a\u6765\u6311\u6218\u4e0e\u65b9\u5411\u3002", "motivation": "\u968f\u7740ML\u53c2\u4e0e\u8d8a\u6765\u8d8a\u591a\u5173\u952e\u51b3\u7b56\uff0c\u4e14\u5e38\u5728\u672a\u8003\u8651\u516c\u5e73\u6027\u7684\u60c5\u51b5\u4e0b\u5f00\u53d1\uff0c\u7cfb\u7edf\u53ef\u80fd\u4ea7\u751f\u6b67\u89c6\u6027\u5f71\u54cd\uff0c\u6545\u9700\u5efa\u7acb\u6d4b\u91cf\u4e0e\u7f13\u89e3\u65b9\u6cd5\u4ee5\u5bf9\u9f50\u793e\u4f1a\u4ef7\u503c\u3002", "method": "\u63d0\u51fa\u65b0\u7684\u516c\u5e73\u6027\u6d4b\u91cf\u65b9\u6cd5\u3001\u7cfb\u7edf\u5316\u5206\u89e3ML\u7cfb\u7edf\u4ee5\u5206\u6790\u504f\u89c1\u4f20\u64ad\u8def\u5f84\uff0c\u5e76\u8bbe\u8ba1\u80fd\u5728\u4e0d\u663e\u8457\u635f\u5bb3\u6027\u80fd\u7684\u524d\u63d0\u4e0b\u51cf\u5c11\u6b67\u89c6\u7684\u5e72\u9884\u7b56\u7565\uff08\u5982\u8c03\u6574\u8bad\u7ec3\u6570\u636e\u3001\u6a21\u578b\u7ea6\u675f\u6216\u540e\u5904\u7406\uff09\u3002", "result": "\u5b9e\u73b0\u4e86\u66f4\u6070\u5f53\u7684\u516c\u5e73\u6027\u8bc4\u4f30\u6846\u67b6\u3001\u4e00\u4e2a\u53ef\u7528\u4e8e\u9884\u6d4b\u504f\u89c1\u52a8\u6001\u7684\u5206\u89e3\u65b9\u6cd5\uff0c\u4ee5\u53ca\u5728\u5b9e\u8bc1\u4e0a\u80fd\u51cf\u8f7b\u7b97\u6cd5\u6b67\u89c6\u4e14\u4fdd\u7559\u7cfb\u7edf\u6548\u7528\u7684\u82e5\u5e72\u5e72\u9884\u65b9\u6848\u3002", "conclusion": "\u8bba\u6587\u8ba4\u4e3a\u8981\u786e\u4fddML\u7684\u793e\u4f1a\u5f71\u54cd\u7b26\u5408\u793e\u4f1a\u4ef7\u503c\uff0c\u9700\u8981\u66f4\u7cbe\u786e\u7684\u516c\u5e73\u5ea6\u91cf\u3001\u7cfb\u7edf\u5316\u5206\u89e3\u4ee5\u7406\u89e3\u504f\u89c1\u6765\u6e90\uff0c\u4ee5\u53ca\u517c\u987e\u6548\u7528\u7684\u6709\u6548\u5e72\u9884\uff1b\u5e76\u6307\u51fa\u5728\u751f\u6210\u5f0fAI\u666e\u53ca\u4e0b\u4ecd\u6709\u82e5\u5e72\u6311\u6218\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2510.24383", "categories": ["cs.AI", "cs.CY", "cs.MA", "I.2.11; I.2.1; I.2.4; K.4.1; K.4.3"], "pdf": "https://arxiv.org/pdf/2510.24383", "abs": "https://arxiv.org/abs/2510.24383", "authors": ["Juraj Mavra\u010di\u0107"], "title": "Policy Cards: Machine-Readable Runtime Governance for Autonomous AI Agents", "comment": "First published on 19/10/2025. Canonical archived record and DOI:\n  10.5281/zenodo.17391796", "summary": "Policy Cards are introduced as a machine-readable, deployment-layer standard\nfor expressing operational, regulatory, and ethical constraints for AI agents.\nThe Policy Card sits with the agent and enables it to follow required\nconstraints at runtime. It tells the agent what it must and must not do. As\nsuch, it becomes an integral part of the deployed agent. Policy Cards extend\nexisting transparency artifacts such as Model, Data, and System Cards by\ndefining a normative layer that encodes allow/deny rules, obligations,\nevidentiary requirements, and crosswalk mappings to assurance frameworks\nincluding NIST AI RMF, ISO/IEC 42001, and the EU AI Act. Each Policy Card can\nbe validated automatically, version-controlled, and linked to runtime\nenforcement or continuous-audit pipelines. The framework enables verifiable\ncompliance for autonomous agents, forming a foundation for distributed\nassurance in multi-agent ecosystems. Policy Cards provide a practical mechanism\nfor integrating high-level governance with hands-on engineering practice and\nenabling accountable autonomy at scale.", "AI": {"tldr": "Policy Cards are machine-readable, deployment-layer artifacts that encode normative constraints for AI agents, enabling runtime enforcement, automated validation, and links to assurance frameworks to achieve accountable autonomy.", "motivation": "Enable runtime enforcement of constraints and verifiable compliance for deployed AI agents by providing a standardized, machine-readable artifact encoding operational, regulatory, and ethical rules.", "method": "Define a standardized Policy Card format that includes rules (allow/deny), obligations, evidentiary requirements, and crosswalks to frameworks; implement validation, version control, and runtime enforcement/continuous-audit integrations; apply in multi-agent ecosystems for distributed assurance.", "result": "Defines Policy Cards as a deployment-layer standard that encodes allow/deny rules, obligations, evidence requirements, and mappings to assurance frameworks; supports validation, version control, runtime enforcement, continuous audit, and distributed assurance for multi-agent ecosystems.", "conclusion": "Policy Cards bridge governance and engineering by providing verifiable, version-controlled constraints that support runtime enforcement and distributed assurance, facilitating compliance at scale for autonomous agents."}}
{"id": "2510.23727", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.23727", "abs": "https://arxiv.org/abs/2510.23727", "authors": ["Anisha Saha", "Varsha Suresh", "Timothy Hospedales", "Vera Demberg"], "title": "MUStReason: A Benchmark for Diagnosing Pragmatic Reasoning in Video-LMs for Multimodal Sarcasm Detection", "comment": null, "summary": "Sarcasm is a specific type of irony which involves discerning what is said\nfrom what is meant. Detecting sarcasm depends not only on the literal content\nof an utterance but also on non-verbal cues such as speaker's tonality, facial\nexpressions and conversational context. However, current multimodal models\nstruggle with complex tasks like sarcasm detection, which require identifying\nrelevant cues across modalities and pragmatically reasoning over them to infer\nthe speaker's intention. To explore these limitations in VideoLMs, we introduce\nMUStReason, a diagnostic benchmark enriched with annotations of\nmodality-specific relevant cues and underlying reasoning steps to identify\nsarcastic intent. In addition to benchmarking sarcasm classification\nperformance in VideoLMs, using MUStReason we quantitatively and qualitatively\nevaluate the generated reasoning by disentangling the problem into perception\nand reasoning, we propose PragCoT, a framework that steers VideoLMs to focus on\nimplied intentions over literal meaning, a property core to detecting sarcasm.", "AI": {"tldr": "MUStReason benchmark and PragCoT method help VideoLMs better detect sarcasm by focusing on implied intentions using annotated cues and disentangled perception/reasoning evaluation.", "motivation": "Study limitations of VideoLMs in sarcasm detection and provide diagnostic benchmark and method.", "method": "Created diagnostic benchmark MUStReason with annotations, evaluated VideoLMs on perception vs reasoning, and proposed PragCoT to steer models toward pragmatic reasoning.", "result": "Introduced MUStReason dataset with modality-specific cue annotations and PragCoT framework to improve reasoning and sarcasm detection.", "conclusion": "MUStReason reveals VideoLMs struggle with sarcasm; PragCoT improves focus on intended meaning and aids classification and reasoning."}}
{"id": "2510.24390", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24390", "abs": "https://arxiv.org/abs/2510.24390", "authors": ["Xianjun Gao", "Jianchun Liu", "Hongli Xu", "Liusheng Huang"], "title": "Improving LLM Reasoning via Dependency-Aware Query Decomposition and Logic-Parallel Content Expansion", "comment": null, "summary": "The integration of Large Language Models (LLMs) into real-time Web\napplications, such as AI-powered search and conversational agents, presents a\nfundamental Web infrastructure challenge: reconciling the demand for\nhigh-quality, complex reasoning with the stringent low-latency and\nhigh-throughput requirements of interactive services. Current LLM reasoning,\nhindered by computationally inefficient sequential generation and rigid\nreasoning strategies, creates a critical bottleneck for the Web services.\nExisting approaches typically optimize the LLM reasoning for either efficiency\nor quality but struggle to achieve both, and thus fail to meet the dual\nrequirements of modern Web platforms. To overcome these limitations, we propose\nOrion, a novel and efficient reasoning framework that enables dependency-aware\nquery decomposition and logic-parallel content expansion. Concretely, Orion\ndecomposes a single query reasoning process into two synergistic phases: (1)\n\\textit{key point generation}, which distills logically structured key points\nthrough retrieval-augmented few-shot prompting, and (2) \\textit{content\nparallel expansion}, which concurrently elaborates on these points based on a\ndependency graph to ensure logical consistency. Furthermore, Orion introduces a\npipeline scheduling mechanism that exploits the complementary computational\ncharacteristics of the two phases (generation imposes pressure on GPU computing\nand expansion stresses on GPU memory) across multiple queries, enabling\ncross-query parallelism and dramatically improving reasoning performance (\\ie,\nefficiency and quality). Experiments on diverse benchmarks show that Orion not\nonly delivers up to 4.33x higher token generation speed and 3.42x lower answer\nlatency over the baselines but also improves reasoning quality by up to 18.75%\nthrough explicitly modeling inter-point dependencies.", "AI": {"tldr": "Orion\u901a\u8fc7\u2018\u5173\u952e\u70b9\u751f\u6210+\u4f9d\u8d56\u611f\u77e5\u5e76\u884c\u6269\u5c55\u2019\u4e0e\u8de8\u67e5\u8be2\u6d41\u6c34\u7ebf\u8c03\u5ea6\uff0c\u5728\u4fdd\u8bc1\u903b\u8f91\u4e00\u81f4\u6027\u7684\u524d\u63d0\u4e0b\uff0c\u5b9e\u73b0\u66f4\u9ad8\u541e\u5410\u4e0e\u66f4\u4f4e\u5ef6\u8fdf\u7684LLM\u63a8\u7406\u3002", "motivation": "\u89e3\u51b3\u5c06\u9ad8\u8d28\u91cf\u590d\u6742LLM\u63a8\u7406\u90e8\u7f72\u5230\u8981\u6c42\u4f4e\u5ef6\u8fdf\u9ad8\u541e\u5410\u7684\u5b9e\u65f6Web\u670d\u52a1\u65f6\uff0c\u4f20\u7edf\u987a\u5e8f\u751f\u6210\u548c\u56fa\u5b9a\u63a8\u7406\u7b56\u7565\u5728\u6548\u7387\u4e0e\u8d28\u91cf\u4e4b\u95f4\u7684\u96be\u4ee5\u6743\u8861\u95ee\u9898\u3002", "method": "\u4e24\u4e2a\u9636\u6bb5\uff1a1) \u68c0\u7d22\u589e\u5f3a\u7684\u5c11\u6837\u672c\u63d0\u793a\u751f\u6210\u903b\u8f91\u5316\u5173\u952e\u70b9\uff1b2) \u57fa\u4e8e\u5173\u952e\u70b9\u6784\u5efa\u4f9d\u8d56\u56fe\u5e76\u5e76\u884c\u6269\u5c55\u5185\u5bb9\uff1b\u518d\u901a\u8fc7\u7ba1\u7ebf\u8c03\u5ea6\u5728\u591a\u67e5\u8be2\u95f4\u4ea4\u9519\u6267\u884c\u4ee5\u5229\u7528GPU\u8ba1\u7b97\u4e0e\u5185\u5b58\u7279\u6027\u3002", "result": "Orion\u63d0\u51fa\u4e86\u4e00\u79cd\u9002\u7528\u4e8e\u5b9e\u65f6Web\u5e94\u7528\u7684\u9ad8\u6548\u63a8\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u5355\u6b21\u67e5\u8be2\u7684\u63a8\u7406\u62c6\u5206\u4e3a\u201c\u5173\u952e\u70b9\u751f\u6210\u201d\u548c\u201c\u57fa\u4e8e\u4f9d\u8d56\u56fe\u7684\u5e76\u884c\u6269\u5c55\u201d\u4e24\u9636\u6bb5\uff0c\u5229\u7528\u8de8\u67e5\u8be2\u6d41\u6c34\u7ebf\u8c03\u5ea6\u5b9e\u73b0\u8ba1\u7b97\u8d44\u6e90\u4e92\u8865\uff0c\u4ece\u800c\u663e\u8457\u63d0\u5347\u751f\u6210\u901f\u5ea6\u548c\u964d\u4f4e\u5ef6\u8fdf\uff0c\u540c\u65f6\u4fdd\u6301\u6216\u63d0\u5347\u63a8\u7406\u8d28\u91cf\u3002", "conclusion": "Orion\u5728\u591a\u9879\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u4e86\u6700\u9ad84.33x\u7684\u751f\u6210\u901f\u5ea6\u63d0\u5347\u30013.42x\u7684\u5ef6\u8fdf\u964d\u4f4e\u4ee5\u53ca\u6700\u9ad818.75%\u7684\u8d28\u91cf\u63d0\u5347\uff0c\u8bc1\u660e\u4e86\u5206\u89e3\u63a8\u7406\u5e76\u5229\u7528\u8de8\u67e5\u8be2\u5e76\u884c\u6027\u5bf9\u5b9e\u65f6Web\u573a\u666f\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2510.23751", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.23751", "abs": "https://arxiv.org/abs/2510.23751", "authors": ["Ignavier Ng", "Patrick Bl\u00f6baum", "Siddharth Bhandari", "Kun Zhang", "Shiva Kasiviswanathan"], "title": "Debiasing Reward Models by Representation Learning with Guarantees", "comment": null, "summary": "Recent alignment techniques, such as reinforcement learning from human\nfeedback, have been widely adopted to align large language models with human\npreferences by learning and leveraging reward models. In practice, these models\noften exploit spurious correlations, involving, e.g., response length,\ndiscrimination, sycophancy, and conceptual bias, which is a problem that has\nreceived increasing attention. In this work, we propose a principled framework\nthat mitigates these biases in reward models while preserving the underlying\nfactors that reflect intended preferences. We first provide a formulation of\nthe data-generating process, assuming that the observed data (e.g., text) is\ngenerated from both spurious and non-spurious latent variables. We show that,\ninterestingly, these non-spurious latent variables can be theoretically\nidentified from data, regardless of whether a surrogate for the spurious latent\nvariables is available. This further inspires a practical method that uses\nvariational inference to recover these variables and leverages them to train\nreward models. Experiments on synthetic and real-world datasets demonstrate\nthat our method effectively mitigates spurious correlation issues and yields\nmore robust reward models.", "AI": {"tldr": "\u5efa\u7acb\u53ef\u8bc6\u522b\u6027\u7406\u8bba\u5e76\u7528\u53d8\u5206\u63a8\u65ad\u6062\u590d\u975e\u865a\u5047\u6f5c\u53d8\u91cf\uff0c\u4ece\u800c\u8bad\u7ec3\u5bf9\u865a\u5047\u76f8\u5173\u6027\u66f4\u9c81\u68d2\u7684\u5956\u52b1\u6a21\u578b\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u4eba\u7c7b\u53cd\u9988\u7684\u5f3a\u5316\u5b66\u4e60\u7b49\u5bf9\u9f50\u65b9\u6cd5\u4f9d\u8d56\u5956\u52b1\u6a21\u578b\uff0c\u4f46\u8fd9\u4e9b\u5956\u52b1\u6a21\u578b\u6613\u5229\u7528\u8bf8\u5982\u957f\u5ea6\u3001\u6b67\u89c6\u3001\u8c04\u5a9a\u7b49\u865a\u5047\u76f8\u5173\u6027\uff0c\u5bfc\u81f4\u4e0d\u7b26\u5408\u771f\u5b9e\u504f\u597d\u7684\u884c\u4e3a\uff1b\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u80fd\u524a\u5f31\u6216\u6d88\u9664\u8fd9\u4e9b\u865a\u5047\u76f8\u5173\u6027\u800c\u4fdd\u7559\u771f\u6b63\u504f\u597d\u7684\u65b9\u6cd5\u3002", "method": "\u6784\u5efa\u5305\u542b\u865a\u5047\u4e0e\u975e\u865a\u5047\u6f5c\u53d8\u91cf\u7684\u6570\u636e\u751f\u6210\u6a21\u578b\uff0c\u7ed9\u51fa\u975e\u865a\u5047\u6f5c\u53d8\u91cf\u53ef\u8bc6\u522b\u6027\u7684\u7406\u8bba\u8bc1\u660e\uff1b\u8bbe\u8ba1\u57fa\u4e8e\u53d8\u5206\u63a8\u65ad\u7684\u5b9e\u9645\u7b97\u6cd5\u7528\u4e8e\u6062\u590d\u975e\u865a\u5047\u6f5c\u53d8\u91cf\uff0c\u5e76\u5c06\u5176\u4f5c\u4e3a\u8f93\u5165\u8bad\u7ec3\u5956\u52b1\u6a21\u578b\u4ee5\u907f\u514d\u6a21\u578b\u5229\u7528\u865a\u5047\u76f8\u5173\u6027\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7406\u8bba\u548c\u5b9e\u7528\u76f8\u7ed3\u5408\u7684\u65b9\u6cd5\u6765\u7f13\u89e3\u5956\u52b1\u6a21\u578b\u4e2d\u7684\u865a\u5047\u76f8\u5173\u6027\uff0c\u540c\u65f6\u4fdd\u7559\u4f53\u73b0\u671f\u671b\u504f\u597d\u7684\u6f5c\u5728\u56e0\u7d20\u3002\u4f5c\u8005\u6784\u5efa\u4e86\u5305\u542b\u865a\u5047\u4e0e\u975e\u865a\u5047\u6f5c\u53d8\u91cf\u7684\u6570\u636e\u751f\u6210\u8fc7\u7a0b\uff0c\u8bc1\u660e\u4e86\u975e\u865a\u5047\u6f5c\u53d8\u91cf\u5728\u7406\u8bba\u4e0a\u53ef\u88ab\u8bc6\u522b\uff08\u5373\u4f7f\u6ca1\u6709\u865a\u5047\u53d8\u91cf\u7684\u4ee3\u7406\u4e5f\u53ef\uff09\uff0c\u5e76\u57fa\u4e8e\u53d8\u5206\u63a8\u65ad\u63d0\u51fa\u4e86\u53ef\u5b9e\u73b0\u7684\u65b9\u6cd5\u3002\u5b9e\u9a8c\u8bc1\u660e\u5728\u5408\u6210\u4e0e\u771f\u5b9e\u6570\u636e\u4e0a\u5747\u80fd\u51cf\u5c11\u865a\u5047\u5173\u8054\u5e76\u63d0\u5347\u5956\u52b1\u6a21\u578b\u9c81\u68d2\u6027\u3002", "conclusion": "\u4f5c\u8005\u8bc1\u660e\u5e76\u5b9e\u8bc1\u4e86\uff1a\u975e\u865a\u5047\u6f5c\u53d8\u91cf\u53ef\u88ab\u8bc6\u522b\uff0c\u57fa\u4e8e\u6b64\u53ef\u6784\u5efa\u53d8\u5206\u65b9\u6cd5\u6062\u590d\u8fd9\u4e9b\u53d8\u91cf\u5e76\u8bad\u7ec3\u51fa\u5728\u591a\u79cd\u865a\u5047\u76f8\u5173\u6027\uff08\u957f\u5ea6\u3001\u6b67\u89c6\u3001\u8c04\u5a9a\u3001\u6982\u5ff5\u504f\u5dee\uff09\u4e0b\u66f4\u9c81\u68d2\u7684\u5956\u52b1\u6a21\u578b\u3002"}}
{"id": "2510.24397", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24397", "abs": "https://arxiv.org/abs/2510.24397", "authors": ["Jiarui Qin", "Yunjia Xi", "Junjie Huang", "Renting Rui", "Di Yin", "Weiwen Liu", "Yong Yu", "Weinan Zhang", "Xing Sun"], "title": "APTBench: Benchmarking Agentic Potential of Base LLMs During Pre-Training", "comment": "46 pages", "summary": "With the rapid development of LLM-based agents, there is a growing trend to\nincorporate agent-specific data into the pre-training stage of LLMs, aiming to\nbetter align LLMs with real-world autonomous task execution. However, current\npre-training benchmarks primarily focus on isolated and static skills, e.g.,\ncommon knowledge or mathematical/code reasoning, and fail to reflect model's\nagentic capabilities. On the other hand, agent benchmarks are typically\ndesigned for post-trained models, requiring multi-turn task execution abilities\nthat base models struggle to support. Thus, there is a compelling need for a\nbenchmark that can evaluate agentic potentials during pre-training and guide\nthe model training more effectively. To address this gap, we propose APTBench,\na framework that converts real-world agent tasks and successful trajectories\ninto multiple-choice or text completion questions tailored for base models. It\nfocuses on core agentic abilities, e.g., planning and action, and covers key\nagent scenarios, software engineering and deep research. Compared to existing\ngeneral-purpose benchmarks, APTBench offers a more predictive signal of a\nmodel's downstream performance as an agent, while remaining significantly more\nlightweight and cost-effective than full-scale, end-to-end agent evaluations\nafter post-training.", "AI": {"tldr": "APTBench\u63d0\u51fa\u4e00\u4e2a\u7528\u4e8e\u5728\u9884\u8bad\u7ec3\u9636\u6bb5\u8bc4\u4f30\u6a21\u578b\u4ee3\u7406\u80fd\u529b\u7684\u8f7b\u91cf\u7ea7\u57fa\u51c6\uff0c\u901a\u8fc7\u5c06\u771f\u5b9e\u4ee3\u7406\u4efb\u52a1\u548c\u6210\u529f\u8f68\u8ff9\u8f6c\u6362\u4e3a\u9009\u62e9\u9898\u6216\u6587\u672c\u8865\u5168\u9898\uff0c\u805a\u7126\u89c4\u5212\u4e0e\u884c\u52a8\u7b49\u6838\u5fc3\u80fd\u529b\uff0c\u8986\u76d6\u8f6f\u4ef6\u5de5\u7a0b\u548c\u6df1\u5ea6\u7814\u7a76\u573a\u666f\uff0c\u80fd\u66f4\u6709\u6548\u9884\u6d4b\u540e\u7eed\u4f5c\u4e3a\u4ee3\u7406\u7684\u4e0b\u6e38\u8868\u73b0\u4e14\u6210\u672c\u4f4e\u4e8e\u7aef\u5230\u7aef\u8bc4\u4f30\u3002", "motivation": "\u73b0\u6709\u9884\u8bad\u7ec3\u57fa\u51c6\u591a\u5173\u6ce8\u9759\u6001\u5b64\u7acb\u6280\u80fd\uff0c\u65e0\u6cd5\u53cd\u6620\u6a21\u578b\u7684\u4ee3\u7406\u80fd\u529b\uff1b\u800c\u4ee3\u7406\u57fa\u51c6\u901a\u5e38\u9488\u5bf9\u540e\u8bad\u7ec3\u6a21\u578b\u4e14\u6210\u672c\u9ad8\uff0c\u9700\u4e00\u4e2a\u53ef\u5728\u9884\u8bad\u7ec3\u9636\u6bb5\u8bc4\u4f30\u4ee3\u7406\u6f5c\u529b\u7684\u8f7b\u91cf\u7ea7\u57fa\u51c6\u6765\u6307\u5bfc\u8bad\u7ec3\u3002", "method": "\u6536\u96c6\u771f\u5b9e\u4e16\u754c\u7684\u4ee3\u7406\u4efb\u52a1\u4e0e\u6210\u529f\u8f68\u8ff9\uff0c\u8f6c\u6362\u4e3a\u9002\u914d\u57fa\u7840\u6a21\u578b\u7684\u591a\u9879\u9009\u62e9\u6216\u6587\u672c\u8865\u5168\u9898\uff0c\u8bbe\u8ba1\u8986\u76d6\u89c4\u5212\u4e0e\u884c\u52a8\u7b49\u6838\u5fc3\u4ee3\u7406\u80fd\u529b\u7684\u9898\u76ee\uff0c\u5e76\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e0e\u6df1\u5ea6\u7814\u7a76\u573a\u666f\u4e0a\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "APTBench\u76f8\u6bd4\u901a\u7528\u57fa\u51c6\u80fd\u66f4\u597d\u9884\u6d4b\u6a21\u578b\u4f5c\u4e3a\u4ee3\u7406\u7684\u4e0b\u6e38\u6027\u80fd\uff0c\u540c\u65f6\u663e\u8457\u8282\u7701\u8bc4\u4f30\u6210\u672c\uff0c\u76f8\u8f83\u4e8e\u7aef\u5230\u7aef\u4ee3\u7406\u8bc4\u6d4b\u66f4\u8f7b\u91cf\u9ad8\u6548\u3002", "conclusion": "APTBench\u5728\u9884\u8bad\u7ec3\u9636\u6bb5\u63d0\u4f9b\u4e86\u66f4\u5177\u9884\u6d4b\u6027\u7684\u4ee3\u7406\u80fd\u529b\u8bc4\u4f30\u4fe1\u53f7\uff0c\u80fd\u6307\u5bfc\u6a21\u578b\u8bad\u7ec3\uff0c\u4e14\u8f83\u7aef\u5230\u7aef\u4ee3\u7406\u8bc4\u4f30\u66f4\u8f7b\u91cf\u3001\u6210\u672c\u66f4\u4f4e\u3002"}}
{"id": "2510.23756", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23756", "abs": "https://arxiv.org/abs/2510.23756", "authors": ["Nicki Barari", "Edward Kim", "Christopher MacLellan"], "title": "Explaining Robustness to Catastrophic Forgetting Through Incremental Concept Formation", "comment": "18 pages, 5 figures, Advances in Cognitive Systems 2025", "summary": "Catastrophic forgetting remains a central challenge in continual learning,\nwhere models are required to integrate new knowledge over time without losing\nwhat they have previously learned. In prior work, we introduced Cobweb/4V, a\nhierarchical concept formation model that exhibited robustness to catastrophic\nforgetting in visual domains. Motivated by this robustness, we examine three\nhypotheses regarding the factors that contribute to such stability: (1)\nadaptive structural reorganization enhances knowledge retention, (2) sparse and\nselective updates reduce interference, and (3) information-theoretic learning\nbased on sufficiency statistics provides advantages over gradient-based\nbackpropagation. To test these hypotheses, we compare Cobweb/4V with neural\nbaselines, including CobwebNN, a neural implementation of the Cobweb framework\nintroduced in this work. Experiments on datasets of varying complexity (MNIST,\nFashion-MNIST, MedMNIST, and CIFAR-10) show that adaptive restructuring\nenhances learning plasticity, sparse updates help mitigate interference, and\nthe information-theoretic learning process preserves prior knowledge without\nrevisiting past data. Together, these findings provide insight into mechanisms\nthat can mitigate catastrophic forgetting and highlight the potential of\nconcept-based, information-theoretic approaches for building stable and\nadaptive continual learning systems.", "AI": {"tldr": "Cobweb/4V\u901a\u8fc7\u5c42\u7ea7\u91cd\u7ec4\u3001\u7a00\u758f\u66f4\u65b0\u548c\u57fa\u4e8e\u5145\u5206\u7edf\u8ba1\u91cf\u7684\u4fe1\u606f\u8bba\u5b66\u4e60\uff0c\u6709\u6548\u51cf\u8f7b\u89c6\u89c9\u9886\u57df\u7684\u707e\u96be\u6027\u9057\u5fd8\uff0c\u65e0\u9700\u56de\u653e\u65e7\u6570\u636e\u3002", "motivation": "\u63a2\u7a76\u662f\u4ec0\u4e48\u673a\u5236\u4f7fCobweb/4V\u5bf9\u707e\u96be\u6027\u9057\u5fd8\u8868\u73b0\u51fa\u9c81\u68d2\u6027\uff0c\u4ece\u800c\u4e3a\u6784\u5efa\u66f4\u7a33\u5b9a\u7684\u6301\u7eed\u5b66\u4e60\u7cfb\u7edf\u63d0\u4f9b\u8bbe\u8ba1\u6307\u5f15\u3002", "method": "\u63d0\u51faCobwebNN\u4f5c\u4e3aCobweb\u6846\u67b6\u7684\u795e\u7ecf\u5b9e\u73b0\uff0c\u5e76\u5728MNIST\u3001Fashion-MNIST\u3001MedMNIST\u3001CIFAR-10\u4e0a\u4e0e\u795e\u7ecf\u57fa\u7ebf\u6bd4\u8f83\uff1b\u901a\u8fc7\u6d88\u878d\u548c\u5bf9\u6bd4\u5b9e\u9a8c\u68c0\u9a8c\u81ea\u9002\u5e94\u91cd\u7ec4\u3001\u7a00\u758f\u66f4\u65b0\u53ca\u4fe1\u606f\u8bba\u5b66\u4e60\u7684\u8d21\u732e\u3002", "result": "Cobweb/4V\u5728\u89c6\u89c9\u8fde\u7eed\u5b66\u4e60\u4efb\u52a1\u4e2d\u663e\u793a\u51fa\u5bf9\u707e\u96be\u6027\u9057\u5fd8\u7684\u9c81\u68d2\u6027\uff0c\u4e3b\u8981\u5f52\u56e0\u4e8e\u5c42\u7ea7\u7ed3\u6784\u7684\u81ea\u9002\u5e94\u91cd\u7ec4\u3001\u7a00\u758f\u4e0e\u9009\u62e9\u6027\u66f4\u65b0\uff0c\u4ee5\u53ca\u57fa\u4e8e\u5145\u5206\u7edf\u8ba1\u91cf\u7684\u4fe1\u606f\u8bba\u5b66\u4e60\u8fc7\u7a0b\u3002\u8fd9\u4e9b\u673a\u5236\u5728\u4e0d\u540c\u590d\u6742\u5ea6\u7684\u6570\u636e\u96c6\uff08MNIST\u3001Fashion-MNIST\u3001MedMNIST\u3001CIFAR-10\uff09\u4e0a\u7684\u5b9e\u9a8c\u652f\u6301\u4e86\u4e09\u4e2a\u5047\u8bbe\uff1a\u81ea\u9002\u5e94\u7ed3\u6784\u63d0\u5347\u53ef\u5851\u6027\uff0c\u7a00\u758f\u66f4\u65b0\u51cf\u8f7b\u5e72\u6270\uff0c\u4fe1\u606f\u8bba\u5b66\u4e60\u5728\u65e0\u9700\u91cd\u8bbf\u65e7\u6570\u636e\u7684\u60c5\u51b5\u4e0b\u80fd\u4fdd\u7559\u5148\u524d\u77e5\u8bc6\u3002", "conclusion": "\u57fa\u4e8e\u6982\u5ff5\u7684\u5c42\u7ea7\u7ed3\u6784\u3001\u81ea\u9002\u5e94\u91cd\u7ec4\u548c\u4fe1\u606f\u8bba\u5b66\u4e60\u6784\u6210\u4e86\u4e00\u6761\u6709\u524d\u666f\u7684\u8def\u5f84\uff0c\u53ef\u5728\u4e0d\u56de\u653e\u65e7\u6570\u636e\u7684\u524d\u63d0\u4e0b\u6784\u5efa\u7a33\u5b9a\u4e14\u9002\u5e94\u6027\u7684\u6301\u7eed\u5b66\u4e60\u7cfb\u7edf\u3002"}}
{"id": "2510.24411", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.HC"], "pdf": "https://arxiv.org/pdf/2510.24411", "abs": "https://arxiv.org/abs/2510.24411", "authors": ["Qiushi Sun", "Mukai Li", "Zhoumianze Liu", "Zhihui Xie", "Fangzhi Xu", "Zhangyue Yin", "Kanzhi Cheng", "Zehao Li", "Zichen Ding", "Qi Liu", "Zhiyong Wu", "Zhuosheng Zhang", "Ben Kao", "Lingpeng Kong"], "title": "OS-Sentinel: Towards Safety-Enhanced Mobile GUI Agents via Hybrid Validation in Realistic Workflows", "comment": "work in progress", "summary": "Computer-using agents powered by Vision-Language Models (VLMs) have\ndemonstrated human-like capabilities in operating digital environments like\nmobile platforms. While these agents hold great promise for advancing digital\nautomation, their potential for unsafe operations, such as system compromise\nand privacy leakage, is raising significant concerns. Detecting these safety\nconcerns across the vast and complex operational space of mobile environments\npresents a formidable challenge that remains critically underexplored. To\nestablish a foundation for mobile agent safety research, we introduce\nMobileRisk-Live, a dynamic sandbox environment accompanied by a safety\ndetection benchmark comprising realistic trajectories with fine-grained\nannotations. Built upon this, we propose OS-Sentinel, a novel hybrid safety\ndetection framework that synergistically combines a Formal Verifier for\ndetecting explicit system-level violations with a VLM-based Contextual Judge\nfor assessing contextual risks and agent actions. Experiments show that\nOS-Sentinel achieves 10%-30% improvements over existing approaches across\nmultiple metrics. Further analysis provides critical insights that foster the\ndevelopment of safer and more reliable autonomous mobile agents.", "AI": {"tldr": "\u6784\u5efa\u79fb\u52a8\u5b89\u5168\u68c0\u6d4b\u57fa\u51c6MobileRisk-Live\u5e76\u63d0\u51fa\u6df7\u5408\u6846\u67b6OS-Sentinel\uff0c\u901a\u8fc7\u5f62\u5f0f\u9a8c\u8bc1\u4e0eVLM\u4e0a\u4e0b\u6587\u8bc4\u4f30\u7ed3\u5408\uff0c\u663e\u8457\u63d0\u5347\u79fb\u52a8\u4ee3\u7406\u7684\u5b89\u5168\u68c0\u6d4b\u80fd\u529b\u3002", "motivation": "\u5206\u6790\u5e76\u63d0\u5347\u79fb\u52a8\u73af\u5883\u4e2d\u7531\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u7684\u667a\u80fd\u4f53\u7684\u5b89\u5168\u68c0\u6d4b\u80fd\u529b\uff0c\u89e3\u51b3\u5176\u53ef\u80fd\u5bfc\u81f4\u7684\u7cfb\u7edf\u59a5\u534f\u4e0e\u9690\u79c1\u6cc4\u9732\u7b49\u4e0d\u5b89\u5168\u64cd\u4f5c\u95ee\u9898\u3002", "method": "\u6784\u5efa\u52a8\u6001\u6c99\u7bb1\u73af\u5883\u5e76\u6536\u96c6\u6ce8\u91ca\u8f68\u8ff9\uff1b\u8bbe\u8ba1\u53cc\u5206\u652f\u67b6\u6784\uff1a\u5f62\u5f0f\u9a8c\u8bc1\u5668\u7528\u4e8e\u663e\u5f0f\u7cfb\u7edf\u7ea7\u8fdd\u89c4\u68c0\u6d4b\uff0cVLM\u4e0a\u4e0b\u6587\u8bc4\u5224\u5668\u7528\u4e8e\u8bc4\u4f30\u60c5\u5883\u98ce\u9669\u4e0e\u4ee3\u7406\u884c\u4e3a\uff1b\u4e24\u8005\u878d\u5408\u4ea7\u751f\u6700\u7ec8\u5224\u5b9a\uff1b\u901a\u8fc7\u5b9e\u9a8c\u6bd4\u8f83\u9a8c\u8bc1\u6548\u679c\u3002", "result": "\u63d0\u51faMobileRisk-Live\u52a8\u6001\u6c99\u7bb1\u4e0e\u5e26\u7ec6\u7c92\u5ea6\u6ce8\u91ca\u7684\u5b89\u5168\u68c0\u6d4b\u57fa\u51c6\uff0c\u5e76\u8bbe\u8ba1\u6df7\u5408\u5b89\u5168\u68c0\u6d4b\u6846\u67b6OS-Sentinel\uff0c\u7ed3\u5408\u5f62\u5f0f\u9a8c\u8bc1\u5668\u4e0eVLM\u4e0a\u4e0b\u6587\u8bc4\u5224\u5668\uff0c\u5728\u591a\u4e2a\u6307\u6807\u4e0a\u6bd4\u73b0\u6709\u65b9\u6cd5\u63d0\u534710%-30%\u3002", "conclusion": "OS-Sentinel\u5728\u79fb\u52a8\u73af\u5883\u5b89\u5168\u68c0\u6d4b\u4e0a\u53d6\u5f97\u660e\u663e\u6539\u8fdb\uff0cMobileRisk-Live\u4e3a\u8be5\u9886\u57df\u63d0\u4f9b\u4e86\u91cd\u8981\u57fa\u51c6\uff0c\u540c\u65f6\u5206\u6790\u63ed\u793a\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u4ee5\u8fdb\u4e00\u6b65\u63d0\u5347\u5b89\u5168\u6027\u4e0e\u53ef\u9760\u6027\u3002"}}
{"id": "2510.23786", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.23786", "abs": "https://arxiv.org/abs/2510.23786", "authors": ["Joohwan Ko", "Aristofanis Rontogiannis", "Yih-En Andrew Ban", "Axel Elaldi", "Nicholas Franklin"], "title": "Relaxed Sequence Sampling for Diverse Protein Design", "comment": null, "summary": "Protein design using structure prediction models such as AlphaFold2 has shown\nremarkable success, but existing approaches like relaxed sequence optimization\n(RSO) rely on single-path gradient descent and ignore sequence-space\nconstraints, limiting diversity and designability. We introduce Relaxed\nSequence Sampling (RSS), a Markov chain Monte Carlo (MCMC) framework that\nintegrates structural and evolutionary information for protein design. RSS\noperates in continuous logit space, combining gradient-guided exploration with\nprotein language model-informed jumps. Its energy function couples\nAlphaFold2-derived structural objectives with ESM2-derived sequence priors,\nbalancing accuracy and biological plausibility. In an in silico protein binder\ndesign task, RSS produces 5$\\times$ more designable structures and 2-3$\\times$\ngreater structural diversity than RSO baselines, at equal computational cost.\nThese results highlight RSS as a principled approach for efficiently exploring\nthe protein design landscape.", "AI": {"tldr": "RSS\u662f\u4e00\u79cd\u5728\u8fde\u7eedlogit\u7a7a\u95f4\u4e0a\u7684MCMC\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u7ed3\u6784\u9884\u6d4b\uff08AlphaFold2\uff09\u548c\u5e8f\u5217\u5148\u9a8c\uff08ESM2\uff09\u8026\u5408\uff0c\u663e\u8457\u63d0\u5347\u86cb\u767d\u8bbe\u8ba1\u7684\u53ef\u8bbe\u8ba1\u6027\u4e0e\u591a\u6837\u6027\uff0c\u4f18\u4e8e\u4f20\u7edf\u7684RSO\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u7ed3\u6784\u9884\u6d4b\u7684\u86cb\u767d\u8d28\u8bbe\u8ba1\u65b9\u6cd5\uff08\u5982AlphaFold2\uff09\u5728\u6548\u679c\u4e0a\u6709\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5982\u653e\u677e\u5e8f\u5217\u4f18\u5316\uff08RSO\uff09\u4f9d\u8d56\u5355\u8def\u5f84\u68af\u5ea6\u4e0b\u964d\u4e14\u5ffd\u89c6\u5e8f\u5217\u7a7a\u95f4\u7ea6\u675f\uff0c\u5bfc\u81f4\u8bbe\u8ba1\u591a\u6837\u6027\u548c\u53ef\u8bbe\u8ba1\u6027\u53d7\u9650\u3002\u4f5c\u8005\u63d0\u51fa\u4e00\u79cd\u65b0\u7684MCMC\u6846\u67b6\uff0c\u7ed3\u5408\u7ed3\u6784\u4e0e\u8fdb\u5316\u4fe1\u606f\u4ee5\u6539\u8fdb\u8bbe\u8ba1\u63a2\u7d22\u3002", "method": "\u5728\u8fde\u7eedlogit\u7a7a\u95f4\u6784\u5efa\u9a6c\u5c14\u53ef\u592b\u94fe\uff1a\u7ed3\u5408\u57fa\u4e8e\u68af\u5ea6\u7684\u5c40\u90e8\u79fb\u52a8\uff08\u5229\u7528AlphaFold2\u7ed3\u6784\u76ee\u6807\u7684\u68af\u5ea6\uff09\u548c\u57fa\u4e8e\u86cb\u767d\u8bed\u8a00\u6a21\u578b\u7684\u5168\u5c40\u8df3\u8dc3\uff08\u7528ESM2\u4f30\u8ba1\u7684\u5e8f\u5217\u5148\u9a8c\uff09\uff0c\u5e76\u7528\u4e00\u4e2a\u8026\u5408\u7684\u80fd\u91cf\u51fd\u6570\u5e73\u8861\u7ed3\u6784\u76f8\u7b26\u6027\u4e0e\u5e8f\u5217\u5408\u7406\u6027\uff0c\u4ece\u800c\u6267\u884c\u91c7\u6837\u751f\u6210\u591a\u6837\u5316\u4e14\u53ef\u8bbe\u8ba1\u7684\u5e8f\u5217\u3002", "result": "\u63d0\u51fa\u4e86Relaxed Sequence Sampling\uff08RSS\uff09\uff0c\u5728\u8fde\u7eedlogit\u7a7a\u95f4\u4e2d\u8fd0\u884c\uff0c\u7ed3\u5408\u68af\u5ea6\u5f15\u5bfc\u7684\u5c40\u90e8\u63a2\u7d22\u4e0e\u86cb\u767d\u8bed\u8a00\u6a21\u578b\uff08\u5982ESM2\uff09\u9a71\u52a8\u7684\u8df3\u8dc3\uff0c\u80fd\u91cf\u51fd\u6570\u5c06AlphaFold2\u6d3e\u751f\u7684\u7ed3\u6784\u76ee\u6807\u4e0eESM2\u7684\u5e8f\u5217\u5148\u9a8c\u8026\u5408\u3002\u5728\u4f53\u5916\u7684\u86cb\u767d\u7ed3\u5408\u5b50\u8bbe\u8ba1\u4efb\u52a1\u4e2d\uff0cRSS\u5728\u76f8\u540c\u8ba1\u7b97\u6210\u672c\u4e0b\u6bd4RSO\u57fa\u7ebf\u4ea7\u751f5\u500d\u66f4\u591a\u53ef\u8bbe\u8ba1\u7ed3\u6784\u548c2-3\u500d\u66f4\u5927\u7684\u7ed3\u6784\u591a\u6837\u6027\u3002", "conclusion": "RSS\u4e3a\u86cb\u767d\u8d28\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u539f\u5219\u7684\u3001\u8ba1\u7b97\u9ad8\u6548\u7684\u63a2\u7d22\u624b\u6bb5\uff0c\u80fd\u5728\u4fdd\u6301\u7ed3\u6784\u51c6\u786e\u6027\u7684\u540c\u65f6\u63d0\u9ad8\u751f\u7269\u5b66\u53ef\u884c\u6027\u548c\u8bbe\u8ba1\u591a\u6837\u6027\uff0c\u6709\u671b\u6539\u8fdb\u57fa\u4e8e\u7ed3\u6784\u7684\u8bbe\u8ba1\u6d41\u7a0b\u3002"}}
{"id": "2510.24435", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24435", "abs": "https://arxiv.org/abs/2510.24435", "authors": ["Benjamin Grando Moreira"], "title": "Human-Level Reasoning: A Comparative Study of Large Language Models on Logical and Abstract Reasoning", "comment": "12 pages", "summary": "Evaluating reasoning ability in Large Language Models (LLMs) is important for\nadvancing artificial intelligence, as it transcends mere linguistic task\nperformance. It involves understanding whether these models truly understand\ninformation, perform inferences, and are able to draw conclusions in a logical\nand valid way. This study compare logical and abstract reasoning skills of\nseveral LLMs - including GPT, Claude, DeepSeek, Gemini, Grok, Llama, Mistral,\nPerplexity, and Sabi\\'a - using a set of eight custom-designed reasoning\nquestions. The LLM results are benchmarked against human performance on the\nsame tasks, revealing significant differences and indicating areas where LLMs\nstruggle with deduction.", "AI": {"tldr": "\u672c\u6587\u6bd4\u8f83\u4e86\u591a\u6b3e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08\u5982GPT\u3001Claude\u7b49\uff09\u5728\u516b\u9053\u81ea\u5236\u903b\u8f91\u4e0e\u62bd\u8c61\u63a8\u7406\u9898\u4e0a\u7684\u8868\u73b0\uff0c\u5e76\u5c06\u5176\u4e0e\u4eba\u7c7b\u8868\u73b0\u8fdb\u884c\u57fa\u51c6\u5bf9\u6bd4\uff0c\u53d1\u73b0\u6a21\u578b\u5728\u6f14\u7ece\u63a8\u7406\u4e0a\u5b58\u5728\u660e\u663e\u5dee\u8ddd\u3002", "motivation": "\u8bc4\u4f30LLM\u7684\u63a8\u7406\u80fd\u529b\u4ee5\u5224\u65ad\u5b83\u4eec\u8d85\u8d8a\u8868\u9762\u8bed\u8a00\u4efb\u52a1\u3001\u5b9e\u73b0\u771f\u6b63\u903b\u8f91\u63a8\u7406\u7684\u7a0b\u5ea6\uff0c\u4ece\u800c\u63a8\u52a8AI\u5728\u66f4\u9ad8\u5c42\u6b21\u7684\u8ba4\u77e5\u4efb\u52a1\u53d1\u5c55\u3002", "method": "\u8bbe\u8ba1\u516b\u9053\u81ea\u5236\u9898\u76ee\u8986\u76d6\u903b\u8f91\u4e0e\u62bd\u8c61\u63a8\u7406\uff0c\u5411\u591a\u6b3eLLM\u63d0\u4ea4\u95ee\u9898\u5e76\u8bb0\u5f55\u7b54\u6848\uff0c\u540c\u65f6\u6536\u96c6\u4eba\u7c7b\u53d7\u8bd5\u8005\u5728\u76f8\u540c\u9898\u76ee\u4e0a\u7684\u8868\u73b0\uff0c\u6bd4\u8f83\u6b63\u786e\u7387\u548c\u9519\u8bef\u7c7b\u578b\u4ee5\u8bc4\u4f30\u5dee\u5f02\u3002", "result": "\u5b9e\u9a8c\u663e\u793aLLMs\u5728\u4e00\u4e9b\u9898\u76ee\u4e0a\u63a5\u8fd1\u6216\u8d85\u8fc7\u4eba\u7c7b\uff0c\u4f46\u5728\u9700\u8981\u4e25\u683c\u6f14\u7ece\u63a8\u7406\u548c\u591a\u6b65\u903b\u8f91\u63a8\u5bfc\u7684\u9898\u76ee\u4e0a\u8868\u73b0\u8f83\u5dee\uff0c\u5e38\u51fa\u73b0\u9519\u5224\u6216\u7ed9\u51fa\u8c8c\u4f3c\u5408\u7406\u4f46\u4e0d\u4e25\u8c28\u7684\u7b54\u6848\u3002", "conclusion": "LLMs\u5728\u67d0\u4e9b\u63a8\u7406\u4efb\u52a1\u4e0a\u80fd\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u603b\u4f53\u4e0a\u4ecd\u6bd4\u4eba\u7c7b\u5728\u903b\u8f91\u6f14\u7ece\u548c\u590d\u6742\u62bd\u8c61\u63a8\u7406\u65b9\u9762\u5f31\uff0c\u9700\u8fdb\u4e00\u6b65\u6539\u8fdb\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u548c\u8bc4\u4f30\u65b9\u6cd5\u3002"}}
{"id": "2510.23794", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.23794", "abs": "https://arxiv.org/abs/2510.23794", "authors": ["Jun Liu", "Tao Zhou", "Jiarui Li", "Xiaohui Zhong", "Peng Zhang", "Jie Feng", "Lei Chen", "Hao Li"], "title": "Revealing the Potential of Learnable Perturbation Ensemble Forecast Model for Tropical Cyclone Prediction", "comment": "30 pages, 21 figures, 1 table", "summary": "Tropical cyclones (TCs) are highly destructive and inherently uncertain\nweather systems. Ensemble forecasting helps quantify these uncertainties, yet\ntraditional systems are constrained by high computational costs and limited\ncapability to fully represent atmospheric nonlinearity. FuXi-ENS introduces a\nlearnable perturbation scheme for ensemble generation, representing a novel\nAI-based forecasting paradigm. Here, we systematically compare FuXi-ENS with\nECMWF-ENS using all 90 global TCs in 2018, examining their performance in\nTC-related physical variables, track and intensity forecasts, and the\nassociated dynamical and thermodynamical fields. FuXi-ENS demonstrates clear\nadvantages in predicting TC-related physical variables, and achieves more\naccurate track forecasts with reduced ensemble spread, though it still\nunderestimates intensity relative to observations. Further dynamical and\nthermodynamical analyses reveal that FuXi-ENS better captures large-scale\ncirculation, with moisture turbulent energy more tightly concentrated around\nthe TC warm core, whereas ECMWF-ENS exhibits a more dispersed distribution.\nThese findings highlight the potential of learnable perturbations to improve TC\nforecasting skill and provide valuable insights for advancing AI-based ensemble\nprediction of extreme weather events that have significant societal impacts.", "AI": {"tldr": "\u4f7f\u7528\u53ef\u5b66\u4e60\u6270\u52a8\u751f\u6210\u96c6\u5408\u7684FuXi-ENS\u6bd4ECMWF-ENS\u5728\u591a\u6570TC\u9884\u62a5\u6307\u6807\u4e0a\u66f4\u4f18\uff0c\u8def\u5f84\u9884\u6d4b\u66f4\u51c6\u3001\u7269\u7406\u573a\u8868\u73b0\u66f4\u597d\uff0c\u4f46\u4ecd\u4f4e\u4f30\u5f3a\u5ea6\u3002", "motivation": "\u4f20\u7edf\u96c6\u5408\u9884\u62a5\u53d7\u8ba1\u7b97\u6210\u672c\u548c\u5bf9\u5927\u6c14\u975e\u7ebf\u6027\u8868\u793a\u80fd\u529b\u7684\u9650\u5236\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u96c6\u5408\u751f\u6210\u65b9\u6cd5\u4ee5\u91cf\u5316\u4e0d\u786e\u5b9a\u6027\u5e76\u63d0\u9ad8\u6781\u7aef\u5929\u6c14\u9884\u62a5\u7cbe\u5ea6\u3002", "method": "\u8be5\u7814\u7a76\u5c06\u57fa\u4e8e\u5b66\u4e60\u7684\u6270\u52a8\u65b9\u6848\uff08learnable perturbation\uff09\u7528\u4e8e\u96c6\u5408\u751f\u6210\uff0c\u7cfb\u7edf\u6027\u5bf9\u6bd4\u4e86FuXi-ENS\u4e0e\u4f20\u7edf\u6570\u503c\u96c6\u5408\uff08ECMWF-ENS\uff09\u57282018\u5e74\u5168\u740390\u4e2a\u70ed\u5e26\u6c14\u65cb\u7684\u8868\u73b0\uff0c\u5206\u6790\u53d8\u91cf\u5305\u62ec\u8def\u5f84\u3001\u5f3a\u5ea6\u3001\u52a8\u529b\u548c\u70ed\u529b\u573a\u3002", "result": "FuXi-ENS\u5728TC\u76f8\u5173\u7269\u7406\u53d8\u91cf\u548c\u8def\u5f84\u9884\u62a5\u4e0a\u663e\u793a\u660e\u663e\u4f18\u52bf\uff0c\u96c6\u5408\u79bb\u6563\u5ea6\u66f4\u5c0f\u4e14\u8def\u5f84\u66f4\u7cbe\u786e\uff1b\u7136\u800c\u5bf9\u98ce\u901f\u5f3a\u5ea6\u7684\u504f\u4f4e\u4f30\u8ba1\u4ecd\u5b58\u5728\u3002\u52a8\u529b\u70ed\u529b\u5206\u6790\u663e\u793aFuXi-ENS\u5728\u5927\u5c3a\u5ea6\u73af\u6d41\u548c\u6696\u82af\u6e7f\u5ea6\u80fd\u91cf\u96c6\u4e2d\u4e0a\u8868\u73b0\u66f4\u597d\u3002", "conclusion": "FuXi-ENS\u5728\u591a\u4e2aTC\u76f8\u5173\u7269\u7406\u91cf\u548c\u8def\u5f84\u9884\u62a5\u4e0a\u4f18\u4e8eECMWF-ENS\uff0c\u80fd\u66f4\u597d\u6355\u6349\u5927\u5c3a\u5ea6\u73af\u6d41\u4e0e\u6e7f\u5ea6\u80fd\u91cf\u5206\u5e03\uff0c\u4f46\u5bf9\u5f3a\u5ea6\u7684\u4f30\u8ba1\u4ecd\u504f\u5f31\u3002"}}
{"id": "2510.24442", "categories": ["cs.AI", "cs.CL", "cs.CY", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.24442", "abs": "https://arxiv.org/abs/2510.24442", "authors": ["Yiding Wang", "Yuxuan Chen", "Fanxu Meng", "Xifan Chen", "Xiaolei Yang", "Muhan Zhang"], "title": "Law in Silico: Simulating Legal Society with LLM-Based Agents", "comment": null, "summary": "Since real-world legal experiments are often costly or infeasible, simulating\nlegal societies with Artificial Intelligence (AI) systems provides an effective\nalternative for verifying and developing legal theory, as well as supporting\nlegal administration. Large Language Models (LLMs), with their world knowledge\nand role-playing capabilities, are strong candidates to serve as the foundation\nfor legal society simulation. However, the application of LLMs to simulate\nlegal systems remains underexplored. In this work, we introduce Law in Silico,\nan LLM-based agent framework for simulating legal scenarios with individual\ndecision-making and institutional mechanisms of legislation, adjudication, and\nenforcement. Our experiments, which compare simulated crime rates with\nreal-world data, demonstrate that LLM-based agents can largely reproduce\nmacro-level crime trends and provide insights that align with real-world\nobservations. At the same time, micro-level simulations reveal that a\nwell-functioning, transparent, and adaptive legal system offers better\nprotection of the rights of vulnerable individuals.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faLaw in Silico\u6846\u67b6\uff0c\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u6a21\u62df\u5305\u542b\u7acb\u6cd5\u3001\u88c1\u5224\u4e0e\u6267\u6cd5\u7b49\u5236\u5ea6\u673a\u5236\u53ca\u4e2a\u4f53\u51b3\u7b56\u7684\u6cd5\u5f8b\u793e\u4f1a\u3002\u901a\u8fc7\u4e0e\u771f\u5b9e\u6570\u636e\u5bf9\u6bd4\uff0cLLM\u4ee3\u7406\u80fd\u5728\u5b8f\u89c2\u5c42\u9762\u91cd\u73b0\u72af\u7f6a\u7387\u8d8b\u52bf\uff0c\u5e76\u5728\u5fae\u89c2\u5c42\u9762\u663e\u793a\u900f\u660e\u3001\u9002\u5e94\u6027\u5f3a\u7684\u6cd5\u5f8b\u4f53\u7cfb\u66f4\u80fd\u4fdd\u62a4\u5f31\u52bf\u7fa4\u4f53\u6743\u5229\u3002", "motivation": "\u771f\u5b9e\u6cd5\u5f8b\u5b9e\u9a8c\u6210\u672c\u9ad8\u6216\u4e0d\u53ef\u884c\uff0c\u9700\u4ef0\u8d56AI\u7cfb\u7edf\u6a21\u62df\u4ee5\u68c0\u9a8c\u6cd5\u5f8b\u7406\u8bba\u5e76\u652f\u6301\u6cd5\u5f8b\u884c\u653f\uff1bLLMs\u51ed\u501f\u77e5\u8bc6\u4e0e\u89d2\u8272\u626e\u6f14\u80fd\u529b\uff0c\u662f\u7406\u60f3\u57fa\u7840\u6a21\u578b\u4f46\u5728\u6cd5\u5f8b\u7cfb\u7edf\u4eff\u771f\u4e0a\u5c1a\u7f3a\u4e4f\u7814\u7a76\u3002", "method": "\u6784\u5efaLaw in Silico\u6846\u67b6\uff1a\u7528LLM\u4f5c\u4e3a\u4ee3\u7406\u6a21\u62df\u4e2a\u4f53\u51b3\u7b56\uff0c\u6574\u5408\u7acb\u6cd5\u3001\u88c1\u5224\u3001\u6267\u6cd5\u4e09\u5927\u5236\u5ea6\u673a\u5236\uff0c\u8bbe\u8ba1\u5b9e\u9a8c\u5e76\u5c06\u6a21\u62df\u51fa\u7684\u72af\u7f6a\u7387\u4e0e\u771f\u5b9e\u4e16\u754c\u6570\u636e\u5bf9\u6bd4\u5206\u6790\uff1b\u540c\u65f6\u8fdb\u884c\u5fae\u89c2\u60c5\u666f\u5b9e\u9a8c\u4ee5\u8bc4\u4f30\u5236\u5ea6\u5bf9\u5f31\u52bf\u7fa4\u4f53\u6743\u5229\u7684\u5f71\u54cd\u3002", "result": "\u5b9e\u9a8c\u8868\u660eLLM\u4ee3\u7406\u5728\u5b8f\u89c2\u5c42\u9762\u80fd\u5927\u4f53\u518d\u73b0\u72af\u7f6a\u7387\u8d8b\u52bf\uff0c\u4e14\u5fae\u89c2\u5b9e\u9a8c\u663e\u793a\u826f\u597d\u3001\u900f\u660e\u4e14\u6709\u9002\u5e94\u6027\u7684\u6cd5\u5f8b\u5236\u5ea6\u66f4\u80fd\u4fdd\u62a4\u5f31\u52bf\u4e2a\u4f53\u7684\u6743\u5229\u3002", "conclusion": "LLM\u9a71\u52a8\u7684\u6cd5\u5f8b\u793e\u4f1a\u6a21\u62df\u53ef\u6709\u6548\u518d\u73b0\u5b8f\u89c2\u72af\u7f6a\u8d8b\u52bf\u5e76\u63d0\u4f9b\u4e0e\u73b0\u5b9e\u4e00\u81f4\u7684\u6d1e\u89c1\uff0c\u4e14\u663e\u793a\u51fa\u5236\u5ea6\u900f\u660e\u4e0e\u9002\u5e94\u6027\u6709\u52a9\u4e8e\u4fdd\u62a4\u5f31\u52bf\u4e2a\u4f53\uff1b\u56e0\u6b64\uff0cLLMs\u9002\u5408\u7528\u4e8e\u6cd5\u5f8b\u7406\u8bba\u9a8c\u8bc1\u4e0e\u884c\u653f\u652f\u6301\u3002"}}
{"id": "2510.23802", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.23802", "abs": "https://arxiv.org/abs/2510.23802", "authors": ["Nathan Paek", "Yongyi Zang", "Qihui Yang", "Randal Leistikow"], "title": "Learning Interpretable Features in Audio Latent Spaces via Sparse Autoencoders", "comment": "Accepted to NeurIPS 2025 Mechanistic Interpretability Workshop", "summary": "While sparse autoencoders (SAEs) successfully extract interpretable features\nfrom language models, applying them to audio generation faces unique\nchallenges: audio's dense nature requires compression that obscures semantic\nmeaning, and automatic feature characterization remains limited. We propose a\nframework for interpreting audio generative models by mapping their latent\nrepresentations to human-interpretable acoustic concepts. We train SAEs on\naudio autoencoder latents, then learn linear mappings from SAE features to\ndiscretized acoustic properties (pitch, amplitude, and timbre). This enables\nboth controllable manipulation and analysis of the AI music generation process,\nrevealing how acoustic properties emerge during synthesis. We validate our\napproach on continuous (DiffRhythm-VAE) and discrete (EnCodec, WavTokenizer)\naudio latent spaces, and analyze DiffRhythm, a state-of-the-art text-to-music\nmodel, to demonstrate how pitch, timbre, and loudness evolve throughout\ngeneration. While our work is only done on audio modality, our framework can be\nextended to interpretable analysis of visual latent space generation models.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5c06\u7a00\u758f\u81ea\u7f16\u7801\u5668(SAE)\u8bad\u7ec3\u4e8e\u97f3\u9891\u81ea\u52a8\u7f16\u7801\u5668\u7684\u6f5c\u5728\u5411\u91cf\u4e0a\uff0c\u5e76\u901a\u8fc7\u7ebf\u6027\u6620\u5c04\u5c06SAE\u7279\u5f81\u4e0e\u79bb\u6563\u5316\u58f0\u5b66\u5c5e\u6027\uff08\u97f3\u9ad8\u3001\u54cd\u5ea6\u3001\u97f3\u8272\uff09\u5bf9\u9f50\uff0c\u4ee5\u5b9e\u73b0\u53ef\u63a7\u751f\u6210\u4e0e\u89e3\u91ca\u6027\u5206\u6790\u3002\u9a8c\u8bc1\u5bf9\u8c61\u5305\u62ec\u8fde\u7eed\u4e0e\u79bb\u6563\u6f5c\u5728\u7a7a\u95f4\uff08DiffRhythm-VAE\u3001EnCodec\u3001WavTokenizer\uff09\uff0c\u5e76\u5728DiffRhythm\u7684\u6587\u672c\u5230\u97f3\u4e50\u751f\u6210\u6d41\u7a0b\u4e2d\u8ffd\u8e2a\u58f0\u5b66\u5c5e\u6027\u5982\u4f55\u968f\u5408\u6210\u8fc7\u7a0b\u6f14\u5316\u3002", "motivation": "\u97f3\u9891\u6f5c\u5728\u7a7a\u95f4\u901a\u5e38\u5bc6\u96c6\u4e14\u96be\u4ee5\u76f4\u63a5\u89e3\u91ca\uff0c\u4e14\u81ea\u52a8\u5316\u7684\u7279\u5f81\u8868\u5f81\u80fd\u529b\u6709\u9650\u3002\u4e3a\u5b9e\u73b0\u5bf9AI\u97f3\u4e50\u751f\u6210\u8fc7\u7a0b\u7684\u53ef\u63a7\u4e0e\u53ef\u89e3\u91ca\uff0c\u9700\u8981\u628a\u6f5c\u5728\u8868\u793a\u6620\u5c04\u5230\u4eba\u7c7b\u53ef\u7406\u89e3\u7684\u58f0\u5b66\u5c5e\u6027\u3002", "method": "\u5148\u5bf9\u97f3\u9891\u81ea\u52a8\u7f16\u7801\u5668\u7684\u6f5c\u5728\u5411\u91cf\u8bad\u7ec3\u7a00\u758f\u81ea\u7f16\u7801\u5668\uff0c\u5f97\u5230\u7a00\u758f\u53ef\u89e3\u91ca\u7279\u5f81\uff1b\u518d\u5c06\u8fd9\u4e9b\u7279\u5f81\u901a\u8fc7\u7ebf\u6027\u6620\u5c04\uff08\u5206\u7c7b\u6216\u56de\u5f52\uff09\u5bf9\u9f50\u5230\u79bb\u6563\u5316\u7684\u58f0\u5b66\u5c5e\u6027\uff08\u97f3\u9ad8\u3001\u54cd\u5ea6\u3001\u97f3\u8272\uff09\uff1b\u6700\u540e\u901a\u8fc7\u5bf9\u6f5c\u5728\u5411\u91cf\u7684\u64cd\u7eb5\u9a8c\u8bc1\u63a7\u5236\u6548\u679c\uff0c\u5e76\u5728\u751f\u6210\u6a21\u578b\uff08\u5982DiffRhythm\uff09\u4e2d\u8ffd\u8e2a\u5c5e\u6027\u968f\u65f6\u95f4\u53d8\u5316\u3002", "result": "\u5728\u8fde\u7eed\uff08DiffRhythm-VAE\uff09\u4e0e\u79bb\u6563\uff08EnCodec\u3001WavTokenizer\uff09\u6f5c\u5728\u7a7a\u95f4\u4e0a\u5747\u80fd\u5b66\u5230\u4e0e\u97f3\u9ad8\u3001\u54cd\u5ea6\u3001\u97f3\u8272\u76f8\u5173\u7684\u7a00\u758f\u7279\u5f81\uff0c\u652f\u6301\u7ebf\u6027\u6620\u5c04\u5230\u79bb\u6563\u5c5e\u6027\u5e76\u5b9e\u73b0\u53ef\u63a7\u64cd\u7eb5\u3002\u5bf9DiffRhythm\u7684\u5206\u6790\u5c55\u793a\u4e86\u8fd9\u4e9b\u58f0\u5b66\u5c5e\u6027\u5728\u751f\u6210\u8fc7\u7a0b\u4e2d\u7684\u6f14\u5316\u8def\u5f84\u3002", "conclusion": "\u5728\u97f3\u9891\u751f\u6210\u6a21\u578b\u4e2d\uff0cSAE\u53ef\u5c06\u62bd\u8c61\u6f5c\u5728\u8868\u793a\u6620\u5c04\u5230\u4eba\u7c7b\u53ef\u7406\u89e3\u7684\u58f0\u5b66\u6982\u5ff5\uff0c\u4ece\u800c\u5b9e\u73b0\u53ef\u63a7\u64cd\u4f5c\u4e0e\u89e3\u91ca\u6027\u5206\u6790\uff0c\u63ed\u793a\u97f3\u9ad8\u3001\u97f3\u8272\u548c\u54cd\u5ea6\u5982\u4f55\u5728\u5408\u6210\u8fc7\u7a0b\u4e2d\u751f\u6210\u548c\u6f14\u5316\u3002\u8be5\u6846\u67b6\u5728\u4e0d\u540c\u6f5c\u5728\u7a7a\u95f4\u4e0a\u5747\u6709\u6548\uff0c\u4e14\u53ef\u6269\u5c55\u5230\u89c6\u89c9\u7b49\u5176\u5b83\u6a21\u6001\u3002"}}
{"id": "2510.24459", "categories": ["cs.AI", "cs.MA", "cs.SE"], "pdf": "https://arxiv.org/pdf/2510.24459", "abs": "https://arxiv.org/abs/2510.24459", "authors": ["Habtom Kahsay Gidey", "Niklas Huber", "Alexander Lenz", "Alois Knoll"], "title": "Affordance Representation and Recognition for Autonomous Agents", "comment": null, "summary": "The autonomy of software agents is fundamentally dependent on their ability\nto construct an actionable internal world model from the structured data that\ndefines their digital environment, such as the Document Object Model (DOM) of\nweb pages and the semantic descriptions of web services. However, constructing\nthis world model from raw structured data presents two critical challenges: the\nverbosity of raw HTML makes it computationally intractable for direct use by\nfoundation models, while the static nature of hardcoded API integrations\nprevents agents from adapting to evolving services.\n  This paper introduces a pattern language for world modeling from structured\ndata, presenting two complementary architectural patterns. The DOM Transduction\nPattern addresses the challenge of web page complexity by distilling} a\nverbose, raw DOM into a compact, task-relevant representation or world model\noptimized for an agent's reasoning core. Concurrently, the Hypermedia\nAffordances Recognition Pattern enables the agent to dynamically enrich its\nworld model by parsing standardized semantic descriptions to discover and\nintegrate the capabilities of unknown web services at runtime. Together, these\npatterns provide a robust framework for engineering agents that can efficiently\nconstruct and maintain an accurate world model, enabling scalable, adaptive,\nand interoperable automation across the web and its extended resources.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u5957\u9762\u5411\u7ed3\u6784\u5316\u6570\u636e\u7684\u4e16\u754c\u5efa\u6a21\u6a21\u5f0f\uff0c\u901a\u8fc7DOM\u8f6c\u5bfc\u548c\u8d85\u5a92\u4f53\u53ef\u4f9b\u6027\u8bc6\u522b\uff0c\u4f7f\u4ee3\u7406\u80fd\u9ad8\u6548\u6784\u5efa\u3001\u52a8\u6001\u6269\u5c55\u5176\u5185\u90e8\u4e16\u754c\u6a21\u578b\uff0c\u4ece\u800c\u5b9e\u73b0\u53ef\u6269\u5c55\u3001\u81ea\u9002\u5e94\u548c\u4e92\u64cd\u4f5c\u7684Web\u81ea\u52a8\u5316\u3002", "motivation": "\u5efa\u7acb\u8f6f\u4ef6\u4ee3\u7406\u7684\u53ef\u64cd\u4f5c\u5185\u90e8\u4e16\u754c\u6a21\u578b\uff0c\u4ee5\u4fbf\u4ece\u7ed3\u6784\u5316\u6570\u636e\uff08\u5982DOM\u548cWeb\u670d\u52a1\u8bed\u4e49\u63cf\u8ff0\uff09\u4e2d\u63d0\u53d6\u5bf9\u63a8\u7406\u548c\u51b3\u7b56\u6709\u7528\u7684\u8868\u793a\uff0c\u89e3\u51b3\u539f\u59cbHTML\u5197\u957f\u96be\u4ee5\u76f4\u63a5\u8f93\u5165\u5927\u6a21\u578b\u4ee5\u53caAPI\u96c6\u6210\u9759\u6001\u5bfc\u81f4\u9002\u5e94\u6027\u5dee\u7684\u95ee\u9898\u3002", "method": "\u8bbe\u8ba1\u5e76\u63cf\u8ff0\u4e24\u79cd\u6a21\u5f0f\u53ca\u5176\u7ec4\u4ef6\u4e0e\u6570\u636e\u6d41\uff1aDOM\u8f6c\u5bfc\u7528\u4e8e\u63d0\u53d6\u7d27\u51d1\u8868\u793a\uff0c\u8d85\u5a92\u4f53\u53ef\u4f9b\u6027\u8bc6\u522b\u7528\u4e8e\u89e3\u6790\u6807\u51c6\u5316\u8bed\u4e49\u63cf\u8ff0\u52a8\u6001\u6269\u5c55\u80fd\u529b\uff1b\u8bf4\u660e\u6a21\u5f0f\u5982\u4f55\u4e0e\u63a8\u7406\u6838\u5fc3\u548c\u6267\u884c\u5668\u63a5\u53e3\uff0c\u4ee5\u53ca\u5982\u4f55\u4fdd\u6301\u6a21\u578b\u66f4\u65b0\u548c\u53ef\u4e92\u64cd\u4f5c\u6027\u3002", "result": "\u63d0\u51fa\u4e86\u4e24\u79cd\u67b6\u6784\u6a21\u5f0f\uff1aDOM\u8f6c\u5bfc\u6a21\u5f0f\uff08\u5c06\u5197\u957f\u7684DOM\u84b8\u998f\u4e3a\u7d27\u51d1\u3001\u4efb\u52a1\u76f8\u5173\u7684\u4e16\u754c\u6a21\u578b\uff09\u548c\u8d85\u5a92\u4f53\u53ef\u4f9b\u6027\u8bc6\u522b\u6a21\u5f0f\uff08\u5728\u8fd0\u884c\u65f6\u89e3\u6790\u8bed\u4e49\u63cf\u8ff0\uff0c\u53d1\u73b0\u5e76\u96c6\u6210\u672a\u77e5Web\u670d\u52a1\u80fd\u529b\uff09\u3002", "conclusion": "\u7ec4\u5408\u4f7f\u7528\u8fd9\u4e24\u79cd\u6a21\u5f0f\uff0c\u53ef\u4ee5\u5de5\u7a0b\u5316\u5730\u4e3a\u4ee3\u7406\u63d0\u4f9b\u9ad8\u6548\u3001\u53ef\u7ef4\u62a4\u548c\u53ef\u6269\u5c55\u7684\u4e16\u754c\u5efa\u6a21\u80fd\u529b\uff0c\u652f\u6301\u8de8\u7f51\u9875\u548c\u6269\u5c55\u8d44\u6e90\u7684\u81ea\u52a8\u5316\u4efb\u52a1\u3002"}}
{"id": "2510.23804", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.23804", "abs": "https://arxiv.org/abs/2510.23804", "authors": ["Adela DePavia", "Vasileios Charisopoulos", "Rebecca Willett"], "title": "How do simple rotations affect the implicit bias of Adam?", "comment": null, "summary": "Adaptive gradient methods such as Adam and Adagrad are widely used in machine\nlearning, yet their effect on the generalization of learned models -- relative\nto methods like gradient descent -- remains poorly understood. Prior work on\nbinary classification suggests that Adam exhibits a ``richness bias,'' which\ncan help it learn nonlinear decision boundaries closer to the Bayes-optimal\ndecision boundary relative to gradient descent. However, the coordinate-wise\npreconditioning scheme employed by Adam renders the overall method sensitive to\northogonal transformations of feature space. We show that this sensitivity can\nmanifest as a reversal of Adam's competitive advantage: even small rotations of\nthe underlying data distribution can make Adam forfeit its richness bias and\nconverge to a linear decision boundary that is farther from the Bayes-optimal\ndecision boundary than the one learned by gradient descent. To alleviate this\nissue, we show that a recently proposed reparameterization method -- which\napplies an orthogonal transformation to the optimization objective -- endows\nany first-order method with equivariance to data rotations, and we empirically\ndemonstrate its ability to restore Adam's bias towards rich decision\nboundaries.", "AI": {"tldr": "Adam's coordinate-wise scaling induces rotation sensitivity that can eliminate its richness bias; applying an orthogonal reparameterization makes first-order methods rotation-equivariant and restores Adam's nonlinear decision boundaries.", "motivation": "Understand how adaptive methods' coordinate-wise scaling affects generalization compared to gradient descent, and why Adam sometimes has a richness bias but can lose it under rotations.", "method": "The paper analyzes Adam's sensitivity to orthogonal transformations theoretically and empirically; shows small rotations can change learned boundary from rich nonlinear to linear; applies a reparameterization (orthogonal transformation of objective) to make methods rotation-equivariant and tests empirically.", "result": "Finds that Adam can forfeit its richness bias under small rotations and perform worse than GD; reparameterization fixes equivariance and empirically restores Adam's advantage.", "conclusion": "Adam's coordinate-wise preconditioning makes it sensitive to rotations; this can reverse its richness bias causing worse generalization than GD; reparameterization with orthogonal transforms restores rotation equivariance and recovers Adam's richness bias."}}
{"id": "2510.24461", "categories": ["cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2510.24461", "abs": "https://arxiv.org/abs/2510.24461", "authors": ["Korneel Van den Berghe", "Stein Stroobants", "Vijay Janapa Reddi", "G. C. H. E. de Croon"], "title": "Adaptive Surrogate Gradients for Sequential Reinforcement Learning in Spiking Neural Networks", "comment": null, "summary": "Neuromorphic computing systems are set to revolutionize energy-constrained\nrobotics by achieving orders-of-magnitude efficiency gains, while enabling\nnative temporal processing. Spiking Neural Networks (SNNs) represent a\npromising algorithmic approach for these systems, yet their application to\ncomplex control tasks faces two critical challenges: (1) the non-differentiable\nnature of spiking neurons necessitates surrogate gradients with unclear\noptimization properties, and (2) the stateful dynamics of SNNs require training\non sequences, which in reinforcement learning (RL) is hindered by limited\nsequence lengths during early training, preventing the network from bridging\nits warm-up period.\n  We address these challenges by systematically analyzing surrogate gradient\nslope settings, showing that shallower slopes increase gradient magnitude in\ndeeper layers but reduce alignment with true gradients. In supervised learning,\nwe find no clear preference for fixed or scheduled slopes. The effect is much\nmore pronounced in RL settings, where shallower slopes or scheduled slopes lead\nto a 2.1x improvement in both training and final deployed performance. Next, we\npropose a novel training approach that leverages a privileged guiding policy to\nbootstrap the learning process, while still exploiting online environment\ninteractions with the spiking policy. Combining our method with an adaptive\nslope schedule for a real-world drone position control task, we achieve an\naverage return of 400 points, substantially outperforming prior techniques,\nincluding Behavioral Cloning and TD3BC, which achieve at most --200 points\nunder the same conditions. This work advances both the theoretical\nunderstanding of surrogate gradient learning in SNNs and practical training\nmethodologies for neuromorphic controllers demonstrated in real-world robotic\nsystems.", "AI": {"tldr": "They study surrogate gradient slope effects in SNNs, find adaptive/shallow slopes help especially in RL, and introduce a privileged guiding policy bootstrapping method achieving strong drone control results.", "motivation": "enable efficient neuromorphic controllers and bridge SNN training gaps in RL", "method": "systematic analysis", "result": "adaptive slope schedules + privileged guiding policy greatly improve performance; 2.1x improvement and real-world drone results", "conclusion": "Combined adaptive slope schedule and privileged guiding policy enable effective training of SNNs for real-world robotic control, outperforming prior methods."}}
{"id": "2510.23810", "categories": ["cs.LG", "math.AP", "physics.comp-ph", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.23810", "abs": "https://arxiv.org/abs/2510.23810", "authors": ["Sumanta Roy", "Bahador Bahmani", "Ioannis G. Kevrekidis", "Michael D. Shields"], "title": "A Physics-informed Multi-resolution Neural Operator", "comment": "26 pages, 14 figures, 4 tables", "summary": "The predictive accuracy of operator learning frameworks depends on the\nquality and quantity of available training data (input-output function pairs),\noften requiring substantial amounts of high-fidelity data, which can be\nchallenging to obtain in some real-world engineering applications. These\ndatasets may be unevenly discretized from one realization to another, with the\ngrid resolution varying across samples. In this study, we introduce a\nphysics-informed operator learning approach by extending the Resolution\nIndependent Neural Operator (RINO) framework to a fully data-free setup,\naddressing both challenges simultaneously. Here, the arbitrarily (but\nsufficiently finely) discretized input functions are projected onto a latent\nembedding space (i.e., a vector space of finite dimensions), using pre-trained\nbasis functions. The operator associated with the underlying partial\ndifferential equations (PDEs) is then approximated by a simple multi-layer\nperceptron (MLP), which takes as input a latent code along with spatiotemporal\ncoordinates to produce the solution in the physical space. The PDEs are\nenforced via a finite difference solver in the physical space. The validation\nand performance of the proposed method are benchmarked on several numerical\nexamples with multi-resolution data, where input functions are sampled at\nvarying resolutions, including both coarse and fine discretizations.", "AI": {"tldr": "Physics-informed, data-free extension of RINO projects variable-resolution inputs to latent space with pre-trained bases; MLP maps latent code+coords to solutions, PDE enforced by finite differences, validated on multi-resolution benchmarks.", "motivation": "Reduce reliance on scarce high-fidelity paired data and handle unevenly discretized inputs across samples.", "method": "Paper proposes physics-informed, data-free operator learning by extending RINO to handle multi-resolution inputs using pre-trained basis and an MLP approximating PDE operator; finite difference enforces PDEs.", "result": "Method validated on numerical benchmarks with multi-resolution inputs; shows capability to learn operators without training data by enforcing PDE via FD solver and using latent embeddings from pre-trained bases.", "conclusion": "Framework can approximate PDE operators without paired training data and handle varying input discretizations, enabling operator learning in data-scarce settings."}}
{"id": "2510.24528", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24528", "abs": "https://arxiv.org/abs/2510.24528", "authors": ["Zihan Chen", "Song Wang", "Xingbo Fu", "Chengshuai Shi", "Zhenyu Lei", "Cong Shen", "Jundong Li"], "title": "From Cross-Task Examples to In-Task Prompts: A Graph-Based Pseudo-Labeling Framework for In-context Learning", "comment": null, "summary": "The capability of in-context learning (ICL) enables large language models\n(LLMs) to perform novel tasks without parameter updates by conditioning on a\nfew input-output examples. However, collecting high-quality examples for new or\nchallenging tasks can be costly and labor-intensive. In this work, we propose a\ncost-efficient two-stage pipeline that reduces reliance on LLMs for data\nlabeling. Our approach first leverages readily available cross-task examples to\nprompt an LLM and pseudo-label a small set of target task instances. We then\nintroduce a graph-based label propagation method that spreads label information\nto the remaining target examples without additional LLM queries. The resulting\nfully pseudo-labeled dataset is used to construct in-task demonstrations for\nICL. This pipeline combines the flexibility of cross-task supervision with the\nscalability of LLM-free propagation. Experiments across five tasks demonstrate\nthat our method achieves strong performance while lowering labeling costs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4e24\u9636\u6bb5\u7684\u6210\u672c\u9ad8\u6548\u7ba1\u9053\uff1a\u5148\u7528\u8de8\u4efb\u52a1\u793a\u4f8b\u548cLLM\u5bf9\u5c11\u91cf\u76ee\u6807\u5b9e\u4f8b\u8fdb\u884c\u4f2a\u6807\u6ce8\uff0c\u518d\u7528\u56fe\u4f20\u64ad\u5c06\u6807\u7b7e\u6269\u6563\u5230\u5269\u4f59\u5b9e\u4f8b\uff0c\u6700\u7ec8\u7528\u5b8c\u6574\u7684\u4f2a\u6807\u6ce8\u6570\u636e\u6784\u9020ICL\u793a\u4f8b\uff0c\u4ece\u800c\u51cf\u5c11\u5bf9LLM\u6807\u6ce8\u7684\u4f9d\u8d56\u5e76\u4fdd\u6301\u6027\u80fd\u3002", "motivation": "\u9ad8\u8d28\u91cf\u793a\u4f8b\u6536\u96c6\u6210\u672c\u9ad8\u3001\u8017\u65f6\u3002\u5e0c\u671b\u51cf\u5c11\u5bf9LLM\u67e5\u8be2\u548c\u4eba\u5de5\u6807\u6ce8\u7684\u4f9d\u8d56\uff0c\u540c\u65f6\u4ecd\u80fd\u4e3aICL\u63d0\u4f9b\u6709\u6548\u793a\u4f8b\u3002", "method": "\u4e24\u9636\u6bb5\u65b9\u6cd5\uff1a1) \u7528\u8de8\u4efb\u52a1\u793a\u4f8b\u63d0\u793aLLM\uff0c\u5bf9\u5c11\u91cf\u76ee\u6807\u4efb\u52a1\u5b9e\u4f8b\u8fdb\u884c\u4f2a\u6807\u6ce8\uff1b2) \u6784\u5efa\u56fe\u5e76\u91c7\u7528\u57fa\u4e8e\u56fe\u7684\u6807\u7b7e\u4f20\u64ad\uff0c\u5c06\u6807\u7b7e\u6269\u6563\u5230\u672a\u6807\u6ce8\u6837\u672c\uff0c\u4ece\u800c\u5f97\u5230\u5b8c\u6574\u4f2a\u6807\u6ce8\u96c6\uff0c\u968f\u540e\u7528\u5176\u6784\u5efain-task\u793a\u4f8b\u8fdb\u884cICL\u3002", "result": "\u5728\u4e94\u4e2a\u4efb\u52a1\u7684\u5b9e\u9a8c\u8bc1\u660e\u8be5\u7ba1\u9053\u5728\u964d\u4f4e\u6807\u6ce8\u6210\u672c\u7684\u540c\u65f6\u4ecd\u80fd\u53d6\u5f97\u5f3a\u6027\u80fd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u4e94\u4e2a\u4efb\u52a1\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u80fd\u5728\u5927\u5e45\u964d\u4f4e\u6807\u6ce8\u6210\u672c\u7684\u540c\u65f6\u7ef4\u6301\u5f3a\u7ade\u4e89\u529b\u7684ICL\u6027\u80fd\u3002"}}
{"id": "2510.23817", "categories": ["cs.LG", "stat.ME"], "pdf": "https://arxiv.org/pdf/2510.23817", "abs": "https://arxiv.org/abs/2510.23817", "authors": ["Pedro Cortes dos Santos", "Matheus Becali Rocha", "Renato A Krohling"], "title": "Combining SHAP and Causal Analysis for Interpretable Fault Detection in Industrial Processes", "comment": null, "summary": "Industrial processes generate complex data that challenge fault detection\nsystems, often yielding opaque or underwhelming results despite advanced\nmachine learning techniques. This study tackles such difficulties using the\nTennessee Eastman Process, a well-established benchmark known for its intricate\ndynamics, to develop an innovative fault detection framework. Initial attempts\nwith standard models revealed limitations in both performance and\ninterpretability, prompting a shift toward a more tractable approach. By\nemploying SHAP (SHapley Additive exPlanations), we transform the problem into a\nmore manageable and transparent form, pinpointing the most critical process\nfeatures driving fault predictions. This reduction in complexity unlocks the\nability to apply causal analysis through Directed Acyclic Graphs, generated by\nmultiple algorithms, to uncover the underlying mechanisms of fault propagation.\nThe resulting causal structures align strikingly with SHAP findings,\nconsistently highlighting key process elements-like cooling and separation\nsystems-as pivotal to fault development. Together, these methods not only\nenhance detection accuracy but also provide operators with clear, actionable\ninsights into fault origins, a synergy that, to our knowledge, has not been\npreviously explored in this context. This dual approach bridges predictive\npower with causal understanding, offering a robust tool for monitoring complex\nmanufacturing environments and paving the way for smarter, more interpretable\nfault detection in industrial systems.", "AI": {"tldr": "\u4f7f\u7528SHAP\u7b5b\u9009\u5173\u952e\u7279\u5f81\u540e\uff0c\u7ed3\u5408\u591a\u7b97\u6cd5\u751f\u6210\u7684\u6709\u5411\u65e0\u73af\u56fe\u8fdb\u884c\u56e0\u679c\u5206\u6790\uff0c\u5728TEP\u4e0a\u5b9e\u73b0\u4e86\u66f4\u53ef\u89e3\u91ca\u4e14\u51c6\u786e\u7684\u6545\u969c\u68c0\u6d4b\u3002", "motivation": "\u5de5\u4e1a\u8fc7\u7a0b\u6570\u636e\u590d\u6742\u4e14\u6a21\u578b\u7ed3\u679c\u5f80\u5f80\u4e0d\u53ef\u89e3\u91ca\uff0c\u7814\u7a76\u65e8\u5728\u63d0\u9ad8\u68c0\u6d4b\u6027\u80fd\u540c\u65f6\u63d0\u4f9b\u53ef\u64cd\u4f5c\u7684\u89e3\u91ca\uff0c\u5e2e\u52a9\u64cd\u4f5c\u8005\u7406\u89e3\u6545\u969c\u673a\u5236\u3002", "method": "\u5148\u7528\u5e38\u89c4\u6a21\u578b\u8fdb\u884c\u6545\u969c\u68c0\u6d4b\uff0c\u968f\u540e\u7528SHAP\u8bc6\u522b\u91cd\u8981\u7279\u5f81\u5e76\u964d\u7ef4\uff0c\u7136\u540e\u7528\u591a\u79cd\u7ed3\u6784\u5b66\u4e60\u7b97\u6cd5\u751f\u6210DAG\u4ee5\u5f00\u5c55\u56e0\u679c\u5206\u6790\uff0c\u6700\u540e\u6bd4\u8f83DAG\u7ed3\u679c\u4e0eSHAP\u91cd\u8981\u6027\u4ee5\u9a8c\u8bc1\u4e00\u81f4\u6027\u5e76\u89e3\u91ca\u6545\u969c\u8def\u5f84\u3002", "result": "The paper develops a fault detection framework for the Tennessee Eastman Process using SHAP for feature reduction and DAG-based causal analysis, improving interpretability and aligning causal structures with SHAP-identified key features.", "conclusion": "SHAP\u4e0eDAG\u56e0\u679c\u5206\u6790\u7684\u7ed3\u5408\u4e0d\u4ec5\u63d0\u5347\u4e86\u6545\u969c\u68c0\u6d4b\u51c6\u786e\u6027\uff0c\u8fd8\u4e3a\u64cd\u4f5c\u5458\u63d0\u4f9b\u4e86\u5bf9\u6545\u969c\u8d77\u56e0\u7684\u53ef\u89e3\u91ca\u6027\u6d1e\u89c1\uff0c\u5173\u952e\u8fc7\u7a0b\u5355\u5143\uff08\u5982\u51b7\u5374\u4e0e\u5206\u79bb\u7cfb\u7edf\uff09\u5728\u6545\u969c\u4f20\u64ad\u4e2d\u8d77\u4e3b\u8981\u4f5c\u7528\u3002"}}
{"id": "2510.24551", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24551", "abs": "https://arxiv.org/abs/2510.24551", "authors": ["Gang Chen", "Changshuo Liu", "Gene Anne Ooi", "Marcus Tan", "Zhongle Xie", "Jianwei Yin", "James Wei Luen Yip", "Wenqiao Zhang", "Jiaqi Zhu", "Beng Chin Ooi"], "title": "Generative AI for Healthcare: Fundamentals, Challenges, and Perspectives", "comment": null, "summary": "Generative Artificial Intelligence (GenAI) is taking the world by storm. It\npromises transformative opportunities for advancing and disrupting existing\npractices, including healthcare. From large language models (LLMs) for clinical\nnote synthesis and conversational assistance to multimodal systems that\nintegrate medical imaging, electronic health records, and genomic data for\ndecision support, GenAI is transforming the practice of medicine and the\ndelivery of healthcare, such as diagnosis and personalized treatments, with\ngreat potential in reducing the cognitive burden on clinicians, thereby\nimproving overall healthcare delivery. However, GenAI deployment in healthcare\nrequires an in-depth understanding of healthcare tasks and what can and cannot\nbe achieved. In this paper, we propose a data-centric paradigm in the design\nand deployment of GenAI systems for healthcare. Specifically, we reposition the\ndata life cycle by making the medical data ecosystem as the foundational\nsubstrate for generative healthcare systems. This ecosystem is designed to\nsustainably support the integration, representation, and retrieval of diverse\nmedical data and knowledge. With effective and efficient data processing\npipelines, such as semantic vector search and contextual querying, it enables\nGenAI-powered operations for upstream model components and downstream clinical\napplications. Ultimately, it not only supplies foundation models with\nhigh-quality, multimodal data for large-scale pretraining and domain-specific\nfine-tuning, but also serves as a knowledge retrieval backend to support\ntask-specific inference via the agentic layer. The ecosystem enables the\ndeployment of GenAI for high-quality and effective healthcare delivery.", "AI": {"tldr": "\u672c\u6587\u4e3b\u5f20\u4ee5\u533b\u7597\u6570\u636e\u751f\u6001\u4e3a\u6838\u5fc3\uff0c\u6784\u5efa\u53ef\u6301\u7eed\u7684\u6570\u636e\u751f\u547d\u5468\u671f\uff0c\u5229\u7528\u8bed\u4e49\u68c0\u7d22\u4e0e\u4e0a\u4e0b\u6587\u67e5\u8be2\u4e3aGenAI\u6a21\u578b\u63d0\u4f9b\u9ad8\u8d28\u91cf\u3001\u591a\u6a21\u6001\u8bad\u7ec3\u4e0e\u68c0\u7d22\u652f\u6491\uff0c\u4ece\u800c\u5b89\u5168\u6709\u6548\u5730\u90e8\u7f72\u4e8e\u4e34\u5e8a\u5e94\u7528\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3GenAI\u5728\u533b\u7597\u90e8\u7f72\u4e2d\u5bf9\u4efb\u52a1\u7406\u89e3\u3001\u6570\u636e\u591a\u6837\u6027\u4e0e\u68c0\u7d22\u80fd\u529b\u7684\u9700\u6c42\uff0c\u4f5c\u8005\u63d0\u51fa\u4ee5\u6570\u636e\u751f\u6001\u4e3a\u57fa\u5e95\uff0c\u4fdd\u8bc1\u6a21\u578b\u5728\u9ad8\u8d28\u91cf\u3001\u591a\u6a21\u6001\u533b\u7597\u6570\u636e\u652f\u6301\u4e0b\u5b9e\u73b0\u53ef\u9760\u4e0e\u53ef\u89e3\u91ca\u7684\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u3002", "method": "\u63d0\u51fa\u91cd\u6784\u6570\u636e\u751f\u547d\u5468\u671f\u7684\u8bbe\u8ba1\uff0c\u5c06\u6570\u636e\u6536\u96c6\u3001\u8868\u793a\u3001\u96c6\u6210\u3001\u68c0\u7d22\u4f5c\u4e3a\u6838\u5fc3\u6a21\u5757\uff0c\u91c7\u7528\u8bed\u4e49\u5411\u91cf\u8868\u793a\u3001\u4e0a\u4e0b\u6587\u67e5\u8be2\u4e0e\u9ad8\u6548\u6570\u636e\u5904\u7406\u7ba1\u9053\u6765\u652f\u6301\u4e0a\u6e38\u57fa\u7840\u6a21\u578b\u8bad\u7ec3\u4e0e\u4e0b\u6e38\u4e34\u5e8a\u5e94\u7528\u3002", "result": "\u63d0\u51fa\u57fa\u4e8e\u6570\u636e\u4e2d\u5fc3\u8303\u5f0f\u7684\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\uff08GenAI\uff09\u533b\u7597\u7cfb\u7edf\u6846\u67b6\uff0c\u5c06\u533b\u7597\u6570\u636e\u751f\u6001\u4f5c\u4e3a\u57fa\u7840\uff0c\u652f\u6301\u591a\u6a21\u6001\u6570\u636e\u6574\u5408\u3001\u8bed\u4e49\u5411\u91cf\u641c\u7d22\u548c\u60c5\u5883\u67e5\u8be2\uff0c\u4e3a\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\u3001\u9886\u57df\u5fae\u8c03\u548c\u57fa\u4e8e\u68c0\u7d22\u7684\u63a8\u7406\u63d0\u4f9b\u6570\u636e\u4e0e\u77e5\u8bc6\u540e\u7aef\u3002", "conclusion": "\u6784\u5efa\u4ee5\u533b\u7597\u6570\u636e\u751f\u6001\u4e3a\u57fa\u7840\u7684GenAI\u7cfb\u7edf\u80fd\u63d0\u5347\u6a21\u578b\u9884\u8bad\u7ec3\u4e0e\u5fae\u8c03\u7684\u6570\u636e\u8d28\u91cf\uff0c\u5e76\u901a\u8fc7\u68c0\u7d22\u540e\u7aef\u4e0e\u4ee3\u7406\u5c42\u652f\u6301\u4efb\u52a1\u7279\u5b9a\u63a8\u7406\uff0c\u63a8\u52a8GenAI\u5728\u4e34\u5e8a\u8bca\u65ad\u4e0e\u4e2a\u6027\u5316\u6cbb\u7597\u4e2d\u7684\u9ad8\u8d28\u91cf\u90e8\u7f72\u3002"}}
{"id": "2510.23818", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.23818", "abs": "https://arxiv.org/abs/2510.23818", "authors": ["Yilang Zhang", "Xiaodong Yang", "Yiwei Cai", "Georgios B. Giannakis"], "title": "ScaLoRA: Optimally Scaled Low-Rank Adaptation for Efficient High-Rank Fine-Tuning", "comment": null, "summary": "As large language models (LLMs) continue to scale in size, the computational\noverhead has become a major bottleneck for task-specific fine-tuning. While\nlow-rank adaptation (LoRA) effectively curtails this cost by confining the\nweight updates to a low-dimensional subspace, such a restriction can hinder\neffectiveness and slow convergence. This contribution deals with these\nlimitations by accumulating progressively a high-rank weight update from\nconsecutive low-rank increments. Specifically, the per update optimal low-rank\nmatrix is identified to minimize the loss function and closely approximate full\nfine-tuning. To endow efficient and seamless optimization without restarting,\nthis optimal choice is formed by appropriately scaling the columns of the\noriginal low-rank matrix. Rigorous performance guarantees reveal that the\noptimal scaling can be found analytically. Extensive numerical tests with\npopular LLMs scaling up to 12 billion parameters demonstrate a consistent\nperformance gain and fast convergence relative to state-of-the-art LoRA\nvariants on diverse tasks including natural language understanding, commonsense\nreasoning, and mathematical problem solving.", "AI": {"tldr": "\u901a\u8fc7\u5faa\u73af\u7d2f\u79ef\u5e76\u6309\u5217\u7f29\u653e\u4f4e\u79e9\u589e\u91cf\uff0c\u6784\u5efa\u9ad8\u79e9\u6743\u91cd\u66f4\u65b0\uff0c\u4ece\u800c\u5728\u6548\u679c\u4e0e\u6536\u655b\u901f\u5ea6\u4e0a\u4f18\u4e8e\u5e38\u89c4LoRA\u3002", "motivation": "\u89e3\u51b3LoRA\u9650\u5236\uff1a\u4f4e\u79e9\u9650\u5236\u53ef\u80fd\u964d\u4f4e\u6548\u80fd\u5e76\u653e\u6162\u6536\u655b\uff0c\u901a\u8fc7\u6784\u9020\u9ad8\u79e9\u66f4\u65b0\u5c1d\u8bd5\u517c\u987e\u53c2\u6570\u6548\u7387\u4e0e\u8868\u8fbe\u80fd\u529b\u3002", "method": "\u6bcf\u6b21\u8ba1\u7b97\u5bf9\u635f\u5931\u6700\u4f18\u7684\u4f4e\u79e9\u77e9\u9635\u66f4\u65b0\uff0c\u89e3\u6790\u5f97\u5230\u5217\u7f29\u653e\u7cfb\u6570\uff0c\u7528\u4e8e\u8c03\u6574\u5e76\u7d2f\u79ef\u4f4e\u79e9\u589e\u91cf\u5f62\u6210\u9ad8\u79e9\u66f4\u65b0\uff0c\u4fdd\u6301\u4f18\u5316\u6d41\u7a0b\u8fde\u7eed\u65e0\u9700\u91cd\u542f\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4ece\u8fde\u7eed\u4f4e\u79e9\u589e\u91cf\u7d2f\u79ef\u5f62\u6210\u9ad8\u79e9\u6743\u91cd\u66f4\u65b0\u7684\u65b9\u6cd5\uff0c\u4ee5\u5728\u4fdd\u6301LoRA\u9ad8\u6548\u6027\u7684\u540c\u65f6\u63d0\u5347\u6548\u679c\u4e0e\u6536\u655b\u901f\u5ea6\u3002\u901a\u8fc7\u5bf9\u6bcf\u6b21\u66f4\u65b0\u627e\u5230\u6700\u4f18\u4f4e\u79e9\u77e9\u9635\u5e76\u901a\u8fc7\u7f29\u653e\u5217\u6765\u8fd1\u4f3c\u5168\u91cf\u5fae\u8c03\uff0c\u7ed9\u51fa\u89e3\u6790\u7684\u6700\u4f18\u7f29\u653e\u56e0\u5b50\uff0c\u652f\u6301\u65e0\u7f1d\u4f18\u5316\u3002\u5b9e\u9a8c\u8bc1\u660e\u5728\u6700\u591a12B\u53c2\u6570\u7684LLM\u4e0a\u5728\u591a\u4efb\u52a1\u4e0a\u4f18\u4e8e\u73b0\u6709LoRA\u53d8\u4f53\u3002", "conclusion": "\u9002\u5f53\u7f29\u653e\u4f4e\u79e9\u66f4\u65b0\u7684\u5217\u5e76\u7d2f\u79ef\u53ef\u5728\u4e0d\u91cd\u542f\u8bad\u7ec3\u7684\u60c5\u51b5\u4e0b\u8fd1\u4f3c\u5168\u91cf\u5fae\u8c03\uff0c\u5e26\u6765\u4e00\u81f4\u4e14\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u4e0e\u66f4\u5feb\u6536\u655b\u3002"}}
{"id": "2510.24645", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24645", "abs": "https://arxiv.org/abs/2510.24645", "authors": ["Zengzhuang Xu", "Bingguang Hao", "Zechuan Wang", "Yuntao Wen", "Maolin Wang", "Yang Liu", "Long Chen", "Dong Wang", "Yicheng Chen", "Cunyin Peng", "Chenyi Zhuang", "Jinjie Gu", "Leilei Gan", "Xiangyu Zhao", "Shi Gu"], "title": "FunReason-MT Technical Report: Overcoming the Complexity Barrier in Multi-Turn Function Calling", "comment": null, "summary": "Function calling (FC) empowers large language models (LLMs) and autonomous\nagents to interface with external tools, a critical capability for solving\ncomplex, real-world problems. As this ability becomes increasingly central to\nadvanced AI systems, the need for high-quality, multi-turn training data to\ndevelop and refine it cannot be overstated. Existing data synthesis methods,\nsuch as random environment sampling or multi-agent role-playing, are not\npowerful enough to generate high-quality data in real-world environments.\nPractical challenges come in three folds: targeted model training, isolation of\ntool architecture, and multi-turn logical dependency. To address these\nstructural deficiencies, we present FunReason-MT, a novel data synthesis\nframework for real-world multi-turn tool use. FunReason-MT resolves the\ncomplexity barrier in multi-turn FC data by employing 1) Environment-API Graph\nInteractions to gather varied high-quality trajectories, 2) Advanced Tool-Query\nSynthesis to simplify hard query construction, and 3) Guided Iterative Chain\nfor sophisticated CoT generation. Evaluations on Berkeley Function-Calling\nLeaderboard (BFCLv3) demonstrate the power of our framework: a 4B model built\nupon FunReason-MT generated data achieves state-of-the-art performance among\ncomparable-sized models, outperforming most close-source models. Further\nperformance improvements on BFCLv4 confirm that FunReason-MT provides a\nreliable and robust source for agentic learning.", "AI": {"tldr": "\u63d0\u51faFunReason-MT\uff0c\u901a\u8fc7\u73af\u5883-API\u56fe\u4ea4\u4e92\u3001\u5de5\u5177\u67e5\u8be2\u5408\u6210\u3001\u5f15\u5bfc\u8fed\u4ee3\u94fe\u751f\u6210\u591a\u56de\u5408\u9ad8\u8d28\u91cf\u51fd\u6570\u8c03\u7528\u6570\u636e\uff0c\u663e\u8457\u63d0\u53474B\u6a21\u578b\u5728BFCL\u4e0a\u7684\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u5408\u6210\u65b9\u6cd5\u5728\u771f\u5b9e\u73af\u5883\u4e0b\u96be\u4ee5\u4ea7\u51fa\u9ad8\u8d28\u91cf\u3001\u591a\u56de\u5408\u7684\u6570\u636e\uff0c\u53d7\u9650\u4e8e\u76ee\u6807\u5316\u8bad\u7ec3\u3001\u5de5\u5177\u67b6\u6784\u9694\u79bb\u548c\u591a\u56de\u5408\u903b\u8f91\u4f9d\u8d56\u4e09\u5927\u95ee\u9898\uff1b\u9700\u8981\u65b0\u7684\u6846\u67b6\u6765\u89e3\u51b3\u8fd9\u4e9b\u7ed3\u6784\u6027\u7f3a\u9677\u3002", "method": "\u6784\u5efaEnvironment-API Graph\u4ea4\u4e92\u91c7\u96c6\u8f68\u8ff9\uff1bAdvanced Tool-Query Synthesis\u6784\u9020\u9ad8\u8d28\u91cf\u67e5\u8be2\uff1bGuided Iterative Chain\u7528\u4e8e\u590d\u6742\u7684Chain-of-Thought\u591a\u56de\u5408\u751f\u6210\u3002", "result": "FunReason-MT: a framework to synthesize multi-turn function-calling training data for LLMs, focusing on real-world environments.", "conclusion": "FunReason-MT\u80fd\u7a33\u5b9a\u751f\u6210\u9ad8\u8d28\u91cf\u3001\u591a\u56de\u5408\u3001\u5177\u903b\u8f91\u4f9d\u8d56\u7684\u51fd\u6570\u8c03\u7528\u6570\u636e\uff0c\u63a8\u52a8\u5c0f\u6a21\u578b\u5728BFCLv3/v4\u4e0a\u8fbe\u6210\u6216\u8d85\u8d8a\u73b0\u6709\u540c\u89c4\u6a21\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2510.23866", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23866", "abs": "https://arxiv.org/abs/2510.23866", "authors": ["Paul Rosu", "Muchang Bahng", "Erick Jiang", "Rico Zhu", "Vahid Tarokh"], "title": "A PDE-Informed Latent Diffusion Model for 2-m Temperature Downscaling", "comment": null, "summary": "This work presents a physics-conditioned latent diffusion model tailored for\ndynamical downscaling of atmospheric data, with a focus on reconstructing\nhigh-resolution 2-m temperature fields. Building upon a pre-existing diffusion\narchitecture and employing a residual formulation against a reference UNet, we\nintegrate a partial differential equation (PDE) loss term into the model's\ntraining objective. The PDE loss is computed in the full resolution (pixel)\nspace by decoding the latent representation and is designed to enforce physical\nconsistency through a finite-difference approximation of an effective\nadvection-diffusion balance. Empirical observations indicate that conventional\ndiffusion training already yields low PDE residuals, and we investigate how\nfine-tuning with this additional loss further regularizes the model and\nenhances the physical plausibility of the generated fields. The entirety of our\ncodebase is available on Github, for future reference and development.", "AI": {"tldr": "\u8bba\u6587\u5728\u6f5c\u53d8\u91cf\u6269\u6563\u7528\u4e8e\u6c14\u5019\u4e0b\u91c7\u6837\u7684\u6846\u67b6\u4e2d\u52a0\u5165\u50cf\u7d20\u7a7a\u95f4PDE\u635f\u5931\uff08\u57fa\u4e8e\u6709\u9650\u5dee\u5206\u7684\u5e73\u6d41-\u6269\u6563\u9879\uff09\uff0c\u4ee5\u589e\u5f3a\u7269\u7406\u4e00\u81f4\u6027\uff1b\u5b9e\u9a8c\u8bc1\u660e\u5e38\u89c4\u8bad\u7ec3\u5df2\u8868\u73b0\u826f\u597d\uff0cPDE\u5fae\u8c03\u80fd\u5e26\u6765\u989d\u5916\u6b63\u5219\u5316\u548c\u7269\u7406\u6027\u63d0\u5347\uff0c\u4f46\u6539\u8fdb\u6709\u9650\u3002", "motivation": "\u5728\u5927\u6c14\u52a8\u529b\u5b66\u4e0b\u91c7\u6837\u4efb\u52a1\u4e2d\uff0c\u671f\u671b\u751f\u6210\u7684\u9ad8\u5206\u8fa8\u7387\u6e29\u5ea6\u573a\u4e0d\u4ec5\u89c6\u89c9\u4e0a\u903c\u8fd1\u771f\u5b9e\u6570\u636e\uff0c\u8fd8\u9700\u6ee1\u8db3\u7269\u7406\u5b88\u6052\u4e0e\u52a8\u529b\u5b66\u7ea6\u675f\uff0c\u56e0\u6b64\u5728\u751f\u6210\u6a21\u578b\u4e2d\u5f15\u5165\u7269\u7406\u635f\u5931\u4ee5\u63d0\u9ad8\u7269\u7406\u53ef\u63a5\u53d7\u6027\u3002", "method": "\u5728\u73b0\u6709\u7684\u6f5c\u53d8\u91cf\u6269\u6563\u67b6\u6784\u4e0a\uff0c\u4ee5\u5bf9\u53c2\u8003UNet\u7684\u6b8b\u5dee\u5f62\u5f0f\u5de5\u4f5c\uff0c\u8bad\u7ec3\u76ee\u6807\u4e2d\u52a0\u5165\u5728\u89e3\u7801\u540e\u50cf\u7d20\u7a7a\u95f4\u8ba1\u7b97\u7684PDE\u635f\u5931\uff0c\u8be5\u635f\u5931\u901a\u8fc7\u6709\u9650\u5dee\u5206\u8fd1\u4f3c\u6709\u6548\u5e73\u6d41-\u6269\u6563\u5e73\u8861\u9879\u6765\u8861\u91cf\u7269\u7406\u4e00\u81f4\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5e38\u89c4\u6269\u6563\u8bad\u7ec3\u5df2\u7ecf\u4ea7\u751f\u8f83\u4f4e\u7684PDE\u6b8b\u5dee\uff1b\u5728\u6b64\u57fa\u7840\u4e0a\u5fae\u8c03\u5e76\u52a0\u5165PDE\u635f\u5931\u53ef\u4ee5\u8fdb\u4e00\u6b65\u6b63\u5219\u5316\u6a21\u578b\uff0c\u63d0\u9ad8\u751f\u6210\u573a\u7684\u7269\u7406\u5408\u7406\u6027\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u5728\u6269\u6563\u6a21\u578b\u8bad\u7ec3\u4e2d\u52a0\u5165PDE\u635f\u5931\uff0c\u80fd\u8fdb\u4e00\u6b65\u63d0\u5347\u751f\u6210\u6c14\u6e29\u573a\u7684\u7269\u7406\u4e00\u81f4\u6027\uff0c\u4f46\u4f20\u7edf\u6269\u6563\u8bad\u7ec3\u5df2\u80fd\u5f97\u5230\u8f83\u4f4e\u7684PDE\u6b8b\u5dee\uff0c\u56e0\u6b64\u6539\u8fdb\u5e45\u5ea6\u6709\u9650\u3002"}}
{"id": "2510.24650", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24650", "abs": "https://arxiv.org/abs/2510.24650", "authors": ["Nitin Rai", "Daeun", "Choi", "Nathan S. Boyd", "Arnold W. Schumann"], "title": "Advancing site-specific disease and pest management in precision agriculture: From reasoning-driven foundation models to adaptive, feedback-based learning", "comment": "26 pages, 8 figures, and 2 tables", "summary": "Site-specific disease management (SSDM) in crops has advanced rapidly through\nmachine and deep learning (ML and DL) for real-time computer vision. Research\nevolved from handcrafted feature extraction to large-scale automated feature\nlearning. With foundation models (FMs), crop disease datasets are now processed\nin fundamentally new ways. Unlike traditional neural networks, FMs integrate\nvisual and textual data, interpret symptoms in text, reason about\nsymptom-management relationships, and support interactive QA for growers and\neducators. Adaptive and imitation learning in robotics further enables\nfield-based disease management. This review screened approx. 40 articles on FM\napplications for SSDM, focusing on large-language models (LLMs) and\nvision-language models (VLMs), and discussing their role in adaptive learning\n(AL), reinforcement learning (RL), and digital twin frameworks for targeted\nspraying. Key findings: (a) FMs are gaining traction with surging literature in\n2023-24; (b) VLMs outpace LLMs, with a 5-10x increase in publications; (c) RL\nand AL are still nascent for smart spraying; (d) digital twins with RL can\nsimulate targeted spraying virtually; (e) addressing the sim-to-real gap is\ncritical for real-world deployment; (f) human-robot collaboration remains\nlimited, especially in human-in-the-loop approaches where robots detect early\nsymptoms and humans validate uncertain cases; (g) multi-modal FMs with\nreal-time feedback will drive next-gen SSDM. For updates, resources, and\ncontributions, visit, https://github.com/nitin-dominic/AgriPathogenDatabase, to\nsubmit papers, code, or datasets.", "AI": {"tldr": "\u7efc\u8ff0\u8868\u660e\uff0c\u591a\u6a21\u6001\u57fa\u7840\u6a21\u578b\uff08\u5c24\u4ee5VLMs\uff09\u5728\u4f5c\u7269\u90e8\u4f4d\u6027\u75c5\u5bb3\u7ba1\u7406\u4e2d\u6f5c\u529b\u5de8\u5927\uff0c\u4f46\u8981\u5b9e\u73b0\u91ce\u5916\u90e8\u7f72\u9700\u514b\u670dsim-to-real\u5dee\u8ddd\u3001\u52a0\u5f3a\u4eba\u673a\u5728\u73af\u534f\u4f5c\u5e76\u63a8\u52a8RL/AL\u5e94\u7528\u843d\u5730\u3002", "motivation": "\u968f\u7740\u673a\u5668\u5b66\u4e60\u4ece\u624b\u5de5\u7279\u5f81\u5411\u5927\u89c4\u6a21\u81ea\u52a8\u7279\u5f81\u5b66\u4e60\u6f14\u8fdb\uff0c\u5f15\u5165\u80fd\u7efc\u5408\u89c6\u89c9\u4e0e\u6587\u672c\u4fe1\u606f\u7684\u57fa\u7840\u6a21\u578b\u53ef\u671b\u63d0\u5347\u4f5c\u7269\u75c5\u5bb3\u68c0\u6d4b\u3001\u75c7\u72b6\u89e3\u91ca\u53ca\u7ba1\u7406\u51b3\u7b56\u7684\u667a\u80fd\u5316\u4e0e\u4ea4\u4e92\u6027\uff0c\u4ece\u800c\u63a8\u52a8\u7cbe\u51c6\u519c\u836f\u65bd\u7528\u4e0e\u6559\u80b2\u63a8\u5e7f\u3002", "method": "\u901a\u8fc7\u7b5b\u9009\u7ea640\u7bc7\u5173\u4e8e\u57fa\u7840\u6a21\u578b\u5728SSDM\u5e94\u7528\u7684\u8bba\u6587\uff0c\u91cd\u70b9\u5ba1\u89c6\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4e0e\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\uff08VLMs\uff09\uff0c\u5e76\u8ba8\u8bba\u5176\u4e0e\u81ea\u9002\u5e94\u5b66\u4e60\uff08AL\uff09\u3001\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u4ee5\u53ca\u7528\u4e8e\u5b9a\u70b9\u55b7\u6d12\u7684\u6570\u5b57\u5b6a\u751f\u6846\u67b6\u7684\u7ed3\u5408\u3002\u5bf9\u6bd4\u4e86\u4e0d\u540c\u5e74\u4efd\u7684\u53d1\u8868\u8d8b\u52bf\uff0c\u5206\u6790\u4e86VLMs\u76f8\u5bf9\u4e8eLLMs\u7684\u53d1\u8868\u91cf\u4f18\u52bf\uff0c\u5e76\u8bc4\u4f30\u4e86\u73b0\u6709\u7814\u7a76\u5728\u5b9e\u5730\u90e8\u7f72\u65b9\u9762\u7684\u6210\u719f\u5ea6\u3002", "result": "\u4e3b\u8981\u53d1\u73b0\u5305\u62ec\uff1a1) 2023-24\u5e74\u5173\u4e8eFMs\u7684\u6587\u732e\u6fc0\u589e\uff1b2) VLMs\u8bba\u6587\u6570\u91cf\u660e\u663e\u9ad8\u4e8eLLMs\uff08\u7ea65-10\u500d\uff09\uff1b3) \u5f3a\u5316\u5b66\u4e60\u4e0e\u81ea\u9002\u5e94\u5b66\u4e60\u5728\u667a\u80fd\u55b7\u6d12\u5e94\u7528\u4ecd\u8f83\u5c11\uff1b4) \u6570\u5b57\u5b6a\u751f\u7ed3\u5408RL\u53ef\u5728\u865a\u62df\u73af\u5883\u4e2d\u6a21\u62df\u5b9a\u70b9\u55b7\u6d12\u7b56\u7565\uff1b5) sim-to-real\u5dee\u8ddd\u662f\u73b0\u5b9e\u90e8\u7f72\u7684\u5173\u952e\u969c\u788d\uff1b6) \u4eba\u673a\u534f\u4f5c\u4e0e\u4eba\u7c7b\u5728\u73af\u9a8c\u8bc1\u5c1a\u4e0d\u8db3\uff1b7) \u591a\u6a21\u6001\u5b9e\u65f6\u53cd\u9988\u578bFMs\u5c06\u63a8\u52a8\u4e0b\u4e00\u4ee3SSDM\u3002", "conclusion": "\u672c\u6587\u7efc\u8ff0\u6307\u51fa\u57fa\u7840\u6a21\u578b\uff08FMs\uff09\u6b63\u91cd\u5851\u4f5c\u7269\u90e8\u4f4d\u6027\u75c5\u5bb3\u7ba1\u7406\uff08SSDM\uff09\uff0c\u5c24\u5176\u662f\u591a\u6a21\u6001\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u5728\u75c5\u5bb3\u8bc6\u522b\u4e0e\u4ea4\u4e92\u652f\u6301\u65b9\u9762\u8868\u73b0\u7a81\u51fa\uff0c\u4f46\u5f3a\u5316\u5b66\u4e60\u4e0e\u81ea\u9002\u5e94\u5b66\u4e60\u5728\u667a\u80fd\u5b9a\u70b9\u55b7\u6d12\u7b49\u5b9e\u5730\u5e94\u7528\u4e2d\u4ecd\u5904\u4e8e\u8d77\u6b65\u9636\u6bb5\u3002\u5173\u952e\u6311\u6218\u5305\u62ec\u6a21\u62df\u5230\u73b0\u5b9e\uff08sim-to-real\uff09\u5dee\u8ddd\u3001\u4eba\u673a\u534f\u4f5c\u4e0d\u8db3\u4ee5\u53ca\u9700\u5b9e\u65f6\u591a\u6a21\u6001\u53cd\u9988\u3002"}}
{"id": "2510.23868", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.23868", "abs": "https://arxiv.org/abs/2510.23868", "authors": ["Zhichao Wang"], "title": "GIFT: Group-relative Implicit Fine Tuning Integrates GRPO with DPO and UNA", "comment": null, "summary": "I propose \\textbf{G}roup-relative \\textbf{I}mplicit \\textbf{F}ine\n\\textbf{T}uning (GIFT), a novel reinforcement learning framework for aligning\nLLMs. Instead of directly maximizing cumulative rewards like PPO or GRPO, GIFT\nminimizes the discrepancy between implicit and explicit reward models. It\ncombines three key ideas: (1) the online multi-response generation and\nnormalization of GRPO, (2) the implicit reward formulation of DPO, and (3) the\nimplicit-explicit reward alignment principle of UNA. By jointly normalizing the\nimplicit and explicit rewards, GIFT eliminates an otherwise intractable term\nthat prevents effective use of implicit rewards. This normalization transforms\nthe complex reward maximization objective into a simple mean squared error\n(MSE) loss between the normalized reward functions, converting a non-convex\noptimization problem into a convex, stable, and analytically differentiable\nformulation. Unlike offline methods such as DPO and UNA, GIFT remains on-policy\nand thus retains exploration capability. Compared to GRPO, it requires fewer\nhyperparameters, converges faster, and generalizes better with significantly\nreduced training overfitting. Empirically, GIFT achieves superior reasoning and\nalignment performance on mathematical benchmarks while remaining\ncomputationally efficient.", "AI": {"tldr": "GIFT\u901a\u8fc7\u5f52\u4e00\u5316\u5e76\u6700\u5c0f\u5316\u9690\u5f0f\u663e\u5f0f\u5956\u52b1\u5dee\u5f02\uff0c\u5c06\u590d\u6742\u7684\u5728\u7ebfRL\u5bf9\u9f50\u95ee\u9898\u8f6c\u4e3a\u7a33\u5b9a\u7684MSE\u4f18\u5316\uff0c\u517c\u987e\u63a2\u7d22\u4e0e\u7a33\u5b9a\u6027\uff0c\u5e76\u63d0\u5347\u6cdb\u5316\u4e0e\u6536\u655b\u901f\u5ea6\u3002", "motivation": "\u89e3\u51b3\u9690\u5f0f\u5956\u52b1\u65b9\u6cd5\u5728\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u548c\u63a2\u7d22\u53d7\u9650\u7684\u95ee\u9898\uff0c\u540c\u65f6\u4fdd\u7559\u5728\u7ebf\u7b56\u7565\u4f18\u5316\u7684\u63a2\u7d22\u80fd\u529b\uff0c\u5e76\u51cf\u5c11\u8d85\u53c2\u6570\u4e0e\u8fc7\u62df\u5408\u3002", "method": "\u5206\u6790\u65b9\u6cd5\u4e0e\u521b\u65b0\u70b9", "result": "\u63d0\u51faGIFT\u6846\u67b6\uff0c\u901a\u8fc7\u5bf9\u9690\u5f0f\u4e0e\u663e\u5f0f\u5956\u52b1\u8fdb\u884c\u5f52\u4e00\u5316\u5e76\u4ee5\u5747\u65b9\u8bef\u5dee\u5bf9\u9f50\uff0c\u4ece\u975e\u51f8\u7684\u5956\u52b1\u4f18\u5316\u8f6c\u4e3a\u51f8\u7a33\u5b9a\u7684\u4f18\u5316\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5728\u6570\u5b66\u63a8\u7406\u4e0e\u5bf9\u9f50\u4efb\u52a1\u4e0a\u8868\u73b0\u66f4\u4f18\u4e14\u8ba1\u7b97\u9ad8\u6548\u3002", "conclusion": "GIFT\u5c06\u5728\u7ebf\u591a\u54cd\u5e94\u751f\u6210\u3001\u9690\u5f0f\u5956\u52b1\u4e0e\u9690\u5f0f-\u663e\u5f0f\u5bf9\u9f50\u4e09\u8005\u7ed3\u5408\uff0c\u63d0\u4f9b\u4e00\u79cd\u5728\u4fdd\u7559\u63a2\u7d22\u7684\u540c\u65f6\u63d0\u9ad8\u7a33\u5b9a\u6027\u548c\u6cdb\u5316\u6027\u7684LLM\u5bf9\u9f50\u65b9\u6cd5\uff0c\u5b9e\u9a8c\u8bc1\u636e\u652f\u6301\u5176\u4f18\u8d8a\u6027\u3002"}}
{"id": "2510.24663", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24663", "abs": "https://arxiv.org/abs/2510.24663", "authors": ["Yifu Lu", "Shengjie Liu", "Li Dong"], "title": "OrchDAG: Complex Tool Orchestration in Multi-Turn Interactions with Plan DAGs", "comment": "9 pages, 4 figures", "summary": "Agentic tool use has gained traction with the rise of agentic tool calling,\nyet most existing work overlooks the complexity of multi-turn tool\ninteractions. We introduce OrchDAG, a synthetic data generation pipeline that\nmodels tool execution as directed acyclic graphs (DAGs) with controllable\ncomplexity. Using this dataset, we benchmark model performance and propose a\ngraph-based reward to enhance RLVR training. Experiments show that the dataset\npresents a challenging but solvable benchmark, and the proposed reward is\neffective when combined with GRPO-style algorithms, highlighting the importance\nof leveraging topological structure and data complexity in multi-turn tool use.", "AI": {"tldr": "\u63d0\u51faOrchDAG\u751f\u6210\u5de5\u5177\u6267\u884cDAG\u7684\u6570\u636e\u96c6\uff0c\u63a7\u5236\u590d\u6742\u5ea6\uff1b\u8bbe\u8ba1\u57fa\u4e8e\u56fe\u7684\u5956\u52b1\u7528\u4e8eRLVR\u8bad\u7ec3\uff0c\u4e0eGRPO\u7ed3\u5408\u6709\u6548\uff0c\u5f3a\u8c03\u62d3\u6251\u7ed3\u6784\u4e0e\u6570\u636e\u590d\u6742\u5ea6\u7684\u91cd\u8981\u6027\u3002", "motivation": "Agentic tool use is expanding but current approaches often ignore complex multi-turn tool interactions; need synthetic benchmarks modeling such interactions to study and improve methods.", "method": "\u8bbe\u8ba1OrchDAG\u751f\u6210\u6d41\u7a0b\u751f\u6210\u5e26\u53ef\u63a7\u590d\u6742\u5ea6\u7684\u6709\u5411\u65e0\u73af\u56fe\u5de5\u5177\u6267\u884c\u8f68\u8ff9\uff1b\u7528\u8be5\u6570\u636e\u96c6\u505a\u6a21\u578b\u57fa\u51c6\u6d4b\u8bd5\uff1b\u63d0\u51fa\u57fa\u4e8e\u56fe\u7684\u5956\u52b1\u4fe1\u53f7\u5e76\u5728RLVR+GRPO\u6846\u67b6\u4e0b\u8bad\u7ec3\u8bc4\u4f30\u3002", "result": "OrchDAG: a synthetic data pipeline generating DAG-structured tool execution traces with controllable complexity; benchmarking shows it's challenging but solvable; propose a graph-based reward for RLVR training that improves performance when combined with GRPO-style algorithms.", "conclusion": "\u901a\u8fc7\u6784\u9020DAG\u5f62\u5f0f\u7684\u591a\u8f6e\u5de5\u5177\u4ea4\u4e92\u6570\u636e\u53ca\u56fe\u5f62\u5316\u5956\u52b1\uff0c\u80fd\u66f4\u597d\u5730\u8bad\u7ec3\u548c\u8bc4\u4f30\u4ee3\u7406\u5f0f\u5de5\u5177\u4f7f\u7528\uff0c\u7279\u522b\u662f\u7ed3\u5408GRPO\u98ce\u683c\u7b97\u6cd5\u80fd\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002"}}
{"id": "2510.23879", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.23879", "abs": "https://arxiv.org/abs/2510.23879", "authors": ["Ayse Irmak Ercevik", "Ahmet Murat Ozbayoglu"], "title": "Artificial Intelligence Based Predictive Maintenance for Electric Buses", "comment": null, "summary": "Predictive maintenance (PdM) is crucial for optimizing efficiency and\nminimizing downtime of electric buses. While these vehicles provide\nenvironmental benefits, they pose challenges for PdM due to complex electric\ntransmission and battery systems. Traditional maintenance, often based on\nscheduled inspections, struggles to capture anomalies in multi-dimensional\nreal-time CAN Bus data. This study employs a graph-based feature selection\nmethod to analyze relationships among CAN Bus parameters of electric buses and\ninvestigates the prediction performance of targeted alarms using artificial\nintelligence techniques. The raw data collected over two years underwent\nextensive preprocessing to ensure data quality and consistency. A hybrid\ngraph-based feature selection tool was developed by combining statistical\nfiltering (Pearson correlation, Cramer's V, ANOVA F-test) with\noptimization-based community detection algorithms (InfoMap, Leiden, Louvain,\nFast Greedy). Machine learning models, including SVM, Random Forest, and\nXGBoost, were optimized through grid and random search with data balancing via\nSMOTEEN and binary search-based down-sampling. Model interpretability was\nachieved using LIME to identify the features influencing predictions. The\nresults demonstrate that the developed system effectively predicts vehicle\nalarms, enhances feature interpretability, and supports proactive maintenance\nstrategies aligned with Industry 4.0 principles.", "AI": {"tldr": "\u5229\u7528\u56fe\u57fa\u7279\u5f81\u9009\u62e9\u548c\u673a\u5668\u5b66\u4e60\uff08SVM\u3001\u968f\u673a\u68ee\u6797\u3001XGBoost\uff09\u5bf9\u4e24\u5e74CAN Bus\u6570\u636e\u8fdb\u884c\u9884\u6d4b\u6027\u7ef4\u62a4\u7814\u7a76\uff0c\u7ed3\u5408SMOTEEN\u4e0e\u4e0b\u91c7\u6837\u5904\u7406\u4e0d\u5e73\u8861\uff0c\u5e76\u7528LIME\u89e3\u91ca\u6a21\u578b\uff0c\u7ed3\u679c\u663e\u793a\u80fd\u6709\u6548\u9884\u6d4b\u544a\u8b66\u5e76\u652f\u6301\u4e3b\u52a8\u7ef4\u62a4\u3002", "motivation": "Address predictive maintenance challenges for electric buses by leveraging CAN Bus data to predict alarms and enable proactive maintenance.", "method": "\u6570\u636e\u7ecf\u8be6\u5c3d\u9884\u5904\u7406\u540e\uff0c\u5148\u7528Pearson\u3001Cramer's V\u3001ANOVA F-test\u505a\u7edf\u8ba1\u8fc7\u6ee4\uff0c\u518d\u7528InfoMap\u3001Leiden\u3001Louvain\u3001Fast Greedy\u7b49\u793e\u533a\u68c0\u6d4b\u8fdb\u884c\u56fe\u8c31\u4f18\u5316\u7684\u7279\u5f81\u9009\u62e9\uff1b\u6a21\u578b\u8bad\u7ec3\u7528\u7f51\u683c/\u968f\u673a\u641c\u7d22\u8c03\u53c2\uff0c\u5e76\u7528SMOTEEN\u548c\u4e8c\u5206\u6cd5\u4e0b\u91c7\u6837\u5904\u7406\u7c7b\u522b\u4e0d\u5e73\u8861\uff1b\u6700\u540e\u7528LIME\u505a\u5c40\u90e8\u53ef\u89e3\u91ca\u6027\u5206\u6790\u3002", "result": "Developed a hybrid graph-based feature selection combining statistical filters and community detection; trained optimized ML models (SVM, RF, XGBoost) with balancing; used LIME for interpretability; system effectively predicts alarms and supports PdM.", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u4ece\u591a\u7ef4CAN\u603b\u7ebf\u6570\u636e\u4e2d\u7b5b\u9009\u5173\u952e\u7279\u5f81\u3001\u6784\u5efa\u53ef\u89e3\u91ca\u7684\u6545\u969c\u9884\u6d4b\u6a21\u578b\uff0c\u63d0\u5347\u7535\u52a8\u516c\u4ea4\u7684\u9884\u6d4b\u7ef4\u62a4\u80fd\u529b\uff0c\u7b26\u5408\u5de5\u4e1a4.0\u8981\u6c42\u3002"}}
{"id": "2510.24690", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24690", "abs": "https://arxiv.org/abs/2510.24690", "authors": ["Shengjie Liu", "Li Dong", "Zhenyu Zhang"], "title": "Bridging Tool Dependencies and Domain Knowledge: A Graph-Based Framework for In-Context Planning", "comment": "4 pages, 2 figures, short paper, NeurIPS 2025 workshop on Bridging\n  Language, Agent, and World Models for Reasoning and Planning", "summary": "We present a framework for uncovering and exploiting dependencies among tools\nand documents to enhance exemplar artifact generation. Our method begins by\nconstructing a tool knowledge graph from tool schemas,including descriptions,\narguments, and output payloads, using a DeepResearch-inspired analysis. In\nparallel, we derive a complementary knowledge graph from internal documents and\nSOPs, which is then fused with the tool graph. To generate exemplar plans, we\nadopt a deep-sparse integration strategy that aligns structural tool\ndependencies with procedural knowledge. Experiments demonstrate that this\nunified framework effectively models tool interactions and improves plan\ngeneration, underscoring the benefits of linking tool graphs with domain\nknowledge graphs for tool-augmented reasoning and planning.", "AI": {"tldr": "Build tool and document knowledge graphs, fuse them, and use deep-sparse integration to generate better exemplar plans for tool-augmented reasoning", "motivation": "Tools have rich schemas but lack domain procedural grounding; documents/SOPs contain procedures but not tool semantics; fusing both yields better plans", "method": "Construct fused tool-document knowledge graphs and deep-sparse integration for exemplar plan generation", "result": "Framework builds tool graph from schemas, document graph from SOPs, fuses them, uses deep-sparse alignment to produce exemplar plans; experiments show improved modeling of tool interactions and plan quality", "conclusion": "Linking tool graphs with domain knowledge graphs enables more accurate tool interaction modeling and improved exemplar artifact/plan generation"}}
{"id": "2510.23901", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23901", "abs": "https://arxiv.org/abs/2510.23901", "authors": ["Cristobal Heredia", "Pedro Chumpitaz-Flores", "Kaixun Hua"], "title": "RS-ORT: A Reduced-Space Branch-and-Bound Algorithm for Optimal Regression Trees", "comment": "20 pages, 1 figure, uses ICLR 2026 LaTeX style. Submitted to arXiv as\n  a preprint version", "summary": "Mixed-integer programming (MIP) has emerged as a powerful framework for\nlearning optimal decision trees. Yet, existing MIP approaches for regression\ntasks are either limited to purely binary features or become computationally\nintractable when continuous, large-scale data are involved. Naively binarizing\ncontinuous features sacrifices global optimality and often yields needlessly\ndeep trees. We recast the optimal regression-tree training as a two-stage\noptimization problem and propose Reduced-Space Optimal Regression Trees\n(RS-ORT) - a specialized branch-and-bound (BB) algorithm that branches\nexclusively on tree-structural variables. This design guarantees the\nalgorithm's convergence and its independence from the number of training\nsamples. Leveraging the model's structure, we introduce several bound\ntightening techniques - closed-form leaf prediction, empirical threshold\ndiscretization, and exact depth-1 subtree parsing - that combine with\ndecomposable upper and lower bounding strategies to accelerate the training.\nThe BB node-wise decomposition enables trivial parallel execution, further\nalleviating the computational intractability even for million-size datasets.\nBased on the empirical studies on several regression benchmarks containing both\nbinary and continuous features, RS-ORT also delivers superior training and\ntesting performance than state-of-the-art methods. Notably, on datasets with up\nto 2,000,000 samples with continuous features, RS-ORT can obtain guaranteed\ntraining performance with a simpler tree structure and a better generalization\nability in four hours.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aRS-ORT\u7684\u4e13\u7528\u5206\u652f\u5b9a\u754c\u7b97\u6cd5\uff0c\u7528\u4e8e\u8bad\u7ec3\u6700\u4f18\u56de\u5f52\u6811\uff0c\u907f\u514d\u5bf9\u8fde\u7eed\u7279\u5f81\u8fdb\u884c\u7b80\u5355\u4e8c\u503c\u5316\uff0c\u80fd\u5728\u6837\u672c\u89c4\u6a21\u5927\u65f6\u4fdd\u6301\u53ef\u89e3\u6027\u5e76\u4fdd\u8bc1\u6536\u655b\uff1b\u901a\u8fc7\u5c01\u95ed\u5f62\u5f0f\u53f6\u9884\u6d4b\u3001\u7ecf\u9a8c\u9608\u503c\u79bb\u6563\u5316\u548c\u6df1\u5ea61\u5b50\u6811\u89e3\u6790\u7b49\u754c\u7d27\u7f29\u6280\u5de7\u4ee5\u53ca\u5206\u89e3\u4e0a\u4e0b\u754c\u52a0\u901f\u8bad\u7ec3\uff1b\u652f\u6301\u8282\u70b9\u5e76\u884c\uff0c\u4ece\u800c\u5728\u767e\u4e07\u7ea7\u6837\u672c\u4e0a\u4ecd\u80fd\u5728\u6570\u5c0f\u65f6\u5185\u5f97\u5230\u6709\u4fdd\u8bc1\u7684\u8bad\u7ec3\u7ed3\u679c\u4e14\u6cdb\u5316\u6027\u80fd\u66f4\u4f18\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eMIP\u7684\u56de\u5f52\u6811\u65b9\u6cd5\u5728\u9047\u5230\u8fde\u7eed\u6216\u5927\u89c4\u6a21\u6570\u636e\u65f6\u4e0d\u53ef\u6269\u5c55\uff0c\u7b80\u5355\u5bf9\u8fde\u7eed\u7279\u5f81\u4e8c\u503c\u5316\u65e2\u635f\u5931\u5168\u5c40\u6700\u4f18\u6027\u53c8\u5bfc\u81f4\u6811\u6df1\u5ea6\u8fc7\u5927\uff0c\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u4fdd\u8bc1\u6700\u4f18\u6027\u53c8\u53ef\u6269\u5c55\u5230\u767e\u4e07\u7ea7\u6837\u672c\u53ca\u8fde\u7eed\u7279\u5f81\u7684\u8bad\u7ec3\u65b9\u6cd5\u3002", "method": "\u5c06\u6700\u4f18\u56de\u5f52\u6811\u8bad\u7ec3\u91cd\u5199\u4e3a\u4e24\u9636\u6bb5\u4f18\u5316\u95ee\u9898\uff0c\u4ec5\u5bf9\u6811\u7ed3\u6784\u53d8\u91cf\u5206\u652f\u7684\u4e13\u7528\u5206\u652f\u5b9a\u754c\u7b97\u6cd5\uff08RS-ORT\uff09\uff1b\u5f15\u5165\u95ed\u5f0f\u53f6\u503c\u9884\u6d4b\u3001\u7ecf\u9a8c\u9608\u503c\u79bb\u6563\u5316\u3001\u6df1\u5ea6-1\u5b50\u6811\u7cbe\u786e\u89e3\u6790\u7b49\u754c\u7d27\u7f29\u6280\u5de7\uff0c\u7ed3\u5408\u53ef\u5206\u89e3\u7684\u4e0a/\u4e0b\u754c\u7b56\u7565\uff1b\u8282\u70b9\u7ea7\u522b\u7684BB\u5206\u89e3\u5229\u4e8e\u5e76\u884c\u5316\u5b9e\u73b0\u3002", "result": "\u5728\u591a\u9879\u56de\u5f52\u57fa\u51c6\u4e0a\uff0c\u5c24\u5176\u5305\u542b\u8fde\u7eed\u7279\u5f81\u7684\u6570\u636e\u96c6\uff0cRS-ORT\u5728\u8bad\u7ec3/\u6d4b\u8bd5\u6027\u80fd\u4e0a\u4f18\u4e8e\u6700\u5148\u8fdb\u65b9\u6cd5\uff1b\u5728\u6700\u9ad8\u8fbe200\u4e07\u6837\u672c\u7684\u8fde\u7eed\u7279\u5f81\u6570\u636e\u4e0a\uff0c\u56db\u5c0f\u65f6\u5185\u53ef\u5f97\u5230\u5e26\u6709\u5168\u5c40\u6027\u80fd\u4fdd\u8bc1\u3001\u7ed3\u6784\u66f4\u7b80\u5355\u4e14\u6cdb\u5316\u66f4\u597d\u7684\u56de\u5f52\u6811\u3002", "conclusion": "RS-ORT\u5728\u7406\u8bba\u4e0a\u4fdd\u8bc1\u6536\u655b\u4e14\u4e0e\u8bad\u7ec3\u6837\u672c\u6570\u65e0\u5173\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u5206\u652f\u548c\u591a\u79cd\u754c\u7d27\u7f29/\u5206\u89e3\u6280\u5de7\u663e\u8457\u63d0\u5347\u4e86\u5927\u89c4\u6a21\u8fde\u7eed\u7279\u5f81\u56de\u5f52\u6811\u8bad\u7ec3\u7684\u53ef\u6269\u5c55\u6027\u548c\u89e3\u8d28\u91cf\uff0c\u5728\u591a\u9879\u57fa\u51c6\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u80fd\u5728\u56db\u5c0f\u65f6\u5185\u5bf9200\u4e07\u6837\u672c\u5f97\u5230\u66f4\u7b80\u5355\u4e14\u6cdb\u5316\u66f4\u597d\u7684\u6700\u4f18\u56de\u5f52\u6811\u3002"}}
{"id": "2505.22820", "categories": ["cs.LG", "cs.AI", "econ.TH", "stat.ML"], "pdf": "https://arxiv.org/pdf/2505.22820", "abs": "https://arxiv.org/abs/2505.22820", "authors": ["Ayush Sawarni", "Sahasrajit Sarmasarkar", "Vasilis Syrgkanis"], "title": "Preference Learning with Response Time: Robust Losses and Guarantees", "comment": "Accepted at NeurIPS 2025", "summary": "This paper investigates the integration of response time data into human\npreference learning frameworks for more effective reward model elicitation.\nWhile binary preference data has become fundamental in fine-tuning foundation\nmodels, generative AI systems, and other large-scale models, the valuable\ntemporal information inherent in user decision-making remains largely\nunexploited. We propose novel methodologies to incorporate response time\ninformation alongside binary choice data, leveraging the Evidence Accumulation\nDrift Diffusion (EZ) model, under which response time is informative of the\npreference strength. We develop Neyman-orthogonal loss functions that achieve\noracle convergence rates for reward model learning, matching the theoretical\noptimal rates that would be attained if the expected response times for each\nquery were known a priori. Our theoretical analysis demonstrates that for\nlinear reward functions, conventional preference learning suffers from error\nrates that scale exponentially with reward magnitude. In contrast, our response\ntime-augmented approach reduces this to polynomial scaling, representing a\nsignificant improvement in sample efficiency. We extend these guarantees to\nnon-parametric reward function spaces, establishing convergence properties for\nmore complex, realistic reward models. Our extensive experiments validate our\ntheoretical findings in the context of preference learning over images.", "AI": {"tldr": "\u5229\u7528Drift Diffusion\u6a21\u578b\u5c06\u53cd\u5e94\u65f6\u95f4\u5e76\u5165\u504f\u597d\u5b66\u4e60\uff0c\u6784\u5efaNeyman-orthogonal\u635f\u5931\uff0c\u5b9e\u73b0oracle\u6536\u655b\u7387\uff0c\u663e\u8457\u63d0\u5347\u6837\u672c\u6548\u7387\u5e76\u5728\u56fe\u50cf\u504f\u597d\u5b9e\u9a8c\u4e2d\u5f97\u5230\u9a8c\u8bc1\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u4e8c\u5143\u504f\u597d\u7684\u5b66\u4e60\u5ffd\u7565\u4e86\u51b3\u7b56\u65f6\u95f4\u8fd9\u4e00\u91cd\u8981\u4fe1\u606f\uff0c\u5bfc\u81f4\u5728\u5956\u52b1\u5e45\u5ea6\u8f83\u5927\u6216\u6837\u672c\u6709\u9650\u65f6\u4f30\u8ba1\u8bef\u5dee\u548c\u6837\u672c\u9700\u6c42\u663e\u8457\u589e\u52a0\u3002\u5229\u7528\u53cd\u5e94\u65f6\u95f4\u53ef\u83b7\u53d6\u5173\u4e8e\u504f\u597d\u5f3a\u5ea6\u7684\u989d\u5916\u4fe1\u606f\uff0c\u4ece\u800c\u63d0\u5347\u5956\u52b1\u6a21\u578b\u7684\u5b66\u4e60\u6548\u7387\u548c\u9c81\u68d2\u6027\u3002", "method": "\u5728\u4e8c\u5143\u9009\u62e9\u6570\u636e\u57fa\u7840\u4e0a\uff0c\u7ed3\u5408Evidence Accumulation Drift Diffusion\uff08EZ\uff09\u6a21\u578b\uff0c\u5c06\u53cd\u5e94\u65f6\u95f4\u4f5c\u4e3a\u504f\u597d\u5f3a\u5ea6\u7684\u4fe1\u53f7\uff1b\u6784\u9020Neyman-orthogonal\u635f\u5931\u51fd\u6570\u4ee5\u6d88\u9664\u4f30\u8ba1\u504f\u5dee\uff0c\u5b9e\u73b0\u4e0e\u5df2\u77e5\u671f\u671b\u53cd\u5e94\u65f6\u95f4\u60c5\u5f62\u76f8\u540c\u7684oracle\u6536\u655b\u7387\uff1b\u7406\u8bba\u8bc1\u660e\u5e76\u63a8\u5e7f\u5230\u975e\u53c2\u6570\u60c5\u5f62\uff1b\u5728\u56fe\u50cf\u504f\u597d\u5b66\u4e60\u4efb\u52a1\u4e0a\u505a\u5927\u91cf\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "\u7406\u8bba\u4e0a\uff1a\u6784\u5efa\u7684\u7b97\u6cd5\u5728\u7ebf\u6027\u5956\u52b1\u4e0b\u5c06\u8bef\u5dee\u4ece\u4e0e\u5956\u52b1\u5e45\u5ea6\u5448\u6307\u6570\u5173\u7cfb\u964d\u4e3a\u591a\u9879\u5f0f\u5173\u7cfb\uff1b\u975e\u53c2\u6570\u60c5\u5f62\u4e5f\u83b7\u5f97\u6536\u655b\u4fdd\u8bc1\u3002\u5b9e\u8bc1\u4e0a\uff1a\u5728\u56fe\u50cf\u504f\u597d\u5b66\u4e60\u4efb\u52a1\u4e2d\uff0c\u542b\u53cd\u5e94\u65f6\u95f4\u7684\u65b9\u6cd5\u5728\u6837\u672c\u6548\u7387\u548c\u4f30\u8ba1\u7cbe\u5ea6\u4e0a\u5747\u4f18\u4e8e\u4ec5\u7528\u4e8c\u5143\u9009\u62e9\u7684\u65b9\u6cd5\uff0c\u5e76\u4e0e\u7406\u8bba\u9884\u6d4b\u4e00\u81f4\u3002", "conclusion": "\u672c\u6587\u901a\u8fc7\u5c06\u53cd\u5e94\u65f6\u95f4\u5f15\u5165\u504f\u597d\u5b66\u4e60\u6846\u67b6\uff0c\u6709\u6548\u63d0\u5347\u4e86\u5956\u52b1\u6a21\u578b\u7684\u5b66\u4e60\u6548\u7387\uff0c\u5c24\u5176\u5728\u5956\u52b1\u5e45\u5ea6\u8f83\u5927\u65f6\u663e\u8457\u6539\u5584\u4e86\u6837\u672c\u590d\u6742\u5ea6\uff0c\u4ece\u6307\u6570\u7ea7\u9000\u5316\u964d\u4e3a\u591a\u9879\u5f0f\u7ea7\u522b\u3002"}}
{"id": "2510.23906", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23906", "abs": "https://arxiv.org/abs/2510.23906", "authors": ["Wasim Ahmad", "Maha Shadaydeh", "Joachim Denzler"], "title": "Group Interventions on Deep Networks for Causal Discovery in Subsystems", "comment": "Submitted to IEEE Access. We are working on the revised version", "summary": "Causal discovery uncovers complex relationships between variables, enhancing\npredictions, decision-making, and insights into real-world systems, especially\nin nonlinear multivariate time series. However, most existing methods primarily\nfocus on pairwise cause-effect relationships, overlooking interactions among\ngroups of variables, i.e., subsystems and their collective causal influence. In\nthis study, we introduce gCDMI, a novel multi-group causal discovery method\nthat leverages group-level interventions on trained deep neural networks and\nemploys model invariance testing to infer causal relationships. Our approach\ninvolves three key steps. First, we use deep learning to jointly model the\nstructural relationships among groups of all time series. Second, we apply\ngroup-wise interventions to the trained model. Finally, we conduct model\ninvariance testing to determine the presence of causal links among variable\ngroups. We evaluate our method on simulated datasets, demonstrating its\nsuperior performance in identifying group-level causal relationships compared\nto existing methods. Additionally, we validate our approach on real-world\ndatasets, including brain networks and climate ecosystems. Our results\nhighlight that applying group-level interventions to deep learning models,\ncombined with invariance testing, can effectively reveal complex causal\nstructures, offering valuable insights for domains such as neuroscience and\nclimate science.", "AI": {"tldr": "gCDMI\u901a\u8fc7\u5bf9\u8bad\u7ec3\u597d\u7684\u6df1\u5ea6\u6a21\u578b\u8fdb\u884c\u7ec4\u7ea7\u5e72\u9884\u5e76\u68c0\u9a8c\u6a21\u578b\u4e0d\u53d8\u6027\u6765\u53d1\u73b0\u53d8\u5143\u7ec4\u4e4b\u95f4\u7684\u56e0\u679c\u5173\u7cfb\uff0c\u5728\u6a21\u62df\u548c\u771f\u5b9e\u6570\u636e\u4e0a\u6548\u679c\u8f83\u597d\uff0c\u9002\u7528\u4e8e\u795e\u7ecf\u79d1\u5b66\u4e0e\u6c14\u5019\u5b66\u7b49\u9886\u57df", "motivation": "\u89e3\u51b3\u73b0\u6709\u56e0\u679c\u53d1\u73b0\u65b9\u6cd5\u53ea\u5173\u6ce8\u53d8\u91cf\u5bf9\u5bf9\u4e4b\u95f4\u7684\u56e0\u679c\u5173\u7cfb\uff0c\u5ffd\u7565\u53d8\u91cf\u7ec4\uff08\u5b50\u7cfb\u7edf\uff09\u53ca\u5176\u6574\u4f53\u5f71\u54cd\u7684\u8bc6\u522b\u95ee\u9898\uff0c\u5c24\u5176\u5728\u975e\u7ebf\u6027\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u4e2d", "method": "1) \u4f7f\u7528\u6df1\u5ea6\u5b66\u4e60\u8054\u5408\u5efa\u6a21\u6240\u6709\u65f6\u95f4\u5e8f\u5217\u7ec4\u95f4\u7684\u7ed3\u6784\u5173\u7cfb\uff1b2) \u5bf9\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u5b9e\u65bd\u7ec4\u7ea7\u5e72\u9884\uff08\u6270\u52a8\u7279\u5b9a\u53d8\u91cf\u7ec4\u6216\u5176\u8868\u793a\uff09\uff1b3) \u901a\u8fc7\u6a21\u578b\u4e0d\u53d8\u6027\u68c0\u9a8c\uff08\u6bd4\u8f83\u5e72\u9884\u524d\u540e\u9884\u6d4b\u5206\u5e03/\u6027\u80fd\u7684\u663e\u8457\u53d8\u5316\uff09\u6765\u5224\u65ad\u7ec4\u95f4\u56e0\u679c\u8fde\u8fb9\u7684\u5b58\u5728", "result": "\u63d0\u51fagCDMI\u65b9\u6cd5\uff1a\u5728\u8bad\u7ec3\u597d\u7684\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u4e0a\u65bd\u52a0\u7ec4\u7ea7\u5e72\u9884\u5e76\u7ed3\u5408\u6a21\u578b\u4e0d\u53d8\u6027\u68c0\u9a8c\uff0c\u4ece\u800c\u8bc6\u522b\u7ec4\u7ea7\u56e0\u679c\u5173\u7cfb\uff1b\u5728\u6a21\u62df\u6570\u636e\u548c\u771f\u5b9e\u6570\u636e\uff08\u8111\u7f51\u7edc\u3001\u6c14\u5019\u7cfb\u7edf\uff09\u4e0a\u663e\u793a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u7684\u6027\u80fd", "conclusion": "\u5728\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u4e0a\u6267\u884c\u7ec4\u7ea7\u5e72\u9884\u5e76\u5229\u7528\u4e0d\u53d8\u6027\u68c0\u6d4b\uff0c\u53ef\u6709\u6548\u63ed\u793a\u590d\u6742\u7684\u7ec4\u7ea7\u56e0\u679c\u7ed3\u6784\uff0c\u63d0\u4f9b\u6bd4\u57fa\u4e8e\u6210\u5bf9\u5206\u6790\u66f4\u5168\u9762\u7684\u56e0\u679c\u6d1e\u89c1"}}
{"id": "2510.23912", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23912", "abs": "https://arxiv.org/abs/2510.23912", "authors": ["Marko Karbevski", "Antonij Mijoski"], "title": "Key and Value Weights Are Probably All You Need: On the Necessity of the Query, Key, Value weight Triplet in Decoder-Only Transformers", "comment": null, "summary": "The Query, Key, Value weight triplet is a building block of current attention\nmechanisms in state-of-the-art LLMs. We theoretically investigate whether this\ntriplet can be reduced, proving under simplifying assumptions that the Query\nweights are redundant, thereby reducing the number of non-embedding/lm-head\nparameters by over 8%. We validate the theory on full-complexity GPT-3 small\narchitectures (with layer normalization, skip connections, and weight decay)\ntrained from scratch, demonstrating that the reduced model achieves comparable\nvalidation loss to standard baselines. These findings motivate the\ninvestigation of the Query weight redundancy at scale.", "AI": {"tldr": "Under assumptions, Query weights are unnecessary; removing them saves >8% parameters and preserves performance on GPT-3 small", "motivation": "Reduce parameters and simplify attention by testing if Query weights are redundant", "method": "Theoretical analysis + empirical verification", "result": "Proved Query weights redundant under simplifying assumptions; reduced model (no Query weights) matches validation loss of baseline on GPT-3 small trained from scratch; >8% reduction in non-embedding/lm-head parameters", "conclusion": "Query weight redundancy holds in theory and empirically for tested architectures, motivating scale-up investigations."}}
{"id": "2510.23914", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.23914", "abs": "https://arxiv.org/abs/2510.23914", "authors": ["Arsenii Mustafin", "Xinyi Sheng", "Dominik Baumann"], "title": "Geometry-Inspired Unified Framework for Discounted and Average Reward MDPs", "comment": "12 pages, 1 figure", "summary": "The theoretical analysis of Markov Decision Processes (MDPs) is commonly\nsplit into two cases - the average-reward case and the discounted-reward case -\nwhich, while sharing similarities, are typically analyzed separately. In this\nwork, we extend a recently introduced geometric interpretation of MDPs for the\ndiscounted-reward case to the average-reward case, thereby unifying both. This\nallows us to extend a major result known for the discounted-reward case to the\naverage-reward case: under a unique and ergodic optimal policy, the Value\nIteration algorithm achieves a geometric convergence rate.", "AI": {"tldr": "Unified geometric view of discounted and average-reward MDPs; proved geometric (linear) convergence of Value Iteration in average-reward case under uniqueness and ergodicity.", "motivation": "Unify geometric interpretation of MDPs across discounted and average-reward cases to transfer convergence results.", "method": "Extend geometric interpretation from discounted to average-reward MDPs and adapt analysis to prove geometric convergence of Value Iteration.", "result": "Extended geometric framework to average-reward MDPs and proved Value Iteration has geometric convergence rate under unique ergodic optimal policy.", "conclusion": "With a unique, ergodic optimal policy, Value Iteration converges geometrically in average-reward MDPs, matching known discounted-case results."}}
{"id": "2510.23926", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.23926", "abs": "https://arxiv.org/abs/2510.23926", "authors": ["Ningfeng Yang", "Tor M. Aamodt"], "title": "Improving the Straight-Through Estimator with Zeroth-Order Information", "comment": "39th Conference on Neural Information Processing Systems (NeurIPS\n  2025)", "summary": "We study the problem of training neural networks with quantized parameters.\nLearning low-precision quantized parameters by enabling computation of\ngradients via the Straight-Through Estimator (STE) can be challenging. While\nthe STE enables back-propagation, which is a first-order method, recent works\nhave explored the use of zeroth-order (ZO) gradient descent for fine-tuning. We\nnote that the STE provides high-quality biased gradients, and ZO gradients are\nunbiased but can be expensive. We thus propose First-Order-Guided Zeroth-Order\nGradient Descent (FOGZO) that reduces STE bias while reducing computations\nrelative to ZO methods. Empirically, we show FOGZO improves the tradeoff\nbetween quality and training time in Quantization-Aware Pre-Training.\nSpecifically, versus STE at the same number of iterations, we show a 1-8\\%\naccuracy improvement for DeiT Tiny/Small, 1-2\\% accuracy improvement on ResNet\n18/50, and 1-22 perplexity point improvement for LLaMA models with up to 0.3\nbillion parameters. For the same loss, FOGZO yields a 796$\\times$ reduction in\ncomputation versus n-SPSA for a 2-layer MLP on MNIST. Code is available at\nhttps://github.com/1733116199/fogzo.", "AI": {"tldr": "FOGZO mixes STE and occasional ZO updates to correct bias, achieving better accuracy/perplexity than STE with much lower cost than pure ZO.", "motivation": "STE gives biased but cheap gradients; ZO gives unbiased but expensive gradients. Combine strengths to reduce STE bias while lowering ZO cost.", "method": "First-Order-Guided Zeroth-Order Gradient Descent (FOGZO)", "result": "FOGZO improves accuracy/perplexity vs STE across models (DeiT, ResNet, LLaMA) and greatly reduces computation vs n-SPSA (796x) for small MLP; better quality-training time tradeoff in QAT.", "conclusion": "FOGZO offers practical middle ground for quantized training: reduces bias and computation, improving performance in Quantization-Aware Pre-Training."}}
{"id": "2510.23936", "categories": ["cs.LG", "physics.flu-dyn"], "pdf": "https://arxiv.org/pdf/2510.23936", "abs": "https://arxiv.org/abs/2510.23936", "authors": ["Junho Choi", "Teng-Yuan Chang", "Namjung Kim", "Youngjoon Hong"], "title": "A data free neural operator enabling fast inference of 2D and 3D Navier Stokes equations", "comment": null, "summary": "Ensemble simulations of high-dimensional flow models (e.g., Navier Stokes\ntype PDEs) are computationally prohibitive for real time applications. Neural\noperators enable fast inference but are limited by costly data requirements and\npoor generalization to 3D flows. We present a data-free operator network for\nthe Navier Stokes equations that eliminates the need for paired solution data\nand enables robust, real time inference for large ensemble forecasting. The\nphysics-grounded architecture takes initial and boundary conditions as well as\nforcing functions, yielding solutions robust to high variability and\nperturbations. Across 2D benchmarks and 3D test cases, the method surpasses\nprior neural operators in accuracy and, for ensembles, achieves greater\nefficiency than conventional numerical solvers. Notably, it delivers accurate\nsolutions of the three dimensional Navier Stokes equations, a regime not\npreviously demonstrated for data free neural operators. By uniting a\nnumerically grounded architecture with the scalability of machine learning,\nthis approach establishes a practical pathway toward data free, high fidelity\nPDE surrogates for end to end scientific simulation and prediction.", "AI": {"tldr": "A physics-grounded, data-free neural operator for Navier Stokes enables real-time, robust ensemble inference in 2D and 3D, outperforming prior neural operators and beating solvers in ensemble efficiency.", "motivation": "Enable real-time, robust ensemble forecasting for high-dimensional flow models without costly paired solution data and with better generalization to 3D flows.", "method": "Data-free physics-informed operator network for Navier Stokes", "result": "Surpasses prior neural operators in accuracy on 2D benchmarks, provides accurate 3D Navier Stokes solutions for the first time among data-free neural operators, and is more efficient than numerical solvers for ensembles.", "conclusion": "Combining numerically grounded architecture with ML scalability produces practical data-free, high-fidelity PDE surrogates for scientific simulation and prediction."}}
{"id": "2510.23940", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23940", "abs": "https://arxiv.org/abs/2510.23940", "authors": ["Anastasia-Maria Leventi-Peetz", "J\u00f6rg-Volker Peetz", "Kai Weber", "Nikolaos Zacharis"], "title": "Modeling Biological Multifunctionality with Echo State Networks", "comment": "26 pages, 17 figures, 6 tables, 23 references", "summary": "In this work, a three-dimensional multicomponent reaction-diffusion model has\nbeen developed, combining excitable-system dynamics with diffusion processes\nand sharing conceptual features with the FitzHugh-Nagumo model. Designed to\ncapture the spatiotemporal behavior of biological systems, particularly\nelectrophysiological processes, the model was solved numerically to generate\ntime-series data. These data were subsequently used to train and evaluate an\nEcho State Network (ESN), which successfully reproduced the system's dynamic\nbehavior. The results demonstrate that simulating biological dynamics using\ndata-driven, multifunctional ESN models is both feasible and effective.", "AI": {"tldr": "\u6784\u5efa\u4e86\u4e0eFitzHugh\u2013Nagumo\u76f8\u4f3c\u76843D\u53cd\u5e94-\u6269\u6563\u591a\u7ec4\u5206\u6a21\u578b\uff0c\u751f\u6210\u65f6\u7a7a\u6570\u636e\u5e76\u7528\u56de\u58f0\u72b6\u6001\u7f51\u7edc(ESN)\u5b66\u4e60\uff0cESN\u80fd\u6709\u6548\u91cd\u73b0\u52a8\u529b\u5b66\u3002", "motivation": "\u4e3a\u6355\u6349\u751f\u7269\u7535\u751f\u7406\u8fc7\u7a0b\u7684\u590d\u6742\u65f6\u7a7a\u52a8\u6001\uff0c\u63a2\u7d22\u5c06\u89e3\u91ca\u6027\u53cd\u5e94-\u6269\u6563\u6a21\u578b\u4e0e\u9ad8\u6548\u6570\u636e\u9a71\u52a8\u7684\u9012\u5f52\u795e\u7ecf\u7f51\u7edc\uff08ESN\uff09\u7ed3\u5408\u4ee5\u5b9e\u73b0\u5feb\u901f\u9884\u6d4b\u4e0e\u4eff\u771f\u3002", "method": "\u6570\u503c\u6c42\u89e3\u4e09\u7ef4\u53cd\u5e94-\u6269\u6563\u65b9\u7a0b\u751f\u6210\u65f6\u95f4\u5e8f\u5217\uff0c\u4f7f\u7528\u8fd9\u4e9b\u6570\u636e\u8bad\u7ec3\u5e76\u8bc4\u4f30ESN\uff1b\u53ef\u80fd\u5305\u542b\u53c2\u6570\u626b\u63cf\u3001\u566a\u58f0\u5904\u7406\u548c\u9884\u6d4b\u6d4b\u8bd5\u3002", "result": "The paper develops a 3D multicomponent reaction-diffusion model analogous to FitzHugh-Nagumo, numerically generates time-series, and trains an Echo State Network (ESN) to replicate dynamics; ESN successfully reproduces system behavior suggesting feasibility of data-driven ESN for biological dynamics.", "conclusion": "\u6570\u636e\u9a71\u52a8\u7684\u591a\u529f\u80fdESN\u80fd\u6709\u6548\u6a21\u62df\u590d\u6742\u751f\u7269\u7535\u6d3b\u52a8\u7684\u65f6\u7a7a\u52a8\u6001\uff0c\u8bc1\u660e\u5c06\u6570\u503c\u4eff\u771f\u4e0e\u673a\u5668\u5b66\u4e60\u7ed3\u5408\u7684\u53ef\u884c\u6027\u4e0e\u5b9e\u7528\u6027\u3002"}}
{"id": "2510.23948", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23948", "abs": "https://arxiv.org/abs/2510.23948", "authors": ["Qianfeng Wen", "Zhenwei Tang", "Ashton Anderson"], "title": "ChessQA: Evaluating Large Language Models for Chess Understanding", "comment": "33 pages,8 figures", "summary": "Chess provides an ideal testbed for evaluating the reasoning, modeling, and\nabstraction capabilities of large language models (LLMs), as it has\nwell-defined structure and objective ground truth while admitting a wide\nspectrum of skill levels. However, existing evaluations of LLM ability in chess\nare ad hoc and narrow in scope, making it difficult to accurately measure LLM\nchess understanding and how it varies with scale, post-training methodologies,\nor architecture choices. We present ChessQA, a comprehensive benchmark that\nassesses LLM chess understanding across five task categories (Structural,\nMotifs, Short Tactics, Position Judgment, and Semantic), which approximately\ncorrespond to the ascending abstractions that players master as they accumulate\nchess knowledge, from understanding basic rules and learning tactical motifs to\ncorrectly calculating tactics, evaluating positions, and semantically\ndescribing high-level concepts. In this way, ChessQA captures a more\ncomprehensive picture of chess ability and understanding, going significantly\nbeyond the simple move quality evaluations done previously, and offers a\ncontrolled, consistent setting for diagnosis and comparison. Furthermore,\nChessQA is inherently dynamic, with prompts, answer keys, and construction\nscripts that can evolve as models improve. Evaluating a range of contemporary\nLLMs, we find persistent weaknesses across all five categories and provide\nresults and error analyses by category. We will release the code, periodically\nrefreshed datasets, and a public leaderboard to support further research.", "AI": {"tldr": "ChessQA\u662f\u4e00\u4e2a\u52a8\u6001\u3001\u5168\u9762\u7684\u56fd\u9645\u8c61\u68cb\u80fd\u529b\u8bc4\u6d4b\u57fa\u51c6\uff0c\u8986\u76d6\u4ece\u89c4\u5219\u5230\u9ad8\u9636\u8bed\u4e49\u7406\u89e3\u7684\u4e94\u5927\u4efb\u52a1\u7c7b\uff0c\u5b9e\u9a8c\u663e\u793a\u5f53\u524dLLM\u5728\u6240\u6709\u7c7b\u522b\u5747\u6709\u660e\u663e\u4e0d\u8db3\uff0c\u5e76\u5c06\u5f00\u6e90\u6570\u636e\u4e0e\u6392\u884c\u699c\u3002", "motivation": "\u63d0\u4f9b\u4e00\u4e2a\u5168\u9762\u3001\u4e00\u81f4\u7684\u57fa\u51c6\u6765\u8bc4\u4f30LLM\u5728\u56fd\u9645\u8c61\u68cb\u9886\u57df\u7684\u7406\u89e3\u80fd\u529b\uff0c\u5f25\u8865\u73b0\u6709\u8bc4\u4f30\u7684\u96f6\u6563\u548c\u72ed\u9698\u6027\uff0c\u80fd\u968f\u7740\u6a21\u578b\u8fdb\u6b65\u52a8\u6001\u66f4\u65b0\u3002", "method": "\u8bbe\u8ba1\u4e94\u7c7b\u4efb\u52a1\u5bf9\u5e94\u68cb\u624b\u9010\u6b65\u638c\u63e1\u7684\u62bd\u8c61\u80fd\u529b\uff0c\u6784\u5efa\u53ef\u66f4\u65b0\u7684\u6570\u636e\u96c6\u3001\u63d0\u793a\u4e0e\u7b54\u6848\u811a\u672c\uff0c\u5e76\u5728\u591a\u6b3e\u5f53\u4ee3LLM\u4e0a\u8fd0\u884c\u8bc4\u6d4b\u4e0e\u8bef\u5dee\u5206\u6790\uff0c\u63d0\u4f9b\u4ee3\u7801\u548c\u6392\u884c\u699c\u4ee5\u4fbf\u540e\u7eed\u7814\u7a76\u3002", "result": "\u63d0\u51faChessQA\u57fa\u51c6\uff0c\u6db5\u76d6\u7ed3\u6784\u3001\u5175\u5f62\u52a8\u673a\u3001\u77ed\u6218\u672f\u3001\u5c40\u9762\u5224\u65ad\u3001\u8bed\u4e49\u4e94\u7c7b\u4efb\u52a1\uff0c\u63d0\u4f9b\u811a\u672c\u3001\u63d0\u793a\u548c\u7b54\u6848\u53ef\u52a8\u6001\u5237\u65b0\uff0c\u5e76\u5bf9\u591a\u6b3e\u5f53\u4ee3LLM\u8fdb\u884c\u8bc4\u4f30\uff0c\u53d1\u73b0\u5404\u7c7b\u6301\u7eed\u5f31\u70b9\uff0c\u9644\u5e26\u7c7b\u522b\u7ea7\u8bef\u5dee\u5206\u6790\u4e0e\u516c\u5f00\u53d1\u5e03\u8ba1\u5212\u3002", "conclusion": "ChessQA\u80fd\u66f4\u5168\u9762\u8bca\u65adLLM\u7684\u68cb\u529b\u4e0e\u7406\u89e3\u5dee\u8ddd\uff0c\u652f\u6301\u6301\u7eed\u66f4\u65b0\u548c\u793e\u533a\u6bd4\u8f83\uff0c\u63ed\u793a\u6a21\u578b\u5728\u4e0d\u540c\u62bd\u8c61\u5c42\u9762\u4e0a\u7684\u7cfb\u7edf\u6027\u5f31\u70b9\u3002"}}
{"id": "2510.23966", "categories": ["cs.LG", "cs.SE"], "pdf": "https://arxiv.org/pdf/2510.23966", "abs": "https://arxiv.org/abs/2510.23966", "authors": ["Scott Emmons", "Roland S. Zimmermann", "David K. Elson", "Rohin Shah"], "title": "A Pragmatic Way to Measure Chain-of-Thought Monitorability", "comment": "The first two authors contributed equally", "summary": "While Chain-of-Thought (CoT) monitoring offers a unique opportunity for AI\nsafety, this opportunity could be lost through shifts in training practices or\nmodel architecture. To help preserve monitorability, we propose a pragmatic way\nto measure two components of it: legibility (whether the reasoning can be\nfollowed by a human) and coverage (whether the CoT contains all the reasoning\nneeded for a human to also produce the final output). We implement these\nmetrics with an autorater prompt that enables any capable LLM to compute the\nlegibility and coverage of existing CoTs. After sanity-checking our prompted\nautorater with synthetic CoT degradations, we apply it to several frontier\nmodels on challenging benchmarks, finding that they exhibit high\nmonitorability. We present these metrics, including our complete autorater\nprompt, as a tool for developers to track how design decisions impact\nmonitorability. While the exact prompt we share is still a preliminary version\nunder ongoing development, we are sharing it now in the hopes that others in\nthe community will find it useful. Our method helps measure the default\nmonitorability of CoT - it should be seen as a complement, not a replacement,\nfor the adversarial stress-testing needed to test robustness against\ndeliberately evasive models.", "AI": {"tldr": "\u63d0\u51fa\u53ef\u6d4b\u91cfCoT\u53ef\u76d1\u63a7\u6027\u7684\u4e24\u9879\u6307\u6807\uff1a\u53ef\u8bfb\u6027\u4e0e\u8986\u76d6\u7387\uff0c\u4f7f\u7528\u81ea\u52a8\u8bc4\u5206\u63d0\u793a(prompt)\u7531\u5f3a\u5927LLM\u8bc4\u4f30CoT\uff0c\u7ecf\u5408\u6210\u964d\u7ea7\u9a8c\u8bc1\u5e76\u5728\u524d\u6cbf\u6a21\u578b\u4e0a\u6d4b\u8bd5\uff0c\u53d1\u73b0\u9ad8\u53ef\u76d1\u63a7\u6027\uff1b\u63d0\u4f9b\u63d0\u793a\u4e0e\u65b9\u6cd5\u4f9b\u5f00\u53d1\u8005\u8ddf\u8e2a\u8bbe\u8ba1\u5f71\u54cd\uff0c\u4f46\u975e\u66ff\u4ee3\u5bf9\u6297\u6d4b\u8bd5\u3002", "motivation": "\u9632\u6b62\u8bad\u7ec3\u6216\u67b6\u6784\u6539\u53d8\u5bfc\u81f4\u5931\u53bb\u5bf9\u94fe\u5f0f\u601d\u8003\u7684\u76d1\u63a7\u80fd\u529b\uff0c\u63d0\u4f9b\u53ef\u64cd\u4f5c\u7684\u5ea6\u91cf\u4e0e\u5de5\u5177\u4ee5\u4fdd\u6301\u76d1\u63a7\u6027\u3002", "method": "\u5b9a\u4e49legibility\u4e0ecoverage\u6307\u6807\uff0c\u8bbe\u8ba1\u5e76\u5206\u4eab\u4e00\u4e2aautorater\u63d0\u793a\u4ee5\u8ba9LLM\u8bc4\u4f30CoT\uff0c\u5bf9\u5408\u6210\u9000\u5316\u6837\u672c\u8fdb\u884c\u68c0\u9a8c\uff0c\u518d\u5728\u591a\u4e2a\u524d\u6cbf\u6a21\u578b\u4e0e\u57fa\u51c6\u4e0a\u5e94\u7528\uff0c\u8f93\u51fa\u8bc4\u5206\u5206\u6790\u3002", "result": "They propose measures for monitorability: legibility and coverage; implement via autorater prompt enabling LLM to rate CoTs; sanity-checked with synthetic degradations; applied to frontier models showing high monitorability; provide prompt as tool; emphasize complement to adversarial testing.", "conclusion": "\u6240\u63d0\u6307\u6807\u4e0e\u81ea\u52a8\u8bc4\u5206\u63d0\u793a\u4e3a\u4fdd\u7559\u4e0e\u8ddf\u8e2aCoT\u53ef\u76d1\u63a7\u6027\u63d0\u4f9b\u5b9e\u7528\u5de5\u5177\uff0c\u5f53\u524d\u4e3a\u521d\u6b65\u7248\u672c\uff0c\u5e94\u7ed3\u5408\u5bf9\u6297\u6027\u538b\u529b\u6d4b\u8bd5\u4f7f\u7528\u3002"}}
{"id": "2510.23972", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23972", "abs": "https://arxiv.org/abs/2510.23972", "authors": ["Andra\u017e Jelin\u010di\u010d", "Owen Lockwood", "Akhil Garlapati", "Guillaume Verdon", "Trevor McCourt"], "title": "An efficient probabilistic hardware architecture for diffusion-like models", "comment": "9 pages, 6 figures", "summary": "The proliferation of probabilistic AI has promoted proposals for specialized\nstochastic computers. Despite promising efficiency gains, these proposals have\nfailed to gain traction because they rely on fundamentally limited modeling\ntechniques and exotic, unscalable hardware. In this work, we address these\nshortcomings by proposing an all-transistor probabilistic computer that\nimplements powerful denoising models at the hardware level. A system-level\nanalysis indicates that devices based on our architecture could achieve\nperformance parity with GPUs on a simple image benchmark using approximately\n10,000 times less energy.", "AI": {"tldr": "\u8be5\u6587\u63d0\u51fa\u4e00\u79cd\u5168\u90e8\u4f7f\u7528\u6676\u4f53\u7ba1\u5b9e\u73b0\u7684\u6982\u7387\u8ba1\u7b97\u673a\u67b6\u6784\uff0c\u5728\u786c\u4ef6\u5c42\u76f4\u63a5\u5b9e\u73b0\u5f3a\u5927\u7684\u53bb\u566a\u6a21\u578b\uff0c\u4ece\u800c\u4fdd\u7559\u6982\u7387AI\u7684\u4f18\u52bf\u540c\u65f6\u907f\u5f00\u4ee5\u5f80\u65b9\u6848\u7684\u5c40\u9650\u3002\u7cfb\u7edf\u5206\u6790\u663e\u793a\uff0c\u8be5\u67b6\u6784\u5728\u7c21\u5355\u56fe\u50cf\u57fa\u51c6\u4e0a\u80fd\u4ee5\u7ea61\u4e07\u500d\u66f4\u4f4e\u7684\u80fd\u8017\u5b9e\u73b0\u4e0eGPU\u6027\u80fd\u6301\u5e73\u3002", "motivation": "\u9488\u5bf9\u73b0\u6709\u6982\u7387\u8ba1\u7b97\u673a\u4f9d\u8d56\u53d7\u9650\u5efa\u6a21\u624b\u6bb5\u548c\u4e0d\u53ef\u6269\u5c55\u7684\u5f02\u8d28\u786c\u4ef6\uff0c\u63d0\u51fa\u4e00\u79cd\u66f4\u901a\u7528\u3001\u53ef\u6269\u5c55\u4e14\u80fd\u6548\u9ad8\u7684\u672c\u5f81\u6982\u7387\u8ba1\u7b97\u786c\u4ef6\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u79cd\u652f\u6301\u53bb\u566a\u6a21\u578b\u786c\u4ef6\u5b9e\u73b0\u7684\u6676\u4f53\u7ba1\u67b6\u6784\uff0c\u7ed3\u5408\u7cfb\u7edf\u7ea7\u6a21\u62df\u548c\u57fa\u51c6\u6d4b\u8bd5\u8bc4\u4f30\u6027\u80fd\u4e0e\u80fd\u8017\uff0c\u6bd4\u8f83\u4e86\u4e0e\u73b0\u6709GPU\u7684\u80fd\u6548\u4e0e\u8ba1\u7b97\u6027\u80fd\u3002", "result": "\u7cfb\u7edf\u7ea7\u5206\u6790\u548c\u56fe\u50cf\u57fa\u51c6\u6d4b\u8bd5\u8868\u660e\uff0c\u8be5\u67b6\u6784\u5728\u6027\u80fd\u4e0eGPU\u53ef\u6bd4\u7684\u524d\u63d0\u4e0b\uff0c\u80fd\u8017\u964d\u4f4e\u7ea64\u4e2a\u6570\u91cf\u7ea7\uff08\u7ea610,000\u500d\uff09\u3002", "conclusion": "\u4f5c\u8005\u63d0\u51fa\u7684\u5168\u6676\u4f53\u7ba1\u6982\u7387\u8ba1\u7b97\u673a\u5728\u80fd\u8017\u4e0a\u663e\u8457\u4f18\u4e8eGPU\uff0c\u5e76\u80fd\u5b9e\u73b0\u5728\u786c\u4ef6\u5c42\u8fd0\u884c\u5f3a\u5927\u7684\u53bb\u566a\u6a21\u578b\uff0c\u8868\u660e\u53ef\u884c\u4e14\u9ad8\u6548\u3002"}}
{"id": "2510.23974", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23974", "abs": "https://arxiv.org/abs/2510.23974", "authors": ["Byeonghu Na", "Minsang Park", "Gyuwon Sim", "Donghyeok Shin", "HeeSun Bae", "Mina Kang", "Se Jung Kwon", "Wanmo Kang", "Il-Chul Moon"], "title": "Diffusion Adaptive Text Embedding for Text-to-Image Diffusion Models", "comment": "Accepted at NeurIPS 2025", "summary": "Text-to-image diffusion models rely on text embeddings from a pre-trained\ntext encoder, but these embeddings remain fixed across all diffusion timesteps,\nlimiting their adaptability to the generative process. We propose Diffusion\nAdaptive Text Embedding (DATE), which dynamically updates text embeddings at\neach diffusion timestep based on intermediate perturbed data. We formulate an\noptimization problem and derive an update rule that refines the text embeddings\nat each sampling step to improve alignment and preference between the mean\npredicted image and the text. This allows DATE to dynamically adapts the text\nconditions to the reverse-diffused images throughout diffusion sampling without\nrequiring additional model training. Through theoretical analysis and empirical\nresults, we show that DATE maintains the generative capability of the model\nwhile providing superior text-image alignment over fixed text embeddings across\nvarious tasks, including multi-concept generation and text-guided image\nediting. Our code is available at https://github.com/aailab-kaist/DATE.", "AI": {"tldr": "DATE\u5728\u91c7\u6837\u9636\u6bb5\u52a8\u6001\u4f18\u5316\u6587\u672c\u5d4c\u5165\uff0c\u65e0\u9700\u91cd\u8bad\uff0c\u5373\u65f6\u589e\u5f3a\u6587\u672c\u4e0e\u56fe\u50cf\u7684\u5339\u914d\uff0c\u63d0\u5347\u591a\u6982\u5ff5\u4e0e\u7f16\u8f91\u4efb\u52a1\u8868\u73b0\u3002", "motivation": "\u56fa\u5b9a\u7684\u6587\u672c\u5d4c\u5165\u65e0\u6cd5\u968f\u6269\u6563\u8fc7\u7a0b\u81ea\u9002\u5e94\uff0c\u9650\u5236\u4e86\u6587\u672c\u6761\u4ef6\u4e0e\u751f\u6210\u56fe\u50cf\u4e4b\u95f4\u7684\u4e00\u81f4\u6027\u4e0e\u504f\u597d\u5bf9\u9f50\u3002", "method": "\u5728\u91c7\u6837\u65f6\u57fa\u4e8e\u4e2d\u95f4\u6270\u52a8\u56fe\u50cf\u6784\u5efa\u4f18\u5316\u95ee\u9898\uff0c\u63a8\u5bfc\u51fa\u4e00\u6b65\u66f4\u65b0\u89c4\u5219\u7528\u4e8e\u7cbe\u70bc\u6587\u672c\u5d4c\u5165\uff0c\u5e76\u5728\u53cd\u5411\u6269\u6563\u8fc7\u7a0b\u4e2d\u9010\u6b65\u8c03\u6574\u6587\u672c\u6761\u4ef6\uff0c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u3002", "result": "\u7406\u8bba\u5206\u6790\u4e0e\u5b9e\u9a8c\u8bc1\u660e\uff0cDATE\u5728\u591a\u6982\u5ff5\u751f\u6210\u548c\u6587\u672c\u5f15\u5bfc\u56fe\u50cf\u7f16\u8f91\u7b49\u4efb\u52a1\u4e0a\uff0c\u6bd4\u56fa\u5b9a\u6587\u672c\u5d4c\u5165\u63d0\u4f9b\u66f4\u597d\u7684\u6587\u672c-\u56fe\u50cf\u5bf9\u9f50\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u751f\u6210\u80fd\u529b\u3002", "conclusion": "DATE\u901a\u8fc7\u5728\u6bcf\u4e2a\u6269\u6563\u65f6\u95f4\u6b65\u52a8\u6001\u66f4\u65b0\u6587\u672c\u5d4c\u5165\uff0c\u63d0\u9ad8\u4e86\u6587\u672c-\u56fe\u50cf\u5bf9\u9f50\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u751f\u6210\u6a21\u578b\u7684\u80fd\u529b\u3002"}}
{"id": "2510.23977", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.23977", "abs": "https://arxiv.org/abs/2510.23977", "authors": ["Yohan Abeysinghe", "Muhammad Akhtar Munir", "Sanoojan Baliah", "Ron Sarafian", "Fahad Shahbaz Khan", "Yinon Rudich", "Salman Khan"], "title": "Synergistic Neural Forecasting of Air Pollution with Stochastic Sampling", "comment": null, "summary": "Air pollution remains a leading global health and environmental risk,\nparticularly in regions vulnerable to episodic air pollution spikes due to\nwildfires, urban haze and dust storms. Accurate forecasting of particulate\nmatter (PM) concentrations is essential to enable timely public health warnings\nand interventions, yet existing models often underestimate rare but hazardous\npollution events. Here, we present SynCast, a high-resolution neural\nforecasting model that integrates meteorological and air composition data to\nimprove predictions of both average and extreme pollution levels. Built on a\nregionally adapted transformer backbone and enhanced with a diffusion-based\nstochastic refinement module, SynCast captures the nonlinear dynamics driving\nPM spikes more accurately than existing approaches. Leveraging on harmonized\nERA5 and CAMS datasets, our model shows substantial gains in forecasting\nfidelity across multiple PM variables (PM$_1$, PM$_{2.5}$, PM$_{10}$),\nespecially under extreme conditions. We demonstrate that conventional loss\nfunctions underrepresent distributional tails (rare pollution events) and show\nthat SynCast, guided by domain-aware objectives and extreme value theory,\nsignificantly enhances performance in highly impacted regions without\ncompromising global accuracy. This approach provides a scalable foundation for\nnext-generation air quality early warning systems and supports climate-health\nrisk mitigation in vulnerable regions.", "AI": {"tldr": "SynCast \u7528\u533a\u57df\u5316 transformer + \u6269\u6563\u968f\u673a\u7cbe\u5316\uff0c\u5e76\u7ed3\u5408\u6781\u503c\u7406\u8bba\u4e0e\u9886\u57df\u611f\u77e5\u635f\u5931\uff0c\u663e\u8457\u6539\u5584\u4e86 PM \u6781\u7aef\u4e8b\u4ef6\u7684\u9884\u62a5\uff0c\u9002\u5408\u7528\u4e8e\u7a7a\u6c14\u8d28\u91cf\u9884\u8b66\u7cfb\u7edf\u3002", "motivation": "\u73b0\u6709\u6a21\u578b\u5e38\u4f4e\u4f30\u7f55\u89c1\u4f46\u5371\u5bb3\u5927\u7684\u6c61\u67d3\u5cf0\u503c\uff0c\u9700\u63d0\u9ad8\u5bf9\u6781\u7aef\u6c61\u67d3\u4e8b\u4ef6\u7684\u9884\u6d4b\u80fd\u529b\u4ee5\u652f\u6301\u53ca\u65f6\u516c\u5171\u5065\u5eb7\u9884\u8b66\u3002", "method": "\u57fa\u4e8e\u533a\u57df\u9002\u914d\u7684 transformer \u4e3b\u5e72\u7f51\u7edc\uff0c\u7ed3\u5408\u57fa\u4e8e\u6269\u6563\u7684\u968f\u673a\u7cbe\u5316\u6a21\u5757\uff1b\u4f7f\u7528 ERA5 \u4e0e CAMS \u6570\u636e\u7684\u878d\u5408\u8f93\u5165\uff1b\u91c7\u7528\u9886\u57df\u611f\u77e5\u76ee\u6807\u51fd\u6570\u5e76\u7ed3\u5408\u6781\u503c\u7406\u8bba\u8fdb\u884c\u8bad\u7ec3\u3002", "result": "\u5728 PM1\u3001PM2.5\u3001PM10 \u7b49\u591a\u79cd\u53d8\u91cf\u4e0a\u5bf9\u6781\u7aef\u6761\u4ef6\u4e0b\u7684\u9884\u6d4b\u6709\u663e\u8457\u6539\u8fdb\uff0c\u5728\u9ad8\u5ea6\u53d7\u5f71\u54cd\u533a\u57df\u8868\u73b0\u63d0\u5347\u660e\u663e\u4e14\u672a\u635f\u5bb3\u6574\u4f53\u7cbe\u5ea6\u3002", "conclusion": "SynCast \u663e\u8457\u63d0\u5347\u4e86\u7a7a\u6c14\u9897\u7c92\u7269\u6d53\u5ea6\u7684\u6781\u7aef\u503c\u548c\u5e73\u5747\u503c\u9884\u6d4b\u80fd\u529b\uff0c\u4e3a\u7a7a\u6c14\u8d28\u91cf\u9884\u8b66\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u57fa\u7840\u3002"}}
{"id": "2510.23980", "categories": ["cs.LG", "cs.AI", "cs.NE"], "pdf": "https://arxiv.org/pdf/2510.23980", "abs": "https://arxiv.org/abs/2510.23980", "authors": ["Guojing Cong", "Tom Potok", "Hamed Poursiami", "Maryam Parsa"], "title": "HyperGraphX: Graph Transductive Learning with Hyperdimensional Computing and Message Passing", "comment": null, "summary": "We present a novel algorithm, \\hdgc, that marries graph convolution with\nbinding and bundling operations in hyperdimensional computing for transductive\ngraph learning. For prediction accuracy \\hdgc outperforms major and popular\ngraph neural network implementations as well as state-of-the-art\nhyperdimensional computing implementations for a collection of homophilic\ngraphs and heterophilic graphs. Compared with the most accurate learning\nmethodologies we have tested, on the same target GPU platform, \\hdgc is on\naverage 9561.0 and 144.5 times faster than \\gcnii, a graph neural network\nimplementation and HDGL, a hyperdimensional computing implementation,\nrespectively. As the majority of the learning operates on binary vectors, we\nexpect outstanding energy performance of \\hdgc on neuromorphic and emerging\nprocess-in-memory devices.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a HDGC \u7684\u65b0\u7b97\u6cd5\uff0c\u5c06\u56fe\u5377\u79ef\u4e0e\u8d85\u7ef4\u8ba1\u7b97\uff08binding \u548c bundling\uff09\u7ed3\u5408\uff0c\u7528\u4e8e\u4f20\u9012\u5f0f\u56fe\u5b66\u4e60\u3002\u5728\u591a\u79cd\u540c\u6e90\u548c\u5f02\u6e90\u56fe\u4e0a\uff0cHDGC \u5728\u9884\u6d4b\u51c6\u786e\u7387\u4e0a\u4f18\u4e8e\u4e3b\u6d41 GNN \u548c\u73b0\u6709 HD \u5b9e\u73b0\uff1b\u5728\u540c\u4e00 GPU \u5e73\u53f0\u4e0a\uff0cHDGC \u6bd4\u6700\u51c6\u786e\u7684\u65b9\u6cd5\u5e73\u5747\u5feb 9561\u00d7\uff08\u4e0e GCNII\uff09\u548c 144.5\u00d7\uff08\u4e0e HDGL\uff09\u3002\u7531\u4e8e\u5927\u90e8\u5206\u8fd0\u7b97\u662f\u5728\u4e8c\u503c\u5411\u91cf\u4e0a\u8fdb\u884c\uff0cHDGC \u5728\u7c7b\u8111\u6216\u5b58\u5185\u8ba1\u7b97\u786c\u4ef6\u4e0a\u6709\u5f88\u597d\u7684\u80fd\u6548\u6f5c\u529b\u3002", "motivation": "\u901a\u8fc7\u878d\u5408\u56fe\u795e\u7ecf\u7f51\u7edc\u7684\u8868\u8fbe\u80fd\u529b\u4e0e\u8d85\u7ef4\u8ba1\u7b97\u7684\u9ad8\u6548\u4e8c\u503c\u8fd0\u7b97\uff0c\u5bfb\u6c42\u5728\u51c6\u786e\u7387\u4e0e\u8ba1\u7b97/\u80fd\u8017\u6548\u7387\u4e4b\u95f4\u53d6\u5f97\u66f4\u597d\u5e73\u8861\u3002", "method": "\u5c06\u56fe\u5377\u79ef\u4e0e\u8d85\u7ef4\u8ba1\u7b97\u4e2d\u7684 bind\uff08\u7ed1\u5b9a\uff09\u548c bundle\uff08\u6346\u7ed1\uff09\u64cd\u4f5c\u7ed3\u5408\uff0c\u5f62\u6210\u7528\u4e8e\u4f20\u9012\u5f0f\uff08transductive\uff09\u56fe\u5b66\u4e60\u7684\u7b97\u6cd5\uff1b\u5927\u91cf\u8fd0\u7b97\u5728\u4e8c\u503c\u9ad8\u7ef4\u5411\u91cf\u4e0a\u8fdb\u884c\u4ee5\u63d0\u9ad8\u6548\u7387\u3002", "result": "\u5728\u540c\u6e90\u548c\u5f02\u6e90\u56fe\u6570\u636e\u96c6\u4e0a\uff0cHDGC \u5728\u51c6\u786e\u7387\u4e0a\u4f18\u4e8e\u4e3b\u6d41 GNN \u548c HD \u65b9\u6cd5\uff1b\u5728 GPU \u4e0a\u6bd4 GCNII \u5feb\u7ea6 9561 \u500d\uff0c\u6bd4 HDGL \u5feb\u7ea6 144.5 \u500d\uff1b\u6697\u793a\u5728 neuromorphic \u4e0e PIM \u786c\u4ef6\u4e0a\u5177\u4f18\u5f02\u80fd\u6548\u3002", "conclusion": "HDGC \u5728\u51c6\u786e\u7387\u548c\u901f\u5ea6\u4e0a\u5747\u8d85\u8d8a\u4e86\u6240\u6bd4\u8f83\u7684 GNN \u4e0e HD \u65b9\u6cd5\uff0c\u5e76\u9002\u5408\u80fd\u6548\u654f\u611f\u7684\u786c\u4ef6\u52a0\u901f\u3002"}}
{"id": "2510.23986", "categories": ["cs.LG", "cs.AI", "cs.NA", "math.NA"], "pdf": "https://arxiv.org/pdf/2510.23986", "abs": "https://arxiv.org/abs/2510.23986", "authors": ["Hong Wang", "Jiang Yixuan", "Jie Wang", "Xinyi Li", "Jian Luo", "Huanshuo Dong"], "title": "STNet: Spectral Transformation Network for Solving Operator Eigenvalue Problem", "comment": null, "summary": "Operator eigenvalue problems play a critical role in various scientific\nfields and engineering applications, yet numerical methods are hindered by the\ncurse of dimensionality. Recent deep learning methods provide an efficient\napproach to address this challenge by iteratively updating neural networks.\nThese methods' performance relies heavily on the spectral distribution of the\ngiven operator: larger gaps between the operator's eigenvalues will improve\nprecision, thus tailored spectral transformations that leverage the spectral\ndistribution can enhance their performance. Based on this observation, we\npropose the Spectral Transformation Network (STNet). During each iteration,\nSTNet uses approximate eigenvalues and eigenfunctions to perform spectral\ntransformations on the original operator, turning it into an equivalent but\neasier problem. Specifically, we employ deflation projection to exclude the\nsubspace corresponding to already solved eigenfunctions, thereby reducing the\nsearch space and avoiding converging to existing eigenfunctions. Additionally,\nour filter transform magnifies eigenvalues in the desired region and suppresses\nthose outside, further improving performance. Extensive experiments demonstrate\nthat STNet consistently outperforms existing learning-based methods, achieving\nstate-of-the-art performance in accuracy.", "AI": {"tldr": "STNet iteratively transforms operator using deflation and spectral filters based on learned approximate eigenpairs, making eigenvalue problems easier and improving accuracy.", "motivation": "Deep learning methods for operator eigenvalue problems struggle with curse of dimensionality and depend on operator spectral distribution; transforming the operator spectrum can improve convergence and precision.", "method": "Spectral Transformation Network (STNet)", "result": "STNet uses approximate eigenpairs each iteration to apply deflation projection and filter transforms, shrinking search space and amplifying desired eigenvalues, leading to state-of-the-art accuracy over prior learning-based methods.", "conclusion": "STNet effectively leverages spectral transformations (deflation and filtering) to improve neural-network-based eigenvalue solvers, outperforming existing methods in experiments."}}
{"id": "2510.23992", "categories": ["cs.LG", "cs.IT", "math.IT", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.23992", "abs": "https://arxiv.org/abs/2510.23992", "authors": ["Yuxiao Wen", "Yanjun Han", "Zhengyuan Zhou"], "title": "Optimal Arm Elimination Algorithms for Combinatorial Bandits", "comment": null, "summary": "Combinatorial bandits extend the classical bandit framework to settings where\nthe learner selects multiple arms in each round, motivated by applications such\nas online recommendation and assortment optimization. While extensions of upper\nconfidence bound (UCB) algorithms arise naturally in this context, adapting arm\nelimination methods has proved more challenging. We introduce a novel\nelimination scheme that partitions arms into three categories (confirmed,\nactive, and eliminated), and incorporates explicit exploration to update these\nsets. We demonstrate the efficacy of our algorithm in two settings: the\ncombinatorial multi-armed bandit with general graph feedback, and the\ncombinatorial linear contextual bandit. In both cases, our approach achieves\nnear-optimal regret, whereas UCB-based methods can provably fail due to\ninsufficient explicit exploration. Matching lower bounds are also provided.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u5c06\u81c2\u5212\u4e3aconfirmed/active/eliminated\u5e76\u5f15\u5165\u663e\u5f0f\u63a2\u7d22\u7684\u6dd8\u6c70\u7b97\u6cd5\uff0c\u5e94\u7528\u4e8e\u5e26\u4e00\u822c\u56fe\u53cd\u9988\u7684\u7ec4\u5408\u591a\u81c2\u548c\u7ec4\u5408\u7ebf\u6027\u4e0a\u4e0b\u6587\u81c2\uff0c\u83b7\u5f97\u8fd1\u6700\u4f18\u540e\u6094\u5e76\u7ed9\u51fa\u5339\u914d\u4e0b\u754c\uff0c\u89e3\u51b3\u4e86UCB\u6269\u5c55\u5728\u67d0\u4e9b\u573a\u666f\u63a2\u7d22\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "motivation": "\u5728\u7ec4\u5408\u81c2\u8bbe\u7f6e\u4e0b\uff0c\u76f4\u63a5\u63a8\u5e7fUCB\u65b9\u6cd5\u4f1a\u56e0\u7f3a\u4e4f\u663e\u5f0f\u63a2\u7d22\u800c\u5728\u67d0\u4e9b\u5b9e\u4f8b\u4e0a\u5931\u8d25\uff0c\u5c24\u5176\u662f\u5f53\u53cd\u9988\u7ed3\u6784\u6216\u4e0a\u4e0b\u6587\u76f8\u5173\u6027\u5bfc\u81f4\u4fe1\u606f\u65e0\u6cd5\u81ea\u7136\u8986\u76d6\u6240\u6709\u81c2\u65f6\u3002\u56e0\u800c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u663e\u5f0f\u63a7\u5236\u63a2\u7d22\u3001\u4fdd\u8bc1\u91cd\u8981\u81c2\u88ab\u533a\u5206\u548c\u6dd8\u6c70\u7684\u6dd8\u6c70\u5f0f\u65b9\u6cd5\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u79cd\u65b0\u7684\u6dd8\u6c70\u6846\u67b6\uff1a\u5728\u6bcf\u4e2a\u9636\u6bb5\u901a\u8fc7\u663e\u5f0f\u63a2\u7d22\u6536\u96c6\u4fe1\u606f\uff0c\u6839\u636e\u7f6e\u4fe1\u533a\u95f4\u5c06\u81c2\u5212\u5206\u4e3a\u4e09\u7c7b\uff08confirmed/active/eliminated\uff09\uff0c\u5e76\u5bf9active\u96c6\u5408\u8fdb\u884c\u8fdb\u4e00\u6b65\u8bd5\u9a8c\u6765\u51b3\u5b9a\u66f4\u65b0\u3002\u628a\u8be5\u6846\u67b6\u5e94\u7528\u5230\u4e24\u7c7b\u95ee\u9898\u4e2d\uff1a\u4e00\u662f\u5e26\u4e00\u822c\u56fe\u53cd\u9988\u7684\u7ec4\u5408\u591a\u81c2\u95ee\u9898\uff0c\u4e8c\u662f\u7ec4\u5408\u7ebf\u6027\u4e0a\u4e0b\u6587\u81c2\uff1b\u5206\u522b\u7ed9\u51fa\u7b97\u6cd5\u7ec6\u8282\u3001\u7f6e\u4fe1\u754c\u4f30\u8ba1\u548c\u63a2\u7d22\u7b56\u7565\uff0c\u5e76\u8fdb\u884c\u7406\u8bba\u5206\u6790\u5f97\u5230\u4e0a\u754c\u3002", "result": "\u63d0\u51fa\u7684\u7b97\u6cd5\u5728\u4e24\u7c7b\u7ec4\u5408\u5e26\u80cc\u666f\u4e0b\u5747\u83b7\u5f97\u8fd1\u6700\u4f18\u540e\u6094\u754c\uff08\u4e0a\u754c\uff09\uff0c\u6bd4\u4f20\u7edfUCB\u6269\u5c55\u5728\u53ef\u6784\u9020\u7684\u56f0\u96be\u5b9e\u4f8b\u4e0a\u8868\u73b0\u66f4\u597d\uff1b\u540c\u65f6\u8bc1\u660e\u4e86\u5339\u914d\u7684\u4e0b\u754c\uff0c\u8bf4\u660e\u7b97\u6cd5\u5728\u6e10\u8fd1\u610f\u4e49\u4e0a\u662f\u6700\u4f18\u7684\u3002\u5e76\u901a\u8fc7\u7406\u8bba\u8bc1\u660e\u5c55\u793a\u4e86\u663e\u5f0f\u63a2\u7d22\u5bf9\u907f\u514dUCB\u5931\u8d25\u7684\u5173\u952e\u6027\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u81c2\u6dd8\u6c70\uff08elimination\uff09\u65b9\u6848\uff0c\u901a\u8fc7\u5c06\u81c2\u5206\u4e3a\u201c\u786e\u8ba4\uff08confirmed\uff09\u201d\u3001\u201c\u6d3b\u8dc3\uff08active\uff09\u201d\u548c\u201c\u6dd8\u6c70\uff08eliminated\uff09\u201d\u4e09\u7c7b\uff0c\u5e76\u5f15\u5165\u663e\u5f0f\u63a2\u7d22\u6b65\u9aa4\u6765\u66f4\u65b0\u8fd9\u4e9b\u96c6\u5408\uff0c\u4ece\u800c\u514b\u670d\u4e86\u5c06\u4f20\u7edfUCB\u65b9\u6cd5\u76f4\u63a5\u63a8\u5e7f\u5230\u7ec4\u5408\u81c2\u95ee\u9898\u65f6\u7684\u63a2\u7d22\u4e0d\u8db3\u95ee\u9898\u3002\u4f5c\u8005\u8bc1\u660e\u4e86\u5728\u7ec4\u5408\u591a\u81c2\u5e26\u6709\u4e00\u822c\u56fe\u53cd\u9988\u548c\u7ec4\u5408\u7ebf\u6027\u4e0a\u4e0b\u6587\u81c2\u4e24\u79cd\u573a\u666f\u4e0b\uff0c\u8be5\u65b9\u6cd5\u80fd\u83b7\u5f97\u8fd1\u6700\u4f18\u7684\u7d2f\u79ef\u540e\u6094\uff08regret\uff09\uff0c\u5e76\u7ed9\u51fa\u4e86\u76f8\u5e94\u7684\u4e0b\u754c\uff0c\u8868\u660e\u5176\u6e10\u8fd1\u6700\u4f18\u6027\u3002"}}
{"id": "2510.23994", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.23994", "abs": "https://arxiv.org/abs/2510.23994", "authors": ["Geoffery Agorku", "Sarah Hernandez", "Hayley Hames", "Cade Wagner"], "title": "Predicting Barge Tow Size on Inland Waterways Using Vessel Trajectory Derived Features: Proof of Concept", "comment": null, "summary": "Accurate, real-time estimation of barge quantity on inland waterways remains\na critical challenge due to the non-self-propelled nature of barges and the\nlimitations of existing monitoring systems. This study introduces a novel\nmethod to use Automatic Identification System (AIS) vessel tracking data to\npredict the number of barges in tow using Machine Learning (ML). To train and\ntest the model, barge instances were manually annotated from satellite scenes\nacross the Lower Mississippi River. Labeled images were matched to AIS vessel\ntracks using a spatiotemporal matching procedure. A comprehensive set of 30\nAIS-derived features capturing vessel geometry, dynamic movement, and\ntrajectory patterns were created and evaluated using Recursive Feature\nElimination (RFE) to identify the most predictive variables. Six regression\nmodels, including ensemble, kernel-based, and generalized linear approaches,\nwere trained and evaluated. The Poisson Regressor model yielded the best\nperformance, achieving a Mean Absolute Error (MAE) of 1.92 barges using 12 of\nthe 30 features. The feature importance analysis revealed that metrics\ncapturing vessel maneuverability such as course entropy, speed variability and\ntrip length were most predictive of barge count. The proposed approach provides\na scalable, readily implementable method for enhancing Maritime Domain\nAwareness (MDA), with strong potential applications in lock scheduling, port\nmanagement, and freight planning. Future work will expand the proof of concept\npresented here to explore model transferability to other inland rivers with\ndiffering operational and environmental conditions.", "AI": {"tldr": "Using AIS-derived features and ML (best: Poisson Regressor), the study predicts barge counts with MAE 1.92; maneuverability metrics are most predictive.", "motivation": "Develop a scalable method to estimate number of barges in tow on inland waterways using AIS data and machine learning, addressing limitations of current monitoring due to barges being unpropelled.", "method": "Manually labeled barges from satellite imagery matched to AIS tracks; 30 AIS features computed; RFE selected top features; trained six regression models and evaluated performance; Poisson Regressor best.", "result": "Poisson Regressor achieved best performance with MAE 1.92 barges using 12 selected AIS-derived features; key predictive features include course entropy, speed variability, and trip length.", "conclusion": "The approach offers a scalable method to improve maritime domain awareness and operational planning; future work should test transferability to other rivers."}}
{"id": "2510.24012", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24012", "abs": "https://arxiv.org/abs/2510.24012", "authors": ["Byeonghu Na", "Mina Kang", "Jiseok Kwak", "Minsang Park", "Jiwoo Shin", "SeJoon Jun", "Gayoung Lee", "Jin-Hwa Kim", "Il-Chul Moon"], "title": "Training-Free Safe Text Embedding Guidance for Text-to-Image Diffusion Models", "comment": "Accepted at NeurIPS 2025", "summary": "Text-to-image models have recently made significant advances in generating\nrealistic and semantically coherent images, driven by advanced diffusion models\nand large-scale web-crawled datasets. However, these datasets often contain\ninappropriate or biased content, raising concerns about the generation of\nharmful outputs when provided with malicious text prompts. We propose Safe Text\nembedding Guidance (STG), a training-free approach to improve the safety of\ndiffusion models by guiding the text embeddings during sampling. STG adjusts\nthe text embeddings based on a safety function evaluated on the expected final\ndenoised image, allowing the model to generate safer outputs without additional\ntraining. Theoretically, we show that STG aligns the underlying model\ndistribution with safety constraints, thereby achieving safer outputs while\nminimally affecting generation quality. Experiments on various safety\nscenarios, including nudity, violence, and artist-style removal, show that STG\nconsistently outperforms both training-based and training-free baselines in\nremoving unsafe content while preserving the core semantic intent of input\nprompts. Our code is available at https://github.com/aailab-kaist/STG.", "AI": {"tldr": "STG steers text embeddings at sampling time using a safety score on expected denoised images to reduce harmful outputs without retraining, aligning model distribution to safety constraints with minimal quality loss", "motivation": "Prevent generation of unsafe or biased content from text-to-image diffusion models without additional training", "method": "STG-guidance for diffusion models", "result": "A training-free algorithm that adjusts text embeddings during sampling based on a safety function evaluated on expected final denoised image, showing improved safety across nudity/violence/artist-style removal while preserving semantics", "conclusion": "STG effectively reduces unsafe content generation compared to baselines, is training-free, theoretically justified, and preserves semantic intent; code released"}}
{"id": "2510.24025", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24025", "abs": "https://arxiv.org/abs/2510.24025", "authors": ["Guo Tianqi Guo", "Chen Liping", "Peng Ciyuan", "Guo Jingjing", "Ren Jing"], "title": "NeuroPathNet: Dynamic Path Trajectory Learning for Brain Functional Connectivity Analysis", "comment": null, "summary": "Understanding the evolution of brain functional networks over time is of\ngreat significance for the analysis of cognitive mechanisms and the diagnosis\nof neurological diseases. Existing methods often have difficulty in capturing\nthe temporal evolution characteristics of connections between specific\nfunctional communities. To this end, this paper proposes a new path-level\ntrajectory modeling framework (NeuroPathNet) to characterize the dynamic\nbehavior of connection pathways between brain functional partitions. Based on\nmedically supported static partitioning schemes (such as Yeo and Smith ICA), we\nextract the time series of connection strengths between each pair of functional\npartitions and model them using a temporal neural network. We validate the\nmodel performance on three public functional Magnetic Resonance Imaging (fMRI)\ndatasets, and the results show that it outperforms existing mainstream methods\nin multiple indicators. This study can promote the development of dynamic graph\nlearning methods for brain network analysis, and provide possible clinical\napplications for the diagnosis of neurological diseases.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faNeuroPathNet\uff0c\u4e00\u79cd\u57fa\u4e8e\u5206\u533a\u5bf9\u4e4b\u95f4\u8def\u5f84\u7ea7\u8f68\u8ff9\u5efa\u6a21\u7684\u52a8\u6001\u8111\u529f\u80fd\u7f51\u7edc\u5206\u6790\u6846\u67b6\u3002\u901a\u8fc7\u91c7\u7528\u533b\u5b66\u652f\u6301\u7684\u9759\u6001\u5206\u533a\uff08\u5982Yeo\u3001Smith ICA\uff09\uff0c\u63d0\u53d6\u5404\u5206\u533a\u5bf9\u95f4\u8fde\u63a5\u5f3a\u5ea6\u968f\u65f6\u95f4\u7684\u5e8f\u5217\uff0c\u5e76\u7528\u65f6\u5e8f\u795e\u7ecf\u7f51\u7edc\u5efa\u6a21\uff0c\u4ee5\u66f4\u597d\u6355\u6349\u529f\u80fd\u5b50\u7f51\u7edc\u95f4\u8fde\u63a5\u6f14\u5316\u3002\u5b9e\u9a8c\u8bc1\u660e\u5728\u4e09\u4e2a\u516c\u5f00fMRI\u6570\u636e\u96c6\u4e0a\u591a\u9879\u6307\u6807\u4f18\u4e8e\u4e3b\u6d41\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u6355\u6349\u7279\u5b9a\u529f\u80fd\u5b50\u7f51\u7edc\uff08\u5206\u533a\uff09\u4e4b\u95f4\u8fde\u901a\u6027\u7684\u65f6\u95f4\u6f14\u5316\uff0c\u7279\u522b\u662f\u5728\u8def\u5f84\u7ea7\u522b\u7684\u52a8\u6001\u884c\u4e3a\uff0c\u56e0\u6b64\u63d0\u51fa\u4e00\u79cd\u9488\u5bf9\u5206\u533a\u5bf9\u4e4b\u95f4\u8def\u5f84\u8f68\u8ff9\u5efa\u6a21\u7684\u6846\u67b6\u4ee5\u589e\u5f3a\u5bf9\u529f\u80fd\u6027\u8fde\u63a5\u52a8\u6001\u6027\u7684\u523b\u753b\u3002", "method": "\u57fa\u4e8e\u9884\u5b9a\u4e49\u533b\u5b66\u9759\u6001\u5206\u533a\uff0c\u8ba1\u7b97\u6bcf\u5bf9\u529f\u80fd\u5206\u533a\u95f4\u7684\u8fde\u63a5\u5f3a\u5ea6\u968f\u65f6\u95f4\u7684\u5e8f\u5217\uff08\u8def\u5f84\u7ea7\u65f6\u95f4\u5e8f\u5217\uff09\uff0c\u5c06\u8fd9\u4e9b\u5e8f\u5217\u8f93\u5165\u65f6\u5e8f\u795e\u7ecf\u7f51\u7edc\uff08\u53ef\u80fd\u5305\u62ecLSTM/Transformer\u7b49\uff09\u8fdb\u884c\u5efa\u6a21\uff0c\u6700\u540e\u8fdb\u884c\u9884\u6d4b\u6216\u4e0b\u6e38\u5206\u7c7b\u8bc4\u4f30\uff0c\u4e14\u5728\u4e09\u4e2afMRI\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u4e0e\u4e3b\u6d41\u52a8\u6001\u56fe\u5b66\u4e60\u65b9\u6cd5\u6bd4\u8f83\u3002", "result": "\u5728\u4e09\u4e2a\u516c\u5f00fMRI\u6570\u636e\u96c6\u4e0a\u7684\u591a\u9879\u6307\u6807\uff08\u53ef\u80fd\u5305\u62ec\u9884\u6d4b\u51c6\u786e\u7387\u3001AUC\u3001\u91cd\u6784\u8bef\u5dee\u7b49\uff09\u8d85\u8fc7\u73b0\u6709\u4e3b\u6d41\u65b9\u6cd5\uff0c\u8868\u660eNeuroPathNet\u5728\u6355\u6349\u5206\u533a\u5bf9\u95f4\u52a8\u6001\u8fde\u63a5\u65b9\u9762\u5177\u6709\u4f18\u52bf\u3002", "conclusion": "NeuroPathNet\u80fd\u66f4\u51c6\u786e\u5730\u523b\u753b\u5206\u533a\u95f4\u8fde\u63a5\u7684\u65f6\u95f4\u6f14\u5316\u7279\u5f81\uff0c\u4ece\u800c\u5728\u52a8\u6001\u8111\u7f51\u7edc\u5206\u6790\u4efb\u52a1\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5177\u6709\u6f5c\u5728\u4e34\u5e8a\u8bca\u65ad\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2510.24026", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24026", "abs": "https://arxiv.org/abs/2510.24026", "authors": ["Jiaqi Luo", "Shixin Xu", "Zhouwang Yang"], "title": "Efficient Global-Local Fusion Sampling for Physics-Informed Neural Networks", "comment": null, "summary": "The accuracy of Physics-Informed Neural Networks (PINNs) critically depends\non the placement of collocation points, as the PDE loss is approximated through\nsampling over the solution domain. Global sampling ensures stability by\ncovering the entire domain but requires many samples and is computationally\nexpensive, whereas local sampling improves efficiency by focusing on\nhigh-residual regions but may neglect well-learned areas, reducing robustness.\nWe propose a Global-Local Fusion (GLF) Sampling Strategy that combines the\nstrengths of both approaches. Specifically, new collocation points are\ngenerated by perturbing training points with Gaussian noise scaled inversely to\nthe residual, thereby concentrating samples in difficult regions while\npreserving exploration. To further reduce computational overhead, a lightweight\nlinear surrogate is introduced to approximate the global residual-based\ndistribution, achieving similar effectiveness at a fraction of the cost.\nTogether, these components, residual-adaptive sampling and residual-based\napproximation, preserve the stability of global methods while retaining the\nefficiency of local refinement. Extensive experiments on benchmark PDEs\ndemonstrate that GLF consistently improves both accuracy and efficiency\ncompared with global and local sampling strategies. This study provides a\npractical and scalable framework for enhancing the reliability and efficiency\nof PINNs in solving complex and high-dimensional PDEs.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cdGlobal-Local Fusion (GLF)\u91c7\u6837\u7b56\u7565\uff0c\u901a\u8fc7\u6309\u6b8b\u5dee\u53cd\u6bd4\u7f29\u653e\u7684\u9ad8\u65af\u6270\u52a8\u5728\u8bad\u7ec3\u70b9\u5468\u56f4\u751f\u6210\u65b0\u7684\u7f51\u683c\u70b9\uff0c\u5b9e\u73b0\u5bf9\u9ad8\u6b8b\u5dee\u533a\u57df\u96c6\u4e2d\u91c7\u6837\u540c\u65f6\u7ef4\u6301\u5168\u5c40\u8986\u76d6\uff1b\u5f15\u5165\u7ebf\u6027\u8f7b\u91cf\u4ee3\u7406\u8fd1\u4f3c\u6b8b\u5dee\u5206\u5e03\u4ee5\u964d\u4f4e\u5f00\u9500\u3002\u5b9e\u9a8c\u8bc1\u660e\u5728\u57fa\u51c6PDE\u4e0a\u6bd4\u5168\u5c40/\u5c40\u90e8\u91c7\u6837\u66f4\u51c6\u786e\u9ad8\u6548\uff0c\u9002\u7528\u4e8e\u590d\u6742\u9ad8\u7ef4PDE\u3002", "motivation": "\u5168\u5c40\u91c7\u6837\u867d\u7136\u7a33\u5b9a\u4f46\u6837\u672c\u6602\u8d35\uff0c\u5c40\u90e8\u91c7\u6837\u9ad8\u6548\u4f46\u53ef\u80fd\u5ffd\u7565\u5df2\u5b66\u597d\u7684\u533a\u57df\u5bfc\u81f4\u9c81\u68d2\u6027\u4e0b\u964d\uff0c\u6545\u9700\u4e00\u79cd\u517c\u987e\u7a33\u5b9a\u6027\u4e0e\u6548\u7387\u7684\u91c7\u6837\u7b56\u7565\u3002", "method": "\u5bf9\u8bad\u7ec3\u70b9\u8fdb\u884c\u57fa\u4e8e\u6b8b\u5dee\u7684\u9ad8\u65af\u6270\u52a8\u751f\u6210\u65b0\u7684collocation\u70b9\uff1a\u566a\u58f0\u6807\u51c6\u5dee\u4e0e\u70b9\u6b8b\u5dee\u6210\u53cd\u6bd4\uff0c\u4ece\u800c\u5728\u9ad8\u6b8b\u5dee\u533a\u57df\u751f\u6210\u66f4\u591a\u91c7\u6837\uff1b\u4e3a\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\uff0c\u7528\u4e00\u4e2a\u8f7b\u91cf\u7ebf\u6027\u4ee3\u7406\u8fd1\u4f3c\u5168\u5c40\u6b8b\u5dee\u5206\u5e03\u6765\u5f15\u5bfc\u91c7\u6837\u5206\u5e03\u3002", "result": "\u5728\u591a\u79cd\u57fa\u51c6PDE\u4e0a\uff0cGLF\u5728\u8bef\u5dee\u4e0e\u8bad\u7ec3\u65f6\u95f4\u4e0a\u5747\u4f18\u4e8e\u7eaf\u5168\u5c40\u4e0e\u7eaf\u5c40\u90e8\u91c7\u6837\uff0c\u663e\u793a\u51fa\u66f4\u9ad8\u7684\u6536\u655b\u901f\u5ea6\u548c\u8ba1\u7b97\u6548\u7387\u3002", "conclusion": "GLF\u901a\u8fc7\u6b8b\u5dee\u81ea\u9002\u5e94\u91c7\u6837\u4e0e\u6b8b\u5dee\u5206\u5e03\u8fd1\u4f3c\uff0c\u517c\u987e\u4e86\u5168\u5c40\u65b9\u6cd5\u7684\u7a33\u5b9a\u6027\u4e0e\u5c40\u90e8\u7ec6\u5316\u7684\u6548\u7387\uff0c\u663e\u8457\u63d0\u5347PINNs\u6c42\u89e3PDE\u7684\u51c6\u786e\u6027\u4e0e\u8ba1\u7b97\u6548\u7387\uff0c\u9002\u5408\u590d\u6742\u3001\u9ad8\u7ef4\u95ee\u9898\u3002"}}
{"id": "2510.24027", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24027", "abs": "https://arxiv.org/abs/2510.24027", "authors": ["Zibo Liu", "Zhe Jiang", "Zelin Xu", "Tingsong Xiao", "Yupu Zhang", "Zhengkun Xiao", "Haibo Wang", "Shigang Chen"], "title": "Spatio-temporal Multivariate Time Series Forecast with Chosen Variables", "comment": "In submission", "summary": "Spatio-Temporal Multivariate time series Forecast (STMF) uses the time series\nof $n$ spatially distributed variables in a period of recent past to forecast\ntheir values in a period of near future. It has important applications in\nspatio-temporal sensing forecast such as road traffic prediction and air\npollution prediction. Recent papers have addressed a practical problem of\nmissing variables in the model input, which arises in the sensing applications\nwhere the number $m$ of sensors is far less than the number $n$ of locations to\nbe monitored, due to budget constraints. We observe that the state of the art\nassumes that the $m$ variables (i.e., locations with sensors) in the model\ninput are pre-determined and the important problem of how to choose the $m$\nvariables in the input has never been studied. This paper fills the gap by\nstudying a new problem of STMF with chosen variables, which optimally selects\n$m$-out-of-$n$ variables for the model input in order to maximize the forecast\naccuracy. We propose a unified framework that jointly performs variable\nselection and model optimization for both forecast accuracy and model\nefficiency. It consists of three novel technical components: (1) masked\nvariable-parameter pruning, which progressively prunes less informative\nvariables and attention parameters through quantile-based masking; (2)\nprioritized variable-parameter replay, which replays low-loss past samples to\npreserve learned knowledge for model stability; (3) dynamic extrapolation\nmechanism, which propagates information from variables selected for the input\nto all other variables via learnable spatial embeddings and adjacency\ninformation. Experiments on five real-world datasets show that our work\nsignificantly outperforms the state-of-the-art baselines in both accuracy and\nefficiency, demonstrating the effectiveness of joint variable selection and\nmodel optimization.", "AI": {"tldr": "\u8be5\u6587\u9996\u6b21\u7814\u7a76\u5728\u8f93\u5165\u53d8\u91cf\u53ef\u9009\u7684STMF\u95ee\u9898\uff0c\u63d0\u51fa\u8054\u5408\u53d8\u91cf\u9009\u62e9\u4e0e\u6a21\u578b\u4f18\u5316\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u63a9\u7801\u526a\u679d\u3001\u4f18\u5148\u56de\u653e\u548c\u52a8\u6001\u5916\u63a8\u4e09\u9879\u6280\u672f\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u540c\u65f6\u63d0\u5347\u9884\u6d4b\u7cbe\u5ea6\u548c\u6548\u7387\u3002", "motivation": "\u73b0\u5b9e\u4f20\u611f\u573a\u666f\u4e2d\u4f20\u611f\u5668\u6570\u91cfm\u8fdc\u5c0f\u4e8e\u76d1\u6d4b\u4f4d\u7f6en\uff0c\u5982\u4f55\u4ecen\u4e2d\u9009\u62e9m\u4e2a\u4f20\u611f\u5668\u8f93\u5165\u4ee5\u6700\u5927\u5316\u77ed\u671f\u65f6\u7a7a\u591a\u53d8\u91cf\u9884\u6d4b\u51c6\u786e\u6027\u5c1a\u672a\u88ab\u7814\u7a76\uff0c\u6b64\u95ee\u9898\u5bf9\u4ea4\u901a\u3001\u7a7a\u6c14\u8d28\u91cf\u7b49\u5e94\u7528\u91cd\u8981\u3002", "method": "1) \u63a9\u7801\u53d8\u91cf-\u53c2\u6570\u526a\u679d\uff1a\u7528\u5206\u4f4d\u6570\u9608\u503c\u5bf9\u53d8\u91cf\u548c\u6ce8\u610f\u529b\u53c2\u6570\u8fdb\u884c\u9010\u6b65\u63a9\u7801\u4ee5\u526a\u679d\uff1b2) \u4f18\u5148\u53d8\u91cf-\u53c2\u6570\u56de\u653e\uff1a\u4fdd\u5b58\u5e76\u91cd\u653e\u4f4e\u635f\u6837\u672c\u4ee5\u7a33\u5b9a\u8bad\u7ec3\u5e76\u4fdd\u7559\u5df2\u5b66\u77e5\u8bc6\uff1b3) \u52a8\u6001\u5916\u63a8\u673a\u5236\uff1a\u901a\u8fc7\u5b66\u4e60\u7684\u7a7a\u95f4\u5d4c\u5165\u4e0e\u90bb\u63a5\u77e9\u9635\u5c06\u6240\u9009m\u4e2a\u53d8\u91cf\u7684\u4fe1\u606f\u5916\u63a8\u5230\u5176\u4f59n-m\u4e2a\u4f4d\u7f6e\u3002", "result": "\u63d0\u51fa\u5e76\u89e3\u51b3\u4e86\u5728STMF\u4e2d\u9009\u62e9\u8f93\u5165\u53d8\u91cf\u7684\u95ee\u9898\uff0c\u5373\u5728\u4f20\u611f\u5668\u6570\u91cf\u53d7\u9650\u65f6\u5982\u4f55\u4ecen\u4e2a\u4f4d\u7f6e\u4e2d\u9009\u51fam\u4e2a\u8f93\u5165\u53d8\u91cf\u4ee5\u6700\u5927\u5316\u9884\u6d4b\u51c6\u786e\u6027\u3002\u63d0\u51fa\u7edf\u4e00\u6846\u67b6\u8054\u5408\u6267\u884c\u53d8\u91cf\u9009\u62e9\u4e0e\u6a21\u578b\u4f18\u5316\uff0c\u517c\u987e\u7cbe\u5ea6\u4e0e\u6548\u7387\u3002\u4e09\u4e2a\u5173\u952e\u6280\u672f\uff1a1) \u57fa\u4e8e\u5206\u4f4d\u6570\u63a9\u7801\u7684\u53d8\u91cf-\u53c2\u6570\u526a\u679d\uff0c\u9010\u6b65\u526a\u6389\u4e0d\u91cd\u8981\u7684\u53d8\u91cf\u548c\u6ce8\u610f\u529b\u53c2\u6570\uff1b2) \u4f18\u5148\u56de\u653e\u673a\u5236\uff0c\u91cd\u653e\u4f4e\u635f\u6837\u672c\u4ee5\u4fdd\u6301\u6a21\u578b\u7a33\u5b9a\u6027\uff1b3) \u52a8\u6001\u5916\u63a8\u673a\u5236\uff0c\u901a\u8fc7\u53ef\u5b66\u4e60\u7684\u7a7a\u95f4\u5d4c\u5165\u548c\u90bb\u63a5\u4fe1\u606f\u5c06\u6240\u9009\u53d8\u91cf\u7684\u4fe1\u606f\u4f20\u64ad\u5230\u5176\u4ed6\u53d8\u91cf\u3002\u5b9e\u9a8c\u8bc1\u660e\u5728\u4e94\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u5728\u51c6\u786e\u6027\u548c\u6548\u7387\u4e0a\u663e\u8457\u4f18\u4e8eSOTA\u3002", "conclusion": "\u8054\u5408\u53d8\u91cf\u9009\u62e9\u4e0e\u6a21\u578b\u4f18\u5316\u80fd\u5728\u4f20\u611f\u5668\u53d7\u9650\u573a\u666f\u4e0b\u663e\u8457\u63d0\u5347STMF\u6027\u80fd\uff1b\u672c\u6587\u65b9\u6cd5\u5728\u7cbe\u5ea6\u548c\u6548\u7387\u4e0a\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u3002"}}
{"id": "2510.24035", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.24035", "abs": "https://arxiv.org/abs/2510.24035", "authors": ["Xinqi Li", "Yiqun Liu", "Shan Jiang", "Enrong Zheng", "Huaijin Zheng", "Wenhao Dai", "Haodong Deng", "Dianhai Yu", "Yanjun Ma"], "title": "GraphNet: A Large-Scale Computational Graph Dataset for Tensor Compiler Research", "comment": null, "summary": "We introduce GraphNet, a dataset of 2.7K real-world deep learning\ncomputational graphs with rich metadata, spanning six major task categories\nacross multiple deep learning frameworks. To evaluate tensor compiler\nperformance on these samples, we propose the benchmark metric Speedup Score\nS(t), which jointly considers runtime speedup and execution correctness under\ntunable tolerance levels, offering a reliable measure of general optimization\ncapability. Furthermore, we extend S(t) to the Error-aware Speedup Score ES(t),\nwhich incorporates error information and helps compiler developers identify key\nperformance bottlenecks. In this report, we benchmark the default tensor\ncompilers, CINN for PaddlePaddle and TorchInductor for PyTorch, on computer\nvision (CV) and natural language processing (NLP) samples to demonstrate the\npracticality of GraphNet. The full construction pipeline with graph extraction\nand compiler evaluation tools is available at\nhttps://github.com/PaddlePaddle/GraphNet .", "AI": {"tldr": "\u63d0\u51faGraphNet\u6570\u636e\u96c6(2.7K\u771f\u5b9e\u6df1\u5ea6\u5b66\u4e60\u8ba1\u7b97\u56fe)\u548cSpeedup Score S(t)/Error-aware ES(t)\u8bc4\u4f30\u6307\u6807\uff0c\u7528\u4e8e\u8bc4\u4f30\u5f20\u91cf\u7f16\u8bd1\u5668\u5728CV\u548cNLP\u4e0a\u7684\u6027\u80fd\uff0c\u63d0\u4f9b\u6784\u5efa\u4e0e\u8bc4\u6d4b\u5de5\u5177\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u7f3a\u4e4f\u771f\u5b9e\u591a\u6846\u67b6\u8ba1\u7b97\u56fe\u6837\u672c\u4e0e\u517c\u987e\u6027\u80fd\u4e0e\u6570\u503c\u6b63\u786e\u6027\u7684\u7efc\u5408\u5ea6\u91cf\uff0c\u56e0\u800c\u9700\u8981GraphNet\u6765\u4fc3\u8fdb\u5f20\u91cf\u7f16\u8bd1\u5668\u4f18\u5316\u4e0e\u6bd4\u8f83\u3002", "method": "\u6784\u5efa2.7K\u8ba1\u7b97\u56fe\u5e76\u91c7\u96c6\u5143\u6570\u636e\uff0c\u5b9a\u4e49S(t)\u540c\u65f6\u8003\u8651\u52a0\u901f\u4e0e\u6b63\u786e\u6027\u5bb9\u5dee\uff0c\u6269\u5c55\u4e3aES(t)\u7eb3\u5165\u8bef\u5dee\u4fe1\u606f\uff1b\u4ee5CINN\u4e0eTorchInductor\u5728CV/NLP\u6837\u672c\u4e0a\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "GraphNet dataset and benchmark for tensor compilers", "conclusion": "GraphNet\u4e3a\u5f20\u91cf\u7f16\u8bd1\u5668\u63d0\u4f9b\u4e86\u4e30\u5bcc\u7684\u771f\u5b9e\u8ba1\u7b97\u56fe\u57fa\u51c6\u548c\u53ef\u8c03\u5bb9\u9519\u7684\u6027\u80fd\u5ea6\u91cf\uff0c\u5b9e\u9a8c\u8bc1\u660e\u53ef\u7528\u4e8e\u6bd4\u8f83CINN\u4e0eTorchInductor\u7b49\u7f16\u8bd1\u5668\u5728CV/NLP\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u3002"}}
{"id": "2510.24039", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24039", "abs": "https://arxiv.org/abs/2510.24039", "authors": ["Nikolaos Karalias", "Akbar Rafiey", "Yifei Xu", "Zhishang Luo", "Behrooz Tahmasebi", "Connie Jiang", "Stefanie Jegelka"], "title": "Geometric Algorithms for Neural Combinatorial Optimization with Constraints", "comment": null, "summary": "Self-Supervised Learning (SSL) for Combinatorial Optimization (CO) is an\nemerging paradigm for solving combinatorial problems using neural networks. In\nthis paper, we address a central challenge of SSL for CO: solving problems with\ndiscrete constraints. We design an end-to-end differentiable framework that\nenables us to solve discrete constrained optimization problems with neural\nnetworks. Concretely, we leverage algorithmic techniques from the literature on\nconvex geometry and Carath\\'eodory's theorem to decompose neural network\noutputs into convex combinations of polytope corners that correspond to\nfeasible sets. This decomposition-based approach enables self-supervised\ntraining but also ensures efficient quality-preserving rounding of the neural\nnet output into feasible solutions. Extensive experiments in\ncardinality-constrained optimization show that our approach can consistently\noutperform neural baselines. We further provide worked-out examples of how our\nmethod can be applied beyond cardinality-constrained problems to a diverse set\nof combinatorial optimization tasks, including finding independent sets in\ngraphs, and solving matroid-constrained problems.", "AI": {"tldr": "\u7528Carath\u00e9odory\u5206\u89e3\u628a\u7f51\u7edc\u8f93\u51fa\u5199\u6210\u591a\u9762\u4f53\u9876\u70b9\u7684\u51f8\u7ec4\u5408\uff0c\u5b9e\u73b0\u53ef\u5fae\u5206\u3001\u53ef\u56db\u820d\u4e94\u5165\u7684\u81ea\u76d1\u7763\u7ec4\u5408\u4f18\u5316\u6846\u67b6\uff0c\u5b9e\u9a8c\u5728\u57fa\u6570\u7ea6\u675f\u7b49\u4efb\u52a1\u4e0a\u4f18\u4e8e\u57fa\u7ebf\u3002", "motivation": "\u89e3\u51b3\u5e26\u79bb\u6563\u7ea6\u675f\u7684\u7ec4\u5408\u4f18\u5316\u95ee\u9898\uff0c\u4f7f\u795e\u7ecf\u7f51\u7edc\u80fd\u5728\u81ea\u76d1\u7763\u5b66\u4e60\u6846\u67b6\u4e0b\u751f\u6210\u53ef\u884c\u89e3\u3002", "method": "\u5229\u7528\u51f8\u51e0\u4f55\u4e0eCarath\u00e9odory\u5b9a\u7406\u5c06\u7f51\u7edc\u8f93\u51fa\u5206\u89e3\u4e3a\u5bf9\u5e94\u53ef\u884c\u96c6\u5408\u7684\u591a\u9762\u4f53\u9876\u70b9\u7684\u51f8\u7ec4\u5408\uff0c\u5e76\u8bbe\u8ba1\u540e\u5904\u7406\u56db\u820d\u4e94\u5165\u7b56\u7565\u4fdd\u8bc1\u53ef\u884c\u6027\u4e0e\u89e3\u8d28\u91cf\uff0c\u540c\u65f6\u4fdd\u6301\u7aef\u5230\u7aef\u53ef\u5fae\u6027\u4ee5\u4fbf\u81ea\u76d1\u7763\u8bad\u7ec3\u3002", "result": "\u63d0\u51fa\u4e00\u4e2a\u7aef\u5230\u7aef\u53ef\u5fae\u5206\u6846\u67b6\uff0c\u5229\u7528Carath\u00e9odory\u5206\u89e3\u5c06\u7f51\u7edc\u8f93\u51fa\u8868\u793a\u4e3a\u591a\u9762\u4f53\u9876\u70b9\u7684\u51f8\u7ec4\u5408\uff0c\u652f\u6301\u53ef\u884c\u89e3\u7684\u9ad8\u8d28\u91cf\u56db\u820d\u4e94\u5165\u4e0e\u81ea\u76d1\u7763\u8bad\u7ec3\uff1b\u5728\u57fa\u6570\u7ea6\u675f\u4efb\u52a1\u4e0a\u4f18\u4e8e\u795e\u7ecf\u57fa\u7ebf\uff0c\u5e76\u6269\u5c55\u5230\u72ec\u7acb\u96c6\u548c\u57fa\u7ed3\u6784\u7ea6\u675f\u95ee\u9898\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u5728\u5904\u7406\u79bb\u6563\u7ea6\u675f\u65f6\u65e2\u4fdd\u7559\u53ef\u5fae\u6027\u4fbf\u4e8e\u81ea\u76d1\u7763\u8bad\u7ec3\uff0c\u53c8\u80fd\u9ad8\u6548\u5c06\u8f93\u51fa\u6620\u5c04\u5230\u53ef\u884c\u79bb\u6563\u89e3\uff0c\u9002\u7528\u8303\u56f4\u5305\u62ec\u57fa\u6570\u7ea6\u675f\u3001\u72ec\u7acb\u96c6\u548c\u57fa\u7b49\u66f4\u5e7f\u6cdb\u7684\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u3002"}}
{"id": "2510.24043", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24043", "abs": "https://arxiv.org/abs/2510.24043", "authors": ["Akira Tamamori"], "title": "Localized Kernel Projection Outlyingness: A Two-Stage Approach for Multi-Modal Outlier Detection", "comment": "10 pages, 4 figures; submitted to The IEICE Transactions on\n  Information and Systems", "summary": "This paper presents Two-Stage LKPLO, a novel multi-stage outlier detection\nframework that overcomes the coexisting limitations of conventional\nprojection-based methods: their reliance on a fixed statistical metric and\ntheir assumption of a single data structure. Our framework uniquely synthesizes\nthree key concepts: (1) a generalized loss-based outlyingness measure (PLO)\nthat replaces the fixed metric with flexible, adaptive loss functions like our\nproposed SVM-like loss; (2) a global kernel PCA stage to linearize non-linear\ndata structures; and (3) a subsequent local clustering stage to handle\nmulti-modal distributions. Comprehensive 5-fold cross-validation experiments on\n10 benchmark datasets, with automated hyperparameter optimization, demonstrate\nthat Two-Stage LKPLO achieves state-of-the-art performance. It significantly\noutperforms strong baselines on datasets with challenging structures where\nexisting methods fail, most notably on multi-cluster data (Optdigits) and\ncomplex, high-dimensional data (Arrhythmia). Furthermore, an ablation study\nempirically confirms that the synergistic combination of both the kernelization\nand localization stages is indispensable for its superior performance. This\nwork contributes a powerful new tool for a significant class of outlier\ndetection problems and underscores the importance of hybrid, multi-stage\narchitectures.", "AI": {"tldr": "Two-Stage LKPLO: adaptive loss-based outlyingness + kernel PCA + local clustering \u2192 robust, SOTA outlier detection for nonlinear and multi-cluster data.", "motivation": "Conventional projection-based methods use fixed statistical metrics and assume single data structure, which limits detection performance on multi-modal or nonlinear data; need flexible, multi-stage framework.", "method": "Introduce PLO (generalized loss-based outlyingness) with SVM-like loss; apply global kernel PCA to linearize nonlinear structures; perform local clustering to handle multi-modal distributions; automated hyperparameter tuning and 5-fold CV on 10 datasets; ablation study to validate components.", "result": "State-of-the-art performance across benchmarks, notably outperforming baselines on Optdigits and Arrhythmia; ablation confirms both kernelization and localization are necessary.", "conclusion": "Two-Stage LKPLO effectively addresses limitations of projection-based outlier detection by combining adaptive loss-based scoring with global kernel PCA and local clustering, yielding state-of-the-art results on benchmark datasets."}}
{"id": "2510.24044", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24044", "abs": "https://arxiv.org/abs/2510.24044", "authors": ["Hui Sun", "Zheng Xie", "Hao-Yuan He", "Ming Li"], "title": "Mitigating Negative Transfer via Reducing Environmental Disagreement", "comment": "13 pages, 5 figures", "summary": "Unsupervised Domain Adaptation~(UDA) focuses on transferring knowledge from a\nlabeled source domain to an unlabeled target domain, addressing the challenge\nof \\emph{domain shift}. Significant domain shifts hinder effective knowledge\ntransfer, leading to \\emph{negative transfer} and deteriorating model\nperformance. Therefore, mitigating negative transfer is essential. This study\nrevisits negative transfer through the lens of causally disentangled learning,\nemphasizing cross-domain discriminative disagreement on non-causal\nenvironmental features as a critical factor. Our theoretical analysis reveals\nthat overreliance on non-causal environmental features as the environment\nevolves can cause discriminative disagreements~(termed \\emph{environmental\ndisagreement}), thereby resulting in negative transfer. To address this, we\npropose Reducing Environmental Disagreement~(RED), which disentangles each\nsample into domain-invariant causal features and domain-specific non-causal\nenvironmental features via adversarially training domain-specific environmental\nfeature extractors in the opposite domains. Subsequently, RED estimates and\nreduces environmental disagreement based on domain-specific non-causal\nenvironmental features. Experimental results confirm that RED effectively\nmitigates negative transfer and achieves state-of-the-art performance.", "AI": {"tldr": "Paper identifies environmental disagreement from non-causal features as a source of negative transfer in UDA and proposes RED, an adversarial disentanglement method to estimate and reduce this disagreement, improving transfer performance.", "motivation": "Large domain shifts cause models to rely on non-causal environmental features, producing discriminative disagreement across domains that leads to negative transfer; need to disentangle causal features and suppress harmful environmental features.", "method": "Disentangle causal vs non-causal features and reduce environmental disagreement using adversarial training", "result": "Proposed RED method: adversarially train domain-specific environmental extractors in opposite domains to disentangle causal/non-causal features, estimate and reduce environmental disagreement, achieving SOTA performance and mitigating negative transfer.", "conclusion": "Mitigating cross-domain environmental disagreement via causal/non-causal disentanglement reduces negative transfer and enhances UDA performance; RED demonstrates effectiveness empirically."}}
{"id": "2510.24046", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24046", "abs": "https://arxiv.org/abs/2510.24046", "authors": ["Tu Anh Hoang Nguyen", "Dang Nguyen", "Tri-Nhan Vo", "Thuc Duy Le", "Sunil Gupta"], "title": "Causal-Aware Generative Adversarial Networks with Reinforcement Learning", "comment": null, "summary": "The utility of tabular data for tasks ranging from model training to\nlarge-scale data analysis is often constrained by privacy concerns or\nregulatory hurdles. While existing data generation methods, particularly those\nbased on Generative Adversarial Networks (GANs), have shown promise, they\nfrequently struggle with capturing complex causal relationship, maintaining\ndata utility, and providing provable privacy guarantees suitable for enterprise\ndeployment. We introduce CA-GAN, a novel generative framework specifically\nengineered to address these challenges for real-world tabular datasets. CA-GAN\nutilizes a two-step approach: causal graph extraction to learn a robust,\ncomprehensive causal relationship in the data's manifold, followed by a custom\nConditional WGAN-GP (Wasserstein GAN with Gradient Penalty) that operates\nexclusively as per the structure of nodes in the causal graph. More\nimportantly, the generator is trained with a new Reinforcement Learning-based\nobjective that aligns the causal graphs constructed from real and fake data,\nensuring the causal awareness in both training and sampling phases. We\ndemonstrate CA-GAN superiority over six SOTA methods across 14 tabular\ndatasets. Our evaluations, focused on core data engineering metrics: causal\npreservation, utility preservation, and privacy preservation. Our method offers\na practical, high-performance solution for data engineers seeking to create\nhigh-quality, privacy-compliant synthetic datasets to benchmark database\nsystems, accelerate software development, and facilitate secure data-driven\nresearch.", "AI": {"tldr": "\u63d0\u51faCA-GAN\uff1a\u5148\u63d0\u53d6\u56e0\u679c\u56fe\uff0c\u518d\u57fa\u4e8e\u56e0\u679c\u8282\u70b9\u7ed3\u6784\u8bad\u7ec3\u6761\u4ef6WGAN-GP\uff0c\u52a0\u5165\u5f3a\u5316\u5b66\u4e60\u76ee\u6807\u5bf9\u9f50\u56e0\u679c\u56fe\uff0c\u572814\u4e2a\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e6\u4e2aSOTA\u65b9\u6cd5\u3002", "motivation": "\u73b0\u5b9e\u8868\u683c\u6570\u636e\u5728\u5171\u4eab\u4e0e\u5206\u6790\u4e2d\u53d7\u9690\u79c1\u548c\u6cd5\u89c4\u9650\u5236\uff0c\u73b0\u6709GAN\u65b9\u6cd5\u96be\u4ee5\u540c\u65f6\u517c\u987e\u56e0\u679c\u5173\u7cfb\u4fdd\u7559\u3001\u6570\u636e\u6548\u7528\u548c\u53ef\u8bc1\u660e\u7684\u9690\u79c1\u4fdd\u8bc1\uff0c\u6545\u63d0\u51fa\u7ed3\u5408\u56e0\u679c\u5b66\u4e60\u4e0e\u751f\u6210\u6a21\u578b\u7684\u65b0\u6846\u67b6\u4ee5\u6ee1\u8db3\u4f01\u4e1a\u9700\u6c42\u3002", "method": "\u4e24\u9636\u6bb5\uff1a1\uff09\u56e0\u679c\u56fe\u63d0\u53d6\u2014\u2014\u4ece\u539f\u59cb\u6570\u636e\u5b66\u4e60\u53d8\u91cf\u95f4\u56e0\u679c\u7ed3\u6784\uff08\u53ef\u7528\u56e0\u679c\u53d1\u73b0\u7b97\u6cd5\u5982NOTEARS/PC\u6216\u57fa\u4e8e\u7ea6\u675f/\u8bc4\u5206\u7684\u65b9\u6cd5\uff09\uff1b2\uff09\u6761\u4ef6WGAN-GP\u2014\u2014\u4f9d\u636e\u56e0\u679c\u56fe\u7684\u8282\u70b9\u7ed3\u6784\u6784\u5efa\u6761\u4ef6\u751f\u6210\u5668\u548c\u5224\u522b\u5668\uff0c\u751f\u6210\u5668\u8bad\u7ec3\u65f6\u52a0\u5165\u5f3a\u5316\u5b66\u4e60\u76ee\u6807\uff0c\u5956\u52b1\u51fd\u6570\u8861\u91cf\u771f\u5b9e\u4e0e\u5408\u6210\u6570\u636e\u6784\u5efa\u51fa\u7684\u56e0\u679c\u56fe\u76f8\u4f3c\u5ea6\uff08\u4f8b\u5982\u57fa\u4e8e\u7ed3\u6784\u76f8\u4f3c\u5ea6\u6307\u6807\uff09\uff1b\u540c\u65f6\u5e94\u7528\u9690\u79c1\u4fdd\u62a4\u673a\u5236\uff08\u5982\u5dee\u5206\u9690\u79c1\uff09\u5728\u8bad\u7ec3\u4e2d\u63a7\u5236\u4fe1\u606f\u6cc4\u9732\u3002", "result": "CA-GAN\u5728\u771f\u5b9e\u8868\u683c\u6570\u636e\u7684\u5408\u6210\u4e2d\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u56e0\u679c\u7ed3\u6784\u5b66\u4e60\u4e0e\u6761\u4ef6WGAN-GP\u7684\u4e24\u9636\u6bb5\u65b9\u6cd5\uff0c\u5e76\u7528\u5f3a\u5316\u5b66\u4e60\u76ee\u6807\u6765\u5bf9\u9f50\u771f\u5b9e\u4e0e\u5408\u6210\u6570\u636e\u7684\u56e0\u679c\u56fe\uff0c\u4ece\u800c\u63d0\u5347\u6570\u636e\u7684\u56e0\u679c\u4fdd\u7559\u3001\u6548\u7528\u548c\u9690\u79c1\u6027\u3002", "conclusion": "CA-GAN\u901a\u8fc7\u5728\u751f\u6210\u5668\u8bad\u7ec3\u4e2d\u76f4\u63a5\u8003\u8651\u56e0\u679c\u7ed3\u6784\uff08\u5e76\u7528\u5f3a\u5316\u5b66\u4e60\u5bf9\u9f50\u56e0\u679c\u56fe\uff09\uff0c\u6709\u6548\u63d0\u9ad8\u4e86\u5408\u6210\u8868\u683c\u6570\u636e\u5728\u56e0\u679c\u5173\u7cfb\u4fdd\u7559\u3001\u4e0b\u6e38\u4efb\u52a1\u6548\u7528\u548c\u9690\u79c1\u4fdd\u62a4\u65b9\u9762\u7684\u8868\u73b0\uff0c\u9002\u5408\u4f01\u4e1a\u7ea7\u5e94\u7528\u3002"}}
{"id": "2510.24049", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24049", "abs": "https://arxiv.org/abs/2510.24049", "authors": ["Hao Jia", "Penghao Zhao", "Hao Wu", "Yuan Gao", "Yangyu Tao", "Bin Cui"], "title": "Learning from History: A Retrieval-Augmented Framework for Spatiotemporal Prediction", "comment": null, "summary": "Accurate and long-term spatiotemporal prediction for complex physical systems\nremains a fundamental challenge in scientific computing. While deep learning\nmodels, as powerful parametric approximators, have shown remarkable success,\nthey suffer from a critical limitation: the accumulation of errors during\nlong-term autoregressive rollouts often leads to physically implausible\nartifacts. This deficiency arises from their purely parametric nature, which\nstruggles to capture the full constraints of a system's intrinsic dynamics. To\naddress this, we introduce a novel \\textbf{Retrieval-Augmented Prediction\n(RAP)} framework, a hybrid paradigm that synergizes the predictive power of\ndeep networks with the grounded truth of historical data. The core philosophy\nof RAP is to leverage historical evolutionary exemplars as a non-parametric\nestimate of the system's local dynamics. For any given state, RAP efficiently\nretrieves the most similar historical analog from a large-scale database. The\ntrue future evolution of this analog then serves as a \\textbf{reference\ntarget}. Critically, this target is not a hard constraint in the loss function\nbut rather a powerful conditional input to a specialized dual-stream\narchitecture. It provides strong \\textbf{dynamic guidance}, steering the\nmodel's predictions towards physically viable trajectories. In extensive\nbenchmarks across meteorology, turbulence, and fire simulation, RAP not only\nsurpasses state-of-the-art methods but also significantly outperforms a strong\n\\textbf{analog-only forecasting baseline}. More importantly, RAP generates\npredictions that are more physically realistic by effectively suppressing error\ndivergence in long-term rollouts.", "AI": {"tldr": "Introduce RAP: retrieve similar historical analogs and feed their true future as a conditional input to a dual-stream network, improving long-term spatiotemporal forecasts and reducing error accumulation.", "motivation": "Deep models accumulate errors in long-term rollouts due to inability to fully capture intrinsic dynamical constraints; use historical data to provide non-parametric local dynamics guidance.", "method": "Retrieval-Augmented Prediction (RAP)", "result": "RAP surpasses state-of-the-art and analog-only baselines across meteorology, turbulence, and fire simulation; produces more physically realistic long-term predictions and suppresses error divergence.", "conclusion": "Combining parametric deep models with non-parametric retrieved evolutionary exemplars yields stronger dynamic guidance and more realistic long-term predictions, outperforming prior methods and analog-only forecasts."}}
{"id": "2510.24053", "categories": ["cs.LG", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2510.24053", "abs": "https://arxiv.org/abs/2510.24053", "authors": ["Jacob B. Roberts", "Catherine R. Ji", "Isaac Donnell", "Thomas D. Young", "Allison N. Pearson", "Graham A. Hudson", "Leah S. Keiser", "Mia Wesselkamper", "Peter H. Winegar", "Janik Ludwig", "Sarah H. Klass", "Isha V. Sheth", "Ezechinyere C. Ukabiala", "Maria C. T. Astolfi", "Benjamin Eysenbach", "Jay D. Keasling"], "title": "Low-N Protein Activity Optimization with FolDE", "comment": "18 pages, 4 figures. Preprint. Open-source software available at\n  https://github.com/JBEI/foldy", "summary": "Proteins are traditionally optimized through the costly construction and\nmeasurement of many mutants. Active Learning-assisted Directed Evolution (ALDE)\nalleviates that cost by predicting the best improvements and iteratively\ntesting mutants to inform predictions. However, existing ALDE methods face a\ncritical limitation: selecting the highest-predicted mutants in each round\nyields homogeneous training data insufficient for accurate prediction models in\nsubsequent rounds. Here we present FolDE, an ALDE method designed to maximize\nend-of-campaign success. In simulations across 20 protein targets, FolDE\ndiscovers 23% more top 10% mutants than the best baseline ALDE method (p=0.005)\nand is 55% more likely to find top 1% mutants. FolDE achieves this primarily\nthrough naturalness-based warm-starting, which augments limited activity\nmeasurements with protein language model outputs to improve activity\nprediction. We also introduce a constant-liar batch selector, which improves\nbatch diversity; this is important in multi-mutation campaigns but had limited\neffect in our benchmarks. The complete workflow is freely available as\nopen-source software, making efficient protein optimization accessible to any\nlaboratory.", "AI": {"tldr": "FolDE improves ALDE by warm-starting activity predictors with protein language model naturalness scores and using a constant-liar batch selector to increase batch diversity, leading to substantially better discovery of top mutants in simulations; open-source workflow provided.", "motivation": "Existing ALDE methods pick top predicted mutants each round, producing homogeneous training sets that hurt later prediction accuracy; need to improve end-of-campaign discovery of high-performing mutants.", "method": "Active Learning-assisted Directed Evolution (ALDE) with FolDE", "result": "Across 20 protein targets in simulation, FolDE found 23% more top-10% mutants than best baseline (p=0.005) and was 55% more likely to find top-1% mutants. Naturalness-based warm-starting was the main contributor; constant-liar batch selector improved diversity but had limited benchmark effect.", "conclusion": "Naturalness-informed warm-starting and diversity-aware batch selection make ALDE more effective, enabling more efficient protein optimization and broader accessibility via open-source release."}}
{"id": "2510.24061", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24061", "abs": "https://arxiv.org/abs/2510.24061", "authors": ["Kanghyun Choi", "Hyeyoon Lee", "SunJong Park", "Dain Kwon", "Jinho Lee"], "title": "FALQON: Accelerating LoRA Fine-tuning with Low-Bit Floating-Point Arithmetic", "comment": "NeurIPS 2025", "summary": "Low-bit floating-point (FP) formats, such as FP8, provide significant\nacceleration and memory savings in model training thanks to native hardware\nsupport on modern GPUs and NPUs. However, we analyze that FP8 quantization\noffers speedup primarily for large-dimensional matrix multiplications, while\ninherent quantization overheads diminish speedup when applied to low-rank\nadaptation (LoRA), which uses small-dimensional matrices for efficient\nfine-tuning of large language models (LLMs). To address this limitation, we\npropose FALQON, a novel framework that eliminates the quantization overhead\nfrom separate LoRA computational paths by directly merging LoRA adapters into\nan FP8-quantized backbone during fine-tuning. Furthermore, we reformulate the\nforward and backward computations for merged adapters to significantly reduce\nquantization overhead, and introduce a row-wise proxy update mechanism that\nefficiently integrates substantial updates into the quantized backbone.\nExperimental evaluations demonstrate that FALQON achieves approximately a\n3$\\times$ training speedup over existing quantized LoRA methods with a similar\nlevel of accuracy, providing a practical solution for efficient large-scale\nmodel fine-tuning. Moreover, FALQON's end-to-end FP8 workflow removes the need\nfor post-training quantization, facilitating efficient deployment. Code is\navailable at https://github.com/iamkanghyunchoi/falqon.", "AI": {"tldr": "FALQON\u901a\u8fc7\u5c06LoRA\u9002\u914d\u5668\u5408\u5e76\u5230FP8\u91cf\u5316\u4e3b\u5e72\u3001\u91cd\u6784\u524d\u540e\u5411\u8ba1\u7b97\u5e76\u5f15\u5165\u884c\u7ea7\u4ee3\u7406\u66f4\u65b0\uff0c\u6d88\u9664LoRA\u7684\u91cf\u5316\u5f00\u9500\uff0c\u8fbe\u5230\u7ea63\u00d7\u7684\u5fae\u8c03\u901f\u5ea6\u63d0\u5347\u5e76\u4fdd\u6301\u76f8\u4f3c\u7cbe\u5ea6\u3002", "motivation": "FP8\u5bf9\u5927\u578b\u77e9\u9635\u4e58\u6cd5\u6709\u663e\u8457\u52a0\u901f\uff0c\u4f46\u5bf9LoRA\u8fd9\u7c7b\u5c0f\u7ef4\u5ea6\u77e9\u9635\u7684\u91cf\u5316\u4f1a\u56e0\u989d\u5916\u7684\u91cf\u5316\u5f00\u9500\u800c\u62b5\u6d88\u52a0\u901f\u4f18\u52bf\uff0c\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u6d88\u9664\u8fd9\u90e8\u5206\u5f00\u9500\u4ee5\u5728\u5fae\u8c03\u9636\u6bb5\u83b7\u5f97\u5b9e\u9645\u901f\u5ea6\u63d0\u5347\u3002", "method": "\u63d0\u51fa\u5728\u5fae\u8c03\u9636\u6bb5\u5c06LoRA\u9002\u914d\u5668\u76f4\u63a5\u5408\u5e76\u8fdbFP8\u91cf\u5316\u7684\u4e3b\u5e72\u6a21\u578b\uff0c\u91cd\u5199\u5408\u5e76\u9002\u914d\u5668\u7684\u524d\u5411\u4e0e\u53cd\u5411\u4f20\u64ad\u4ee5\u51cf\u5c11\u91cf\u5316\u5f00\u9500\uff0c\u5e76\u8bbe\u8ba1\u884c\u7ea7\u4ee3\u7406\u66f4\u65b0\uff08row-wise proxy update\uff09\u4ee5\u6709\u6548\u96c6\u6210\u8f83\u5927\u66f4\u65b0\u3002", "result": "\u5728\u5b9e\u9a8c\u4e2d\uff0cFALQON\u76f8\u6bd4\u73b0\u6709\u7684\u91cf\u5316LoRA\u65b9\u6cd5\u5728\u4fdd\u6301\u8fd1\u4f3c\u76f8\u540c\u7cbe\u5ea6\u7684\u540c\u65f6\uff0c\u5b9e\u73b0\u4e86\u7ea63\u500d\u7684\u8bad\u7ec3\u901f\u5ea6\u63d0\u5347\uff0c\u5e76\u652f\u6301\u7aef\u5230\u7aefFP8\u6d41\u7a0b\uff0c\u65e0\u9700\u8bad\u7ec3\u540e\u518d\u91cf\u5316\uff0c\u65b9\u4fbf\u90e8\u7f72\u3002", "conclusion": "FALQON\u6d88\u9664\u4e86LoRA\u4e0e\u91cf\u5316\u4e3b\u5e72\u4e4b\u95f4\u7684\u8ba1\u7b97\u8def\u5f84\u5f00\u9500\uff0c\u901a\u8fc7\u5c06LoRA\u9002\u914d\u5668\u5728\u5fae\u8c03\u65f6\u76f4\u63a5\u5408\u5e76\u5230FP8\u91cf\u5316\u4e3b\u5e72\u4e2d\u5e76\u91cd\u6784\u524d\u540e\u5411\u8ba1\u7b97\u53ca\u5f15\u5165\u884c\u7ea7\u4ee3\u7406\u66f4\u65b0\u673a\u5236\uff0c\u5b9e\u73b0\u4e86\u5728\u7cbe\u5ea6\u76f8\u8fd1\u7684\u60c5\u51b5\u4e0b\u7ea63\u500d\u7684\u8bad\u7ec3\u52a0\u901f\u548c\u7aef\u5230\u7aefFP8\u5de5\u4f5c\u6d41\u3002"}}
{"id": "2510.24088", "categories": ["cs.LG", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.24088", "abs": "https://arxiv.org/abs/2510.24088", "authors": ["Moongyu Jeon", "Sangwoo Shin", "Dongjae Jeon", "Albert No"], "title": "Information-Theoretic Discrete Diffusion", "comment": "Accepted at NeurIPS 2025", "summary": "We present an information-theoretic framework for discrete diffusion models\nthat yields principled estimators of log-likelihood using score-matching\nlosses. Inspired by the I-MMSE identity for the Gaussian setup, we derive\nanalogous results for the discrete setting. Specifically, we introduce the\nInformation-Minimum Denoising Score Entropy (I-MDSE) relation, which links\nmutual information between data and its diffused version to the minimum\ndenoising score entropy (DSE) loss. We extend this theory to masked diffusion\nand establish the Information-Minimum Denoising Cross-Entropy (I-MDCE)\nrelation, connecting cross-entropy losses to mutual information in discrete\nmasked processes. These results provide a time-integral decomposition of the\nlog-likelihood of the data in terms of optimal score-based losses, showing that\ncommonly used losses such as DSE and DCE are not merely variational bounds but\ntight and principled estimators of log-likelihood. The I-MDCE decomposition\nfurther enables practical extensions, including time-free formula, conditional\nlikelihood estimation in prompt-response tasks, and coupled Monte Carlo\nestimation of likelihood ratios. Experiments on synthetic and real-world data\nconfirm the accuracy, variance stability, and utility of our estimators. The\ncode is publicly available at https://github.com/Dongjae0324/infodis.", "AI": {"tldr": "\u5efa\u7acb\u79bb\u6563\u6269\u6563\u7684\u4e92\u4fe1\u606f\u2014\u53bb\u566a\u635f\u5931\u6052\u7b49\u5f0f(I-MDSE/I-MDCE)\uff0c\u4ece\u7406\u8bba\u4e0e\u5b9e\u8df5\u4e0a\u628aDSE/DCE\u53d8\u4e3a\u7d27\u786e\u7684\u5bf9\u6570\u4f3c\u7136\u4f30\u8ba1\u5668\uff0c\u652f\u6301\u65f6\u95f4\u65e0\u5173\u4e0e\u6761\u4ef6\u4f3c\u7136\u7b49\u5e94\u7528\u3002", "motivation": "\u5f53\u524d\u79bb\u6563\u6269\u6563\u6a21\u578b\u4e2d\u5e38\u7528\u7684\u53bb\u566a\u635f\u5931\u591a\u88ab\u89c6\u4f5c\u53d8\u5206\u4e0b\u754c\u6216\u4ee3\u7406\u76ee\u6807\uff0c\u7f3a\u4e4f\u76f4\u63a5\u4e0e\u6570\u636e\u5bf9\u6570\u4f3c\u7136\u7cbe\u786e\u5bf9\u5e94\u7684\u4fe1\u606f\u8bba\u89e3\u91ca\uff1b\u9700\u6784\u5efa\u7406\u8bba\u5de5\u5177\u5c06\u79bb\u6563\u53bb\u566a\u635f\u5931\u4e0e\u4e92\u4fe1\u606f/\u5bf9\u6570\u4f3c\u7136\u8054\u7cfb\u8d77\u6765\uff0c\u4ee5\u4fbf\u63d0\u4f9b\u7cbe\u786e\u7684\u4f3c\u7136\u4f30\u8ba1\u4e0e\u4f4e\u65b9\u5dee\u4f30\u8ba1\u65b9\u6cd5\u3002", "method": "\u501f\u9274\u9ad8\u65af\u60c5\u5f62\u7684I-MMSE\u6052\u7b49\u5f0f\uff0c\u4f5c\u8005\u5728\u79bb\u6563\u60c5\u5f62\u5f15\u5165\u4fe1\u606f-\u6700\u5c0f\u53bb\u566a\u5206\u6570\u71b5(I-MDSE)\u4e0e\u4fe1\u606f-\u6700\u5c0f\u53bb\u566a\u4ea4\u53c9\u71b5(I-MDCE)\u5173\u7cfb\uff0c\u5efa\u7acb\u4e92\u4fe1\u606f\u4e0e\u6700\u4f18\u53bb\u566a\u5206\u6570\uff08\u6216\u4ea4\u53c9\u71b5\uff09\u635f\u5931\u4e4b\u95f4\u7684\u7b49\u4ef7\uff0c\u8fdb\u800c\u5c06\u6570\u636e\u5bf9\u6570\u4f3c\u7136\u5206\u89e3\u4e3a\u65f6\u95f4\u79ef\u5206\u5f62\u5f0f\uff1b\u5e76\u63d0\u51fa\u65f6\u95f4\u65e0\u5173\u516c\u5f0f\u3001\u6761\u4ef6\u4f3c\u7136\u4f30\u8ba1\u4e0e\u8026\u5408\u8499\u7279\u5361\u6d1b\u4f3c\u7136\u6bd4\u4f30\u8ba1\u7b49\u5b9e\u7528\u6269\u5c55\u3002", "result": "\u63a8\u5bfc\u5f97\u5230I-MDSE\u4e0eI-MDCE\u6052\u7b49\u5f0f\uff0c\u8bc1\u660eDSE\u548cDCE\u5728\u6700\u4f18\u60c5\u51b5\u4e0b\u786e\u5b9e\u7b49\u4e8e\u5206\u89e3\u9879\uff0c\u4ece\u800c\u53ef\u4f5c\u4e3a\u5bf9\u6570\u4f3c\u7136\u7684\u7d27\u786e\u4f30\u8ba1\uff1b\u63d0\u51fa\u65f6\u95f4\u65e0\u5173\u4e0e\u6761\u4ef6\u4f3c\u7136\u4f30\u8ba1\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u5408\u6210\u4e0e\u771f\u5b9e\u6570\u636e\u5b9e\u9a8c\u9a8c\u8bc1\u4f30\u8ba1\u7684\u51c6\u786e\u6027\u4e0e\u65b9\u5dee\u7a33\u5b9a\u6027\u3002\u4ee3\u7801\u5f00\u6e90\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u79bb\u6563\u6269\u6563\u6a21\u578b\u7684\u4fe1\u606f\u8bba\u6846\u67b6\uff0c\u63a8\u5bfc\u51fa\u4e0e\u4e92\u4fe1\u606f\u76f8\u5173\u7684\u6709\u6839\u6709\u636e\u7684\u5bf9\u6570\u4f3c\u7136\u4f30\u8ba1\u5668\uff0c\u8bc1\u660e\u5e38\u7528\u635f\u5931\u4e3a\u7d27\u786e\u4f30\u8ba1\u91cf\uff0c\u5e76\u6269\u5c55\u5230\u63a9\u7801\u60c5\u5f62\u4ee5\u652f\u6301\u6761\u4ef6\u4f3c\u7136\u7b49\u5e94\u7528\u3002"}}
{"id": "2510.24095", "categories": ["cs.LG", "cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2510.24095", "abs": "https://arxiv.org/abs/2510.24095", "authors": ["Vedant Gupta", "Haotian Fu", "Calvin Luo", "Yiding Jiang", "George Konidaris"], "title": "Learning Parameterized Skills from Demonstrations", "comment": "Neurips 2025", "summary": "We present DEPS, an end-to-end algorithm for discovering parameterized skills\nfrom expert demonstrations. Our method learns parameterized skill policies\njointly with a meta-policy that selects the appropriate discrete skill and\ncontinuous parameters at each timestep. Using a combination of temporal\nvariational inference and information-theoretic regularization methods, we\naddress the challenge of degeneracy common in latent variable models, ensuring\nthat the learned skills are temporally extended, semantically meaningful, and\nadaptable. We empirically show that learning parameterized skills from\nmultitask expert demonstrations significantly improves generalization to unseen\ntasks. Our method outperforms multitask as well as skill learning baselines on\nboth LIBERO and MetaWorld benchmarks. We also demonstrate that DEPS discovers\ninterpretable parameterized skills, such as an object grasping skill whose\ncontinuous arguments define the grasp location.", "AI": {"tldr": "\u63d0\u51faDEPS\uff0c\u4e00\u79cd\u7aef\u5230\u7aef\u4ece\u4e13\u5bb6\u793a\u8303\u4e2d\u53d1\u73b0\u53c2\u6570\u5316\u6280\u80fd\u7684\u65b9\u6cd5\u3002\u901a\u8fc7\u8054\u5408\u5b66\u4e60\u6280\u80fd\u7b56\u7565\u548c\u5143\u7b56\u7565\uff0c\u5e76\u7ed3\u5408\u65f6\u95f4\u53d8\u5206\u63a8\u65ad\u4e0e\u4fe1\u606f\u8bba\u6b63\u5219\u5316\uff0c\u907f\u514d\u6f5c\u5728\u53d8\u91cf\u6a21\u578b\u7684\u9000\u5316\uff0c\u4f7f\u6280\u80fd\u5177\u6709\u65f6\u95f4\u6269\u5c55\u6027\u3001\u8bed\u4e49\u53ef\u89e3\u91ca\u6027\u4e0e\u53ef\u9002\u5e94\u6027\u3002\u5728LIBERO\u548cMetaWorld\u4e0a\u4f18\u4e8e\u591a\u4efb\u52a1\u548c\u6280\u80fd\u5b66\u4e60\u57fa\u7ebf\uff0c\u5e76\u80fd\u53d1\u73b0\u53ef\u89e3\u91ca\u6280\u80fd\uff08\u5982\u5b9a\u4e49\u6293\u53d6\u4f4d\u7f6e\u7684\u6293\u53d6\u6280\u80fd\uff09\u3002", "motivation": "\u73b0\u6709\u6f5c\u53d8\u91cf\u6216\u6280\u80fd\u5b66\u4e60\u65b9\u6cd5\u5e38\u51fa\u73b0\u9000\u5316\u3001\u6280\u80fd\u4e0d\u53ef\u89e3\u91ca\u6216\u96be\u4ee5\u6cdb\u5316\u5230\u65b0\u4efb\u52a1\u3002\u901a\u8fc7\u76f4\u63a5\u4ece\u591a\u4efb\u52a1\u4e13\u5bb6\u793a\u8303\u5b66\u4e60\u53c2\u6570\u5316\u6280\u80fd\u5e76\u4e0e\u5143\u7b56\u7565\u8054\u5408\u8bad\u7ec3\uff0c\u53ef\u4ee5\u83b7\u5f97\u53ef\u590d\u7528\u3001\u53ef\u53c2\u6570\u5316\u4e14\u8bed\u4e49\u660e\u786e\u7684\u6280\u80fd\uff0c\u63d0\u5347\u5728\u672a\u89c1\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u3002", "method": "\u8054\u5408\u8bad\u7ec3\u53c2\u6570\u5316\u6280\u80fd\u7b56\u7565\u4e0e\u9009\u62e9\u79bb\u6563\u6280\u80fd\u53ca\u5176\u8fde\u7eed\u53c2\u6570\u7684\u5143\u7b56\u7565\uff1b\u91c7\u7528\u65f6\u95f4\u7ef4\u5ea6\u7684\u53d8\u5206\u63a8\u65ad\u5bf9\u6f5c\u53d8\u91cf\u8fdb\u884c\u5efa\u6a21\uff0c\u5e76\u5f15\u5165\u4fe1\u606f\u8bba\u6b63\u5219\u5316\uff08\u4f8b\u5982\u4fc3\u4f7f\u6280\u80fd\u53ef\u533a\u5206\u5e76\u9632\u6b62\u9000\u5316\uff09\u6765\u4fdd\u8bc1\u6280\u80fd\u7684\u65f6\u5e8f\u5ef6\u5c55\u6027\u4e0e\u8bed\u4e49\u6027\u3002", "result": "\u5728LIBERO\u548cMetaWorld\u57fa\u51c6\u4e0a\uff0cDEPS\u663e\u8457\u4f18\u4e8e\u591a\u4efb\u52a1\u5b66\u4e60\u548c\u73b0\u6709\u6280\u80fd\u5b66\u4e60\u57fa\u7ebf\uff1b\u5b66\u5230\u7684\u6280\u80fd\u5177\u6709\u6613\u89e3\u91ca\u7684\u53c2\u6570\uff08\u5982\u6293\u53d6\u4f4d\u7f6e\uff09\uff0c\u5e76\u80fd\u66f4\u597d\u5730\u6cdb\u5316\u5230\u65b0\u4efb\u52a1\u3002", "conclusion": "DEPS\u80fd\u4ece\u591a\u4efb\u52a1\u4e13\u5bb6\u793a\u8303\u4e2d\u6709\u6548\u5b66\u4e60\u53c2\u6570\u5316\u6280\u80fd\uff0c\u6539\u5584\u5bf9\u672a\u89c1\u4efb\u52a1\u7684\u6cdb\u5316\uff0c\u4e14\u6240\u5b66\u6280\u80fd\u8bed\u4e49\u6e05\u6670\u3001\u53ef\u8c03\u8282\uff0c\u5b9e\u8bc1\u4e0a\u5728\u4e24\u4e2a\u57fa\u51c6\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2510.24120", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24120", "abs": "https://arxiv.org/abs/2510.24120", "authors": ["Ziyu Liu", "Yijing Liu", "Jianfei Yuan", "Minzhi Yan", "Le Yue", "Honghui Xiong", "Yi Yang"], "title": "Graph-Guided Concept Selection for Efficient Retrieval-Augmented Generation", "comment": null, "summary": "Graph-based RAG constructs a knowledge graph (KG) from text chunks to enhance\nretrieval in Large Language Model (LLM)-based question answering. It is\nespecially beneficial in domains such as biomedicine, law, and political\nscience, where effective retrieval often involves multi-hop reasoning over\nproprietary documents. However, these methods demand numerous LLM calls to\nextract entities and relations from text chunks, incurring prohibitive costs at\nscale. Through a carefully designed ablation study, we observe that certain\nwords (termed concepts) and their associated documents are more important.\nBased on this insight, we propose Graph-Guided Concept Selection (G2ConS). Its\ncore comprises a chunk selection method and an LLM-independent concept graph.\nThe former selects salient document chunks to reduce KG construction costs; the\nlatter closes knowledge gaps introduced by chunk selection at zero cost.\nEvaluations on multiple real-world datasets show that G2ConS outperforms all\nbaselines in construction cost, retrieval effectiveness, and answering quality.", "AI": {"tldr": "Identify important concept words and salient chunks to build a cheaper partial KG, then use a prebuilt concept graph to fill gaps; yields better performance and lower cost.", "motivation": "Reduce LLM calls and costs in graph-based RAG while preserving retrieval quality by identifying key 'concept' words and selecting salient chunks; use an LLM-independent concept graph to fill knowledge gaps.", "method": "Graph-Guided Concept Selection", "result": "G2ConS reduces KG construction cost, improves retrieval effectiveness and QA quality across multiple real-world datasets compared to baselines.", "conclusion": "G2ConS effectively lowers LLM usage and cost while maintaining or improving retrieval and QA performance by combining chunk selection with a zero-cost concept graph."}}
{"id": "2510.24125", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24125", "abs": "https://arxiv.org/abs/2510.24125", "authors": ["Kiran Bacsa", "Wei Liu", "Xudong Jian", "Huangbin Liang", "Eleni Chatzi"], "title": "Causal Convolutional Neural Networks as Finite Impulse Response Filters", "comment": "14 pages, 19 figures, Under review", "summary": "This study investigates the behavior of Causal Convolutional Neural Networks\n(CNNs) with quasi-linear activation functions when applied to time-series data\ncharacterized by multimodal frequency content. We demonstrate that, once\ntrained, such networks exhibit properties analogous to Finite Impulse Response\n(FIR) filters, particularly when the convolutional kernels are of extended\nlength exceeding those typically employed in standard CNN architectures. Causal\nCNNs are shown to capture spectral features both implicitly and explicitly,\noffering enhanced interpretability for tasks involving dynamic systems.\nLeveraging the associative property of convolution, we further show that the\nentire network can be reduced to an equivalent single-layer filter resembling\nan FIR filter optimized via least-squares criteria. This equivalence yields new\ninsights into the spectral learning behavior of CNNs trained on signals with\nsparse frequency content. The approach is validated on both simulated beam\ndynamics and real-world bridge vibration datasets, underlining its relevance\nfor modeling and identifying physical systems governed by dynamic responses.", "AI": {"tldr": "\u56e0\u679cCNN\uff08\u51c6\u7ebf\u6027\u6fc0\u6d3b\u3001\u8d85\u957f\u6838\uff09\u53ef\u7b49\u4ef7\u4e3a\u6700\u5c0f\u4e8c\u4e58\u4f18\u5316\u7684FIR\u6ee4\u6ce2\u5668\uff0c\u589e\u5f3a\u5bf9\u591a\u6a21\u6001\u9891\u8c31\u65f6\u5e8f\u6570\u636e\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u5e76\u5728\u4eff\u771f\u4e0e\u5b9e\u9645\u632f\u52a8\u6570\u636e\u4e0a\u9a8c\u8bc1\u3002", "motivation": "\u7406\u89e3\u5e76\u89e3\u91ca\u56e0\u679cCNN\u5728\u5904\u7406\u591a\u6a21\u6001\u9891\u8c31\u65f6\u95f4\u5e8f\u5217\u65f6\u7684\u9891\u8c31\u5b66\u4e60\u673a\u5236\uff0c\u63d0\u5347\u53ef\u89e3\u91ca\u6027\u5e76\u5c06\u5176\u4e0e\u7ecf\u5178\u4fe1\u53f7\u5904\u7406\uff08FIR\u6ee4\u6ce2\u5668\u3001\u6700\u5c0f\u4e8c\u4e58\uff09\u8054\u7cfb\u8d77\u6765\u3002", "method": "\u57fa\u4e8e\u5377\u79ef\u7684\u7ed3\u5408\u6027\u8bc1\u660e\u7f51\u7edc\u591a\u5c42\uff08\u5e26\u51c6\u7ebf\u6027\u6fc0\u6d3b\uff09\u5377\u79ef\u53ef\u7b49\u4ef7\u4e3a\u5355\u5c42\u957f\u5377\u79ef\u6838\uff0c\u5bf9\u7b49\u6548\u6838\u7ed9\u51fa\u6700\u5c0f\u4e8c\u4e58\u89e3\u91ca\uff0c\u5e76\u5728\u4eff\u771f\u6881\u4f53\u52a8\u529b\u5b66\u548c\u5b9e\u9645\u6865\u6881\u632f\u52a8\u6570\u636e\u4e0a\u9a8c\u8bc1\u3002", "result": "\u8868\u660e\u5f53\u5377\u79ef\u6838\u8db3\u591f\u957f\u4e14\u6fc0\u6d3b\u8fd1\u4f3c\u7ebf\u6027\u65f6\uff0c\u8bad\u7ec3\u5f97\u5230\u7684\u56e0\u679cCNN\u4f1a\u5b66\u5230\u7b49\u6548\u7684FIR\u6ee4\u6ce2\u5668\uff0c\u80fd\u663e\u5f0f/\u9690\u5f0f\u6355\u6349\u7a00\u758f\u9891\u8c31\u7279\u5f81\uff1b\u5728\u4eff\u771f\u548c\u5b9e\u6d4b\u6570\u636e\u4e0a\u5747\u53d6\u5f97\u4e86\u826f\u597d\u62df\u5408\u548c\u7269\u7406\u89e3\u91ca\u6027\u3002", "conclusion": "\u8bad\u7ec3\u540e\u7684\u56e0\u679c\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u5728\u51c6\u7ebf\u6027\u6fc0\u6d3b\u4e0b\u3001\u4e14\u4f7f\u7528\u8d85\u957f\u5377\u79ef\u6838\u65f6\uff0c\u884c\u4e3a\u7b49\u4ef7\u4e8e\u6709\u9650\u51b2\u6fc0\u54cd\u5e94\uff08FIR\uff09\u6ee4\u6ce2\u5668\uff1b\u7f51\u7edc\u6574\u4f53\u53ef\u5408\u5e76\u4e3a\u5355\u5c42\u7b49\u6548\u6ee4\u6ce2\u5668\u5e76\u7528\u6700\u5c0f\u4e8c\u4e58\u51c6\u5219\u89e3\u91ca\u5176\u9891\u8c31\u5b66\u4e60\u7279\u6027\u3002"}}
{"id": "2510.24135", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24135", "abs": "https://arxiv.org/abs/2510.24135", "authors": ["Hojin Cheon", "Hyeongseok Seo", "Jihun Jeon", "Wooju Lee", "Dohyun Jeong", "Hongseok Kim"], "title": "Fixed Point Neural Acceleration and Inverse Surrogate Model for Battery Parameter Identification", "comment": "31 pages, 11 figures, submitted to Applied Energy", "summary": "The rapid expansion of electric vehicles has intensified the need for\naccurate and efficient diagnosis of lithium-ion batteries. Parameter\nidentification of electrochemical battery models is widely recognized as a\npowerful method for battery health assessment. However, conventional\nmetaheuristic approaches suffer from high computational cost and slow\nconvergence, and recent machine learning methods are limited by their reliance\non constant current data, which may not be available in practice. To overcome\nthese challenges, we propose deep learning-based framework for parameter\nidentification of electrochemical battery models. The proposed framework\ncombines a neural surrogate model of the single particle model with electrolyte\n(NeuralSPMe) and a deep learning-based fixed-point iteration method. NeuralSPMe\nis trained on realistic EV load profiles to accurately predict lithium\nconcentration dynamics under dynamic operating conditions while a parameter\nupdate network (PUNet) performs fixed-point iterative updates to significantly\nreduce both the evaluation time per sample and the overall number of iterations\nrequired for convergence. Experimental evaluations demonstrate that the\nproposed framework accelerates the parameter identification by more than 2000\ntimes, achieves superior sample efficiency and more than 10 times higher\naccuracy compared to conventional metaheuristic algorithms, particularly under\ndynamic load scenarios encountered in practical applications.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u795e\u7ecf\u7f51\u7edc\u7684\u7535\u5316\u5b66\u7535\u6c60\u53c2\u6570\u8bc6\u522b\u6846\u67b6\uff1a\u7528NeuralSPMe\u66ff\u4ee3SPMe\u5e76\u8f85\u4ee5PUNet\u56fa\u5b9a\u70b9\u8fed\u4ee3\uff0c\u5927\u5e45\u52a0\u901f\uff08>2000\u500d\uff09\u3001\u63d0\u9ad8\u6837\u672c\u6548\u7387\u5e76\u5728\u52a8\u6001\u5de5\u51b5\u4e0b\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u7b97\u6cd5\u3002", "motivation": "The paper aims to address limitations in battery parameter identification for lithium-ion batteries: high computational cost and slow convergence of metaheuristic methods, and ML methods' dependence on constant current data. It seeks an accurate, efficient method usable under dynamic EV load profiles.", "method": "Train NeuralSPMe on realistic EV load profiles to emulate the Single Particle Model with electrolyte; train PUNet to perform fixed-point iterative parameter updates, reducing per-sample evaluation time and total iterations; evaluate versus metaheuristic baselines on dynamic datasets.", "result": "They propose a deep-learning framework combining a neural surrogate (NeuralSPMe) and a parameter update network (PUNet) that together speed up identification by >2000x, improve sample efficiency, and achieve >10x better accuracy versus metaheuristics, especially under dynamic loads.", "conclusion": "The framework enables fast, accurate parameter identification for electrochemical battery models under realistic EV dynamic loads, making it practical for online or frequent diagnostics."}}
{"id": "2510.24160", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24160", "abs": "https://arxiv.org/abs/2510.24160", "authors": ["Aiqing Zhu", "Beatrice W. Soh", "Grigorios A. Pavliotis", "Qianxiao Li"], "title": "Identifiable learning of dissipative dynamics", "comment": null, "summary": "Complex dissipative systems appear across science and engineering, from\npolymers and active matter to learning algorithms. These systems operate far\nfrom equilibrium, where energy dissipation and time irreversibility are key to\ntheir behavior, but are difficult to quantify from data. Learning accurate and\ninterpretable models of such dynamics remains a major challenge: the models\nmust be expressive enough to describe diverse processes, yet constrained enough\nto remain physically meaningful and mathematically identifiable. Here, we\nintroduce I-OnsagerNet, a neural framework that learns dissipative stochastic\ndynamics directly from trajectories while ensuring both interpretability and\nuniqueness. I-OnsagerNet extends the Onsager principle to guarantee that the\nlearned potential is obtained from the stationary density and that the drift\ndecomposes cleanly into time-reversible and time-irreversible components, as\ndictated by the Helmholtz decomposition. Our approach enables us to calculate\nthe entropy production and to quantify irreversibility, offering a principled\nway to detect and quantify deviations from equilibrium. Applications to polymer\nstretching in elongational flow and to stochastic gradient Langevin dynamics\nreveal new insights, including super-linear scaling of barrier heights and\nsub-linear scaling of entropy production rates with the strain rate, and the\nsuppression of irreversibility with increasing batch size. I-OnsagerNet thus\nestablishes a general, data-driven framework for discovering and interpreting\nnon-equilibrium dynamics.", "AI": {"tldr": "We propose I-OnsagerNet, a neural model that learns stochastic dissipative dynamics with guaranteed interpretability and uniqueness by enforcing Onsager principle and Helmholtz decomposition; enables entropy production estimation and reveals scaling laws in applications", "motivation": "Quantify and model non-equilibrium dissipative systems from trajectory data while ensuring interpretability and identifiability", "method": "Read and extend the abstract", "result": "I-OnsagerNet: neural framework that imposes Onsager/Helmholtz structure, learns potential from stationary density, decomposes drift into reversible/irreversible parts, computes entropy production, applied to polymer stretching and SGLD showing scaling results", "conclusion": "I-OnsagerNet provides a general, data-driven, physically-constrained approach to discover and interpret non-equilibrium dynamics from trajectories, enabling quantification of irreversibility and insights into complex systems."}}
{"id": "2510.24173", "categories": ["cs.LG", "cs.NA", "math.DS", "math.NA", "physics.flu-dyn"], "pdf": "https://arxiv.org/pdf/2510.24173", "abs": "https://arxiv.org/abs/2510.24173", "authors": ["Yiheng Du", "Aditi S. Krishnapriyan"], "title": "EddyFormer: Accelerated Neural Simulations of Three-Dimensional Turbulence at Scale", "comment": "NeurIPS 2025", "summary": "Computationally resolving turbulence remains a central challenge in fluid\ndynamics due to its multi-scale interactions. Fully resolving large-scale\nturbulence through direct numerical simulation (DNS) is computationally\nprohibitive, motivating data-driven machine learning alternatives. In this\nwork, we propose EddyFormer, a Transformer-based spectral-element (SEM)\narchitecture for large-scale turbulence simulation that combines the accuracy\nof spectral methods with the scalability of the attention mechanism. We\nintroduce an SEM tokenization that decomposes the flow into grid-scale and\nsubgrid-scale components, enabling capture of both local and global features.\nWe create a new three-dimensional isotropic turbulence dataset and train\nEddyFormer to achieves DNS-level accuracy at 256^3 resolution, providing a 30x\nspeedup over DNS. When applied to unseen domains up to 4x larger than in\ntraining, EddyFormer preserves accuracy on physics-invariant metrics-energy\nspectra, correlation functions, and structure functions-showing domain\ngeneralization. On The Well benchmark suite of diverse turbulent flows,\nEddyFormer resolves cases where prior ML models fail to converge, accurately\nreproducing complex dynamics across a wide range of physical conditions.", "AI": {"tldr": "\u63d0\u51faEddyFormer\uff0c\u7ed3\u5408\u8c31\u65b9\u6cd5\u548cTransformer\uff0c\u4f7f\u7528SEM\u5206\u89e3\u6d41\u573a\u4e3a\u7f51\u683c\u5c3a\u5ea6\u548c\u4e9a\u683c\u5c3a\u5ea6\uff0c\u80fd\u5728256^3\u4e0a\u8fbe\u5230DNS\u7cbe\u5ea6\u5e76\u5feb30\u500d\uff0c\u4e14\u5728\u66f4\u5927\u57df\u4e0e\u591a\u6837\u6d41\u52a8\u57fa\u51c6\u4e0a\u4fdd\u6301\u7269\u7406\u4e0d\u53d8\u91cf\u7684\u51c6\u786e\u6027\u3002", "motivation": "The paper aims to address the computational cost of fully resolving turbulence via DNS by developing a scalable ML method combining spectral-element accuracy with Transformer attention to model large-scale turbulence efficiently.", "method": "Introduce SEM tokenization separating grid-scale and subgrid-scale components, use Transformer-based attention across spectral-element tokens, train on new 3D isotropic turbulence dataset, evaluate on larger unseen domains and The Well benchmark.", "result": "EddyFormer, a Transformer-based spectral-element architecture, achieves DNS-level accuracy at 256^3 with 30x speedup over DNS, generalizes to larger domains (up to 4x), and succeeds on The Well benchmark where prior ML models failed.", "conclusion": "EddyFormer provides an efficient, generalizable ML surrogate for turbulence simulation that retains spectral accuracy and domain generalization, outperforming previous ML approaches on challenging benchmarks."}}
{"id": "2510.24180", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24180", "abs": "https://arxiv.org/abs/2510.24180", "authors": ["Arpita Kundu", "Joyita Chakraborty", "Anindita Desarkar", "Aritra Sen", "Srushti Anil Patil", "Vishwanathan Raman"], "title": "V-SAT: Video Subtitle Annotation Tool", "comment": null, "summary": "The surge of audiovisual content on streaming platforms and social media has\nheightened the demand for accurate and accessible subtitles. However, existing\nsubtitle generation methods primarily speech-based transcription or OCR-based\nextraction suffer from several shortcomings, including poor synchronization,\nincorrect or harmful text, inconsistent formatting, inappropriate reading\nspeeds, and the inability to adapt to dynamic audio-visual contexts. Current\napproaches often address isolated issues, leaving post-editing as a\nlabor-intensive and time-consuming process. In this paper, we introduce V-SAT\n(Video Subtitle Annotation Tool), a unified framework that automatically\ndetects and corrects a wide range of subtitle quality issues. By combining\nLarge Language Models(LLMs), Vision-Language Models (VLMs), Image Processing,\nand Automatic Speech Recognition (ASR), V-SAT leverages contextual cues from\nboth audio and video. Subtitle quality improved, with the SUBER score reduced\nfrom 9.6 to 3.54 after resolving all language mode issues and F1-scores of\n~0.80 for image mode issues. Human-in-the-loop validation ensures high-quality\nresults, providing the first comprehensive solution for robust subtitle\nannotation.", "AI": {"tldr": "\u63d0\u51faV-SAT\uff0c\u4e00\u4e2a\u7ed3\u5408LLM\u3001VLM\u3001\u56fe\u50cf\u5904\u7406\u4e0eASR\u7684\u7edf\u4e00\u89c6\u9891\u5b57\u5e55\u68c0\u6d4b\u4e0e\u4fee\u6b63\u6846\u67b6\uff0c\u81ea\u52a8\u53d1\u73b0\u5e76\u4fee\u590d\u8bed\u8a00\u4e0e\u56fe\u50cf\u6a21\u5f0f\u4e0b\u7684\u5b57\u5e55\u95ee\u9898\uff0c\u663e\u8457\u964d\u4f4eSUBER\u5f97\u5206\u5e76\u5728\u4eba\u4e3a\u9a8c\u8bc1\u4e0b\u8fbe\u6210\u9ad8\u8d28\u91cf\u8f93\u51fa\u3002", "motivation": "\u6d41\u5a92\u4f53\u4e0e\u793e\u4ea4\u5e73\u53f0\u4e0a\u89c6\u9891\u91cf\u6fc0\u589e\uff0c\u73b0\u6709\u57fa\u4e8e\u8bed\u97f3\u8f6c\u5f55\u6216OCR\u7684\u65b9\u6cd5\u5728\u540c\u6b65\u3001\u51c6\u786e\u6027\u3001\u683c\u5f0f\u548c\u9002\u5e94\u89c6\u542c\u4e0a\u4e0b\u6587\u80fd\u529b\u4e0a\u4e0d\u8db3\uff0c\u9700\u4e00\u5957\u81ea\u52a8\u5316\u3001\u7efc\u5408\u7684\u4fee\u6b63\u5de5\u5177\u4ee5\u51cf\u5c11\u7e41\u91cd\u7684\u540e\u671f\u4eba\u5de5\u7f16\u8f91\u3002", "method": "V-SAT\u6574\u5408ASR\u63d0\u53d6\u8bed\u97f3\u5185\u5bb9\u3001VLM/\u56fe\u50cf\u5904\u7406\u63d0\u53d6\u89c6\u89c9\u7ebf\u7d22\uff0c\u5e76\u7528LLM\u8fdb\u884c\u4e0a\u4e0b\u6587\u7406\u89e3\u4e0e\u7b56\u7565\u751f\u6210\uff0c\u9488\u5bf9\u4e0d\u540c\u95ee\u9898\u7c7b\u578b\u8bbe\u8ba1\u68c0\u6d4b\u4e0e\u4fee\u590d\u6a21\u5757\uff1b\u6700\u540e\u5f15\u5165\u4eba\u7c7b\u5728\u73af\u9a8c\u8bc1\u4ee5\u786e\u4fdd\u7ed3\u679c\u8d28\u91cf\u3002", "result": "\u5728\u5168\u9762\u4fee\u590d\u8bed\u8a00\u6a21\u5f0f\u95ee\u9898\u540e\uff0cSUBER\u75319.6\u964d\u81f33.54\uff1b\u56fe\u50cf\u6a21\u5f0f\u95ee\u9898\u68c0\u6d4b/\u4fee\u590dF1\u7ea60.80\uff1b\u7cfb\u7edf\u7ed3\u5408\u4eba\u7c7b\u6821\u9a8c\u5b9e\u73b0\u9ad8\u8d28\u91cf\u5b57\u5e55\u6ce8\u91ca\u3002", "conclusion": "V-SAT\u80fd\u81ea\u52a8\u5904\u7406\u591a\u79cd\u5b57\u5e55\u8d28\u91cf\u95ee\u9898\uff08\u540c\u6b65\u3001\u9519\u8bef\u6587\u672c\u3001\u683c\u5f0f\u3001\u9605\u8bfb\u901f\u5ea6\u7b49\uff09\uff0c\u5728\u8bed\u8a00\u6a21\u5f0f\u95ee\u9898\u4e0a\u5c06SUBER\u5f97\u5206\u4ece9.6\u964d\u52303.54\uff0c\u5e76\u5728\u56fe\u50cf\u6a21\u5f0f\u95ee\u9898\u4e0a\u5b9e\u73b0\u7ea60.80\u7684F1\uff1b\u7ed3\u5408\u4eba\u673a\u6821\u9a8c\u63d0\u4f9b\u9996\u4e2a\u5168\u9762\u7a33\u5065\u7684\u5b57\u5e55\u6ce8\u91ca\u65b9\u6848\u3002"}}
{"id": "2510.24216", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24216", "abs": "https://arxiv.org/abs/2510.24216", "authors": ["Fan Xu", "Hao Wu", "Kun Wang", "Nan Wang", "Qingsong Wen", "Xian Wu", "Wei Gong", "Xibin Zhao"], "title": "Unlocking Out-of-Distribution Generalization in Dynamics through Physics-Guided Augmentation", "comment": null, "summary": "In dynamical system modeling, traditional numerical methods are limited by\nhigh computational costs, while modern data-driven approaches struggle with\ndata scarcity and distribution shifts. To address these fundamental\nlimitations, we first propose SPARK, a physics-guided quantitative augmentation\nplugin. Specifically, SPARK utilizes a reconstruction autoencoder to integrate\nphysical parameters into a physics-rich discrete state dictionary. This state\ndictionary then acts as a structured dictionary of physical states, enabling\nthe creation of new, physically-plausible training samples via principled\ninterpolation in the latent space. Further, for downstream prediction, these\naugmented representations are seamlessly integrated with a Fourier-enhanced\nGraph ODE, a combination designed to robustly model the enriched data\ndistribution while capturing long-term temporal dependencies. Extensive\nexperiments on diverse benchmarks demonstrate that SPARK significantly\noutperforms state-of-the-art baselines, particularly in challenging\nout-of-distribution scenarios and data-scarce regimes, proving the efficacy of\nour physics-guided augmentation paradigm.", "AI": {"tldr": "\u63d0\u51faSPARK\uff1a\u901a\u8fc7\u81ea\u7f16\u7801\u5668\u5b66\u4e60\u7269\u7406\u72b6\u6001\u5b57\u5178\u5e76\u5728\u6f5c\u7a7a\u95f4\u63d2\u503c\u751f\u6210\u7269\u7406\u589e\u5f3a\u6837\u672c\uff0c\u518d\u7528\u5085\u91cc\u53f6\u589e\u5f3a\u56feODE\u5efa\u6a21\uff0c\u89e3\u51b3\u6570\u503c\u65b9\u6cd5\u548c\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u7684\u5c40\u9650\uff0c\u5728OOD\u548c\u5c0f\u6837\u672c\u573a\u666f\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf", "motivation": "Alleviate high computational cost of numerical simulators and data scarcity/distribution shift of data-driven models by generating physics-plausible augmented samples using a learned discrete state dictionary and integrating them with a Fourier-enhanced Graph ODE for prediction", "method": "Qualitative analysis of methodological novelty and robustness", "result": "SPARK constructs a physics-rich discrete latent dictionary via a reconstruction autoencoder, generates augmented samples through interpolation in latent space, and uses a Fourier-enhanced Graph ODE to learn long-term dynamics on enriched data; shows strong OOD and low-data performance across benchmarks", "conclusion": "\u7269\u7406\u5f15\u5bfc\u7684\u6570\u636e\u589e\u5f3a\u7ed3\u5408\u9891\u57df\u589e\u5f3a\u7684\u56feODE\u5728\u6570\u636e\u7a00\u7f3a\u548c\u5206\u5e03\u504f\u79fb\u60c5\u5f62\u4e0b\u80fd\u663e\u8457\u63d0\u5347\u52a8\u529b\u7cfb\u7edf\u5efa\u6a21\u7684\u6cdb\u5316\u6027\u4e0e\u7a33\u5065\u6027"}}
{"id": "2510.24217", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24217", "abs": "https://arxiv.org/abs/2510.24217", "authors": ["Alisher Turubayev", "Anna Shopova", "Fabian Lange", "Mahmut Kamalak", "Paul Mattes", "Victoria Ayvasky", "Bert Arnrich", "Bjarne Pfitzner", "Robin P. van de Water"], "title": "Closing Gaps: An Imputation Analysis of ICU Vital Signs", "comment": "Preprint", "summary": "As more Intensive Care Unit (ICU) data becomes available, the interest in\ndeveloping clinical prediction models to improve healthcare protocols\nincreases. However, the lack of data quality still hinders clinical prediction\nusing Machine Learning (ML). Many vital sign measurements, such as heart rate,\ncontain sizeable missing segments, leaving gaps in the data that could\nnegatively impact prediction performance. Previous works have introduced\nnumerous time-series imputation techniques. Nevertheless, more comprehensive\nwork is needed to compare a representative set of methods for imputing ICU\nvital signs and determine the best practice. In reality, ad-hoc imputation\ntechniques that could decrease prediction accuracy, like zero imputation, are\nstill used. In this work, we compare established imputation techniques to guide\nresearchers in improving the performance of clinical prediction models by\nselecting the most accurate imputation technique. We introduce an extensible\nand reusable benchmark with currently 15 imputation and 4 amputation methods,\ncreated for benchmarking on major ICU datasets. We hope to provide a\ncomparative basis and facilitate further ML development to bring more models\ninto clinical practice.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9ICU\u751f\u547d\u4f53\u5f81\u6570\u636e\u7f3a\u5931\u95ee\u9898\uff0c\u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542b15\u79cd\u63d2\u8865\u65b9\u6cd5\u548c4\u79cd\u4eba\u5de5\u7f3a\u5931\u751f\u6210\u65b9\u6cd5\u7684\u57fa\u51c6\u6846\u67b6\uff0c\u5728\u4e3b\u8981ICU\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u4e0d\u540c\u63d2\u8865\u6280\u672f\u5bf9\u4e34\u5e8a\u9884\u6d4b\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u65e8\u5728\u4e3a\u7814\u7a76\u8005\u63d0\u4f9b\u6700\u4f73\u5b9e\u8df5\u5efa\u8bae\u5e76\u63a8\u52a8\u673a\u5668\u5b66\u4e60\u6a21\u578b\u4e34\u5e8a\u5e94\u7528\u3002", "motivation": "ICU\u6570\u636e\u4e2d\u5b58\u5728\u5927\u91cf\u7f3a\u5931\u6bb5\uff0c\u52a3\u8d28\u6216\u968f\u610f\u7684\u63d2\u8865\uff08\u5982\u7528\u96f6\u586b\u5145\uff09\u4f1a\u635f\u5bb3\u673a\u5668\u5b66\u4e60\u9884\u6d4b\u6027\u80fd\uff0c\u56e0\u6b64\u9700\u8981\u7cfb\u7edf\u6bd4\u8f83\u548c\u63a8\u8350\u66f4\u5408\u9002\u7684\u63d2\u8865\u65b9\u6cd5\u4ee5\u6539\u8fdb\u4e34\u5e8a\u9884\u6d4b\u6a21\u578b\u3002", "method": "\u5efa\u7acb\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u57fa\u51c6\u6d4b\u8bd5\u5e73\u53f0\uff0c\u5305\u542b15\u79cd\u65f6\u95f4\u5e8f\u5217\u63d2\u8865\u65b9\u6cd5\u548c4\u79cd\u7f3a\u5931\uff08amputation\uff09\u751f\u6210\u7b56\u7565\uff0c\u5728\u4e3b\u6d41ICU\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8bc4\u4f30\u4e0e\u6bd4\u8f83\uff0c\u91cd\u70b9\u8861\u91cf\u63d2\u8865\u8d28\u91cf\u53ca\u5176\u5bf9\u4e0b\u6e38\u4e34\u5e8a\u9884\u6d4b\u4efb\u52a1\u7684\u5f71\u54cd\u3002", "result": "\u63d0\u51fa\u5e76\u5b9e\u73b0\u4e86\u4e00\u4e2a\u5305\u542b\u591a\u79cd\u63d2\u8865\u548c\u7f3a\u5931\u751f\u6210\u65b9\u6cd5\u7684\u57fa\u51c6\u6846\u67b6\uff0c\u63d0\u4f9b\u4e86\u4e0d\u540c\u65b9\u6cd5\u5728ICU\u751f\u547d\u4f53\u5f81\u63d2\u8865\u4e0e\u4e0b\u6e38\u4efb\u52a1\u4e2d\u7684\u5bf9\u6bd4\u7ed3\u679c\uff08\u5177\u4f53\u6570\u503c\u5728\u539f\u6587\u4e2d\uff09\uff0c\u4e3a\u9009\u62e9\u63d2\u8865\u7b56\u7565\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u4f9d\u636e\u3002", "conclusion": "\u901a\u8fc7\u7cfb\u7edf\u6bd4\u8f83\u591a\u79cd\u63d2\u8865\u65b9\u6cd5\uff0c\u4f5c\u8005\u4e3aICU\u751f\u547d\u4f53\u5f81\u6570\u636e\u63d2\u8865\u63d0\u4f9b\u4e86\u53ef\u590d\u7528\u7684\u57fa\u51c6\u6846\u67b6\uff0c\u671f\u5f85\u901a\u8fc7\u91c7\u7528\u66f4\u5408\u9002\u7684\u63d2\u8865\u6280\u672f\u63d0\u5347\u4e34\u5e8a\u9884\u6d4b\u6a21\u578b\u7684\u51c6\u786e\u6027\u5e76\u4fc3\u8fdb\u5176\u5728\u4e34\u5e8a\u5b9e\u8df5\u4e2d\u7684\u5e94\u7528\u3002"}}
{"id": "2510.24233", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24233", "abs": "https://arxiv.org/abs/2510.24233", "authors": ["Antoine Szatkownik", "Aur\u00e9lien Decelle", "Beatriz Seoane", "Nicolas Bereux", "L\u00e9o Planche", "Guillaume Charpiat", "Burak Yelmen", "Flora Jay", "Cyril Furtlehner"], "title": "PRIVET: Privacy Metric Based on Extreme Value Theory", "comment": null, "summary": "Deep generative models are often trained on sensitive data, such as genetic\nsequences, health data, or more broadly, any copyrighted, licensed or protected\ncontent. This raises critical concerns around privacy-preserving synthetic\ndata, and more specifically around privacy leakage, an issue closely tied to\noverfitting. Existing methods almost exclusively rely on global criteria to\nestimate the risk of privacy failure associated to a model, offering only\nquantitative non interpretable insights. The absence of rigorous evaluation\nmethods for data privacy at the sample-level may hinder the practical\ndeployment of synthetic data in real-world applications. Using extreme value\nstatistics on nearest-neighbor distances, we propose PRIVET, a generic\nsample-based, modality-agnostic algorithm that assigns an individual privacy\nleak score to each synthetic sample. We empirically demonstrate that PRIVET\nreliably detects instances of memorization and privacy leakage across diverse\ndata modalities, including settings with very high dimensionality, limited\nsample sizes such as genetic data and even under underfitting regimes. We\ncompare our method to existing approaches under controlled settings and show\nits advantage in providing both dataset level and sample level assessments\nthrough qualitative and quantitative outputs. Additionally, our analysis\nreveals limitations in existing computer vision embeddings to yield\nperceptually meaningful distances when identifying near-duplicate samples.", "AI": {"tldr": "PRIVET \u7528\u6781\u503c\u7edf\u8ba1\u5904\u7406\u6700\u8fd1\u90bb\u8ddd\u79bb\uff0c\u4e3a\u6bcf\u4e2a\u5408\u6210\u6837\u672c\u751f\u6210\u9690\u79c1\u6cc4\u6f0f\u8bc4\u5206\uff0c\u80fd\u68c0\u6d4b\u8bb0\u5fc6\u5316\u3001\u9002\u7528\u4e8e\u9ad8\u7ef4\u4e0e\u5c0f\u6837\u672c\u57fa\u56e0\u6570\u636e\uff0c\u4e14\u5728\u5b9a\u91cf\u4e0e\u5b9a\u6027\u8bc4\u4f30\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u89e3\u51b3\u751f\u6210\u6a21\u578b\u8bad\u7ec3\u5728\u654f\u611f\u6570\u636e\u4e0a\u5bfc\u81f4\u7684\u9690\u79c1\u6cc4\u9732\u95ee\u9898\uff0c\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u6837\u672c\u7ea7\u9690\u79c1\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u5229\u7528\u6781\u503c\u7edf\u8ba1\uff08extreme value statistics\uff09\u5bf9\u5408\u6210\u6837\u672c\u4e0e\u771f\u5b9e\u6570\u636e\u7684\u6700\u8fd1\u90bb\u8ddd\u79bb\u5206\u5e03\u5efa\u6a21\uff0c\u8ba1\u7b97\u6837\u672c\u7ea7\u6cc4\u6f0f\u5206\u6570\uff0c\u652f\u6301\u591a\u6a21\u6001\u4e0e\u4f4e\u6837\u672c\u91cf\u573a\u666f\uff0c\u6bd4\u8f83\u5e76\u9a8c\u8bc1\u4e86\u5176\u68c0\u6d4b\u6548\u80fd\u3002", "result": "\u63d0\u51fa PRIVET\uff1a\u57fa\u4e8e\u6781\u503c\u7edf\u8ba1\u548c\u6700\u8fd1\u90bb\u8ddd\u79bb\u7684\u901a\u7528\u6837\u672c\u7ea7\u9690\u79c1\u6cc4\u9732\u8bc4\u5206\u7b97\u6cd5\uff0c\u80fd\u5728\u591a\u79cd\u6a21\u6001\u548c\u9ad8\u7ef4\u7a00\u6837\u672c\u60c5\u5f62\u4e0b\u68c0\u6d4b\u8bb0\u5fc6\u5316\u548c\u9690\u79c1\u6cc4\u9732\uff0c\u5e76\u4e0e\u73b0\u6709\u65b9\u6cd5\u6bd4\u8f83\u663e\u793a\u4f18\u52bf\u3002", "conclusion": "PRIVET \u63d0\u4f9b\u4e86\u53ef\u89e3\u91ca\u7684\u6837\u672c\u7ea7\u9690\u79c1\u98ce\u9669\u5ea6\u91cf\uff0c\u6269\u5c55\u4e86\u9690\u79c1\u8bc4\u4f30\u5de5\u5177\u7bb1\uff0c\u4f46\u53d7\u9650\u4e8e\u67d0\u4e9b\u8ba1\u7b97\u673a\u89c6\u89c9\u5d4c\u5165\u5728\u611f\u77e5\u76f8\u4f3c\u6027\u65b9\u9762\u7684\u8868\u73b0\u3002"}}
{"id": "2510.24234", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24234", "abs": "https://arxiv.org/abs/2510.24234", "authors": ["Ludovic Schwartz", "Hamish Flynn", "Gergely Neu"], "title": "Sparse Optimistic Information Directed Sampling", "comment": null, "summary": "Many high-dimensional online decision-making problems can be modeled as\nstochastic sparse linear bandits. Most existing algorithms are designed to\nachieve optimal worst-case regret in either the data-rich regime, where\npolynomial dependence on the ambient dimension is unavoidable, or the data-poor\nregime, where dimension-independence is possible at the cost of worse\ndependence on the number of rounds. In contrast, the sparse Information\nDirected Sampling (IDS) algorithm satisfies a Bayesian regret bound that has\nthe optimal rate in both regimes simultaneously. In this work, we explore the\nuse of Sparse Optimistic Information Directed Sampling (SOIDS) to achieve the\nsame adaptivity in the worst-case setting, without Bayesian assumptions.\nThrough a novel analysis that enables the use of a time-dependent learning\nrate, we show that SOIDS can optimally balance information and regret. Our\nresults extend the theoretical guarantees of IDS, providing the first algorithm\nthat simultaneously achieves optimal worst-case regret in both the data-rich\nand data-poor regimes. We empirically demonstrate the good performance of\nSOIDS.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e00\u79cd\u975e\u8d1d\u53f6\u65af\u7684\u7a00\u758f\u4e50\u89c2\u4fe1\u606f\u5bfc\u5411\u62bd\u6837\u7b97\u6cd5SOIDS\uff0c\u80fd\u5728\u6570\u636e\u7a00\u7f3a\u548c\u6570\u636e\u5145\u8db3\u4e24\u79cd\u6781\u7aef\u60c5\u5f62\u4e0b\u540c\u65f6\u8fbe\u5230\u6700\u4f18\u6700\u574f\u60c5\u51b5\u540e\u6094\u754c\uff0c\u4e14\u901a\u8fc7\u5f15\u5165\u65f6\u53d8\u5b66\u4e60\u7387\u7684\u65b0\u5206\u6790\u8bc1\u660e\u4e86\u4fe1\u606f\u4e0e\u540e\u6094\u7684\u6700\u4f18\u5e73\u8861\uff0c\u5e76\u7ed9\u51fa\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "motivation": "\u73b0\u6709\u7b97\u6cd5\u8981\u4e48\u5728\u6570\u636e\u4e30\u5bcc\u65f6\u53d7\u5230\u7ef4\u5ea6\u591a\u9879\u5f0f\u56e0\u5b50\u7684\u5f71\u54cd\uff0c\u8981\u4e48\u5728\u6570\u636e\u8d2b\u4e4f\u65f6\u80fd\u6d88\u9664\u7ef4\u5ea6\u4f9d\u8d56\u4f46\u4ee3\u4ef7\u662f\u5bf9\u8f6e\u6570T\u4f9d\u8d56\u53d8\u5dee\uff1b\u5e0c\u671b\u8bbe\u8ba1\u4e00\u4e2a\u5728\u6700\u574f\u60c5\u5f62\u4e0b\u80fd\u540c\u65f6\u517c\u987e\u4e24\u8005\u7684\u7b97\u6cd5\uff0c\u4e0d\u4f9d\u8d56\u8d1d\u53f6\u65af\u5148\u9a8c\u3002", "method": "\u57fa\u4e8e\u7a00\u758f\u4fe1\u606f\u5bfc\u5411\u62bd\u6837\uff08IDS\uff09\u601d\u60f3\uff0c\u6784\u9020\u7a00\u758f\u4e50\u89c2\u4fe1\u606f\u5bfc\u5411\u62bd\u6837\uff08SOIDS\uff09\uff0c\u5728\u9009\u62e9\u52a8\u4f5c\u65f6\u901a\u8fc7\u6743\u8861\u4fe1\u606f\u589e\u76ca\u548c\u6f5c\u5728\u540e\u6094\u503c\u5e76\u5f15\u5165\u4e50\u89c2\u4f30\u8ba1\uff1b\u5173\u952e\u5206\u6790\u4f7f\u7528\u4e86\u53ef\u968f\u65f6\u95f4\u53d8\u5316\u7684\u5b66\u4e60\u7387\uff0c\u4f7f\u5f97\u540c\u4e00\u7b97\u6cd5\u80fd\u5728\u4e24\u79cd regime \u95f4\u81ea\u9002\u5e94\u5730\u5e73\u8861\u63a2\u7d22\u4e0e\u5229\u7528\u5e76\u83b7\u5f97\u6700\u4f18\u754c\u3002", "result": "\u7406\u8bba\u4e0a\u8bc1\u660eSOIDS\u5728\u6700\u574f\u60c5\u51b5\u540e\u6094\u4e0a\u540c\u65f6\u8fbe\u5230\u4e24\u79cd regime \u7684\u6700\u4f18\u901f\u7387\uff08\u6d88\u9664\u4e86\u5bf9\u5148\u9a8c\u7684\u4f9d\u8d56\uff09\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u5728\u7a00\u758f\u9ad8\u7ef4\u7ebf\u6027bandit\u95ee\u9898\u4e2d\u7684\u4f18\u8d8a\u6027\u3002", "conclusion": "SOIDS\u5728\u65e0\u8d1d\u53f6\u65af\u5047\u8bbe\u4e0b\u4e5f\u80fd\u540c\u65f6\u5728\u6570\u636e\u4e30\u5bcc\u548c\u8d2b\u4e4f\u4e24\u79cd regimes \u8fbe\u5230\u6700\u4f18\u7684\u6700\u574f\u60c5\u51b5\u540e\u6094\u754c\uff0c\u8fd9\u662f\u9996\u6b21\u7ed9\u51fa\u5728\u4e24\u79cd regime \u90fd\u6700\u4f18\u7684\u7b97\u6cd5\uff0c\u4e14\u5b9e\u8bc1\u8868\u73b0\u826f\u597d\u3002"}}
{"id": "2510.24235", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24235", "abs": "https://arxiv.org/abs/2510.24235", "authors": ["Ai Jian", "Jingqing Ruan", "Xing Ma", "Dailin Li", "QianLin Zhou", "Ke Zeng", "Xunliang Cai"], "title": "PaTaRM: Bridging Pairwise and Pointwise Signals via Preference-Aware Task-Adaptive Reward Modeling", "comment": null, "summary": "Reward models (RMs) are central to reinforcement learning from human feedback\n(RLHF), providing the critical supervision signals that align large language\nmodels (LLMs) with human preferences. While generative reward models (GRMs)\noffer greater interpretability than traditional scalar RMs, current training\nparadigms remain limited. Pair-wise methods rely on binary good-versus-bad\nlabels, which cause mismatches for point-wise inference and necessitate complex\npairing strategies for effective application in RLHF. On the other hand,\npoint-wise methods require more elaborate absolute labeling with rubric-driven\ncriteria, resulting in poor adaptability and high annotation costs. In this\nwork, we propose the Preference-Aware Task-Adaptive Reward Model (PaTaRM), a\nunified framework that integrates a preference-aware reward (PAR) mechanism\nwith dynamic rubric adaptation. PaTaRM leverages relative preference\ninformation from pairwise data to construct robust point-wise training signals,\neliminating the need for explicit point-wise labels. Simultaneously, it employs\na task-adaptive rubric system that flexibly generates evaluation criteria for\nboth global task consistency and instance-specific fine-grained reasoning. This\ndesign enables efficient, generalizable, and interpretable reward modeling for\nRLHF. Extensive experiments show that PaTaRM achieves an average relative\nimprovement of 4.7% on RewardBench and RMBench across Qwen3-8B and Qwen3-14B\nmodels. Furthermore, PaTaRM boosts downstream RLHF performance, with an average\nimprovement of 13.6% across IFEval and InFoBench benchmarks, confirming its\neffectiveness and robustness. Our code is available at\nhttps://github.com/JaneEyre0530/PaTaRM.", "AI": {"tldr": "\u63d0\u51faPaTaRM\uff0c\u4e00\u79cd\u7ed3\u5408\u504f\u597d\u611f\u77e5\u5956\u52b1\u673a\u5236\u4e0e\u4efb\u52a1\u81ea\u9002\u5e94\u8bc4\u5206\u7ec6\u5219\u7684\u7edf\u4e00\u5956\u52b1\u6a21\u578b\u6846\u67b6\uff0c\u7528\u914d\u5bf9\u504f\u597d\u6570\u636e\u6784\u5efa\u7a33\u5065\u7684\u70b9\u5f0f\u8bad\u7ec3\u4fe1\u53f7\u5e76\u52a8\u6001\u751f\u6210\u5168\u5c40\u4e0e\u5b9e\u4f8b\u7ea7\u8bc4\u5206\u7ec6\u5219\uff0c\u5b9e\u73b0\u9ad8\u6548\u3001\u53ef\u89e3\u91ca\u7684RLHF\u5956\u52b1\u5efa\u6a21\uff0c\u5728\u591a\u9879\u57fa\u51c6\u4e0a\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u6210\u5bf9\u65b9\u6cd5\u4e0e\u70b9\u5f0f\u65b9\u6cd5\u5404\u81ea\u7f3a\u9677\uff1a\u6210\u5bf9\u65b9\u6cd5\u53ea\u80fd\u63d0\u4f9b\u4e8c\u5143\u504f\u597d\u5bfc\u81f4\u70b9\u5f0f\u63a8\u65ad\u4e0d\u5339\u914d\u5e76\u9700\u590d\u6742\u914d\u5bf9\u7b56\u7565\uff0c\u70b9\u5f0f\u65b9\u6cd5\u9700\u6602\u8d35\u4e14\u8106\u5f31\u7684\u7edd\u5bf9\u6807\u6ce8\u4e0e\u8bc4\u5206\u7ec6\u5219\u3002\u901a\u8fc7\u5229\u7528\u5df2\u6709\u7684\u914d\u5bf9\u504f\u597d\u5e76\u81ea\u52a8\u751f\u6210\u4efb\u52a1/\u5b9e\u4f8b\u7ea7\u8bc4\u5206\u7ec6\u5219\uff0c\u964d\u4f4e\u6807\u6ce8\u6210\u672c\u5e76\u63d0\u5347\u6cdb\u5316\u4e0e\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u5f15\u5165\u504f\u597d\u611f\u77e5\u5956\u52b1\uff08PAR\uff09\u673a\u5236\uff0c\u5c06\u6210\u5bf9\u504f\u597d\u6570\u636e\u8f6c\u6362\u4e3a\u8fde\u7eed\u7684\u70b9\u5f0f\u76ee\u6807\u5e76\u7528\u4e8e\u8bad\u7ec3\uff0c\u540c\u65f6\u8bbe\u8ba1\u52a8\u6001\u4efb\u52a1\u81ea\u9002\u5e94\u8bc4\u5206\u7ec6\u5219\uff0c\u5728\u5168\u5c40\u4efb\u52a1\u4e00\u81f4\u6027\u548c\u5b9e\u4f8b\u7ea7\u7ec6\u7c92\u5ea6\u63a8\u7406\u95f4\u751f\u6210\u8bc4\u4f30\u6807\u51c6\uff0c\u8054\u5408\u4f18\u5316\u4ee5\u8bad\u7ec3\u751f\u6210\u5f0f\u5956\u52b1\u6a21\u578b\u3002", "result": "\u5728Qwen3-8B\u4e0eQwen3-14B\u4e0a\uff0cPaTaRM\u5728RewardBench\u4e0eRMBench\u5e73\u5747\u63d0\u53474.7%\uff1b\u5728IFEval\u4e0eInFoBench\u7684\u4e0b\u6e38RLHF\u8bc4\u6d4b\u4e2d\u5e73\u5747\u63d0\u534713.6%\uff0c\u5c55\u793a\u4e86\u5956\u52b1\u4f30\u8ba1\u4e0e\u4e0b\u6e38\u8bad\u7ec3\u7684\u5b9e\u7528\u6536\u76ca\u3002", "conclusion": "PaTaRM\u5728\u5956\u52b1\u5efa\u6a21\u4e0e\u4e0b\u6e38RLHF\u4efb\u52a1\u4e0a\u8868\u73b0\u7a33\u5065\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6210\u5bf9\u6216\u70b9\u5f0f\u8bad\u7ec3\u8303\u5f0f\uff0c\u63d0\u5347\u4e86RewardBench/RMBench\u548cIFEval/InFoBench\u4e0a\u7684\u6027\u80fd\uff0c\u8bc1\u660e\u4e86\u5229\u7528\u914d\u5bf9\u504f\u597d\u6784\u5efa\u70b9\u5f0f\u4fe1\u53f7\u5e76\u7ed3\u5408\u4efb\u52a1\u81ea\u9002\u5e94\u8bc4\u5206\u7ec6\u5219\u7684\u6709\u6548\u6027\u4e0e\u901a\u7528\u6027\u3002"}}
{"id": "2510.24240", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24240", "abs": "https://arxiv.org/abs/2510.24240", "authors": ["Edward Markai", "Sina Molavipour"], "title": "Temporal Knowledge Graph Hyperedge Forecasting: Exploring Entity-to-Category Link Prediction", "comment": null, "summary": "Temporal Knowledge Graphs have emerged as a powerful way of not only modeling\nstatic relationships between entities but also the dynamics of how relations\nevolve over time. As these informational structures can be used to store\ninformation from a real-world setting, such as a news flow, predicting future\ngraph components to a certain extent equates predicting real-world events. Most\nof the research in this field focuses on embedding-based methods, often\nleveraging convolutional neural net architectures. These solutions act as black\nboxes, limiting insight. In this paper, we explore an extension to an\nestablished rule-based framework, TLogic, that yields a high accuracy in\ncombination with explainable predictions. This offers transparency and allows\nthe end-user to critically evaluate the rules applied at the end of the\nprediction stage. The new rule format incorporates entity category as a key\ncomponent with the purpose of limiting rule application only to relevant\nentities. When categories are unknown for building the graph, we propose a\ndata-driven method to generate them with an LLM-based approach. Additionally,\nwe investigate the choice of aggregation method for scores of retrieved\nentities when performing category prediction.", "AI": {"tldr": "Paper extends TLogic with category-aware rules and LLM-based category generation, achieving accurate, explainable temporal KG predictions and analyzing score aggregation methods.", "motivation": "Extend rule-based TLogic to improve temporal KG prediction with explainability and high accuracy by incorporating entity categories and LLM-driven category generation.", "method": "Modify TLogic rule format to include entity categories; use LLM to assign categories to entities from data; retrieve candidate entities and aggregate scores using various aggregation functions to predict categories and evaluate performance.", "result": "A new rule format adding entity category constraints improves prediction accuracy and explainability; LLM-based method generates categories when unknown; study of aggregation methods for category prediction scores.", "conclusion": "Incorporating entity categories into rule application yields more relevant, accurate, and explainable predictions; LLMs can generate categories when missing; aggregation choice affects category prediction performance."}}
{"id": "2510.24273", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24273", "abs": "https://arxiv.org/abs/2510.24273", "authors": ["Junlin Mu", "Hantao Huang", "Jihang Zhang", "Minghui Yu", "Tao Wang", "Yidong Li"], "title": "SALS: Sparse Attention in Latent Space for KV cache Compression", "comment": null, "summary": "Large Language Models capable of handling extended contexts are in high\ndemand, yet their inference remains challenging due to substantial Key-Value\ncache size and high memory bandwidth requirements. Previous research has\ndemonstrated that KV cache exhibits low-rank characteristics within the hidden\ndimension, suggesting the potential for effective compression. However, due to\nthe widely adopted Rotary Position Embedding mechanism in modern LLMs, naive\nlow-rank compression suffers severe accuracy degradation or creates a new speed\nbottleneck, as the low-rank cache must first be reconstructed in order to apply\nRoPE. In this paper, we introduce two key insights: first, the application of\nRoPE to the key vectors increases their variance, which in turn results in a\nhigher rank; second, after the key vectors are transformed into the latent\nspace, they largely maintain their representation across most layers. Based on\nthese insights, we propose the Sparse Attention in Latent Space framework. SALS\nprojects the KV cache into a compact latent space via low-rank projection, and\nperforms sparse token selection using RoPE-free query-key interactions in this\nspace. By reconstructing only a small subset of important tokens, it avoids the\noverhead of full KV cache reconstruction. We comprehensively evaluate SALS on\nvarious tasks using two large-scale models: LLaMA2-7b-chat and Mistral-7b, and\nadditionally verify its scalability on the RULER-128k benchmark with\nLLaMA3.1-8B-Instruct. Experimental results demonstrate that SALS achieves SOTA\nperformance by maintaining competitive accuracy. Under different settings, SALS\nachieves 6.4-fold KV cache compression and 5.7-fold speed-up in the attention\noperator compared to FlashAttention2 on the 4K sequence. For the end-to-end\nthroughput performance, we achieves 1.4-fold and 4.5-fold improvement compared\nto GPT-fast on 4k and 32K sequences, respectively.", "AI": {"tldr": "SALS\u5728\u6f5c\u5728\u7a7a\u95f4\u4f4e\u79e9\u6295\u5f71KV\u5e76\u57fa\u4e8e\u65e0RoPE\u7684\u7a00\u758f\u9009\u62e9\u53ea\u91cd\u6784\u91cd\u8981token\uff0c\u8fbe\u52306.4x\u7f13\u5b58\u538b\u7f29\u30015.7x\u6ce8\u610f\u529b\u901f\u5ea6\u63d0\u5347\uff0c\u7aef\u5230\u7aef\u541e\u5410\u91cf\u6bd4GPT-fast\u63d0\u53471.4x\uff084k\uff09\u548c4.5x\uff0832k\uff09\u3002", "motivation": "\u5f53\u524d\u957f\u4e0a\u4e0b\u6587LLM\u7684KV\u7f13\u5b58\u4f53\u79ef\u5927\u4e14\u5e26\u5bbd\u9700\u6c42\u9ad8\uff0c\u5c3d\u7ba1KV\u5728\u9690\u85cf\u7ef4\u5ea6\u4e0a\u5448\u4f4e\u79e9\uff0c\u4f46RoPE\u4f7f\u5f97\u76f4\u63a5\u4f4e\u79e9\u538b\u7f29\u8868\u73b0\u5dee\u6216\u5e26\u6765\u91cd\u5efa\u5f00\u9500\uff0c\u9700\u4e00\u79cd\u5728\u4fdd\u6301RoPE\u6548\u679c\u4e0b\u6709\u6548\u538b\u7f29KV\u7684\u65b9\u6848\u3002", "method": "\u5c06KV\u7f13\u5b58\u6295\u5f71\u5230\u4e00\u4e2a\u4f4e\u7ef4\u6f5c\u5728\u7a7a\u95f4\uff0c\u5229\u7528RoPE-free\u7684\u67e5\u8be2-\u952e\u76f8\u4e92\u4f5c\u7528\u5728\u6f5c\u5728\u7a7a\u95f4\u8fdb\u884c\u7a00\u758ftoken\u9009\u62e9\uff0c\u4ec5\u91cd\u6784\u5c11\u91cf\u91cd\u8981\u7684token\u7684KV\u4ee5\u6267\u884c\u6ce8\u610f\u529b\uff0c\u4ece\u800c\u907f\u514d\u5bf9\u5b8c\u6574KV\u7684\u91cd\u5efa\u5f00\u9500\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u6f5c\u5728\u7a7a\u95f4\u8fdb\u884c\u7a00\u758f\u6ce8\u610f\u529b\uff08SALS\uff09\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5bf9KV\u7f13\u5b58\u8fdb\u884c\u4f4e\u79e9\u6295\u5f71\u5e76\u5728\u4e0d\u4f7f\u7528RoPE\u7684\u6f5c\u5728\u7a7a\u95f4\u4e2d\u8fdb\u884c\u67e5\u8be2-\u952e\u4ea4\u4e92\uff0c\u91cd\u6784\u5c11\u91cf\u91cd\u8981token\u4ee5\u907f\u514d\u6574\u4f53\u91cd\u5efa\u5f00\u9500\uff0c\u4ece\u800c\u5728\u4fdd\u6301\u7cbe\u5ea6\u7684\u540c\u65f6\u663e\u8457\u538b\u7f29KV\u7f13\u5b58\u5e76\u63d0\u5347\u6ce8\u610f\u529b\u7b97\u5b50\u901f\u5ea6\u3002", "conclusion": "SALS\u80fd\u5728\u7ef4\u6301\u7ade\u4e89\u7cbe\u5ea6\u7684\u540c\u65f6\uff0c\u663e\u8457\u51cf\u5c11KV\u7f13\u5b58\u5360\u7528\u5e76\u52a0\u901f\u6ce8\u610f\u529b\u8ba1\u7b97\uff0c\u9002\u7528\u4e8e\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u5e76\u5728\u591a\u4e2a\u5927\u6a21\u578b\u548c\u957f\u5e8f\u5217\u57fa\u51c6\u4e0a\u53d6\u5f97SOTA\u8868\u73b0\u3002"}}
{"id": "2510.24310", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24310", "abs": "https://arxiv.org/abs/2510.24310", "authors": ["Guus Toussaint", "Arno Knobbe"], "title": "EDC: Equation Discovery for Classification", "comment": "This preprint has not undergone peer review or any post-submission\n  improvements or corrections. The Version of Record of this contribution is\n  published in Lecture Notes in Computer Science, and is available online at\n  https://doi.org/10.1007/978-3-032-05461-6_9", "summary": "Equation Discovery techniques have shown considerable success in regression\ntasks, where they are used to discover concise and interpretable models\n(\\textit{Symbolic Regression}). In this paper, we propose a new ED-based binary\nclassification framework. Our proposed method EDC finds analytical functions of\nmanageable size that specify the location and shape of the decision boundary.\nIn extensive experiments on artificial and real-life data, we demonstrate how\nEDC is able to discover both the structure of the target equation as well as\nthe value of its parameters, outperforming the current state-of-the-art\nED-based classification methods in binary classification and achieving\nperformance comparable to the state of the art in binary classification. We\nsuggest a grammar of modest complexity that appears to work well on the tested\ndatasets but argue that the exact grammar -- and thus the complexity of the\nmodels -- is configurable, and especially domain-specific expressions can be\nincluded in the pattern language, where that is required. The presented grammar\nconsists of a series of summands (additive terms) that include linear,\nquadratic and exponential terms, as well as products of two features (producing\nhyperbolic curves ideal for capturing XOR-like dependencies). The experiments\ndemonstrate that this grammar allows fairly flexible decision boundaries while\nnot so rich to cause overfitting.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u57fa\u4e8e\u65b9\u7a0b\u53d1\u73b0\uff08ED\uff09\u7684\u4e8c\u5206\u7c7b\u6846\u67b6EDC\uff0c\u80fd\u53d1\u73b0\u53ef\u89e3\u91ca\u7684\u51b3\u7b56\u8fb9\u754c\u51fd\u6570\u3002\u4f7f\u7528\u4e00\u4e2a\u9002\u5ea6\u590d\u6742\u7684\u6587\u6cd5\uff08\u7ebf\u6027\u3001\u4e8c\u6b21\u3001\u6307\u6570\u53ca\u4e24\u7279\u5f81\u4e58\u79ef\u9879\uff09\u751f\u6210\u53ef\u7ba1\u7406\u5927\u5c0f\u7684\u89e3\u6790\u8868\u8fbe\u5f0f\uff0c\u5728\u4eba\u5de5\u4e0e\u771f\u5b9e\u6570\u636e\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709ED\u5206\u7c7b\u65b9\u6cd5\uff0c\u5e76\u4e0e\u6700\u5148\u8fdb\u4e8c\u5206\u7c7b\u65b9\u6cd5\u6027\u80fd\u76f8\u5f53\uff0c\u4e14\u53ef\u901a\u8fc7\u8c03\u6574\u6587\u6cd5\u878d\u5165\u9886\u57df\u7279\u5b9a\u8868\u8fbe\u5f0f\u3002", "motivation": "\u5c06\u7b26\u53f7\u56de\u5f52\u4e2d\u53ef\u89e3\u91ca\u4e14\u7d27\u51d1\u7684\u6a21\u578b\u4f18\u52bf\u6269\u5c55\u5230\u4e8c\u5206\u7c7b\u4efb\u52a1\uff0c\u4ea7\u751f\u65e2\u53ef\u89e3\u91ca\u53c8\u9ad8\u6548\u7684\u5206\u7c7b\u5668\uff0c\u89e3\u51b3\u73b0\u6709ED\u65b9\u6cd5\u5728\u5206\u7c7b\u4efb\u52a1\u4e0a\u7684\u5c40\u9650\u3002", "method": "\u4f7f\u7528\u65b9\u7a0b\u53d1\u73b0\u65b9\u6cd5\u5728\u4e8c\u5206\u7c7b\u60c5\u5f62\u4e0b\u641c\u7d22\u89e3\u6790\u51fd\u6570\u4f5c\u4e3a\u51b3\u7b56\u51fd\u6570\uff0c\u91c7\u7528\u4e00\u4e2a\u7531\u82e5\u5e72\u52a0\u6cd5\u9879\u7ec4\u6210\u7684\u6587\u6cd5\uff1a\u5305\u62ec\u7ebf\u6027\u3001\u4e8c\u6b21\u3001\u6307\u6570\u4ee5\u53ca\u4e24\u4e2a\u7279\u5f81\u4e58\u79ef\u9879\uff08\u9002\u5408\u6355\u6349XOR\u6837\u5f0f\u4f9d\u8d56\uff09\u3002\u901a\u8fc7\u53c2\u6570\u62df\u5408\u548c\u7ed3\u6784\u641c\u7d22\u540c\u65f6\u786e\u5b9a\u6a21\u578b\u5f62\u5f0f\u4e0e\u53c2\u6570\u503c\u3002", "result": "\u5728\u5408\u6210\u4e0e\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\uff0cEDC\u80fd\u6062\u590d\u76ee\u6807\u65b9\u7a0b\u7684\u7ed3\u6784\u4e0e\u53c2\u6570\uff0c\u5206\u7c7b\u6027\u80fd\u4f18\u4e8e\u73b0\u6709ED\u57fa\u7ebf\u5e76\u63a5\u8fd1\u6700\u5148\u8fdb\u5206\u7c7b\u65b9\u6cd5\uff1b\u6240\u63d0\u51fa\u6587\u6cd5\u5728\u8868\u8fbe\u7075\u6d3b\u6027\u4e0e\u9632\u6b62\u8fc7\u62df\u5408\u4e4b\u95f4\u53d6\u5f97\u4e86\u5e73\u8861\u3002", "conclusion": "EDC\u80fd\u53d1\u73b0\u65e2\u89e3\u91ca\u6027\u5f3a\u53c8\u4e0d\u6613\u8fc7\u62df\u5408\u7684\u51b3\u7b56\u8fb9\u754c\u8868\u8fbe\u5f0f\uff0c\u80fd\u6062\u590d\u76ee\u6807\u65b9\u7a0b\u7ed3\u6784\u548c\u53c2\u6570\uff0c\u5728\u4e8c\u5206\u7c7b\u4efb\u52a1\u4e0a\u8d85\u8d8a\u73b0\u6709ED\u65b9\u6cd5\u5e76\u63a5\u8fd1\u6700\u5148\u8fdb\u5206\u7c7b\u5668\u6027\u80fd\uff0c\u4e14\u6587\u6cd5\u53ef\u914d\u7f6e\u4ee5\u9002\u5e94\u4e0d\u540c\u9886\u57df\u3002"}}
{"id": "2510.24318", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24318", "abs": "https://arxiv.org/abs/2510.24318", "authors": ["Prajit Bhaskaran", "Tom Viering"], "title": "Transformers can do Bayesian Clustering", "comment": null, "summary": "Bayesian clustering accounts for uncertainty but is computationally demanding\nat scale. Furthermore, real-world datasets often contain missing values, and\nsimple imputation ignores the associated uncertainty, resulting in suboptimal\nresults. We present Cluster-PFN, a Transformer-based model that extends\nPrior-Data Fitted Networks (PFNs) to unsupervised Bayesian clustering. Trained\nentirely on synthetic datasets generated from a finite Gaussian Mixture Model\n(GMM) prior, Cluster-PFN learns to estimate the posterior distribution over\nboth the number of clusters and the cluster assignments. Our method estimates\nthe number of clusters more accurately than handcrafted model selection\nprocedures such as AIC, BIC and Variational Inference (VI), and achieves\nclustering quality competitive with VI while being orders of magnitude faster.\nCluster-PFN can be trained on complex priors that include missing data,\noutperforming imputation-based baselines on real-world genomic datasets, at\nhigh missingness. These results show that the Cluster-PFN can provide scalable\nand flexible Bayesian clustering.", "AI": {"tldr": "Cluster-PFN: a Transformer PFN trained on synthetic GMM data to do fast, scalable Bayesian clustering with missing-data-aware priors, better cluster-number estimation and competitive clustering quality", "motivation": "Extend PFNs to Bayesian clustering to handle uncertainty and missing data at scale", "method": "Train a Transformer-based PFN on synthetic datasets sampled from finite GMM prior to learn posterior over number of clusters and assignments; can incorporate complex priors including missing-data mechanisms; compare to AIC/BIC/VI and imputation baselines on real datasets", "result": "Cluster-PFN estimates posterior over number of clusters and assignments, outperforms AIC/BIC/VI in estimating cluster count, competitive clustering quality with much faster runtime, handles missing data better than imputation baselines", "conclusion": "Cluster-PFN offers scalable, flexible Bayesian clustering that accurately estimates cluster count, matches VI clustering quality, handles high missingness, and is much faster"}}
{"id": "2510.24331", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.24331", "abs": "https://arxiv.org/abs/2510.24331", "authors": ["Gabriel O. dos Santos", "Esther Colombini", "Sandra Avila"], "title": "What do vision-language models see in the context? Investigating multimodal in-context learning", "comment": null, "summary": "In-context learning (ICL) enables Large Language Models (LLMs) to learn tasks\nfrom demonstration examples without parameter updates. Although it has been\nextensively studied in LLMs, its effectiveness in Vision-Language Models (VLMs)\nremains underexplored. In this work, we present a systematic study of ICL in\nVLMs, evaluating seven models spanning four architectures on three image\ncaptioning benchmarks. We analyze how prompt design, architectural choices, and\ntraining strategies influence multimodal ICL. To our knowledge, we are the\nfirst to analyze how attention patterns in VLMs vary with an increasing number\nof in-context demonstrations. Our results reveal that training on imag-text\ninterleaved data enhances ICL performance but does not imply effective\nintegration of visual and textual information from demonstration examples. In\ncontrast, instruction tuning improves instruction-following but can reduce\nreliance on in-context demonstrations, suggesting a trade-off between\ninstruction alignment and in-context adaptation. Attention analyses further\nshow that current VLMs primarily focus on textual cues and fail to leverage\nvisual information, suggesting a limited capacity for multimodal integration.\nThese findings highlight key limitations in the ICL abilities of current VLMs\nand provide insights for enhancing their ability to learn from multimodal\nin-context examples.", "AI": {"tldr": "\u7cfb\u7edf\u8bc4\u4f30\u663e\u793a\u5f53\u524dVLM\u5728ICL\u4e0a\u4e3b\u8981\u4f9d\u8d56\u6587\u672c\u4fe1\u606f\uff0c\u89c6\u89c9\u6574\u5408\u80fd\u529b\u5f31\uff0c\u8bad\u7ec3\u4e0e\u5fae\u8c03\u7b56\u7565\u5f71\u54cdICL\u8868\u73b0\u4e14\u5b58\u5728\u6743\u8861\u3002", "motivation": "\u5c3d\u7ba1LLM\u4e2dICL\u5e7f\u6cdb\u7814\u7a76\uff0c\u4f46VLM\u4e2d\u7684\u591a\u6a21\u6001ICL\u6548\u679c\u5c1a\u672a\u5145\u5206\u63a2\u8ba8\uff1b\u9700\u7cfb\u7edf\u8bc4\u4f30\u4e0d\u540c\u56e0\u7d20\u5bf9VLM ICL\u7684\u5f71\u54cd\u3002", "method": "\u5728\u4e09\u4e2a\u4eba\u50cf\u63cf\u8ff0\u4efb\u52a1\u4e0a\uff0c\u8bc4\u4f30\u4e03\u4e2aVLM\uff08\u56db\u79cd\u67b6\u6784\uff09\uff0c\u901a\u8fc7\u5bf9\u6bd4\u63d0\u793a\u8bbe\u8ba1\u3001\u6a21\u578b\u67b6\u6784\u3001\u8bad\u7ec3\u7b56\u7565\uff0c\u4ee5\u53ca\u6ce8\u610f\u529b\u6a21\u5f0f\u968f\u793a\u4f8b\u6570\u91cf\u53d8\u5316\u7684\u5206\u6790\u6765\u7814\u7a76\u591a\u6a21\u6001ICL\u3002", "result": "\u53d1\u73b0\u4ea4\u53c9\u56fe\u6587\u8bad\u7ec3\u80fd\u63d0\u5347ICL\u8868\u73b0\u4f46\u672a\u5fc5\u5b9e\u73b0\u793a\u4f8b\u4e2d\u89c6\u89c9-\u6587\u672c\u4fe1\u606f\u7684\u6709\u6548\u878d\u5408\uff1b\u6307\u4ee4\u5fae\u8c03\u63d0\u5347\u6307\u4ee4\u9075\u4ece\u6027\u4f46\u964d\u4f4e\u5bf9\u793a\u4f8b\u4f9d\u8d56\uff1b\u6ce8\u610f\u529b\u5206\u6790\u663e\u793a\u6a21\u578b\u4e3b\u8981\u5173\u6ce8\u6587\u672c\uff0c\u89c6\u89c9\u5229\u7528\u53d7\u9650\u3002", "conclusion": "VLMs\u7684ICL\u80fd\u529b\u6709\u9650\uff0c\u5b58\u5728\u6587\u672c\u4e3b\u5bfc\u3001\u89c6\u89c9\u6574\u5408\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u4e14\u8bad\u7ec3\u7b56\u7565\u548c\u6307\u4ee4\u5fae\u8c03\u4f1a\u5f71\u54cdICL\u8868\u73b0\u4ea7\u751f\u6743\u8861\u3002"}}
{"id": "2510.24356", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.24356", "abs": "https://arxiv.org/abs/2510.24356", "authors": ["Suman Sanyal"], "title": "Perception Learning: A Formal Separation of Sensory Representation Learning from Decision Learning", "comment": null, "summary": "We introduce Perception Learning (PeL), a paradigm that optimizes an agent's\nsensory interface $f_\\phi:\\mathcal{X}\\to\\mathcal{Z}$ using task-agnostic\nsignals, decoupled from downstream decision learning\n$g_\\theta:\\mathcal{Z}\\to\\mathcal{Y}$. PeL directly targets label-free\nperceptual properties, such as stability to nuisances, informativeness without\ncollapse, and controlled geometry, assessed via objective\nrepresentation-invariant metrics. We formalize the separation of perception and\ndecision, define perceptual properties independent of objectives or\nreparameterizations, and prove that PeL updates preserving sufficient\ninvariants are orthogonal to Bayes task-risk gradients. Additionally, we\nprovide a suite of task-agnostic evaluation metrics to certify perceptual\nquality.", "AI": {"tldr": "\u63d0\u51faPerception Learning (PeL)\u8303\u5f0f\uff1a\u7528\u4e0e\u4efb\u52a1\u65e0\u5173\u7684\u4fe1\u53f7\u4f18\u5316\u611f\u77e5\u63a5\u53e3 f_phi\uff0c\u4f7f\u5176\u5728\u4e0d\u4f9d\u8d56\u4e0b\u6e38\u51b3\u7b56\u5b66\u4e60 g_theta \u7684\u60c5\u51b5\u4e0b\u5177\u5907\u7a33\u5b9a\u6027\u3001\u4fe1\u606f\u6027\u548c\u53ef\u63a7\u51e0\u4f55\u7b49\u611f\u77e5\u6027\u8d28\uff1b\u5f62\u5f0f\u5316\u611f\u77e5-\u51b3\u7b56\u5206\u79bb\uff0c\u5b9a\u4e49\u4e0e\u76ee\u6807\u6216\u91cd\u53c2\u6570\u5316\u65e0\u5173\u7684\u611f\u77e5\u6027\u8d28\uff0c\u8bc1\u660e\u4fdd\u6301\u5145\u5206\u4e0d\u53d8\u6027\u7684PeL\u66f4\u65b0\u4e0e\u8d1d\u53f6\u65af\u4efb\u52a1\u98ce\u9669\u68af\u5ea6\u6b63\u4ea4\uff0c\u5e76\u7ed9\u51fa\u4e00\u7ec4\u4efb\u52a1\u65e0\u5173\u7684\u8bc4\u4f30\u6307\u6807\u4ee5\u8bc1\u660e\u611f\u77e5\u8d28\u91cf\u3002", "motivation": "\u5728\u8bb8\u591a\u7cfb\u7edf\u4e2d\u611f\u77e5\u6a21\u5757\u5e94\u5177\u5907\u666e\u9002\u4e14\u53ef\u8ba4\u8bc1\u7684\u6027\u8d28\uff08\u5982\u5bf9\u5e72\u6270\u7684\u7a33\u5b9a\u6027\u548c\u4fe1\u606f\u5b8c\u6574\u6027\uff09\uff0c\u4f46\u4f20\u7edf\u7aef\u5230\u7aef\u6216\u4efb\u52a1\u9a71\u52a8\u8bad\u7ec3\u96be\u4ee5\u4fdd\u8bc1\u8fd9\u4e9b\u6027\u8d28\u6216\u5728\u4efb\u52a1\u5207\u6362\u65f6\u8fc1\u79fb\u3002PeL\u65e8\u5728\u72ec\u7acb\u8bad\u7ec3\u611f\u77e5\u63a5\u53e3\u4ee5\u83b7\u5f97\u53ef\u8bc1\u660e\u7684\u3001\u4efb\u52a1\u65e0\u5173\u7684\u611f\u77e5\u8d28\u91cf\u3002", "method": "\u5b9a\u4e49\u611f\u77e5/\u51b3\u7b56\u5206\u79bb\u6846\u67b6\uff0c\u8bbe\u8ba1\u57fa\u4e8e\u8868\u5f81\u4e0d\u53d8\u6027\u7684\u4efb\u52a1\u65e0\u5173\u76ee\u6807\u6765\u8bad\u7ec3\u611f\u77e5\u6620\u5c04 f_phi\uff1b\u8bc1\u660e\u6570\u5b66\u6027\u8d28\u2014\u2014\u4fdd\u6301\u5145\u5206\u4e0d\u53d8\u6027\u65f6PeL\u66f4\u65b0\u4e0e\u4e0b\u6e38\u8d1d\u53f6\u65af\u98ce\u9669\u68af\u5ea6\u6b63\u4ea4\uff1b\u5e76\u63d0\u51fa\u82e5\u5e72\u65e0\u6807\u7b7e\u8bc4\u4f30\u6307\u6807\uff08\u5982\u7a33\u5065\u6027\u3001\u4e92\u4fe1\u606f\u8fd1\u4f3c\u6216\u8868\u5f81\u51e0\u4f55\u91cf\u5ea6\uff09\u6765\u5ea6\u91cf\u611f\u77e5\u8d28\u91cf\u3002", "result": "\u7406\u8bba\u8bc1\u660ePeL\u66f4\u65b0\u4e0e\u8d1d\u53f6\u65af\u4efb\u52a1\u98ce\u9669\u68af\u5ea6\u5728\u4fdd\u6301\u8db3\u591f\u4e0d\u53d8\u6027\u4e0b\u6b63\u4ea4\uff1b\u63d0\u51fa\u5e76\u5b9e\u73b0\u4e00\u5957\u4efb\u52a1\u65e0\u5173\u8bc4\u4f30\u6307\u6807\u7528\u4e8e\u9a8c\u8bc1\u611f\u77e5\u8d28\u91cf\uff08\u7a33\u5b9a\u6027\u3001\u65e0\u574d\u7f29\u7684\u4fe1\u606f\u6027\u3001\u53ef\u63a7\u8868\u5f81\u51e0\u4f55\uff09\u3002", "conclusion": "PeL\u80fd\u5728\u4e0d\u4f9d\u8d56\u4efb\u52a1\u6807\u7b7e\u6216\u4e0b\u6e38\u51b3\u7b56\u7684\u60c5\u51b5\u4e0b\uff0c\u901a\u8fc7\u4f18\u5316\u611f\u77e5\u63a5\u53e3\u6765\u83b7\u5f97\u7a33\u5b9a\u3001\u6709\u4fe1\u606f\u4e14\u51e0\u4f55\u53ef\u63a7\u7684\u8868\u793a\uff1b\u7406\u8bba\u4e0a\uff0c\u5176\u66f4\u65b0\u5728\u4fdd\u62a4\u5fc5\u8981\u4e0d\u53d8\u6027\u7684\u524d\u63d0\u4e0b\u4e0d\u4f1a\u5e72\u6270\u8d1d\u53f6\u65af\u6700\u5c0f\u5316\u4efb\u52a1\u98ce\u9669\uff1b\u5e76\u53ef\u901a\u8fc7\u63d0\u51fa\u7684\u4efb\u52a1\u65e0\u5173\u5ea6\u91cf\u6765\u8ba4\u8bc1\u611f\u77e5\u8d28\u91cf\u3002"}}
{"id": "2510.24368", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24368", "abs": "https://arxiv.org/abs/2510.24368", "authors": ["Maria Gabriela Valeriano", "David Kohan Marzag\u00e3o", "Alfredo Montelongo", "Carlos Roberto Veiga Kiffer", "Natan Katz", "Ana Carolina Lorena"], "title": "Filtering instances and rejecting predictions to obtain reliable models in healthcare", "comment": "This paper is under review at Machine Learning (Springer)", "summary": "Machine Learning (ML) models are widely used in high-stakes domains such as\nhealthcare, where the reliability of predictions is critical. However, these\nmodels often fail to account for uncertainty, providing predictions even with\nlow confidence. This work proposes a novel two-step data-centric approach to\nenhance the performance of ML models by improving data quality and filtering\nlow-confidence predictions. The first step involves leveraging Instance\nHardness (IH) to filter problematic instances during training, thereby refining\nthe dataset. The second step introduces a confidence-based rejection mechanism\nduring inference, ensuring that only reliable predictions are retained. We\nevaluate our approach using three real-world healthcare datasets, demonstrating\nits effectiveness at improving model reliability while balancing predictive\nperformance and rejection rate. Additionally, we use alternative criteria -\ninfluence values for filtering and uncertainty for rejection - as baselines to\nevaluate the efficiency of the proposed method. The results demonstrate that\nintegrating IH filtering with confidence-based rejection effectively enhances\nmodel performance while preserving a large proportion of instances. This\napproach provides a practical method for deploying ML systems in\nsafety-critical applications.", "AI": {"tldr": "\u901a\u8fc7\u8bad\u7ec3\u65f6\u5254\u9664\u9ad8IH\u6837\u672c\u5e76\u5728\u63a8\u7406\u65f6\u62d2\u7edd\u4f4e\u7f6e\u4fe1\u9884\u6d4b\uff0c\u80fd\u5728\u533b\u7597\u573a\u666f\u4e0b\u63d0\u5347\u6a21\u578b\u53ef\u9760\u6027\uff0c\u662f\u4e00\u79cd\u7b80\u5355\u6709\u6548\u7684\u5b89\u5168\u90e8\u7f72\u7b56\u7565\u3002", "motivation": "\u5728\u533b\u7597\u7b49\u9ad8\u98ce\u9669\u9886\u57df\uff0c\u6a21\u578b\u5728\u4f4e\u7f6e\u4fe1\u5ea6\u60c5\u51b5\u4e0b\u4ecd\u7ed9\u51fa\u9884\u6d4b\u53ef\u80fd\u9020\u6210\u4e25\u91cd\u540e\u679c\uff1b\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u5b9e\u7528\u65b9\u6cd5\u65e2\u63d0\u9ad8\u8bad\u7ec3\u6570\u636e\u8d28\u91cf\u53c8\u5728\u63a8\u7406\u65f6\u8fc7\u6ee4\u4e0d\u53ef\u9760\u9884\u6d4b\u4ee5\u63d0\u5347\u7cfb\u7edf\u5b89\u5168\u6027\u548c\u53ef\u9760\u6027\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\uff1a1) \u5229\u7528\u5b9e\u4f8b\u96be\u5ea6(Instance Hardness, IH)\u6307\u6807\u5728\u8bad\u7ec3\u9636\u6bb5\u7b5b\u9664\u9ad8\u96be\u5ea6\u6216\u566a\u58f0\u6837\u672c\u4ee5\u63d0\u5347\u6570\u636e\u8d28\u91cf\uff1b2) \u5728\u63a8\u7406\u9636\u6bb5\u5f15\u5165\u57fa\u4e8e\u7f6e\u4fe1\u5ea6\u7684\u62d2\u7edd\u673a\u5236\uff0c\u5254\u9664\u4f4e\u7f6e\u4fe1\u5ea6\u9884\u6d4b\u4ee5\u63d0\u9ad8\u53ef\u9760\u6027\u3002\u5e76\u7528\u5f71\u54cd\u529b\u503c(influence)\u548c\u4e0d\u786e\u5b9a\u6027(uncertainty)\u4f5c\u4e3a\u66ff\u4ee3\u57fa\u7ebf\u5206\u522b\u7528\u4e8e\u7b5b\u9664\u4e0e\u62d2\u7edd\u6b65\u9aa4\u7684\u6bd4\u8f83\u3002", "result": "\u5728\u4e09\u4e2a\u771f\u5b9e\u533b\u7597\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff1a\u4e0e\u57fa\u7ebf\uff08\u5982\u5f71\u54cd\u529b\u7b5b\u9664\u6216\u4e0d\u786e\u5b9a\u6027\u62d2\u7edd\uff09\u76f8\u6bd4\uff0cIH\u7b5b\u9664+\u7f6e\u4fe1\u5ea6\u62d2\u7edd\u7ec4\u5408\u5728\u591a\u9879\u6027\u80fd\u5ea6\u91cf\uff08\u5982\u51c6\u786e\u7387\u3001F1\u3001\u4fdd\u7559\u7387\u4e0e\u62d2\u7edd\u7387\u6298\u4e2d\uff09\u4e0a\u5177\u6709\u4f18\u52bf\uff0c\u4e14\u80fd\u4fdd\u7559\u5927\u91cf\u6837\u672c\uff0c\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4f4e\u7f6e\u4fe1\u9519\u8bef\u9884\u6d4b\u7684\u53d1\u751f\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u6570\u636e\u4e2d\u5fc3\u5316\u4e24\u6b65\u65b9\u6cd5\uff08\u8bad\u7ec3\u65f6\u57fa\u4e8e\u5b9e\u4f8b\u96be\u5ea6\u7b5b\u9664\u95ee\u9898\u6837\u672c\uff0c\u63a8\u7406\u65f6\u57fa\u4e8e\u7f6e\u4fe1\u5ea6\u62d2\u7edd\u4f4e\u7f6e\u4fe1\u9884\u6d4b\uff09\u80fd\u5728\u771f\u5b9e\u533b\u7597\u6570\u636e\u96c6\u4e0a\u63d0\u5347\u6a21\u578b\u53ef\u9760\u6027\uff0c\u5728\u4fdd\u6301\u8f83\u5927\u4fdd\u7559\u7387\u7684\u540c\u65f6\u6539\u5584\u9884\u6d4b\u6027\u80fd\u4e0e\u62d2\u7edd\u7387\u4e4b\u95f4\u7684\u5e73\u8861\u3002"}}
{"id": "2510.24375", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24375", "abs": "https://arxiv.org/abs/2510.24375", "authors": ["Yuanyuan Wu", "Zhenlin Qin", "Zhenliang Ma"], "title": "A Comprehensive Evaluation Framework for Synthetic Trip Data Generation in Public Transport", "comment": null, "summary": "Synthetic data offers a promising solution to the privacy and accessibility\nchallenges of using smart card data in public transport research. Despite rapid\nprogress in generative modeling, there is limited attention to comprehensive\nevaluation, leaving unclear how reliable, safe, and useful synthetic data truly\nare. Existing evaluations remain fragmented, typically limited to\npopulation-level representativeness or record-level privacy, without\nconsidering group-level variations or task-specific utility. To address this\ngap, we propose a Representativeness-Privacy-Utility (RPU) framework that\nsystematically evaluates synthetic trip data across three complementary\ndimensions and three hierarchical levels (record, group, population). The\nframework integrates a consistent set of metrics to quantify similarity,\ndisclosure risk, and practical usefulness, enabling transparent and balanced\nassessment of synthetic data quality. We apply the framework to benchmark\ntwelve representative generation methods, spanning conventional statistical\nmodels, deep generative networks, and privacy-enhanced variants. Results show\nthat synthetic data do not inherently guarantee privacy and there is no\n\"one-size-fits-all\" model, the trade-off between privacy and\nrepresentativeness/utility is obvious. Conditional Tabular generative\nadversarial network (CTGAN) provide the most balanced trade-off and is\nsuggested for practical applications. The RPU framework provides a systematic\nand reproducible basis for researchers and practitioners to compare synthetic\ndata generation techniques and select appropriate methods in public transport\napplications.", "AI": {"tldr": "\u63d0\u51fa RPU \u6846\u67b6\uff0c\u7cfb\u7edf\u8bc4\u4f30\u5408\u6210\u51fa\u884c\u6570\u636e\u5728\u4ee3\u8868\u6027\u3001\u9690\u79c1\u4e0e\u6548\u7528\u4e09\u65b9\u9762\u7684\u8d28\u91cf\uff0c\u5e76\u57fa\u51c6\u6bd4\u8f8312\u79cd\u751f\u6210\u65b9\u6cd5\uff0c\u53d1\u73b0 CTGAN \u5728\u6743\u8861\u5404\u9879\u6307\u6807\u4e0a\u6700\u4f18\uff0c\u5f3a\u8c03\u9700\u4efb\u52a1\u4e0e\u7fa4\u7ec4\u654f\u611f\u7684\u7efc\u5408\u8bc4\u4f30\u3002", "motivation": "\u73b0\u6709\u5408\u6210\u667a\u80fd\u5361\u51fa\u884c\u6570\u636e\u8bc4\u4f30\u96f6\u6563\u4e14\u4e0d\u5168\u9762\uff0c\u591a\u6570\u53ea\u5173\u6ce8\u603b\u4f53\u4ee3\u8868\u6027\u6216\u8bb0\u5f55\u7ea7\u9690\u79c1\uff0c\u5ffd\u89c6\u7fa4\u7ec4\u5dee\u5f02\u548c\u4efb\u52a1\u4e13\u7528\u6548\u7528\uff0c\u5bfc\u81f4\u5bf9\u5408\u6210\u6570\u636e\u53ef\u9760\u6027\u3001\u5b89\u5168\u6027\u548c\u5b9e\u7528\u6027\u7684\u7406\u89e3\u4e0d\u8db3\u3002", "method": "\u63d0\u51fa RPU\uff08Representativeness-Privacy-Utility\uff09\u8bc4\u4f30\u6846\u67b6\uff0c\u4e09\u7ef4\u5ea6\uff08\u4ee3\u8868\u6027/\u9690\u79c1/\u6548\u7528\uff09\u00d7\u4e09\u5c42\u6b21\uff08\u8bb0\u5f55/\u7fa4\u7ec4/\u603b\u4f53\uff09\uff0c\u5e76\u7528\u4e00\u81f4\u6027\u5ea6\u91cf\u96c6\u5408\u8bc4\u4f30\u76f8\u4f3c\u6027\u3001\u6cc4\u9732\u98ce\u9669\u4e0e\u4efb\u52a1\u6548\u7528\uff1b\u5bf9\u6bd412\u79cd\u751f\u6210\u65b9\u6cd5\uff08\u7edf\u8ba1\u6a21\u578b\u3001\u6df1\u5ea6\u751f\u6210\u6a21\u578b\u3001\u9690\u79c1\u589e\u5f3a\u53d8\u4f53\uff09\u3002", "result": "\u5b9e\u9a8c\u57fa\u51c6\u663e\u793a\uff1a\u5408\u6210\u6570\u636e\u5e76\u4e0d\u81ea\u52a8\u4fdd\u8bc1\u9690\u79c1\uff1b\u9690\u79c1\u4e0e\u4ee3\u8868\u6027/\u6548\u7528\u5b58\u5728\u660e\u663e\u6743\u8861\uff1b\u6ca1\u6709\u5355\u4e00\u6a21\u578b\u9002\u7528\u4e8e\u6240\u6709\u573a\u666f\uff1bCTGAN \u7ed9\u51fa\u6700\u5747\u8861\u7684\u8868\u73b0\u3002", "conclusion": "Synthetic data \u672a\u5fc5\u5929\u7136\u4fdd\u969c\u9690\u79c1\uff0c\u4e14\u4e0d\u5b58\u5728\u666e\u9002\u6700\u4f73\u751f\u6210\u6a21\u578b\uff1bCTGAN \u5728\u4ee3\u8868\u6027\u3001\u9690\u79c1\u3001\u6548\u7528\u4e09\u8005\u95f4\u8868\u73b0\u8f83\u5e73\u8861\u3002"}}
{"id": "2510.24380", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24380", "abs": "https://arxiv.org/abs/2510.24380", "authors": ["Aryan Pedawi", "Jordi Silvestre-Ryan", "Bradley Worley", "Darren J Hsu", "Kushal S Shah", "Elias Stehle", "Jingrong Zhang", "Izhar Wallach"], "title": "APEX: Approximate-but-exhaustive search for ultra-large combinatorial synthesis libraries", "comment": null, "summary": "Make-on-demand combinatorial synthesis libraries (CSLs) like Enamine REAL\nhave significantly enabled drug discovery efforts. However, their large size\npresents a challenge for virtual screening, where the goal is to identify the\ntop compounds in a library according to a computational objective (e.g.,\noptimizing docking score) subject to computational constraints under a limited\ncomputational budget. For current library sizes -- numbering in the tens of\nbillions of compounds -- and scoring functions of interest, a routine virtual\nscreening campaign may be limited to scoring fewer than 0.1% of the available\ncompounds, leaving potentially many high scoring compounds undiscovered.\nFurthermore, as constraints (and sometimes objectives) change during the course\nof a virtual screening campaign, existing virtual screening algorithms\ntypically offer little room for amortization. We propose the\napproximate-but-exhaustive search protocol for CSLs, or APEX. APEX utilizes a\nneural network surrogate that exploits the structure of CSLs in the prediction\nof objectives and constraints to make full enumeration on a consumer GPU\npossible in under a minute, allowing for exact retrieval of approximate top-$k$\nsets. To demonstrate APEX's capabilities, we develop a benchmark CSL comprised\nof more than 10 million compounds, all of which have been annotated with their\ndocking scores on five medically relevant targets along with physicohemical\nproperties measured with RDKit such that, for any objective and set of\nconstraints, the ground truth top-$k$ compounds can be identified and compared\nagainst the retrievals from any virtual screening algorithm. We show APEX's\nconsistently strong performance both in retrieval accuracy and runtime compared\nto alternative methods.", "AI": {"tldr": "APEX\u63d0\u51fa\u7528\u7ed3\u6784\u5316\u795e\u7ecf\u4ee3\u7406\u5b9e\u73b0\u5bf9\u8d85\u5927\u53ef\u7ec4\u5408\u5408\u6210\u5e93\u7684\u5feb\u901f\u8fd1\u4f3c\u7a77\u5c3d\u641c\u7d22\uff0c\u80fd\u5728\u6d88\u8d39GPU\u4e0a\u4e9a\u5206\u949f\u7ea7\u679a\u4e3e\u5e76\u7cbe\u786e\u68c0\u7d22\u8fd1\u4f3ctop-k\uff0c\u5b9e\u9a8c\u8bc1\u660e\u6bd4\u73b0\u6709\u65b9\u6cd5\u66f4\u51c6\u786e\u66f4\u5feb\u3002", "motivation": "\u9762\u5bf9\u6570\u5341\u4ebf\u7ea7\u522b\u7684\u6309\u9700\u5408\u6210\u5316\u5b66\u5e93\uff0c\u4f20\u7edf\u865a\u62df\u7b5b\u9009\u5728\u8ba1\u7b97\u9884\u7b97\u4e0b\u53ea\u80fd\u8bc4\u4f30\u6781\u5c11\u90e8\u5206\u5316\u5408\u7269\uff0c\u5bfc\u81f4\u9ad8\u5f97\u5206\u5316\u5408\u7269\u53ef\u80fd\u88ab\u9057\u6f0f\uff0c\u4e14\u7b97\u6cd5\u8f83\u5c11\u652f\u6301\u5728\u7b5b\u9009\u8fc7\u7a0b\u4e2d\u91cd\u7528\u5df2\u8ba1\u7b97\u4fe1\u606f\u3002", "method": "\u6784\u5efa\u795e\u7ecf\u7f51\u7edc\u4ee3\u7406\u6a21\u578b\u9884\u6d4b\u76ee\u6807\u8bc4\u5206\u4e0e\u7ea6\u675f\uff0c\u5229\u7528CSL\u7684\u5206\u5b50\u6784\u6210\u7ed3\u6784\u5316\u8868\u793a\u5b9e\u73b0\u5feb\u901f\u6253\u5206\u4e0e\u679a\u4e3e\uff1b\u5f00\u53d1\u5305\u542b>1000\u4e07\u5316\u5408\u7269\u5e76\u5e26\u6709\u771f\u503c\u5bf9\u63a5\u5206\u6570\u4e0e\u7269\u5316\u5c5e\u6027\u7684\u57fa\u51c6\u5e93\uff0c\u7528\u4ee5\u8bc4\u4f30\u68c0\u7d22\u51c6\u786e\u7387\u4e0e\u8fd0\u884c\u65f6\u95f4\u3002", "result": "\u572810M\u7ea7\u57fa\u51c6\u5e93\u4e0a\uff0cAPEX\u5728\u68c0\u7d22\u51c6\u786e\u6027\u548c\u8fd0\u884c\u65f6\u95f4\u4e0a\u5747\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\uff0c\u80fd\u5728\u6d88\u8d39GPU\u4e0a<1\u5206\u949f\u5b8c\u6210\u5168\u5e93\u8fd1\u4f3c\u679a\u4e3e\u5e76\u8fd4\u56de\u8fd1\u4f3ctop-k\u96c6\u5408\u3002", "conclusion": "APEX\u901a\u8fc7\u4f7f\u7528\u795e\u7ecf\u7f51\u7edc\u4ee3\u7406\u548c\u5229\u7528\u53ef\u7ec4\u5408\u5408\u6210\u5e93\uff08CSL\uff09\u7684\u7ed3\u6784\uff0c\u5b9e\u73b0\u4e86\u8fd1\u4f3c\u4f46\u7a77\u5c3d\u7684\u641c\u7d22\uff0c\u4ece\u800c\u5728\u6d88\u8d39\u7ea7GPU\u4e0a\u5feb\u901f\u679a\u4e3e\u5e76\u7cbe\u786e\u68c0\u7d22\u8fd1\u4f3ctop-k\u96c6\u5408\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u865a\u62df\u7b5b\u9009\u5728\u8d85\u5927\u5e93\u4e0a\u7684\u6548\u7387\u3002"}}
{"id": "2510.24432", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24432", "abs": "https://arxiv.org/abs/2510.24432", "authors": ["Seyed Mahdi Basiri Azad", "Joschka Boedecker"], "title": "Fill in the Blanks: Accelerating Q-Learning with a Handful of Demonstrations in Sparse Reward Settings", "comment": null, "summary": "Reinforcement learning (RL) in sparse-reward environments remains a\nsignificant challenge due to the lack of informative feedback. We propose a\nsimple yet effective method that uses a small number of successful\ndemonstrations to initialize the value function of an RL agent. By precomputing\nvalue estimates from offline demonstrations and using them as targets for early\nlearning, our approach provides the agent with a useful prior over promising\nactions. The agent then refines these estimates through standard online\ninteraction. This hybrid offline-to-online paradigm significantly reduces the\nexploration burden and improves sample efficiency in sparse-reward settings.\nExperiments on benchmark tasks demonstrate that our method accelerates\nconvergence and outperforms standard baselines, even with minimal or suboptimal\ndemonstration data.", "AI": {"tldr": "\u7528\u5c11\u91cf\u6210\u529f\u793a\u8303\u79bb\u7ebf\u9884\u4f30\u503c\u51fd\u6570\u4f5c\u4e3a\u65e9\u671f\u5b66\u4e60\u76ee\u6807\uff0c\u518d\u5728\u7ebf\u5fae\u8c03\uff0c\u663e\u8457\u63d0\u5347\u7a00\u758f\u5956\u52b1\u73af\u5883\u7684\u6837\u672c\u6548\u7387\u4e0e\u6536\u655b\u901f\u5ea6\u3002", "motivation": "\u7a00\u758f\u5956\u52b1\u73af\u5883\u4e2d\uff0c\u968f\u673a\u63a2\u7d22\u96be\u4ee5\u83b7\u5f97\u6709\u6548\u53cd\u9988\uff0c\u4f7f\u7528\u6210\u529f\u793a\u8303\u63d0\u4f9b\u7684\u4ef7\u503c\u4fe1\u606f\u4f5c\u4e3a\u5148\u9a8c\u80fd\u5f15\u5bfc\u5b66\u4e60\u66f4\u5feb\u627e\u5230\u6709\u5e0c\u671b\u7684\u7b56\u7565\u3002", "method": "\u4ece\u793a\u8303\u8f68\u8ff9\u79bb\u7ebf\u8ba1\u7b97\u72b6\u6001-\u52a8\u4f5c\u4ef7\u503c\u4f30\u8ba1\uff08\u4f8b\u5982\u8499\u7279\u5361\u6d1b\u6216\u56de\u653e\uff09\uff0c\u7528\u8fd9\u4e9b\u4f30\u8ba1\u4f5c\u4e3a\u65e9\u671fQ/\u4ef7\u503c\u7f51\u7edc\u7684\u8bad\u7ec3\u76ee\u6807\uff0c\u4e4b\u540e\u5207\u6362\u5230\u5e38\u89c4\u5728\u7ebfRL\u66f4\u65b0\u6765\u8fdb\u4e00\u6b65\u4f18\u5316\u3002", "result": "Precompute value estimates from offline demonstrations to initialize value function; use as targets for early learning; then online refinement.", "conclusion": "\u65b9\u6cd5\u4e3a\u7a00\u758f\u5956\u52b1\u573a\u666f\u63d0\u4f9b\u4e86\u6709\u7528\u5148\u9a8c\uff0c\u51cf\u5c11\u63a2\u7d22\u8d1f\u62c5\uff0c\u5373\u4f7f\u793a\u8303\u7a00\u5c11\u6216\u6b21\u4f18\u4e5f\u80fd\u52a0\u901f\u8bad\u7ec3\u5e76\u4f18\u4e8e\u57fa\u7ebf\u3002"}}
{"id": "2510.24473", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24473", "abs": "https://arxiv.org/abs/2510.24473", "authors": ["Lucas Buk Cardoso", "Simone Aldrey Angelo", "Yasmin Pacheco Gil Bonilha", "Fernando Maia", "Adeylson Guimar\u00e3es Ribeiro", "Maria Paula Curado", "Gisele Aparecida Fernandes", "Vanderlei Cunha Parro", "Fl\u00e1vio Almeida de Magalh\u00e3es Cipparrone", "Alexandre Dias Porto Chiavegatto Filho", "Tatiana Natasha Toporcov"], "title": "Methodology for Comparing Machine Learning Algorithms for Survival Analysis", "comment": null, "summary": "This study presents a comparative methodological analysis of six machine\nlearning models for survival analysis (MLSA). Using data from nearly 45,000\ncolorectal cancer patients in the Hospital-Based Cancer Registries of S\\~ao\nPaulo, we evaluated Random Survival Forest (RSF), Gradient Boosting for\nSurvival Analysis (GBSA), Survival SVM (SSVM), XGBoost-Cox (XGB-Cox),\nXGBoost-AFT (XGB-AFT), and LightGBM (LGBM), capable of predicting survival\nconsidering censored data. Hyperparameter optimization was performed with\ndifferent samplers, and model performance was assessed using the Concordance\nIndex (C-Index), C-Index IPCW, time-dependent AUC, and Integrated Brier Score\n(IBS). Survival curves produced by the models were compared with predictions\nfrom classification algorithms, and predictor interpretation was conducted\nusing SHAP and permutation importance. XGB-AFT achieved the best performance\n(C-Index = 0.7618; IPCW = 0.7532), followed by GBSA and RSF. The results\nhighlight the potential and applicability of MLSA to improve survival\nprediction and support decision making.", "AI": {"tldr": "\u672c\u6587\u6bd4\u8f83\u4e86\u516d\u79cd\u7528\u4e8e\u751f\u5b58\u5206\u6790\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff08RSF\u3001GBSA\u3001SSVM\u3001XGB-Cox\u3001XGB-AFT\u3001LGBM\uff09\uff0c\u75284.5\u4e07\u4f8b\u7ed3\u76f4\u80a0\u764c\u533b\u9662\u767b\u8bb0\u6570\u636e\u8fdb\u884c\u8bc4\u4f30\uff0c\u91c7\u7528\u591a\u79cd\u8bc4\u4ef7\u6307\u6807\u548c\u8d85\u53c2\u6570\u4f18\u5316\uff0c\u53d1\u73b0XGB-AFT\u8868\u73b0\u6700\u597d\uff08C-Index=0.7618\uff09\u3002", "motivation": "\u63d0\u9ad8\u5bf9\u7ed3\u76f4\u80a0\u764c\u60a3\u8005\u751f\u5b58\u7ed3\u5c40\u9884\u6d4b\u7684\u51c6\u786e\u6027\uff0c\u8bc4\u4f30\u591a\u79cdML\u751f\u5b58\u6a21\u578b\u5728\u5904\u7406\u5e26\u5220\u5931\u6570\u636e\u4e0a\u7684\u6027\u80fd\uff0c\u5e76\u4e3a\u4e34\u5e8a\u51b3\u7b56\u63d0\u4f9b\u53ef\u89e3\u91ca\u6a21\u578b\u652f\u6301\u3002", "method": "\u5bf9\u8fd145,000\u4f8b\u7ed3\u76f4\u80a0\u764c\u60a3\u8005\u7684\u533b\u9662\u57fa\u56e0\u767b\u8bb0\u6570\u636e\u8fdb\u884c\u5efa\u6a21\uff0c\u6bd4\u8f83\u516d\u79cd\u751f\u5b58\u5206\u6790\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff0c\u4f7f\u7528\u4e0d\u540c\u91c7\u6837\u5668\u8fdb\u884c\u8d85\u53c2\u6570\u4f18\u5316\uff0c\u8bc4\u4f30\u6307\u6807\u5305\u62ecC-Index\u3001C-Index IPCW\u3001\u65f6\u53d8AUC\u548cIBS\uff0c\u5e76\u7528SHAP\u4e0e\u7f6e\u6362\u91cd\u8981\u6027\u89e3\u91ca\u9884\u6d4b\u5668\u3002", "result": "XGB-AFT\u53d6\u5f97\u6700\u4f73\u6307\u6807\uff08C-Index=0.7618\uff1bIPCW=0.7532\uff09\uff0cGBSA\u548cRSF\u8868\u73b0\u826f\u597d\uff0c\u6a21\u578b\u53ef\u4ea7\u51fa\u751f\u5b58\u66f2\u7ebf\u5e76\u901a\u8fc7SHAP/\u7f6e\u6362\u6cd5\u89e3\u91ca\u53d8\u91cf\u91cd\u8981\u6027\uff0c\u5c55\u793aMLSA\u5728\u4e34\u5e8a\u9884\u6d4b\u548c\u51b3\u7b56\u652f\u6301\u4e0a\u7684\u6f5c\u529b\u3002", "conclusion": "XGB-AFT\u5728\u8be5\u7ed3\u76f4\u80a0\u764c\u6570\u636e\u96c6\u4e0a\u7efc\u5408\u6027\u80fd\u6700\u4f73\uff0c\u8868\u660e\u57fa\u4e8eAFT\u7684\u6811\u6a21\u578b\u5728\u5904\u7406\u5e26\u5220\u5931\u751f\u5b58\u6570\u636e\u65f6\u5177\u6709\u8f83\u597d\u9884\u6d4b\u80fd\u529b\uff1bGBSA\u548cRSF\u6b21\u4e4b\u3002"}}
{"id": "2510.24482", "categories": ["cs.LG", "cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2510.24482", "abs": "https://arxiv.org/abs/2510.24482", "authors": ["Klemens Iten", "Lenart Treven", "Bhavya Sukhija", "Florian D\u00f6rfler", "Andreas Krause"], "title": "Sample-efficient and Scalable Exploration in Continuous-Time RL", "comment": "26 pages, 6 figures, 6 tables", "summary": "Reinforcement learning algorithms are typically designed for discrete-time\ndynamics, even though the underlying real-world control systems are often\ncontinuous in time. In this paper, we study the problem of continuous-time\nreinforcement learning, where the unknown system dynamics are represented using\nnonlinear ordinary differential equations (ODEs). We leverage probabilistic\nmodels, such as Gaussian processes and Bayesian neural networks, to learn an\nuncertainty-aware model of the underlying ODE. Our algorithm, COMBRL, greedily\nmaximizes a weighted sum of the extrinsic reward and model epistemic\nuncertainty. This yields a scalable and sample-efficient approach to\ncontinuous-time model-based RL. We show that COMBRL achieves sublinear regret\nin the reward-driven setting, and in the unsupervised RL setting (i.e., without\nextrinsic rewards), we provide a sample complexity bound. In our experiments,\nwe evaluate COMBRL in both standard and unsupervised RL settings and\ndemonstrate that it scales better, is more sample-efficient than prior methods,\nand outperforms baselines across several deep RL tasks.", "AI": {"tldr": "\u63d0\u51faCOMBRL\uff1a\u7528\u4e8e\u8fde\u7eed\u65f6\u95f4\u6a21\u578b\u57fa\u5f3a\u5316\u5b66\u4e60\u7684\u53ef\u6269\u5c55\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u7b97\u6cd5\uff0c\u5229\u7528\u9ad8\u65af\u8fc7\u7a0b/\u8d1d\u53f6\u65af\u795e\u7ecf\u7f51\u7edc\u5bf9ODE\u52a8\u529b\u5b66\u5efa\u6a21\uff0c\u901a\u8fc7\u8d2a\u5a6a\u6700\u5927\u5316\u5956\u52b1\u4e0e\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u52a0\u6743\u548c\u4ee5\u5b9e\u73b0\u63a2\u7d22-\u5229\u7528\u5e73\u8861\uff0c\u5728\u6709\u5956\u52b1\u60c5\u51b5\u4e0b\u8bc1\u660e\u6b21\u7ebf\u6027\u9057\u61be\u754c\uff0c\u5728\u65e0\u5956\u52b1\u7684\u65e0\u76d1\u7763\u8bbe\u7f6e\u7ed9\u51fa\u6837\u672c\u590d\u6742\u5ea6\u754c\uff0c\u5b9e\u9a8c\u663e\u793a\u6bd4\u5148\u524d\u65b9\u6cd5\u66f4\u9ad8\u6837\u672c\u6548\u7387\u4e0e\u66f4\u597d\u6027\u80fd\u3002", "motivation": "\u591a\u6570\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u5728\u79bb\u6563\u65f6\u95f4\u4e0b\u8bbe\u8ba1\uff0c\u4f46\u5b9e\u9645\u63a7\u5236\u7cfb\u7edf\u5e38\u4e3a\u8fde\u7eed\u65f6\u95f4\uff0c\u76f4\u63a5\u79bb\u6563\u5316\u4f1a\u5e26\u6765\u8bef\u5dee\u4e0e\u6548\u7387\u95ee\u9898\uff1b\u56e0\u6b64\u9700\u8981\u5728\u8fde\u7eed\u65f6\u95f4\u6846\u67b6\u4e0b\uff0c\u4f7f\u7528\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u7684\u6a21\u578b\u57fa\u65b9\u6cd5\u4ee5\u63d0\u5347\u6837\u672c\u6548\u7387\u4e0e\u53ef\u6269\u5c55\u6027\uff0c\u540c\u65f6\u63d0\u4f9b\u7406\u8bba\u4fdd\u8bc1\u3002", "method": "\u7528\u9ad8\u65af\u8fc7\u7a0b\u6216\u8d1d\u53f6\u65af\u795e\u7ecf\u7f51\u7edc\u5bf9\u8fde\u7eed\u65f6\u95f4\u975e\u7ebf\u6027ODE\u7cfb\u7edf\u5efa\u6a21\u4ee5\u83b7\u5f97\u6a21\u578b\u7684\u8868\u5f81\u4e0e\u4e0d\u786e\u5b9a\u6027\uff1b\u5b9a\u4e49\u4e00\u4e2a\u57fa\u4e8e\u5373\u65f6\u5956\u52b1\u4e0e\u6a21\u578b\u8868\u89c2\u4e0d\u786e\u5b9a\u6027\u52a0\u6743\u548c\u7684\u76ee\u6807\uff0c\u91c7\u7528\u8d2a\u5a6a\u7b56\u7565(maximize weighted sum)\u8fdb\u884c\u6570\u636e\u91c7\u96c6\u4e0e\u7b56\u7565\u66f4\u65b0\uff1b\u5728\u7406\u8bba\u4e0a\u5206\u6790\u5956\u52b1\u9a71\u52a8\u4e0b\u7684\u9057\u61be\u754c\u4ee5\u53ca\u65e0\u76d1\u7763\u4e0b\u7684\u6837\u672c\u590d\u6742\u5ea6\uff0c\u5e76\u5728\u591a\u79cd\u6df1\u5ea6RL\u4efb\u52a1\u4e0a\u4e0e\u57fa\u7ebf\u6bd4\u8f83\u3002", "result": "\u8bc1\u660eCOMBRL\u5728\u5956\u52b1\u8bbe\u5b9a\u4e0b\u5177\u6709\u6b21\u7ebf\u6027\u9057\u61be\uff0c\u4e0a\u8ff0\u65e0\u5956\u52b1\u8bbe\u5b9a\u7ed9\u51fa\u6837\u672c\u590d\u6742\u5ea6\u4e0a\u754c\uff1b\u5b9e\u9a8c\u8bc1\u660e\u5728\u591a\u79cd\u4efb\u52a1\u4e2d\u6837\u672c\u6548\u7387\u4e0e\u6269\u5c55\u6027\u4f18\u4e8e\u5148\u524d\u65b9\u6cd5\u548c\u57fa\u7ebf\u3002", "conclusion": "COMBRL\u5728\u8fde\u7eed\u65f6\u95f4\u6a21\u578b\u57fa\u5f3a\u5316\u5b66\u4e60\u4e2d\uff0c\u901a\u8fc7\u7ed3\u5408\u6982\u7387\u52a8\u529b\u5b66\u6a21\u578b\u4e0e\u57fa\u4e8e\u4e0d\u786e\u5b9a\u6027\u7684\u8d2a\u5a6a\u7b56\u7565\uff0c\u65e2\u80fd\u4fdd\u8bc1\u7406\u8bba\u6027\u80fd\uff08\u5956\u52b1\u60c5\u5f62\u4e0b\u6b21\u7ebf\u6027\u9057\u61be\u3001\u65e0\u76d1\u7763\u60c5\u5f62\u6837\u672c\u590d\u6742\u5ea6\uff09\uff0c\u53c8\u5728\u5b9e\u9a8c\u4e0a\u5b9e\u73b0\u6bd4\u57fa\u7ebf\u66f4\u597d\u7684\u6837\u672c\u6548\u7387\u4e0e\u6269\u5c55\u6027\uff0c\u9002\u7528\u4e8e\u6807\u51c6\u4e0e\u65e0\u5956\u52b1\u4efb\u52a1\u3002"}}
{"id": "2510.24500", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24500", "abs": "https://arxiv.org/abs/2510.24500", "authors": ["Yong Huang", "Zhongqi Yang", "Amir Rahmani"], "title": "MIMIC-Sepsis: A Curated Benchmark for Modeling and Learning from Sepsis Trajectories in the ICU", "comment": null, "summary": "Sepsis is a leading cause of mortality in intensive care units (ICUs), yet\nexisting research often relies on outdated datasets, non-reproducible\npreprocessing pipelines, and limited coverage of clinical interventions. We\nintroduce MIMIC-Sepsis, a curated cohort and benchmark framework derived from\nthe MIMIC-IV database, designed to support reproducible modeling of sepsis\ntrajectories. Our cohort includes 35,239 ICU patients with time-aligned\nclinical variables and standardized treatment data, including vasopressors,\nfluids, mechanical ventilation and antibiotics. We describe a transparent\npreprocessing pipeline-based on Sepsis-3 criteria, structured imputation\nstrategies, and treatment inclusion-and release it alongside benchmark tasks\nfocused on early mortality prediction, length-of-stay estimation, and shock\nonset classification. Empirical results demonstrate that incorporating\ntreatment variables substantially improves model performance, particularly for\nTransformer-based architectures. MIMIC-Sepsis serves as a robust platform for\nevaluating predictive and sequential models in critical care research.", "AI": {"tldr": "MIMIC-Sepsis\uff1a\u4e00\u4e2a\u53ef\u590d\u73b0\u7684\u3001\u5305\u542b\u5173\u952e\u6cbb\u7597\u4fe1\u606f\u7684MIMIC-IV\u8113\u6bd2\u75c7\u6570\u636e\u96c6\u4e0e\u57fa\u51c6\uff0c\u8bc1\u660e\u4e86\u6cbb\u7597\u53d8\u91cf\u80fd\u663e\u8457\u63d0\u5347\u9884\u6d4b\u6027\u80fd\uff0c\u5c24\u5176\u5bf9Transformer\u7c7b\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u5e38\u7528\u8fc7\u65f6\u6570\u636e\u3001\u4e0d\u53ef\u590d\u73b0\u7684\u9884\u5904\u7406\u4ee5\u53ca\u7f3a\u4e4f\u6cbb\u7597\u53d8\u91cf\u8986\u76d6\uff0c\u9650\u5236\u4e86\u8113\u6bd2\u75c7\u9884\u6d4b\u6a21\u578b\u7684\u53ef\u9760\u6027\u4e0e\u53ef\u6bd4\u8f83\u6027\uff1b\u56e0\u6b64\u9700\u8981\u4e00\u4e2a\u53ef\u590d\u73b0\u3001\u8986\u76d6\u4e34\u5e8a\u5e72\u9884\u7684\u6807\u51c6\u5316\u8d44\u6e90\u4ee5\u652f\u6301\u65b9\u6cd5\u5b66\u8bc4\u4f30\u3002", "method": "\u57fa\u4e8eSepsis-3\u5b9a\u4e49\u6784\u5efa\u961f\u5217\uff0c\u8bbe\u8ba1\u900f\u660e\u7684\u9884\u5904\u7406\u6d41\u6c34\u7ebf\uff08\u7f3a\u5931\u503c\u63d2\u8865\u7b56\u7565\u3001\u65f6\u95f4\u5bf9\u9f50\uff09\uff0c\u63d0\u53d6\u5e76\u6807\u51c6\u5316\u6cbb\u7597\u53d8\u91cf\uff08\u5347\u538b\u836f\u3001\u6db2\u4f53\u3001\u673a\u68b0\u901a\u6c14\u3001\u6297\u751f\u7d20\uff09\uff0c\u5e76\u5b9a\u4e49\u591a\u4e2a\u57fa\u51c6\u4efb\u52a1\uff08\u65e9\u671f\u6b7b\u4ea1\u9884\u6d4b\u3001\u4f4f\u9662\u65f6\u957f\u4f30\u8ba1\u3001\u4f11\u514b\u53d1\u751f\u5206\u7c7b\uff09\u3002\u5bf9\u6bd4\u4e0d\u540c\u6a21\u578b\uff08\u5c24\u5176Transformer\u67b6\u6784\uff09\uff0c\u8bc4\u4f30\u662f\u5426\u52a0\u5165\u6cbb\u7597\u53d8\u91cf\u7684\u5f71\u54cd\u3002", "result": "\u6784\u5efa\u4e86\u5305\u542b35,239\u540dICU\u60a3\u8005\u7684\u961f\u5217\u5e76\u5f00\u653e\u9884\u5904\u7406\u4ee3\u7801\u4e0e\u57fa\u51c6\uff1b\u5b9e\u9a8c\u8868\u660e\u52a0\u5165\u6cbb\u7597\u53d8\u91cf\u663e\u8457\u63d0\u5347\u6a21\u578b\u6027\u80fd\uff0c\u5c24\u5176\u5bf9Transformer\u6a21\u578b\u5e2e\u52a9\u6700\u5927\uff0c\u5e76\u63d0\u4f9b\u4e86\u82e5\u5e72\u57fa\u7ebf\u7ed3\u679c\u4f9b\u540e\u7eed\u7814\u7a76\u6bd4\u8f83\u3002", "conclusion": "\u8be5\u8bba\u6587\u6784\u5efa\u5e76\u53d1\u5e03\u4e86\u4e00\u4e2a\u57fa\u4e8eMIMIC-IV\u7684\u6807\u51c6\u5316\u3001\u53ef\u590d\u73b0\u7684\u8113\u6bd2\u75c7ICU\u6570\u636e\u96c6\u53ca\u57fa\u51c6\u6846\u67b6\uff08MIMIC-Sepsis\uff09\uff0c\u5f3a\u8c03\u5305\u542b\u65f6\u95f4\u5bf9\u9f50\u7684\u4e34\u5e8a\u53d8\u91cf\u4e0e\u5173\u952e\u6cbb\u7597\u6570\u636e\uff0c\u4fbf\u4e8e\u7814\u7a76\u8113\u6bd2\u75c7\u75c5\u7a0b\u5efa\u6a21\u4e0e\u9884\u6d4b\u3002"}}
{"id": "2510.24561", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24561", "abs": "https://arxiv.org/abs/2510.24561", "authors": ["Qingyue Zhang", "Chang Chu", "Tianren Peng", "Qi Li", "Xiangyang Luo", "Zhihao Jiang", "Shao-Lun Huang"], "title": "LoRA-DA: Data-Aware Initialization for Low-Rank Adaptation via Asymptotic Analysis", "comment": null, "summary": "With the widespread adoption of LLMs, LoRA has become a dominant method for\nPEFT, and its initialization methods have attracted increasing attention.\nHowever, existing methods have notable limitations: many methods do not\nincorporate target-domain data, while gradient-based methods exploit data only\nat a shallow level by relying on one-step gradient decomposition, which remains\nunsatisfactory due to the weak empirical performance of the one-step\nfine-tuning model that serves as their basis, as well as the fact that these\nmethods either lack a rigorous theoretical foundation or depend heavily on\nrestrictive isotropic assumptions. In this paper, we establish a theoretical\nframework for data-aware LoRA initialization based on asymptotic analysis.\nStarting from a general optimization objective that minimizes the expectation\nof the parameter discrepancy between the fine-tuned and target models, we\nderive an optimization problem with two components: a bias term, which is\nrelated to the parameter distance between the fine-tuned and target models, and\nis approximated using a Fisher-gradient formulation to preserve anisotropy; and\na variance term, which accounts for the uncertainty introduced by sampling\nstochasticity through the Fisher information. By solving this problem, we\nobtain an optimal initialization strategy for LoRA. Building on this\ntheoretical framework, we develop an efficient algorithm, LoRA-DA, which\nestimates the terms in the optimization problem from a small set of target\ndomain samples and obtains the optimal LoRA initialization. Empirical results\nacross multiple benchmarks demonstrate that LoRA-DA consistently improves final\naccuracy over existing initialization methods. Additional studies show faster,\nmore stable convergence, robustness across ranks, and only a small\ninitialization overhead for LoRA-DA. The source code will be released upon\npublication.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u6e10\u8fd1\u5206\u6790\u7684\u9762\u5411\u6570\u636e\u7684LoRA\u521d\u59cb\u5316\u7406\u8bba\uff0c\u5206\u89e3\u4e3a\u504f\u5dee\uff08\u7528Fisher\u68af\u5ea6\u4fdd\u6301\u5404\u5411\u5f02\u6027\uff09\u548c\u65b9\u5dee\uff08\u901a\u8fc7Fisher\u4fe1\u606f\uff09\uff0c\u5f97\u5230\u6700\u4f18\u521d\u59cb\u5316\u5e76\u5b9e\u73b0LoRA-DA\u7b97\u6cd5\uff0c\u4ece\u5c11\u91cf\u76ee\u6807\u57df\u6837\u672c\u4f30\u8ba1\u9879\uff0c\u663e\u8457\u63d0\u5347\u5fae\u8c03\u6027\u80fd\u4e0e\u7a33\u5b9a\u6027\u3002", "motivation": "Study and improve LoRA initialization for PEFT in LLMs, addressing limitations of prior methods that ignore target-domain data or rely on weak one-step gradient approximations and isotropic assumptions.", "method": "Start from minimizing expected parameter discrepancy between fine-tuned and target models; asymptotic analysis yields optimization with bias term approximated by Fisher-gradient and variance term from Fisher information; solve analytically for optimal LoRA init; implement LoRA-DA to estimate necessary matrices/vectors from small dataset and apply initialization.", "result": "The paper derives a theoretical framework splitting objective into bias (Fisher-gradient based to preserve anisotropy) and variance (via Fisher information), solves for optimal LoRA initialization, and proposes LoRA-DA algorithm that estimates terms from few target samples. Empirically, LoRA-DA improves accuracy, convergence stability, robustness across ranks, with small overhead.", "conclusion": "Data-aware Fisher-based decomposition yields an optimal LoRA initialization; LoRA-DA effectively estimates it from limited target data, improving final accuracy, convergence speed/stability, and robustness with minimal cost."}}
{"id": "2510.24574", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24574", "abs": "https://arxiv.org/abs/2510.24574", "authors": ["Hao Wang", "Licheng Pan", "Yuan Lu", "Zhixuan Chu", "Xiaoxi Li", "Shuting He", "Zhichao Chen", "Haoxuan Li", "Qingsong Wen", "Zhouchen Lin"], "title": "DistDF: Time-Series Forecasting Needs Joint-Distribution Wasserstein Alignment", "comment": null, "summary": "Training time-series forecast models requires aligning the conditional\ndistribution of model forecasts with that of the label sequence. The standard\ndirect forecast (DF) approach resorts to minimize the conditional negative\nlog-likelihood of the label sequence, typically estimated using the mean\nsquared error. However, this estimation proves to be biased in the presence of\nlabel autocorrelation. In this paper, we propose DistDF, which achieves\nalignment by alternatively minimizing a discrepancy between the conditional\nforecast and label distributions. Because conditional discrepancies are\ndifficult to estimate from finite time-series observations, we introduce a\nnewly proposed joint-distribution Wasserstein discrepancy for time-series\nforecasting, which provably upper bounds the conditional discrepancy of\ninterest. This discrepancy admits tractable, differentiable estimation from\nempirical samples and integrates seamlessly with gradient-based training.\nExtensive experiments show that DistDF improves the performance diverse\nforecast models and achieves the state-of-the-art forecasting performance. Code\nis available at https://anonymous.4open.science/r/DistDF-F66B.", "AI": {"tldr": "\u5f53\u6807\u7b7e\u81ea\u76f8\u5173\u5b58\u5728\u65f6\uff0c\u4f20\u7edfDF\uff08\u7528MSE\uff09\u6709\u504f\uff0cDistDF\u7528\u53ef\u5fae\u7684\u8054\u5408Wasserstein\u5dee\u5f02\u66ff\u4ee3MSE\u4ee5\u5bf9\u9f50\u5206\u5e03\uff0c\u63d0\u5347\u9884\u6d4b\u6027\u80fd\u5e76\u8fbeSOTA\u3002", "motivation": "\u5728\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\uff0c\u5f53\u6807\u7b7e\u5e8f\u5217\u5b58\u5728\u81ea\u76f8\u5173\u65f6\uff0c\u76f4\u63a5\u6700\u5c0f\u5316\u6761\u4ef6\u8d1f\u5bf9\u6570\u4f3c\u7136\uff08\u5982\u5747\u65b9\u8bef\u5dee\uff09\u4f1a\u4ea7\u751f\u504f\u5dee\uff0c\u9700\u8981\u65b0\u7684\u65b9\u6cd5\u6765\u5bf9\u9f50\u6a21\u578b\u9884\u6d4b\u7684\u6761\u4ef6\u5206\u5e03\u4e0e\u6807\u7b7e\u7684\u6761\u4ef6\u5206\u5e03\u3002", "method": "\u5c06\u8bad\u7ec3\u76ee\u6807\u4ece\u6761\u4ef6\u8d1f\u5bf9\u6570\u4f3c\u7136\uff08MSE\uff09\u66ff\u6362\u4e3a\u6700\u5c0f\u5316\u9884\u6d4b\u548c\u6807\u7b7e\u7684\u8054\u5408\u5206\u5e03Wasserstein\u5dee\u5f02\u3002\u7531\u4e8e\u76f4\u63a5\u4f30\u8ba1\u6761\u4ef6\u5dee\u5f02\u56f0\u96be\uff0c\u8bc1\u660e\u6240\u63d0\u8054\u5408Wasserstein\u5dee\u5f02\u4e0a\u754c\u539f\u59cb\u6761\u4ef6\u5dee\u5f02\uff1b\u63d0\u51fa\u53ef\u5fae\u3001\u53ef\u4ece\u7ecf\u9a8c\u6837\u672c\u4f30\u8ba1\u7684\u8fd1\u4f3c\u8ba1\u7b97\u65b9\u6cd5\uff0c\u5e76\u5c06\u5176\u4e0e\u68af\u5ea6\u4e0b\u964d\u8bad\u7ec3\u6d41\u7a0b\u7ed3\u5408\uff0c\u8fdb\u884c\u5927\u91cf\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "\u63d0\u51fa\u4e86DistDF\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u9884\u6d4b\u4e0e\u6807\u7b7e\u5206\u5e03\u4e4b\u95f4\u7684\u5dee\u5f02\u6765\u5b9e\u73b0\u5bf9\u9f50\uff1b\u5f15\u5165\u4e86\u4e00\u4e2a\u65b0\u7684\u8054\u5408\u5206\u5e03Wasserstein\u5dee\u5f02\uff08joint-distribution Wasserstein discrepancy\uff09\uff0c\u5b83\u53ef\u4ee5\u4e0a\u754c\u5173\u5fc3\u7684\u6761\u4ef6\u5dee\u5f02\uff0c\u5e76\u80fd\u4ece\u6709\u9650\u6837\u672c\u4e2d\u53ef\u5fae\u53ef\u4f30\u8ba1\uff0c\u6613\u4e8e\u4e0e\u68af\u5ea6\u8bad\u7ec3\u96c6\u6210\uff1b\u5b9e\u9a8c\u8bc1\u660eDistDF\u80fd\u63d0\u5347\u591a\u79cd\u9884\u6d4b\u6a21\u578b\u5e76\u8fbeSOTA\u3002", "conclusion": "DistDF\u5728\u7406\u8bba\u548c\u5b9e\u8df5\u4e0a\u90fd\u66f4\u9002\u5408\u542b\u81ea\u76f8\u5173\u6807\u7b7e\u7684\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\uff1a\u7406\u8bba\u4e0a\u901a\u8fc7\u8054\u5408\u5206\u5e03Wasserstein\u5dee\u5f02\u63a7\u5236\u6761\u4ef6\u5206\u5e03\u5dee\u5f02\uff1b\u5b9e\u8df5\u4e0a\u663e\u8457\u63d0\u5347\u591a\u79cd\u6a21\u578b\u7684\u9884\u6d4b\u7ed3\u679c\u3002"}}
{"id": "2510.24577", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24577", "abs": "https://arxiv.org/abs/2510.24577", "authors": ["He Yang", "Fei Ren", "Hai-Sui Yu", "Xiaohui Chen", "Pei-Zhi Zhuang"], "title": "Physics-Informed Extreme Learning Machine (PIELM): Opportunities and Challenges", "comment": null, "summary": "We are very delighted to see the fast development of physics-informed extreme\nlearning machine (PIELM) in recent years for higher computation efficiency and\naccuracy in physics-informed machine learning. As a summary or review on PIELM\nis currently not available, we would like to take this opportunity to show our\nperspective and experience for this promising research direction. We can see\nmany efforts are made to solve PDEs with sharp gradients, nonlinearities,\nhigh-frequency behavior, hard constraints, uncertainty, multiphysics coupling.\nDespite the success, many urgent challenges remain to be tackled, which also\nprovides us opportunities to develop more robust, interpretable, and\ngeneralizable PIELM frameworks with applications in science and engineering.", "AI": {"tldr": "\u4f5c\u8005\u7efc\u8ff0\u4e86\u7269\u7406\u4fe1\u606f\u6781\u9650\u5b66\u4e60\u673a(PIELM)\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u6307\u51fa\u5176\u5728\u6c42\u89e3\u5177\u6709\u5c16\u9510\u68af\u5ea6\u3001\u975e\u7ebf\u6027\u3001\u9ad8\u9891\u3001\u5f3a\u7ea6\u675f\u3001\u4e0d\u786e\u5b9a\u6027\u53ca\u591a\u7269\u7406\u8026\u5408PDE\u95ee\u9898\u4e0a\u7684\u6f5c\u529b\u4e0e\u5df2\u53d6\u5f97\u8fdb\u5c55\uff0c\u540c\u65f6\u5f3a\u8c03\u4ecd\u6709\u9c81\u68d2\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u6cdb\u5316\u6027\u7b49\u6311\u6218\u9700\u89e3\u51b3\u3002", "motivation": "\u5f53\u524d\u7f3a\u4e4f\u9488\u5bf9PIELM\u7684\u7efc\u8ff0\uff0c\u4f5c\u8005\u5e0c\u671b\u7cfb\u7edf\u603b\u7ed3\u8be5\u9886\u57df\u8fdb\u5c55\u4e0e\u6311\u6218\uff0c\u6307\u5f15\u672a\u6765\u7814\u7a76\u4ee5\u63a8\u8fdbPIELM\u5728\u79d1\u5b66\u5de5\u7a0b\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u672c\u6587\u4e3a\u7efc\u8ff0\u6027\u8d28\uff0c\u603b\u7ed3\u548c\u6bd4\u8f83\u4e86\u73b0\u6709PIELM\u65b9\u6cd5\uff0c\u8ba8\u8bba\u4e86\u5b83\u4eec\u5728\u5904\u7406\u4e0d\u540c\u7c7b\u578bPDE\u95ee\u9898\u65f6\u7684\u7b56\u7565\uff08\u5982\u7f51\u7edc\u7ed3\u6784\u8c03\u6574\u3001\u635f\u5931\u51fd\u6570\u8bbe\u8ba1\u3001\u968f\u673a\u5316\u6280\u672f\u548c\u8026\u5408\u65b9\u6cd5\uff09\uff0c\u5e76\u63d0\u51fa\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "result": "\u7efc\u8ff0\u6307\u51faPIELM\u5728\u89e3\u51b3\u9ad8\u6548\u3001\u51c6\u786e\u6c42\u89e3PDE\u65b9\u9762\u53d6\u5f97\u4e86\u8bb8\u591a\u6210\u679c\uff0c\u4f46\u4ecd\u9700\u89e3\u51b3\u82e5\u5e72\u5173\u952e\u95ee\u9898\u4ee5\u63d0\u9ad8\u6a21\u578b\u7684\u7a33\u5065\u6027\u3001\u89e3\u91ca\u6027\u548c\u63a8\u5e7f\u80fd\u529b\u3002", "conclusion": "PIELM\u5728\u8ba1\u7b97\u6548\u7387\u548c\u7cbe\u5ea6\u4e0a\u5c55\u73b0\u51fa\u663e\u8457\u4f18\u52bf\uff0c\u53ef\u7528\u4e8e\u591a\u79cd\u590d\u6742PDE\u95ee\u9898\uff0c\u4f46\u5f53\u524d\u65b9\u6cd5\u5728\u5904\u7406\u590d\u6742\u8fb9\u754c\u6761\u4ef6\u3001\u7a33\u5b9a\u6027\u3001\u6cdb\u5316\u53ca\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u4ecd\u9700\u6539\u8fdb\uff0c\u672a\u6765\u7814\u7a76\u5e94\u805a\u7126\u4e8e\u589e\u5f3a\u9c81\u68d2\u6027\u3001\u7406\u8bba\u5206\u6790\u3001\u6df7\u5408\u6a21\u578b\u548c\u5de5\u7a0b\u5e94\u7528\u3002"}}
{"id": "2510.24614", "categories": ["cs.LG", "cs.CE", "eess.SP"], "pdf": "https://arxiv.org/pdf/2510.24614", "abs": "https://arxiv.org/abs/2510.24614", "authors": ["James Josep Perry", "Pablo Garcia-Conde Ortiz", "George Konstantinou", "Cornelie Vergouwen", "Edlyn Santha Kumaran", "Morteza Moradi"], "title": "Semi-supervised and unsupervised learning for health indicator extraction from guided waves in aerospace composite structures", "comment": null, "summary": "Health indicators (HIs) are central to diagnosing and prognosing the\ncondition of aerospace composite structures, enabling efficient maintenance and\noperational safety. However, extracting reliable HIs remains challenging due to\nvariability in material properties, stochastic damage evolution, and diverse\ndamage modes. Manufacturing defects (e.g., disbonds) and in-service incidents\n(e.g., bird strikes) further complicate this process. This study presents a\ncomprehensive data-driven framework that learns HIs via two learning approaches\nintegrated with multi-domain signal processing. Because ground-truth HIs are\nunavailable, a semi-supervised and an unsupervised approach are proposed: (i) a\ndiversity deep semi-supervised anomaly detection (Diversity-DeepSAD) approach\naugmented with continuous auxiliary labels used as hypothetical damage proxies,\nwhich overcomes the limitation of prior binary labels that only distinguish\nhealthy and failed states while neglecting intermediate degradation, and (ii) a\ndegradation-trend-constrained variational autoencoder (DTC-VAE), in which the\nmonotonicity criterion is embedded via an explicit trend constraint. Guided\nwaves with multiple excitation frequencies are used to monitor single-stiffener\ncomposite structures under fatigue loading. Time, frequency, and time-frequency\nrepresentations are explored, and per-frequency HIs are fused via unsupervised\nensemble learning to mitigate frequency dependence and reduce variance. Using\nfast Fourier transform features, the augmented Diversity-DeepSAD model achieved\n81.6% performance, while DTC-VAE delivered the most consistent HIs with 92.3%\nperformance, outperforming existing baselines.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7528\u4e8e\u822a\u5929\u590d\u5408\u6750\u6599\u7ed3\u6784\u5065\u5eb7\u6307\u6807\uff08HI\uff09\u5b66\u4e60\u7684\u7efc\u5408\u6570\u636e\u9a71\u52a8\u6846\u67b6\u3002\u9488\u5bf9\u7f3a\u4e4f\u771f\u5b9eHI\u6807\u7b7e\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e24\u79cd\u65b9\u6cd5\uff1a\u4e00\u79cd\u662f\u5e26\u8fde\u7eed\u8f85\u52a9\u6807\u7b7e\u7684\u534a\u76d1\u7763\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\uff08Diversity-DeepSAD\uff09\uff0c\u53e6\u4e00\u79cd\u662f\u5d4c\u5165\u9000\u5316\u8d8b\u52bf\u7ea6\u675f\u7684\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff08DTC-VAE\uff09\u3002\u5206\u522b\u7ed3\u5408\u591a\u57df\u4fe1\u53f7\u5904\u7406\u548c\u591a\u9891\u6fc0\u52b1\u5bfc\u6ce2\u6570\u636e\uff0c\u5e76\u901a\u8fc7\u65e0\u76d1\u7763\u96c6\u6210\u878d\u5408\u5404\u9891\u7387HI\u3002\u5b9e\u9a8c\u8868\u660eDTC-VAE\u8868\u73b0\u6700\u597d\uff0892.3%\uff09\uff0cDiversity-DeepSAD\u5728FFT\u7279\u5f81\u4e0b\u4e5f\u670981.6%\u7684\u8868\u73b0\u3002", "motivation": "\u590d\u5408\u6750\u6599\u7ed3\u6784\u7684\u5065\u5eb7\u76d1\u6d4b\u53d7\u6750\u6599\u548c\u635f\u4f24\u6f14\u5316\u7684\u968f\u673a\u6027\u3001\u591a\u79cd\u635f\u4f24\u6a21\u6001\u53ca\u5236\u9020\u7f3a\u9677\u548c\u670d\u5f79\u4e8b\u4ef6\u7684\u5f71\u54cd\uff0c\u4e14\u771f\u5b9e\u5065\u5eb7\u6307\u6807\u96be\u4ee5\u6807\u6ce8\uff0c\u6545\u9700\u53d1\u5c55\u65e0\u9700\u771f\u5b9eHI\u6807\u7b7e\u4e14\u80fd\u6355\u6349\u6e10\u8fdb\u9000\u5316\u7684\u9c81\u68d2\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u3002", "method": "\uff081\uff09\u6570\u636e\u6765\u6e90\uff1a\u5bf9\u5355\u52a0\u52b2\u808b\u590d\u5408\u7ed3\u6784\u65bd\u52a0\u75b2\u52b3\u52a0\u8f7d\u5e76\u7528\u591a\u9891\u5bfc\u6ce2\u6fc0\u52b1\u91c7\u96c6\u65f6\u57df\u3001\u9891\u57df\u548c\u65f6\u9891\u57df\u4fe1\u53f7\uff1b\uff082\uff09\u7279\u5f81\uff1a\u63d0\u53d6FFT\u7b49\u591a\u57df\u7279\u5f81\u5e76\u6309\u9891\u7387\u5206\u901a\u9053\uff1b\uff083\uff09\u5b66\u4e60\u65b9\u6cd5\uff1aA. Diversity-DeepSAD\uff1a\u534a\u76d1\u7763\u5f02\u5e38\u68c0\u6d4b\uff0c\u4f7f\u7528\u8fde\u7eed\u8f85\u52a9\u6807\u7b7e\u4f5c\u4e3a\u5047\u8bbe\u6027\u635f\u4f24\u4ee3\u7406\u6765\u589e\u5f3a\u5b66\u4e60\u591a\u6837\u6027\uff1bB. DTC-VAE\uff1a\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff0c\u5728\u6f5c\u53d8\u91cf\u6216\u91cd\u5efa\u4e0a\u65bd\u52a0\u964d\u7ea7\u8d8b\u52bf\u5355\u8c03\u6027\u7ea6\u675f\u4ee5\u4fdd\u8bc1HI\u968f\u635f\u4f24\u7d2f\u79ef\u5355\u8c03\u53d8\u5316\uff1b\uff084\uff09\u878d\u5408\u96c6\u6210\uff1a\u5bf9\u5404\u9891\u7387HI\u8fdb\u884c\u65e0\u76d1\u7763\u96c6\u6210\u4ee5\u51cf\u8f7b\u9891\u7387\u4f9d\u8d56\u5e76\u964d\u4f4e\u65b9\u5dee\u3002", "result": "\u4f7f\u7528FFT\u7279\u5f81\u65f6\uff0cDiversity-DeepSAD\u8fbe\u523081.6%\u7684\u8868\u73b0\uff0c\u800cDTC-VAE\u6700\u7a33\u5b9a\u4e14\u6027\u80fd\u6700\u9ad8\uff0c\u8fbe\u523092.3%\uff0c\u540c\u65f6\u5728\u591a\u57df\u7279\u5f81\u548c\u591a\u9891\u878d\u5408\u4e0b\u80fd\u66f4\u597d\u5730\u51cf\u8f7b\u9891\u7387\u4f9d\u8d56\u6027\u5e76\u964d\u4f4e\u4f30\u8ba1\u65b9\u5dee\u3002", "conclusion": "\u5728\u7f3a\u4e4f\u771f\u5b9eHI\u6807\u7b7e\u7684\u60c5\u51b5\u4e0b\uff0c\u5d4c\u5165\u9000\u5316\u5355\u8c03\u6027\u7ea6\u675f\u7684DTC-VAE\u80fd\u66f4\u7a33\u5b9a\u5730\u63d0\u53d6\u51fa\u53ef\u89e3\u91ca\u4e14\u4e00\u81f4\u7684\u5065\u5eb7\u6307\u6807\uff0c\u4f18\u4e8e\u57fa\u4e8e\u8f85\u52a9\u8fde\u7eed\u6807\u7b7e\u7684Diversity-DeepSAD\u548c\u5176\u4ed6\u57fa\u7ebf\u65b9\u6cd5\u3002"}}
{"id": "2510.24633", "categories": ["cs.LG", "cs.LO"], "pdf": "https://arxiv.org/pdf/2510.24633", "abs": "https://arxiv.org/abs/2510.24633", "authors": ["Mingyue Liu", "Andrew Cropper"], "title": "Symbolic Snapshot Ensembles", "comment": null, "summary": "Inductive logic programming (ILP) is a form of logical machine learning. Most\nILP algorithms learn a single hypothesis from a single training run. Ensemble\nmethods train an ILP algorithm multiple times to learn multiple hypotheses. In\nthis paper, we train an ILP algorithm only once and save intermediate\nhypotheses. We then combine the hypotheses using a minimum description length\nweighting scheme. Our experiments on multiple benchmarks, including game\nplaying and visual reasoning, show that our approach improves predictive\naccuracy by 4% with less than 1% computational overhead.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u5728\u5355\u6b21ILP\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u4fdd\u5b58\u4e2d\u95f4\u5047\u8bbe\u5e76\u57fa\u4e8e\u6700\u5c0f\u63cf\u8ff0\u957f\u5ea6(MDL)\u52a0\u6743\u7ec4\u5408\u8fd9\u4e9b\u5047\u8bbe\u7684\u65b9\u6cd5\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u6e38\u620f\u548c\u89c6\u89c9\u63a8\u7406\u7b49\u57fa\u51c6\u4e0a\uff0c\u9884\u6d4b\u51c6\u786e\u7387\u63d0\u5347\u7ea64%\uff0c\u8ba1\u7b97\u5f00\u9500\u4f4e\u4e8e1%\u3002", "motivation": "\u4f20\u7edfILP\u591a\u91c7\u7528\u5355\u4e00\u6700\u7ec8\u5047\u8bbe\uff0c\u5ffd\u7565\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u6709\u7528\u4e2d\u95f4\u5047\u8bbe\uff1b\u800c\u91cd\u65b0\u591a\u6b21\u8bad\u7ec3\u4ee5\u6784\u5efa\u96c6\u5408\u65b9\u6cd5\u5f00\u9500\u5927\u3002\u5229\u7528\u4e2d\u95f4\u5047\u8bbe\u53ef\u5728\u4e0d\u663e\u8457\u589e\u52a0\u8ba1\u7b97\u6210\u672c\u4e0b\u83b7\u5f97\u96c6\u5408\u6548\u5e94\u3002", "method": "\u5728ILP\u7b97\u6cd5\u7684\u5355\u6b21\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u4e0d\u4e22\u5f03\u4e2d\u95f4\u4ea7\u751f\u7684\u591a\u4e2a\u5047\u8bbe\uff1b\u5bf9\u6bcf\u4e2a\u5047\u8bbe\u8ba1\u7b97\u5176MDL\u5f97\u5206\uff08\u7ed3\u5408\u5047\u8bbe\u590d\u6742\u5ea6\u4e0e\u6570\u636e\u7f16\u7801\u957f\u5ea6\uff09\uff0c\u5c06\u5f97\u5206\u8f6c\u4e3a\u6743\u91cd\uff0c\u6700\u540e\u5bf9\u591a\u4e2a\u5047\u8bbe\u7684\u9884\u6d4b\u6309\u6743\u91cd\u8fdb\u884c\u96c6\u5408\uff08\u52a0\u6743\u6295\u7968\u6216\u6982\u7387\u7ec4\u5408\uff09\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\uff08\u5305\u62ec\u6e38\u620f\u73a9\u6cd5\u4e0e\u89c6\u89c9\u63a8\u7406\u4efb\u52a1\uff09\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0c\u4f7f\u7528\u8be5\u65b9\u6cd5\u80fd\u5e73\u5747\u63d0\u9ad8\u7ea64%\u7684\u9884\u6d4b\u51c6\u786e\u7387\uff0c\u540c\u65f6\u989d\u5916\u7684\u8ba1\u7b97\u5f00\u9500\u4f4e\u4e8e1%\u3002", "conclusion": "\u901a\u8fc7\u5728\u5355\u6b21\u8bad\u7ec3\u4e2d\u4fdd\u5b58\u5e76\u7ec4\u5408\u4e2d\u95f4\u5047\u8bbe\uff0c\u4f7f\u7528MDL\u6743\u91cd\u80fd\u591f\u663e\u8457\u63d0\u9ad8ILP\u7684\u9884\u6d4b\u6027\u80fd\uff0c\u540c\u65f6\u51e0\u4e4e\u4e0d\u589e\u52a0\u8ba1\u7b97\u6210\u672c\u3002"}}
{"id": "2510.24639", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24639", "abs": "https://arxiv.org/abs/2510.24639", "authors": ["Pedro P. Sanchez", "Damian Machlanski", "Steven McDonagh", "Sotirios A. Tsaftaris"], "title": "Causal Ordering for Structure Learning From Time Series", "comment": "32 pages", "summary": "Predicting causal structure from time series data is crucial for\nunderstanding complex phenomena in physiology, brain connectivity, climate\ndynamics, and socio-economic behaviour. Causal discovery in time series is\nhindered by the combinatorial complexity of identifying true causal\nrelationships, especially as the number of variables and time points grow. A\ncommon approach to simplify the task is the so-called ordering-based methods.\nTraditional ordering methods inherently limit the representational capacity of\nthe resulting model. In this work, we fix this issue by leveraging multiple\nvalid causal orderings, instead of a single one as standard practice. We\npropose DOTS (Diffusion Ordered Temporal Structure), using diffusion-based\ncausal discovery for temporal data. By integrating multiple orderings, DOTS\neffectively recovers the transitive closure of the underlying directed acyclic\ngraph, mitigating spurious artifacts inherent in single-ordering approaches. We\nformalise the problem under standard assumptions such as stationarity and the\nadditive noise model, and leverage score matching with diffusion processes to\nenable efficient Hessian estimation. Extensive experiments validate the\napproach. Empirical evaluations on synthetic and real-world datasets\ndemonstrate that DOTS outperforms state-of-the-art baselines, offering a\nscalable and robust approach to temporal causal discovery. On synthetic\nbenchmarks ($d{=}\\!3-\\!6$ variables, $T{=}200\\!-\\!5{,}000$ samples), DOTS\nimproves mean window-graph $F1$ from $0.63$ (best baseline) to $0.81$. On the\nCausalTime real-world benchmark ($d{=}20\\!-\\!36$), while baselines remain the\nbest on individual datasets, DOTS attains the highest average summary-graph\n$F1$ while halving runtime relative to graph-optimisation methods. These\nresults establish DOTS as a scalable and accurate solution for temporal causal\ndiscovery.", "AI": {"tldr": "DOTS\u901a\u8fc7\u7ed3\u5408\u591a\u4e2a\u56e0\u679c\u6392\u5e8f\u548c\u57fa\u4e8e\u6269\u6563\u7684score matching\uff0c\u6709\u6548\u6062\u590d\u65f6\u95f4\u5e8f\u5217\u7684\u56e0\u679c\u7ed3\u6784\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5728\u5408\u6210\u4e0e\u771f\u5b9e\u6570\u636e\u4e0a\u6027\u80fd\u548c\u8fd0\u884c\u65f6\u95f4\u5747\u4f18\u4e8e\u6216\u53ef\u7ade\u4e89\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u89e3\u51b3\u65f6\u95f4\u5e8f\u5217\u56e0\u679c\u53d1\u73b0\u4e2d\u5355\u4e00\u56e0\u679c\u6392\u5e8f\u8868\u793a\u80fd\u529b\u53d7\u9650\u7684\u95ee\u9898\uff0c\u63d0\u9ad8\u6062\u590d\u771f\u5b9e\u6709\u5411\u65e0\u73af\u56fe\uff08DAG\uff09\u4f20\u9012\u95ed\u5305\u7684\u80fd\u529b\u3002", "method": "\u5229\u7528\u591a\u4e2a\u6709\u6548\u53d8\u91cf\u987a\u5e8f\uff0c\u57fa\u4e8e\u6269\u6563\u8fc7\u7a0b\u7684score matching\u8fdb\u884cHessian\u4f30\u8ba1\u4e0e\u56e0\u679c\u8fb9\u7f18\u8bc4\u5206\uff0c\u6574\u5408\u8fd9\u4e9b\u8bc4\u5206\u4ee5\u6062\u590d\u7a97\u53e3\u56fe\u4e0e\u6458\u8981\u56fe\uff1b\u5728\u5408\u6210\u548cCausalTime\u57fa\u51c6\u4e0a\u4e0e\u73b0\u6709\u57fa\u7ebf\u6bd4\u8f83\u5e76\u8861\u91cfF1\u4e0e\u8fd0\u884c\u65f6\u95f4\u3002", "result": "\u63d0\u51faDOTS\uff08Diffusion Ordered Temporal Structure\uff09\uff0c\u901a\u8fc7\u878d\u5408\u591a\u4e2a\u6709\u6548\u56e0\u679c\u6392\u5e8f\u5e76\u4f7f\u7528\u6269\u6563/score-matching\u65b9\u6cd5\u4f30\u8ba1Hessian\uff0c\u6539\u8fdb\u65f6\u95f4\u5e8f\u5217\u56e0\u679c\u53d1\u73b0\u7684\u51c6\u786e\u6027\u4e0e\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "\u5728\u5e73\u7a33\u6027\u548c\u52a0\u6027\u566a\u58f0\u5047\u8bbe\u4e0b\uff0cDOTS\u80fd\u66f4\u597d\u5730\u6062\u590d\u65f6\u5e8f\u56e0\u679c\u56fe\u7684\u4f20\u9012\u95ed\u5305\uff0c\u63d0\u5347F1\u5206\u6570\u5e76\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\uff0c\u662f\u53ef\u6269\u5c55\u4e14\u9c81\u68d2\u7684\u65f6\u95f4\u5e8f\u5217\u56e0\u679c\u53d1\u73b0\u65b9\u6cd5\u3002"}}
{"id": "2510.24643", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24643", "abs": "https://arxiv.org/abs/2510.24643", "authors": ["Yujun Kim", "Chaewon Moon", "Chulhee Yun"], "title": "The Cost of Robustness: Tighter Bounds on Parameter Complexity for Robust Memorization in ReLU Nets", "comment": "Accepted to NeurIPS 2025, 72 pages, 8 figures", "summary": "We study the parameter complexity of robust memorization for $\\mathrm{ReLU}$\nnetworks: the number of parameters required to interpolate any given dataset\nwith $\\epsilon$-separation between differently labeled points, while ensuring\npredictions remain consistent within a $\\mu$-ball around each training sample.\nWe establish upper and lower bounds on the parameter count as a function of the\nrobustness ratio $\\rho = \\mu / \\epsilon$. Unlike prior work, we provide a\nfine-grained analysis across the entire range $\\rho \\in (0,1)$ and obtain\ntighter upper and lower bounds that improve upon existing results. Our findings\nreveal that the parameter complexity of robust memorization matches that of\nnon-robust memorization when $\\rho$ is small, but grows with increasing $\\rho$.", "AI": {"tldr": "\u7814\u7a76ReLU\u7f51\u7edc\u5728\u9c81\u68d2\u8bb0\u5fc6\u4e0b\u7684\u6700\u5c11\u53c2\u6570\u9700\u6c42\uff0c\u9488\u5bf9\u03c1=\u03bc/\u03b5\u5728(0,1)\u4e0a\u7ed9\u51fa\u66f4\u7d27\u7684\u4e0a\u4e0b\u754c\uff1a\u03c1\u5c0f\u65f6\u65f6\u4e0e\u975e\u9c81\u68d2\u76f8\u540c\uff0c\u03c1\u589e\u5927\u65f6\u53c2\u6570\u9700\u6c42\u4e0a\u5347\u3002", "motivation": "\u7406\u89e3\u5728\u9700\u8981\u9c81\u68d2\u9884\u6d4b\uff08\u5bf9\u8bad\u7ec3\u70b9\u5468\u56f4\u6270\u52a8\u4e0d\u654f\u611f\uff09\u65f6\uff0c\u795e\u7ecf\u7f51\u7edc\u8bb0\u5fc6\u4efb\u610f\u6807\u8bb0\u6570\u636e\u6240\u9700\u7684\u6700\u5c11\u53c2\u6570\u6570\u76ee\u3002\u6b64\u524d\u5de5\u4f5c\u53ea\u5728\u90e8\u5206\u03c1\u8303\u56f4\u6216\u7ed9\u51fa\u677e\u5f1b\u754c\uff0c\u672c\u7814\u7a76\u5728\u5168\u03c1\u8303\u56f4\u5185\u63d0\u4f9b\u7ec6\u5316\u7ed3\u679c\u4ee5\u586b\u8865\u7a7a\u767d\u3002", "method": "\u4f5c\u8005\u5bf9\u795e\u7ecf\u7f51\u7edc\u6784\u9020\u4e0e\u4fe1\u606f\u8bba/\u7ec4\u5408\u4e0b\u754c\u8fdb\u884c\u4e86\u7ec6\u81f4\u5206\u6790\uff1a\u4e00\u65b9\u9762\u6784\u9020\u6ee1\u8db3\u9c81\u68d2\u6027\u7684ReLU\u7f51\u7edc\u4ee5\u83b7\u5f97\u53c2\u6570\u4e0a\u754c\uff1b\u53e6\u4e00\u65b9\u9762\u901a\u8fc7\u7f16\u7801/\u5ea6\u91cf\u5206\u79bb\u6027\u548c\u51e0\u4f55\u8986\u76d6\u53c2\u6570\u7a7a\u95f4\uff0c\u63a8\u5bfc\u51fa\u53c2\u6570\u4e0b\u754c\u3002\u5206\u6790\u6db5\u76d6\u5168\u03c1\u8303\u56f4\uff0c\u5e76\u5728\u4e0d\u540c\u03c1\u533a\u95f4\u91c7\u7528\u4e0d\u540c\u6784\u9020\u4e0e\u4e0b\u754c\u6280\u672f\u4ee5\u5f97\u5230\u66f4\u7d27\u7684\u754c\u3002", "result": "\u7ed9\u51fa\u968f\u03c1\u53d8\u5316\u7684\u4e0a\u754c\u548c\u4e0b\u754c\uff0c\u8bc1\u660e\u5f53\u03c1\u5f88\u5c0f\u65f6\uff0c\u6240\u9700\u53c2\u6570\u4e0e\u975e\u9c81\u68d2\u8bb0\u5fc6\u76f8\u540c\uff1b\u5f53\u03c1\u589e\u52a0\u65f6\uff0c\u53c2\u6570\u590d\u6742\u5ea6\u4e0a\u5347\uff0c\u5e76\u7ed9\u51fa\u660e\u786e\u51fd\u6570\u5173\u7cfb\uff08\u6bd4\u4e4b\u524d\u7ed3\u679c\u66f4\u7d27\uff09\u3002\u603b\u4f53\u4e0a\uff0c\u5efa\u7acb\u4e86\u9c81\u68d2\u8bb0\u5fc6\u53c2\u6570\u590d\u6742\u5ea6\u5173\u4e8e\u03c1\u7684\u7cbe\u786e\u523b\u753b\u7684\u66f4\u5f3a\u7ed3\u8bba\u3002", "conclusion": "\u672c\u6587\u7814\u7a76\u4e86ReLU\u7f51\u7edc\u5728\u9c81\u68d2\u8bb0\u5fc6\uff08robust memorization\uff09\u4e0b\u7684\u53c2\u6570\u590d\u6742\u5ea6\uff0c\u7ed3\u679c\u8868\u660e\uff1a\u5728\u8bad\u7ec3\u6837\u672c\u95f4\u5b58\u5728\u03b5\u5206\u79bb\u7684\u6761\u4ef6\u4e0b\uff0c\u8981\u6c42\u5bf9\u6bcf\u4e2a\u6837\u672c\u5728\u03bc\u7403\u5185\u9884\u6d4b\u4fdd\u6301\u4e00\u81f4\u65f6\uff0c\u6240\u9700\u53c2\u6570\u6570\u76ee\u968f\u9c81\u68d2\u6bd4\u03c1=\u03bc/\u03b5\u589e\u5927\u800c\u589e\u52a0\u3002\u5f53\u03c1\u8f83\u5c0f\u65f6\uff0c\u9c81\u68d2\u8bb0\u5fc6\u7684\u53c2\u6570\u590d\u6742\u5ea6\u4e0e\u975e\u9c81\u68d2\u8bb0\u5fc6\u76f8\u5339\u914d\uff1b\u968f\u7740\u03c1\u589e\u5927\uff0c\u53c2\u6570\u590d\u6742\u5ea6\u4e0a\u5347\u3002\u6587\u4e2d\u7ed9\u51fa\u4e86\u03c1\u2208(0,1)\u8303\u56f4\u5185\u7684\u7ec6\u7c92\u5ea6\u4e0a\u4e0b\u754c\uff0c\u8f83\u4e4b\u524d\u5de5\u4f5c\u66f4\u7d27\u3002"}}
{"id": "2510.24670", "categories": ["cs.LG", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2510.24670", "abs": "https://arxiv.org/abs/2510.24670", "authors": ["Genesis Research Team", "Alejandro Dobles", "Nina Jovic", "Kenneth Leidal", "Pranav Murugan", "David C. Williams", "Drausin Wulsin", "Nate Gruver", "Christina X. Ji", "Korrawat Pruegsanusak", "Gianluca Scarpellini", "Ansh Sharma", "Wojciech Swiderski", "Andrea Bootsma", "Richard Strong Bowen", "Charlotte Chen", "Jamin Chen", "Marc Andr\u00e9 D\u00e4mgen", "Roy Tal Dew", "Benjamin DiFrancesco", "J. D. Fishman", "Alla Ivanova", "Zach Kagin", "David Li-Bland", "Zuli Liu", "Igor Morozov", "Jeffrey Ouyang-Zhang", "Frank C. Pickard IV", "Kushal S. Shah", "Ben Shor", "Gabriel Monteiro da Silva", "Maxx Tessmer", "Carl Tilbury", "Cyr Vetcher", "Daniel Zeng", "Maruan Al-Shedivat", "Aleksandra Faust", "Evan N. Feinberg", "Michael V. LeVine", "Matteus Pan"], "title": "Pearl: A Foundation Model for Placing Every Atom in the Right Location", "comment": null, "summary": "Accurately predicting the three-dimensional structures of protein-ligand\ncomplexes remains a fundamental challenge in computational drug discovery that\nlimits the pace and success of therapeutic design. Deep learning methods have\nrecently shown strong potential as structural prediction tools, achieving\npromising accuracy across diverse biomolecular systems. However, their\nperformance and utility are constrained by scarce experimental data,\ninefficient architectures, physically invalid poses, and the limited ability to\nexploit auxiliary information available at inference. To address these issues,\nwe introduce Pearl (Placing Every Atom in the Right Location), a foundation\nmodel for protein-ligand cofolding at scale. Pearl addresses these challenges\nwith three key innovations: (1) training recipes that include large-scale\nsynthetic data to overcome data scarcity; (2) architectures that incorporate an\nSO(3)-equivariant diffusion module to inherently respect 3D rotational\nsymmetries, improving generalization and sample efficiency, and (3)\ncontrollable inference, including a generalized multi-chain templating system\nsupporting both protein and non-polymeric components as well as dual\nunconditional/conditional modes. Pearl establishes a new state-of-the-art\nperformance in protein-ligand cofolding. On the key metric of generating\naccurate (RMSD < 2 \\r{A}) and physically valid poses, Pearl surpasses AlphaFold\n3 and other open source baselines on the public Runs N' Poses and PoseBusters\nbenchmarks, delivering 14.5% and 14.2% improvements, respectively, over the\nnext best model. In the pocket-conditional cofolding regime, Pearl delivers\n$3.6\\times$ improvement on a proprietary set of challenging, real-world drug\ntargets at the more rigorous RMSD < 1 \\r{A} threshold. Finally, we demonstrate\nthat model performance correlates directly with synthetic dataset size used in\ntraining.", "AI": {"tldr": "Pearl is an SO(3)-equivariant diffusion foundation model trained with large synthetic datasets and controllable inference, achieving significant SOTA gains in protein-ligand pose prediction and scaling with data.", "motivation": "Address data scarcity, physical invalidity, inefficiency, and limited conditional control in protein-ligand cofolding; improve accuracy and generalization.", "method": "Analyse methods and innovations", "result": "Pearl achieves SOTA improvements on Runs N' Poses and PoseBusters, 14.5% and 14.2% over next best; 3.6x improvement at RMSD<1\u00c5 on proprietary targets; performance scales with synthetic data size.", "conclusion": "Combining synthetic data, equivariant diffusion architecture, and controllable multi-chain templating yields major improvements in accuracy and physical validity for protein-ligand cofolding; performance improves with more synthetic data."}}
{"id": "2510.24672", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.24672", "abs": "https://arxiv.org/abs/2510.24672", "authors": ["Burak Var\u0131c\u0131", "Che-Ping Tsai", "Ritabrata Ray", "Nicholas M. Boffi", "Pradeep Ravikumar"], "title": "Eigenfunction Extraction for Ordered Representation Learning", "comment": null, "summary": "Recent advances in representation learning reveal that widely used\nobjectives, such as contrastive and non-contrastive, implicitly perform\nspectral decomposition of a contextual kernel, induced by the relationship\nbetween inputs and their contexts. Yet, these methods recover only the linear\nspan of top eigenfunctions of the kernel, whereas exact spectral decomposition\nis essential for understanding feature ordering and importance. In this work,\nwe propose a general framework to extract ordered and identifiable\neigenfunctions, based on modular building blocks designed to satisfy key\ndesiderata, including compatibility with the contextual kernel and scalability\nto modern settings. We then show how two main methodological paradigms,\nlow-rank approximation and Rayleigh quotient optimization, align with this\nframework for eigenfunction extraction. Finally, we validate our approach on\nsynthetic kernels and demonstrate on real-world image datasets that the\nrecovered eigenvalues act as effective importance scores for feature selection,\nenabling principled efficiency-accuracy tradeoffs via adaptive-dimensional\nrepresentations.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u53ef\u6269\u5c55\u6846\u67b6\u7528\u4e8e\u4ece\u4e0a\u4e0b\u6587\u6838\u4e2d\u63d0\u53d6\u6709\u5e8f\u4e14\u53ef\u8bc6\u522b\u7684\u7279\u5f81\u51fd\u6570\uff08eigenfunctions\uff09\uff0c\u5e76\u7528\u5b9e\u9a8c\u8bc1\u660e\u8fd9\u4e9b\u7279\u5f81\u503c\u53ef\u4f5c\u4e3a\u7279\u5f81\u9009\u62e9\u7684\u91cd\u8981\u6027\u8bc4\u5206\uff0c\u4ece\u800c\u5b9e\u73b0\u6548\u7387-\u7cbe\u5ea6\u7684\u81ea\u9002\u5e94\u6743\u8861\u3002", "motivation": "\u73b0\u6709\u5bf9\u6bd4\u4e0e\u975e\u5bf9\u6bd4\u8868\u793a\u5b66\u4e60\u65b9\u6cd5\u4ec5\u80fd\u6062\u590d\u6838\u7684\u7279\u5f81\u51fd\u6570\u7684\u7ebf\u6027\u5f20\u91cf(span)\uff0c\u4f46\u65e0\u6cd5\u8fdb\u884c\u7cbe\u786e\u7684\u8c31\u5206\u89e3\uff0c\u4ece\u800c\u96be\u4ee5\u786e\u5b9a\u7279\u5f81\u7684\u6392\u5e8f\u4e0e\u91cd\u8981\u6027\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u4e2a\u80fd\u63d0\u53d6\u6709\u5e8f\u4e14\u53ef\u8bc6\u522b\u7279\u5f81\u51fd\u6570\u7684\u901a\u7528\u6846\u67b6\u3002", "method": "\u8bbe\u8ba1\u6a21\u5757\u5316\u6784\u4ef6\u4ee5\u6ee1\u8db3\u4e0e\u4e0a\u4e0b\u6587\u6838\u7684\u517c\u5bb9\u6027\u548c\u53ef\u6269\u5c55\u6027\uff0c\u7ed3\u5408\u4f4e\u79e9\u8fd1\u4f3c\u548cRayleigh\u5546\u4f18\u5316\u4e24\u5927\u65b9\u6cd5\u8303\u5f0f\u6765\u63d0\u53d6\u7279\u5f81\u51fd\u6570\uff1b\u5728\u5408\u6210\u6838\u4e0a\u9a8c\u8bc1\u7cbe\u786e\u5206\u89e3\u80fd\u529b\uff0c\u5e76\u5728\u56fe\u50cf\u4efb\u52a1\u4e0a\u8bc4\u4f30\u7279\u5f81\u503c\u7528\u4e8e\u7279\u5f81\u9009\u62e9\u7684\u6548\u679c\u3002", "result": "This paper proposes a framework for extracting ordered and identifiable eigenfunctions from a contextual kernel induced by inputs and contexts, addressing limitations of existing contrastive and non-contrastive objectives that only recover a linear span of top eigenfunctions. It introduces modular building blocks satisfying compatibility and scalability desiderata, aligns low-rank approximation and Rayleigh quotient optimization with the framework, and demonstrates empirical validation on synthetic kernels and real-world image datasets showing eigenvalues as importance scores for feature selection enabling adaptive-dimensional representations.", "conclusion": "\u6846\u67b6\u80fd\u591f\u6709\u5e8f\u4e14\u53ef\u8bc6\u522b\u5730\u6062\u590d\u6838\u7684\u7279\u5f81\u51fd\u6570\uff0c\u5e76\u5728\u5408\u6210\u4e0e\u771f\u5b9e\u56fe\u50cf\u6570\u636e\u4e0a\u9a8c\u8bc1\uff0c\u7279\u5f81\u503c\u53ef\u7528\u4e8e\u6307\u5bfc\u7279\u5f81\u9009\u62e9\u548c\u5b9e\u73b0\u81ea\u9002\u5e94\u7ef4\u5ea6\u8868\u793a\uff0c\u6709\u5229\u4e8e\u6548\u7387\u4e0e\u51c6\u786e\u7387\u4e4b\u95f4\u7684\u6743\u8861\u3002"}}
{"id": "2510.24674", "categories": ["cs.LG", "cs.AI", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.24674", "abs": "https://arxiv.org/abs/2510.24674", "authors": ["Bram De Cooman", "Johan Suykens"], "title": "Learning to Drive Safely with Hybrid Options", "comment": null, "summary": "Out of the many deep reinforcement learning approaches for autonomous\ndriving, only few make use of the options (or skills) framework. That is\nsurprising, as this framework is naturally suited for hierarchical control\napplications in general, and autonomous driving tasks in specific. Therefore,\nin this work the options framework is applied and tailored to autonomous\ndriving tasks on highways. More specifically, we define dedicated options for\nlongitudinal and lateral manoeuvres with embedded safety and comfort\nconstraints. This way, prior domain knowledge can be incorporated into the\nlearning process and the learned driving behaviour can be constrained more\neasily. We propose several setups for hierarchical control with options and\nderive practical algorithms following state-of-the-art reinforcement learning\ntechniques. By separately selecting actions for longitudinal and lateral\ncontrol, the introduced policies over combined and hybrid options obtain the\nsame expressiveness and flexibility that human drivers have, while being easier\nto interpret than classical policies over continuous actions. Of all the\ninvestigated approaches, these flexible policies over hybrid options perform\nthe best under varying traffic conditions, outperforming the baseline policies\nover actions.", "AI": {"tldr": "\u5c06\u5206\u5c42\u7684 options \u6846\u67b6\u7528\u4e8e\u9ad8\u901f\u516c\u8def\u81ea\u52a8\u9a7e\u9a76\uff0c\u8bbe\u8ba1\u7eb5\u6a2a\u5411\u4e13\u7528\u9009\u9879\u5e76\u5d4c\u5165\u5b89\u5168/\u8212\u9002\u7ea6\u675f\uff0c\u6df7\u5408\u9009\u9879\u7b56\u7565\u5728\u4e0d\u540c\u4ea4\u901a\u6761\u4ef6\u4e0b\u8868\u73b0\u6700\u597d\u3002", "motivation": "\u5c3d\u7ba1 options \u6846\u67b6\u5929\u7136\u9002\u5408\u5c42\u7ea7\u63a7\u5236\uff0c\u4f46\u5728\u81ea\u52a8\u9a7e\u9a76\u9886\u57df\u5e94\u7528\u8f83\u5c11\uff0c\u4f5c\u8005\u65e8\u5728\u5c06\u9886\u57df\u5148\u9a8c\uff08\u5982\u5b89\u5168\u3001\u8212\u9002\u7ea6\u675f\u548c\u7eb5\u6a2a\u5411\u5206\u79bb\u63a7\u5236\uff09\u5d4c\u5165\u5b66\u4e60\u8fc7\u7a0b\uff0c\u4ee5\u589e\u5f3a\u53ef\u89e3\u91ca\u6027\u548c\u9c81\u68d2\u6027\u3002", "method": "\u5728 options \u6846\u67b6\u4e0b\u5b9a\u4e49\u957f/\u6a2a\u5411 manoeuvre \u9009\u9879\uff0c\u6784\u5efa\u591a\u79cd\u5c42\u6b21\u63a7\u5236\u8bbe\u7f6e\uff08\u5305\u62ec\u7ec4\u5408\u4e0e\u6df7\u5408\u9009\u9879\uff09\uff0c\u5e76\u4f7f\u7528\u73b0\u4ee3\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u5bf9\u7b56\u7565\u8fdb\u884c\u5b66\u4e60\uff0c\u6bd4\u8f83\u57fa\u7ebf\u7684\u52a8\u4f5c\u7ea7\u7b56\u7565\u4e0e\u4e0d\u540c\u9009\u9879\u7b56\u7565\u7684\u8868\u73b0\u3002", "result": "\u4f5c\u8005\u5c06 options\uff08\u6280\u80fd/\u5b50\u7b56\u7565\uff09\u6846\u67b6\u5e94\u7528\u4e8e\u9ad8\u901f\u516c\u8def\u81ea\u52a8\u9a7e\u9a76\uff0c\u8bbe\u8ba1\u4e86\u4e13\u95e8\u7684\u7eb5\u5411\u548c\u6a2a\u5411 manoeuvres \u9009\u9879\uff0c\u5e76\u5728\u8fd9\u4e9b\u9009\u9879\u4e2d\u5d4c\u5165\u4e86\u5b89\u5168\u4e0e\u8212\u9002\u6027\u7ea6\u675f\u3002\u901a\u8fc7\u5206\u5f00\u9009\u62e9\u7eb5\u5411\u548c\u6a2a\u5411\u52a8\u4f5c\uff0c\u63d0\u51fa\u7684\u6df7\u5408\u9009\u9879\u7b56\u7565\u517c\u5177\u4eba\u7c7b\u9a7e\u9a76\u7684\u7075\u6d3b\u6027\u548c\u6bd4\u8fde\u7eed\u52a8\u4f5c\u7b56\u7565\u66f4\u597d\u7684\u53ef\u89e3\u91ca\u6027\u3002\u5728\u591a\u79cd\u4ea4\u901a\u6761\u4ef6\u4e0b\uff0c\u6df7\u5408\u9009\u9879\u7b56\u7565\u4f18\u4e8e\u57fa\u51c6\u52a8\u4f5c\u7b56\u7565\u3002", "conclusion": "\u4f7f\u7528\u5e26\u6709\u5b89\u5168\u4e0e\u8212\u9002\u7ea6\u675f\u7684\u7eb5\u6a2a\u5411\u4e13\u7528\u9009\u9879\u5e76\u5728\u5c42\u6b21\u7ed3\u6784\u4e2d\u7ec4\u5408\uff0c\u53ef\u4ee5\u63d0\u9ad8\u81ea\u52a8\u9a7e\u9a76\u5728\u9ad8\u901f\u516c\u8def\u573a\u666f\u4e0b\u7684\u6027\u80fd\u4e0e\u53ef\u89e3\u91ca\u6027\uff0c\u6df7\u5408\u9009\u9879\u7b56\u7565\u8868\u73b0\u4f18\u4e8e\u76f4\u63a5\u5bf9\u8fde\u7eed\u52a8\u4f5c\u5efa\u6a21\u7684\u57fa\u7ebf\u3002"}}
{"id": "2510.24700", "categories": ["cs.LG", "cs.AI", "cs.IT", "math.IT", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.24700", "abs": "https://arxiv.org/abs/2510.24700", "authors": ["Di Wu", "Chengshuai Shi", "Jing Yang", "Cong Shen"], "title": "Greedy Sampling Is Provably Efficient for RLHF", "comment": "NeurIPS 2025", "summary": "Reinforcement Learning from Human Feedback (RLHF) has emerged as a key\ntechnique for post-training large language models. Despite its empirical\nsuccess, the theoretical understanding of RLHF is still limited, as learning\nthe KL-regularized target with only preference feedback poses additional\nchallenges compared with canonical RL. Existing works mostly study the\nreward-based Bradley-Terry (BT) preference model, and extend classical designs\nutilizing optimism or pessimism. This work, instead, considers the general\npreference model (whose practical relevance has been observed recently) and\nobtains performance guarantees with major, order-wise improvements over\nexisting ones. Surprisingly, these results are derived from algorithms that\ndirectly use the empirical estimates (i.e., greedy sampling), as opposed to\nconstructing optimistic or pessimistic estimates in previous works. This\ninsight has a deep root in the unique structural property of the optimal policy\nclass under the KL-regularized target, and we further specialize it to the BT\nmodel, highlighting the surprising sufficiency of greedy sampling in RLHF.", "AI": {"tldr": "The paper proves that for KL-regularized RLHF with general preference models, simple greedy sampling on empirical estimates achieves strong performance guarantees, improving prior work and contradicting need for optimistic/pessimistic methods; also applies to BT model.", "motivation": "The paper seeks to provide theoretical understanding and improved performance guarantees for RLHF under general preference models, addressing challenges of KL-regularized targets learned with only preference feedback.", "method": "Theoretical analysis leveraging structural properties of optimal policies under KL regularization; deriving guarantees for greedy sampling and comparing to prior optimistic/pessimistic algorithms; specialization to BT model.", "result": "They obtain order-wise improved performance guarantees for general preference models and show greedy sampling (empirical estimates) suffices, rather than optimism/pessimism constructions; also specialize to BT model.", "conclusion": "Greedy sampling using empirical preference estimates is sufficient for achieving strong guarantees in RLHF under KL-regularized targets across general and BT preference models, due to structural properties of the optimal policy class."}}

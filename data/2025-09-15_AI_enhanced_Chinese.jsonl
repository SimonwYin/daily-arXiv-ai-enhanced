{"id": "2509.09898", "categories": ["cs.NI", "cs.CR", "cs.DB", "cs.DC", "cs.OS"], "pdf": "https://arxiv.org/pdf/2509.09898", "abs": "https://arxiv.org/abs/2509.09898", "authors": ["Sophia Lockton", "Jeremy Kepner", "Michael Stonebraker", "Hayden Jananthan", "LaToya Anderson", "William Arcand", "David Bestor", "William Bergeron", "Alex Bonn", "Daniel Burrill", "Chansup Byun", "Timothy Davis", "Vijay Gadepally", "Michael Houle", "Matthew Hubbell", "Michael Jones", "Piotr Luszczek", "Peter Michaleas", "Lauren Milechin", "Chasen Milner", "Guillermo Morales", "Julie Mullen", "Michel Pelletier", "Alex Poliakov", "Andrew Prout", "Albert Reuther", "Antonio Rosa", "Charles Yee", "Alex Pentland"], "title": "DBOS Network Sensing: A Web Services Approach to Collaborative Awareness", "comment": "8 pages, 10 figures, 37 references, accepted to IEEE HPEC 2025", "summary": "DBOS (DataBase Operating System) is a novel capability that integrates web\nservices, operating system functions, and database features to significantly\nreduce web-deployment effort while increasing resilience. Integration of high\nperformance network sensing enables DBOS web services to collaboratively create\na shared awareness of their network environments to enhance their collective\nresilience and security. Network sensing is added to DBOS using GraphBLAS\nhypersparse traffic matrices via two approaches: (1) Python-GraphBLAS and (2)\nOneSparse PostgreSQL. These capabilities are demonstrated using the workflow\nand analytics from the IEEE/MIT/Amazon Anonymized Network Sensing Graph\nChallenge. The system was parallelized using pPython and benchmarked using 64\ncompute nodes on the MIT SuperCloud. The web request rate sustained by a single\nDBOS instance was ${>}10^5$, well above the required maximum, indicating that\nnetwork sensing can be added to DBOS with negligible overhead. For\ncollaborative awareness, many DBOS instances were connected to a single DBOS\naggregator. The Python-GraphBLAS and OneSparse PostgreSQL implementations\nscaled linearly up to 64 and 32 nodes respectively. These results suggest that\nDBOS collaborative network awareness can be achieved with a negligible increase\nin computing resources.", "AI": {"tldr": "\u5728DBOS\u4e2d\u901a\u8fc7GraphBLAS\u77e9\u9635\uff08Python-GraphBLAS\u4e0eOneSparse PostgreSQL\uff09\u6dfb\u52a0\u7f51\u7edc\u611f\u77e5\uff0c\u9a8c\u8bc1\u4e86\u9ad8\u541e\u5410\u3001\u4f4e\u5f00\u9500\u548c\u826f\u597d\u6269\u5c55\u6027\uff0c\u652f\u6301\u534f\u4f5c\u7f51\u7edc\u610f\u8bc6\u7684\u53ef\u884c\u6027\u3002", "motivation": "\u964d\u4f4eWeb\u90e8\u7f72\u5de5\u4f5c\u91cf\u5e76\u63d0\u5347\u5206\u5e03\u5f0fWeb\u670d\u52a1\u7684\u5f39\u6027\u4e0e\u5b89\u5168\u6027\uff0c\u501f\u52a9\u534f\u4f5c\u7684\u7f51\u7edc\u611f\u77e5\u5171\u4eab\u73af\u5883\u4fe1\u606f\u6765\u6539\u8fdb\u96c6\u4f53\u9632\u5fa1\u4e0e\u9c81\u68d2\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u6027\u80fdWeb\u8bf7\u6c42\u5904\u7406\u80fd\u529b\u3002", "method": "\u5c06\u7f51\u7edc\u6d41\u91cf\u8868\u793a\u4e3aGraphBLAS\u8d85\u7a00\u758f\u6d41\u91cf\u77e9\u9635\uff0c\u901a\u8fc7\u4e24\u79cd\u5b9e\u73b0\u8def\u5f84\u63a5\u5165DBOS\uff1a1) Python-GraphBLAS\u76f4\u63a5\u5728\u5185\u5b58\u4e2d\u6784\u5efa\u4e0e\u8ba1\u7b97\uff1b2) OneSparse PostgreSQL\u5229\u7528\u6570\u636e\u5e93\u4e00\u7a00\u758f\u8868\u7ed3\u6784\u5b58\u50a8\u4e0e\u67e5\u8be2\u3002\u4f7f\u7528IEEE/MIT/Amazon\u533f\u540d\u7f51\u7edc\u611f\u77e5\u56fe\u6311\u6218\u7684\u6570\u636e\u548c\u5206\u6790\u5de5\u4f5c\u6d41\u8fdb\u884c\u529f\u80fd\u9a8c\u8bc1\uff0c\u5e76\u5728MIT SuperCloud\u4e0a\u7528pPython\u5e76\u884c\u5316\uff0c\u8de8\u6700\u591a64\u4e2a\u8ba1\u7b97\u8282\u70b9\u505a\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u5355\u4e2aDBOS\u5b9e\u4f8b\u53ef\u7ef4\u6301>10^5\u6b21/\u79d2\u7684Web\u8bf7\u6c42\u7387\uff0c\u8868\u660e\u52a0\u5165\u7f51\u7edc\u611f\u77e5\u5f00\u9500\u6781\u5c0f\u3002Python-GraphBLAS\u5b9e\u73b0\u5728\u7ebf\u6027\u6bd4\u4f8b\u4e0b\u6269\u5c55\u523064\u8282\u70b9\uff0cOneSparse PostgreSQL\u5b9e\u73b0\u7ebf\u6027\u6269\u5c55\u523032\u8282\u70b9\uff1b\u805a\u5408\u5668\u67b6\u6784\u9a8c\u8bc1\u4e86\u591a\u5b9e\u4f8b\u534f\u4f5c\u611f\u77e5\u53ef\u884c\u6027\u4e14\u603b\u4f53\u8d44\u6e90\u589e\u52a0\u53ef\u5ffd\u7565\u3002", "conclusion": "DBOS\u6210\u529f\u5c06\u7f51\u7edc\u611f\u77e5\u80fd\u529b\u65e0\u7f1d\u96c6\u6210\u5230\u6570\u636e\u5e93\u64cd\u4f5c\u7cfb\u7edf\u4e2d\uff0c\u4e14\u5bf9\u5355\u5b9e\u4f8b\u541e\u5410\u5f71\u54cd\u53ef\u5ffd\u7565\u4e0d\u8ba1\uff1b\u5728\u534f\u4f5c\u611f\u77e5\u573a\u666f\u4e0b\uff0c\u57fa\u4e8ePython-GraphBLAS\u548cOneSparse PostgreSQL\u7684\u5b9e\u73b0\u5206\u522b\u572864\u548c32\u8282\u70b9\u524d\u7ebf\u6027\u6269\u5c55\uff0c\u8868\u660e\u534f\u4f5c\u7f51\u7edc\u611f\u77e5\u5728\u8d44\u6e90\u5f00\u9500\u4e0a\u4ee3\u4ef7\u5f88\u5c0f\u3002"}}
{"id": "2509.09795", "categories": ["cs.DC", "cs.DB", "cs.DS", "cs.PF"], "pdf": "https://arxiv.org/pdf/2509.09795", "abs": "https://arxiv.org/abs/2509.09795", "authors": ["Arivarasan Karmegam", "Gabina Luz Bianchi", "Margarita Capretto", "Mart\u00edn Ceresa", "Antonio Fern\u00e1ndez Anta", "C\u00e9sar S\u00e1nchez"], "title": "Setchain Algorithms for Blockchain Scalability", "comment": null, "summary": "Setchain has been proposed to increase blockchain scalability by relaxing the\nstrict total order requirement among transactions. Setchain organizes elements\ninto a sequence of sets, referred to as epochs, so that elements within each\nepoch are unordered. In this paper, we propose and evaluate three distinct\nSetchain algorithms, that leverage an underlying block-based ledger. Vanilla is\na basic implementation that serves as a reference point. Compresschain\naggregates elements into batches, and compresses these batches before appending\nthem as epochs in the ledger. Hashchain converts batches into fixed-length\nhashes which are appended as epochs in the ledger. This requires Hashchain to\nuse a distributed service to obtain the batch contents from its hash. To allow\nlight clients to safely interact with only one server, the proposed algorithms\nmaintain, as part of the Setchain, proofs for the epochs. An epoch-proof is the\nhash of the epoch, cryptographically signed by a server. A client can verify\nthe correctness of an epoch with $f+1$ epoch-proofs (where $f$ is the maximum\nnumber of Byzantine servers assumed). All three Setchain algorithms are\nimplemented on top of the CometBFT blockchain application platform. We\nconducted performance evaluations across various configurations, using clusters\nof four, seven, and ten servers. Our results show that the Setchain algorithms\nreach orders of magnitude higher throughput than the underlying blockchain, and\nachieve finality with latency below 4 seconds.", "AI": {"tldr": "\u63d0\u51fa\u5e76\u5b9e\u73b0\u4e09\u79cdSetchain\u65b9\u6848\u4ee5\u653e\u5bbd\u4ea4\u6613\u5168\u5e8f\u7ea6\u675f\uff0c\u5b9e\u73b0\u5728CometBFT\u4e0a\u5927\u5e45\u63d0\u9ad8\u541e\u5410\u91cf\u5e76\u4fdd\u6301\u4f4e\u5ef6\u8fdf\uff1b\u4f7f\u7528epoch-proofs\u786e\u4fdd\u8f7b\u5ba2\u6237\u7aef\u5b89\u5168\u3002", "motivation": "\u4f20\u7edf\u533a\u5757\u94fe\u5bf9\u4e8b\u52a1\u5f3a\u5e8f\u8981\u6c42\u9650\u5236\u4e86\u53ef\u6269\u5c55\u6027\u3002Setchain\u901a\u8fc7\u653e\u5bbd\u987a\u5e8f\u7ea6\u675f\u3001\u5c06\u4e8b\u52a1\u7ec4\u7ec7\u6210\u96c6\u5408\uff08epoch\uff09\uff0c\u65e8\u5728\u63d0\u5347\u5e76\u884c\u5904\u7406\u80fd\u529b\u4e0e\u6574\u4f53\u7cfb\u7edf\u541e\u5410\u91cf\uff0c\u540c\u65f6\u4fdd\u6301\u5b89\u5168\u6027\u548c\u8f7b\u5ba2\u6237\u7aef\u53ef\u9a8c\u8bc1\u6027\u3002", "method": "\u5728CometBFT\u5e73\u53f0\u4e0a\u5b9e\u73b0\u5e76\u6bd4\u8f83\u4e09\u79cd\u8bbe\u8ba1\uff1aVanilla\u4f5c\u4e3a\u57fa\u7ebf\uff1bCompresschain\u5c06\u5143\u7d20\u6279\u91cf\u5316\u5e76\u538b\u7f29\u540e\u4f5c\u4e3aepoch\u5199\u5165\uff1bHashchain\u4ee5\u56fa\u5b9a\u957f\u5ea6\u54c8\u5e0c\u8868\u793a\u6279\u6b21\uff0c\u4f9d\u8d56\u5206\u5e03\u5f0f\u670d\u52a1\u63d0\u4f9b\u6279\u6b21\u5185\u5bb9\u3002\u4e3a\u652f\u6301\u8f7b\u5ba2\u6237\u7aef\uff0c\u4ec5\u9700\u4e0e\u5355\u4e2a\u670d\u52a1\u5668\u4ea4\u4e92\uff0c\u4e09\u8005\u5728Setchain\u4e2d\u7ef4\u62a4epoch-proof\uff08\u5df2\u7b7e\u540d\u7684epoch\u54c8\u5e0c\uff09\uff0c\u5ba2\u6237\u7aef\u53ef\u901a\u8fc7\u6536\u96c6f+1\u4e2aepoch-proofs\u9a8c\u8bc1epoch\u6b63\u786e\u6027\u3002\u8bc4\u4f30\u5728\u4e0d\u540c\u670d\u52a1\u5668\u6570\u91cf\u548c\u914d\u7f6e\u4e0b\u8861\u91cf\u541e\u5410\u91cf\u4e0e\u5ef6\u8fdf\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u4e09\u79cdSetchain\u65b9\u6848\u5728\u5404\u79cd\u914d\u7f6e\u4e0b\u90fd\u5b9e\u73b0\u4e86\u6bd4\u5e95\u5c42CometBFT\u9ad8\u6570\u91cf\u7ea7\u7684\u541e\u5410\u91cf\uff0c\u4e14\u6700\u7ec8\u786e\u5b9a\u6027\u5ef6\u8fdf\u5747\u4f4e\u4e8e4\u79d2\uff1b\u4e0d\u540c\u65b9\u6848\u5728\u5b58\u50a8\u3001\u901a\u4fe1\u548c\u5bf9\u8f7b\u5ba2\u6237\u7aef\u7684\u4f9d\u8d56\u6027\u4e0a\u5b58\u5728\u6743\u8861\uff1aCompresschain\u901a\u8fc7\u538b\u7f29\u51cf\u5c11\u5b58\u50a8/\u5e26\u5bbd\uff0cHashchain\u901a\u8fc7\u54c8\u5e0c\u51cf\u5c11\u8d26\u672c\u5199\u5165\u91cf\u4f46\u9700\u5916\u90e8\u670d\u52a1\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u5e76\u5b9e\u73b0\u4e86\u4e09\u79cd\u57fa\u4e8e\u533a\u5757\u94fe\u8d26\u672c\u7684Setchain\u7b97\u6cd5\uff08Vanilla\u3001Compresschain\u3001Hashchain\uff09\uff0c\u901a\u8fc7\u5c06\u4e8b\u52a1\u6309epoch\uff08\u96c6\u5408\uff09\u7ec4\u7ec7\u3001\u5728\u96c6\u5408\u5185\u65e0\u5e8f\uff0c\u4ece\u800c\u663e\u8457\u63d0\u9ad8\u541e\u5410\u91cf\u5e76\u964d\u4f4e\u786e\u8ba4\u5ef6\u8fdf\u3002\u5b9e\u9a8c\u8bc1\u660e\u57284\u30017\u300110\u8282\u70b9\u96c6\u7fa4\u4e0a\uff0c\u4e09\u79cd\u65b9\u6848\u5728\u541e\u5410\u91cf\u4e0a\u6bd4\u5e95\u5c42\u533a\u5757\u94fe\u9ad8\u51fa\u6570\u91cf\u7ea7\uff0c\u4e14\u6700\u7ec8\u786e\u5b9a\u6027\u5ef6\u8fdf\u4f4e\u4e8e4\u79d2\u3002"}}
{"id": "2509.09997", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2509.09997", "abs": "https://arxiv.org/abs/2509.09997", "authors": ["Richard Jozsa", "Karel Hynek", "Adrian Pekar"], "title": "Taming Volatility: Stable and Private QUIC Classification with Federated Learning", "comment": "Accepted for presentation at CNSM2025", "summary": "Federated Learning (FL) is a promising approach for privacy-preserving\nnetwork traffic analysis, but its practical deployment is challenged by the\nnon-IID nature of real-world data. While prior work has addressed statistical\nheterogeneity, the impact of temporal traffic volatility-the natural daily ebb\nand flow of network activity-on model stability remains largely unexplored.\nThis volatility can lead to inconsistent data availability at clients,\ndestabilizing the entire training process. In this paper, we systematically\naddress the problem of temporal volatility in federated QUIC classification. We\nfirst demonstrate the instability of standard FL in this dynamic setting. We\nthen propose and evaluate a client-side data buffer as a practical mechanism to\nensure stable and consistent local training, decoupling it from real-time\ntraffic fluctuations. Using the real-world CESNET-QUIC22 dataset partitioned\ninto 14 autonomous clients, we then demonstrate that this approach enables\nrobust convergence. Our results show that a stable federated system achieves a\n95.2% F1 score, a mere 2.3 percentage points below a non-private centralized\nmodel. This work establishes a blueprint for building operationally stable FL\nsystems for network management, proving that the challenges of dynamic network\nenvironments can be overcome with targeted architectural choices.", "AI": {"tldr": "\u4e3a\u5e94\u5bf9\u7f51\u7edc\u6d41\u91cf\u7684\u65f6\u95f4\u6ce2\u52a8\u5bf9\u8054\u90a6\u5b66\u4e60\u7684\u7834\u574f\uff0c\u4f5c\u8005\u63d0\u51fa\u5ba2\u6237\u7aef\u6570\u636e\u7f13\u51b2\uff0c\u5b9e\u9a8c\u8bc1\u660e\u80fd\u7a33\u5b9a\u8bad\u7ec3\u5e76\u5728QUIC\u5206\u7c7b\u8fbe\u5230\u63a5\u8fd1\u96c6\u4e2d\u5f0f\u7684\u6027\u80fd\uff0895.2% F1\uff09\u3002", "motivation": "\u73b0\u5b9e\u7f51\u7edc\u6d41\u91cf\u5448\u65e5\u95f4\u6ce2\u52a8\uff0c\u5bfc\u81f4\u5ba2\u6237\u7aef\u6570\u636e\u53ef\u7528\u6027\u4e0d\u7a33\u5b9a\uff0c\u8fdb\u800c\u7834\u574f\u8054\u90a6\u5b66\u4e60\u7684\u8bad\u7ec3\u7a33\u5b9a\u6027\u4e0e\u6536\u655b\u6027\uff1b\u73b0\u6709\u9488\u5bf9\u7edf\u8ba1\u5f02\u8d28\u6027\u7684\u7814\u7a76\u672a\u5145\u5206\u8003\u8651\u65f6\u95f4\u6ce2\u52a8\u5f71\u54cd\u3002", "method": "\u6784\u5efa\u5e76\u8bc4\u4f30\u5ba2\u6237\u7aef\u4fa7\u6570\u636e\u7f13\u51b2\u673a\u5236\uff0c\u5728CESNET-QUIC22\u6570\u636e\u96c6\u4e0a\u4ee514\u4e2a\u81ea\u6cbb\u5ba2\u6237\u7aef\u5212\u5206\uff0c\u6bd4\u8f83\u6807\u51c6FL\u4e0e\u7f13\u51b2\u540eFL\u7684\u6536\u655b\u6027\u4e0e\u6027\u80fd\uff0c\u4f7f\u7528F1\u7b49\u6307\u6807\u91cf\u5316\u3002", "result": "\u5728\u5f15\u5165\u5ba2\u6237\u7aef\u7f13\u51b2\u540e\uff0c\u8054\u90a6\u7cfb\u7edf\u5728QUIC\u6d41\u91cf\u5206\u7c7b\u4efb\u52a1\u4e0a\u7a33\u5b9a\u6536\u655b\uff0c\u53d6\u5f9795.2% F1\uff0c\u6bd4\u96c6\u4e2d\u5f0f\u975e\u9690\u79c1\u6a21\u578b\u4ec5\u4f4e2.3\u4e2a\u767e\u5206\u70b9\uff0c\u8bc1\u660e\u7f13\u51b2\u673a\u5236\u80fd\u6709\u6548\u7f13\u89e3\u65f6\u53d8\u6d41\u91cf\u5e26\u6765\u7684\u4e0d\u7a33\u5b9a\u6027\u3002", "conclusion": "\u672c\u6587\u8868\u660e\u5728\u6709\u65f6\u53d8\u6d41\u91cf\u7684\u771f\u5b9e\u8054\u90a6\u5b66\u4e60\u90e8\u7f72\u4e2d\uff0c\u6807\u51c6FL\u4e0d\u7a33\u5b9a\uff0c\u4f7f\u7528\u5ba2\u6237\u7aef\u6570\u636e\u7f13\u51b2\u53ef\u4ee5\u7a33\u5b9a\u8bad\u7ec3\u5e76\u5b9e\u73b0\u63a5\u8fd1\u96c6\u4e2d\u5f0f\u6a21\u578b\u7684\u6027\u80fd\u3002"}}
{"id": "2509.09868", "categories": ["cs.DC", "cs.CR", "cs.MA"], "pdf": "https://arxiv.org/pdf/2509.09868", "abs": "https://arxiv.org/abs/2509.09868", "authors": ["Yunhao Zhang", "Haobin Ni", "Soumya Basu", "Shir Cohen", "Maofan Yin", "Lorenzo Alvisi", "Robbert van Renesse", "Qi Chen", "Lidong Zhou"], "title": "Ordered Consensus with Equal Opportunity", "comment": null, "summary": "The specification of state machine replication (SMR) has no requirement on\nthe final total order of commands. In blockchains based on SMR, however, order\nmatters, since different orders could provide their clients with different\nfinancial rewards. Ordered consensus augments the specification of SMR to\ninclude specific guarantees on such order, with a focus on limiting the\ninfluence of Byzantine nodes. Real-world ordering manipulations, however, can\nand do happen even without Byzantine replicas, typically because of factors,\nsuch as faster networks or closer proximity to the blockchain infrastructure,\nthat give some clients an unfair advantage. To address this challenge, this\npaper proceeds to extend ordered consensus by requiring it to also support\nequal opportunity, a concrete notion of fairness, widely adopted in social\nsciences. Informally, equal opportunity requires that two candidates who,\naccording to a set of criteria deemed to be relevant, are equally qualified for\na position (in our case, a specific slot in the SMR total order), should have\nan equal chance of landing it. We show how randomness can be leveraged to keep\nbias in check, and, to this end, introduce the secret random oracle (SRO), a\nsystem component that generates randomness in a fault-tolerant manner. We\ndescribe two SRO designs based, respectively, on trusted hardware and threshold\nverifiable random functions, and instantiate them in Bercow, a new ordered\nconsensus protocol that, by approximating equal opportunity up to within a\nconfigurable factor, can effectively mitigate well-known ordering attacks in\nSMR-based blockchains.", "AI": {"tldr": "\u4e3a\u9632\u6b62\u533a\u5757\u94fe\u4e2d\u7684\u6392\u5e8f\u4e0d\u516c\uff0c\u8bba\u6587\u5c06\u5e73\u7b49\u673a\u4f1a\u7eb3\u5165\u6709\u5e8f\u5171\u8bc6\uff0c\u5229\u7528\u79d8\u5bc6\u968f\u673a\u9884\u8a00\u673a\uff08SRO\uff09\u4e0e\u968f\u673a\u5316\u65b9\u6cd5\uff0c\u5e76\u63d0\u51faBercow\u534f\u8bae\u4e0e\u4e24\u79cdSRO\u5b9e\u73b0\u4ee5\u8fd1\u4f3c\u4fdd\u8bc1\u516c\u5e73\u6027\u3002", "motivation": "\u4f20\u7edfSMR\u5bf9\u547d\u4ee4\u7684\u6700\u7ec8\u5168\u5e8f\u5e76\u4e0d\u8981\u6c42\uff0c\u4f46\u5728\u533a\u5757\u94fe\u4e2d\u6392\u5e8f\u4f1a\u4ea7\u751f\u4e0d\u540c\u7ecf\u6d4e\u56de\u62a5\uff0c\u4e14\u5373\u4fbf\u65e0\u62dc\u5360\u5ead\u884c\u4e3a\u4e5f\u4f1a\u56e0\u7f51\u7edc\u901f\u5ea6\u6216\u5730\u7406\u63a5\u8fd1\u6027\u5bfc\u81f4\u4e0d\u516c\u5e73\u6392\u5e8f\uff0c\u9700\u5728\u5171\u8bc6\u5c42\u9762\u5f15\u5165\u516c\u5e73\u6027\u4fdd\u969c\u3002", "method": "\u4f7f\u7528\u968f\u673a\u6027\u6765\u9650\u5236\u504f\u89c1\uff0c\u8bbe\u8ba1\u4e86\u4e24\u79cdSRO\u5b9e\u73b0\uff1a\u57fa\u4e8e\u53ef\u4fe1\u786c\u4ef6\u548c\u57fa\u4e8e\u9608\u503c\u53ef\u9a8c\u8bc1\u968f\u673a\u51fd\u6570\uff08VRF\uff09\uff1b\u5728\u6b64\u57fa\u7840\u4e0a\u63d0\u51fa\u65b0\u534f\u8baeBercow\uff0c\u901a\u8fc7\u53ef\u914d\u7f6e\u56e0\u5b50\u8fd1\u4f3c\u5b9e\u73b0\u5e73\u7b49\u673a\u4f1a\u3002", "result": "\u63d0\u51faSRO\u7684\u4e24\u79cd\u5b9e\u73b0\u548cBercow\u534f\u8bae\uff0c\u7406\u8bba\u4e0a\u53ef\u5728\u53ef\u914d\u7f6e\u8303\u56f4\u5185\u8fd1\u4f3c\u5b9e\u73b0\u5e73\u7b49\u673a\u4f1a\uff0c\u4ece\u800c\u6709\u6548\u7f13\u89e3\u5df2\u77e5\u7684\u6392\u5e8f\u64cd\u63a7\u653b\u51fb\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u5728\u6709\u5e8f\u5171\u8bc6\u4e2d\u5f15\u5165\u5e73\u7b49\u673a\u4f1a\uff08equal opportunity\uff09\u7684\u516c\u5e73\u6027\u8981\u6c42\uff0c\u5e76\u901a\u8fc7\u5f15\u5165\u79d8\u5bc6\u968f\u673a\u9884\u8a00\u673a\uff08SRO\uff09\u6765\u63a7\u5236\u504f\u89c1\uff0c\u4ece\u800c\u51cf\u8f7bSMR\u533a\u5757\u94fe\u4e2d\u7684\u6392\u5e8f\u653b\u51fb\u3002"}}
{"id": "2509.10001", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2509.10001", "abs": "https://arxiv.org/abs/2509.10001", "authors": ["Takanori Hara", "Masahiro Sasabe"], "title": "Service Function Chaining Architecture for Multi-hop Split Inference and Learning", "comment": "11 pages, 12 figures", "summary": "Service Function Chaining (SFC) is a networking technique that ensures\ntraffic traverses a predefined sequence of service functions, realizing\narbitrary network services through dynamic and efficient communication paths.\nInspired by this concept, we propose an SFC-based architecture for Multi-hop\nSplit Inference (MSI), where split sub-models are interpreted as service\nfunctions and their composition forms a service chain representing the global\nmodel. By leveraging SFC, the proposed architecture dynamically establishes\ncommunication paths for split sub-models, ensuring efficient and adaptive\nexecution. Furthermore, we extend this architecture to Multi-hop Split Learning\n(MSL) by applying SFC to the bidirectional communication required for training\ntasks. To realize the proposed architecture, we design Neural Service Functions\n(NSFs) to execute split sub-models as transparent TCP proxies and integrate\nthem with Segment Routing over IPv6 (SRv6) and the extended Berkeley Packet\nFilter (eBPF)-based SFC proxy. This integration ensures efficient ML processing\nover dynamic routing while maintaining compatibility with existing\napplications. Evaluation results demonstrate that (1) the proposed architecture\nis feasible for both MSI and MSL; (2) it is particularly suitable for real-time\ninference in MSI scenarios with small mini-batch sizes; (3) it supports dynamic\npath reconfiguration, enabling adaptive responses to changing network\nconditions while minimizing the impact of control mechanisms on inference and\nlearning processes.", "AI": {"tldr": "\u8bba\u6587\u7528SFC+NSF\u5c06\u62c6\u5206\u795e\u7ecf\u7f51\u7edc\u7f16\u6392\u4e3a\u670d\u52a1\u94fe\u5e76\u5728SRv6/eBPF\u4e0a\u5b9e\u73b0\uff0c\u9a8c\u8bc1\u4e86\u53ef\u884c\u6027\u3001\u5b9e\u65f6\u63a8\u7406\u4f18\u52bf\u4e0e\u52a8\u6001\u8def\u7531\u9002\u5e94\u6027\u3002", "motivation": "\u4f20\u7edf\u7aef\u5230\u7aef\u795e\u7ecf\u7f51\u7edc\u5728\u8d44\u6e90\u53d7\u9650\u6216\u7f51\u7edc\u5206\u5e03\u73af\u5883\u4e0b\u96be\u4ee5\u9ad8\u6548\u90e8\u7f72\uff0c\u62c6\u5206\u63a8\u7406/\u5b66\u4e60\u9700\u8981\u7075\u6d3b\u53ef\u9760\u7684\u8de8\u8282\u70b9\u901a\u4fe1\u4e0e\u8def\u5f84\u7ba1\u7406\uff0cSFC\u53ef\u4e3a\u5b50\u6a21\u578b\u4e32\u8054\u63d0\u4f9b\u52a8\u6001\u8def\u7531\u4e0e\u670d\u52a1\u7ec4\u5408\u80fd\u529b\uff0c\u4ece\u800c\u63d0\u5347\u6548\u7387\u4e0e\u9002\u5e94\u6027\u3002", "method": "\u5c06\u62c6\u5206\u5b50\u6a21\u578b\u89c6\u4e3a\u670d\u52a1\u51fd\u6570\uff0c\u5229\u7528SFC\u52a8\u6001\u5efa\u7acb\u901a\u4fe1\u8def\u5f84\uff1b\u8bbe\u8ba1Neural Service Functions\u4f5c\u4e3a\u900f\u660eTCP\u4ee3\u7406\u6267\u884c\u5b50\u6a21\u578b\uff1b\u5728\u7f51\u7edc\u5c42\u4f7f\u7528SRv6\u4e0eeBPF SFC\u4ee3\u7406\u4ee5\u5b9e\u73b0\u52a8\u6001\u8def\u7531\u4e0e\u6700\u4f4e\u4fb5\u5165\u6027\u3002\u5bf9\u63a8\u7406\u4e0e\u8bad\u7ec3\u573a\u666f\u5206\u522b\u5b9e\u73b0MSI\u4e0eMSL\uff0c\u5e76\u5728\u591a\u8df3\u7f51\u7edc\u73af\u5883\u4e2d\u8bc4\u4f30\u5ef6\u8fdf\u3001\u541e\u5410\u4e0e\u8def\u5f84\u91cd\u914d\u7f6e\u5f71\u54cd\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff1a\u67b6\u6784\u5728MSI/MSL\u4e0b\u53ef\u884c\uff1b\u5bf9\u5b9e\u65f6\u63a8\u7406\uff08\u5c0f\u6279\u91cf\uff09\u6548\u679c\u5c24\u4f73\uff0c\u5ef6\u8fdf\u964d\u4f4e\u5e76\u4fdd\u6301\u541e\u5410\uff1b\u652f\u6301\u52a8\u6001\u8def\u5f84\u91cd\u914d\u7f6e\uff0c\u80fd\u5728\u7f51\u7edc\u53d8\u5316\u65f6\u5feb\u901f\u8c03\u6574\u4e14\u63a7\u5236\u5f00\u9500\u5bf9\u63a8\u7406/\u8bad\u7ec3\u5f71\u54cd\u8f83\u5c0f\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u5c06\u670d\u52a1\u529f\u80fd\u94fe(SFC)\u7406\u5ff5\u5f15\u5165\u5206\u5e03\u5f0f\u795e\u7ecf\u7f51\u7edc\u63a8\u7406\u4e0e\u8bad\u7ec3\uff0c\u6784\u5efaMSI/MSL\u67b6\u6784\uff0c\u5e76\u5b9e\u73b0\u4e86NSF\u4e0eSRv6/eBPF\u96c6\u6210\u539f\u578b\uff0c\u9a8c\u8bc1\u4e86\u53ef\u884c\u6027\u4e0e\u52a8\u6001\u8def\u5f84\u91cd\u914d\u7f6e\u80fd\u529b\u3002"}}
{"id": "2509.10371", "categories": ["cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.10371", "abs": "https://arxiv.org/abs/2509.10371", "authors": ["Seokjin Go", "Joongun Park", "Spandan More", "Hanjiang Wu", "Irene Wang", "Aaron Jezghani", "Tushar Krishna", "Divya Mahajan"], "title": "Characterizing the Efficiency of Distributed Training: A Power, Performance, and Thermal Perspective", "comment": null, "summary": "The rapid scaling of Large Language Models (LLMs) has pushed training\nworkloads far beyond the limits of single-node analysis, demanding a deeper\nunderstanding of how these models behave across large-scale, multi-GPU systems.\nIn this paper, we present a comprehensive characterization of LLM training\nacross diverse real-world workloads and hardware platforms, including NVIDIA\nH100/H200 and AMD MI250 GPUs. We analyze dense and sparse models under various\nparallelism strategies -- tensor, pipeline, data, and expert -- and evaluate\ntheir effects on hardware utilization, power consumption, and thermal behavior.\nWe further evaluate the effectiveness of optimizations such as activation\nrecomputation and compute-communication overlap. Our findings show that\nperformance is not determined solely by scaling hardware capacity. Scale-up\nsystems with fewer, higher-memory GPUs can outperform scale-out systems in\ncommunication-bound regimes, but only under carefully tuned configurations; in\nother cases, scale-out deployments achieve superior throughput. We also show\nthat certain parallelism combinations, such as tensor with pipeline, lead to\nbandwidth underutilization due to inefficient data chunking, while increasing\nmicrobatch sizes beyond a certain point induces bursty execution and peak power\nexcursions that worsen thermal throttling. These insights reveal how training\nperformance is shaped by complex interactions between hardware, system\ntopology, and model execution. We conclude by offering recommendations for\nsystem and hardware design to improve the scalability and reliability of future\nLLM systems and workloads. The source code of this project is available at\nhttps://github.com/sitar-lab/CharLLM-PPT.", "AI": {"tldr": "\u8bba\u6587\u901a\u8fc7\u5b9e\u6d4bH100/H200/MI250\u5e73\u53f0\u4e0a\u591a\u79cd\u5e76\u884c\u7b56\u7565\u548c\u4f18\u5316\uff0c\u63ed\u793a\u4e86LLM\u8bad\u7ec3\u4e2d\u786c\u4ef6\u3001\u62d3\u6251\u4e0e\u5e76\u884c\u7b56\u7565\u7684\u590d\u6742\u4ea4\u4e92\uff0c\u5e76\u7ed9\u51fa\u7cfb\u7edf/\u786c\u4ef6\u8bbe\u8ba1\u5efa\u8bae\u4ee5\u63d0\u5347\u53ef\u6269\u5c55\u6027\u4e0e\u53ef\u9760\u6027\u3002", "motivation": "\u968f\u7740LLM\u89c4\u6a21\u6269\u5927\uff0c\u5355\u673a\u5206\u6790\u4e0d\u8db3\u4ee5\u6307\u5bfc\u591aGPU\u7cfb\u7edf\u8bbe\u8ba1\uff0c\u9700\u8981\u7cfb\u7edf\u6027\u7406\u89e3\u6a21\u578b\u5e76\u884c\u7b56\u7565\u4e0e\u786c\u4ef6\u62d3\u6251\u5982\u4f55\u5171\u540c\u5f71\u54cd\u8bad\u7ec3\u6548\u7387\u4e0e\u53ef\u9760\u6027\u3002", "method": "\u5728\u771f\u5b9e\u591aGPU\u5e73\u53f0\uff08NVIDIA H100/H200\u3001AMD MI250\uff09\u4e0a\uff0c\u9488\u5bf9\u7a20\u5bc6\u4e0e\u7a00\u758f\u6a21\u578b\uff0c\u6bd4\u8f83\u5f20\u91cf\u5e76\u884c\u3001\u6d41\u6c34\u7ebf\u5e76\u884c\u3001\u6570\u636e\u5e76\u884c\u4e0e\u4e13\u5bb6\u5e76\u884c\u7b49\u7b56\u7565\uff1b\u6d4b\u91cf\u786c\u4ef6\u5229\u7528\u7387\u3001\u529f\u8017\u4e0e\u6e29\u63a7\uff1b\u8bc4\u4f30\u6fc0\u6d3b\u91cd\u8ba1\u7b97\u3001\u8ba1\u7b97-\u901a\u4fe1\u91cd\u53e0\u7b49\u4f18\u5316\u3002", "result": "\u53d1\u73b0\u89c4\u6a21\u6269\u5c55\u5e76\u975e\u4e07\u80fd\uff1a\u5c11\u6570\u9ad8\u5185\u5b58GPU\u7684scale-up\u5728\u901a\u4fe1\u53d7\u9650\u65f6\u80fd\u4f18\u4e8escale-out\uff0c\u4f46\u9700\u7cbe\u8c03\uff1b\u67d0\u4e9b\u5e76\u884c\u7ec4\u5408\uff08\u5982\u5f20\u91cf+\u6d41\u6c34\u7ebf\uff09\u9020\u6210\u5e26\u5bbd\u672a\u5145\u5206\u5229\u7528\uff1b\u8fc7\u5927\u5fae\u6279\u91cf\u5f15\u53d1\u7a81\u53d1\u6267\u884c\u4e0e\u5cf0\u503c\u529f\u8017\uff0c\u52a0\u5267\u70ed\u8282\u6d41\uff1b\u6fc0\u6d3b\u91cd\u7b97\u4e0e\u901a\u4fe1\u91cd\u53e0\u5728\u4e0d\u540c\u573a\u666f\u6548\u679c\u4e0d\u540c\u3002", "conclusion": "\u8be5\u8bba\u6587\u901a\u8fc7\u8de8\u5e73\u53f0\u3001\u8de8\u7b56\u7565\u7684\u7cfb\u7edf\u6027\u5b9e\u9a8c\uff0c\u63ed\u793aLLM\u8bad\u7ec3\u6027\u80fd\u53d7\u786c\u4ef6\u3001\u62d3\u6251\u548c\u5e76\u884c\u7b56\u7565\u590d\u6742\u4ea4\u4e92\u5f71\u54cd\uff0c\u63d0\u51fa\u4e86\u786c\u4ef6\u4e0e\u7cfb\u7edf\u8bbe\u8ba1\u4f18\u5316\u5efa\u8bae\u3002"}}
{"id": "2509.10097", "categories": ["cs.NI", "eess.SP"], "pdf": "https://arxiv.org/pdf/2509.10097", "abs": "https://arxiv.org/abs/2509.10097", "authors": ["Ahmed Al-Tahmeesschi", "Yi Chu", "Gurdeep Singh", "Charles Turyagyenda", "Dritan Kaleshi", "David Grace", "Hamed Ahmadi"], "title": "Maximising Energy Efficiency in Large-Scale Open RAN: Hybrid xApps and Digital Twin Integration", "comment": "Accepted in GLOBECOM WS 2025", "summary": "The growing demand for high-speed, ultra-reliable, and low-latency\ncommunications in 5G and beyond networks has significantly driven up power\nconsumption, particularly within the Radio Access Network (RAN). This surge in\nenergy demand poses critical operational and sustainability challenges for\nmobile network operators, necessitating innovative solutions that enhance\nenergy efficiency without compromising Quality of Service (QoS). Open Radio\nAccess Network (O-RAN), spearheaded by the O-RAN Alliance, offers\ndisaggregated, programmable, and intelligent architectures, promoting\nflexibility, interoperability, and cost-effectiveness. However, this\ndisaggregated approach adds complexity, particularly in managing power\nconsumption across diverse network components such as Open Radio Units (RUs).\nIn this paper, we propose a hybrid xApp leveraging heuristic methods and\nunsupervised machine learning, integrated with digital twin technology through\nthe TeraVM AI RAN Scenario Generator (AI-RSG). This approach dynamically\nmanages RU sleep modes to effectively reduce energy consumption. Our\nexperimental evaluation in a realistic, large-scale emulated Open RAN scenario\ndemonstrates that the hybrid xApp achieves approximately 13% energy savings,\nhighlighting its practicality and significant potential for real-world\ndeployments without compromising user QoS.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u542f\u53d1\u5f0f+\u65e0\u76d1\u7763\u5b66\u4e60\u7684\u6df7\u5408xApp\u5e76\u7ed3\u5408TeraVM\u6570\u5b57\u5b6a\u751f\u8fdb\u884c\u9a8c\u8bc1\uff0c\u5b9e\u73b0\u7ea613%\u80fd\u8017\u8282\u7701\u4e14\u4e0d\u635f\u5bb3QoS\uff0c\u9002\u7528\u4e8e\u5927\u89c4\u6a21Open RAN\u90e8\u7f72\u3002", "motivation": "5G\u53ca\u4ee5\u540e\u7f51\u7edc\u5bf9\u9ad8\u5e26\u5bbd\u3001\u8d85\u53ef\u9760\u4f4e\u65f6\u5ef6\u670d\u52a1\u7684\u9700\u6c42\u5bfc\u81f4RAN\u80fd\u8017\u5927\u5e45\u4e0a\u5347\uff0c\u7ed9\u8fd0\u8425\u5546\u5e26\u6765\u8fd0\u8425\u6210\u672c\u548c\u53ef\u6301\u7eed\u6027\u538b\u529b\uff1bO-RAN\u7684\u89e3\u8026\u4e0e\u53ef\u7f16\u7a0b\u6027\u4e3a\u8282\u80fd\u63d0\u4f9b\u673a\u4f1a\uff0c\u4f46\u4e5f\u589e\u52a0\u4e86\u7ba1\u7406\u590d\u6742\u6027\uff0c\u56e0\u800c\u9700\u8981\u667a\u80fd\u5316\u3001\u53ef\u9a8c\u8bc1\u7684\u8282\u80fd\u7b56\u7565\u3002", "method": "\u8bbe\u8ba1\u5e76\u5b9e\u73b0\u4e86\u4e00\u4e2a\u6df7\u5408xApp\uff1a\u9996\u5148\u4f7f\u7528\u65e0\u76d1\u7763\u5b66\u4e60\u5bf9\u57fa\u7ad9/\u5c0f\u533a\u6d41\u91cf\u548c\u8d1f\u8f7d\u6a21\u5f0f\u8fdb\u884c\u805a\u7c7b\uff0c\u4ece\u800c\u8bc6\u522b\u53ef\u8fdb\u5165\u7761\u7720\u6a21\u5f0f\u7684\u5019\u9009RU\uff1b\u7136\u540e\u7ed3\u5408\u542f\u53d1\u5f0f\u89c4\u5219\uff08\u4f8b\u5982\u8d1f\u8f7d\u9608\u503c\u3001QoS\u7ea6\u675f\u548c\u5207\u6362\u6210\u672c\uff09\u51b3\u5b9a\u5177\u4f53\u7684\u7761\u7720/\u5524\u9192\u7b56\u7565\uff1b\u901a\u8fc7\u6570\u5b57\u5b6a\u751f\uff08AI-RSG\uff09\u751f\u6210\u903c\u771f\u7684RAN\u573a\u666f\u8fdb\u884c\u5927\u89c4\u6a21\u4eff\u771f\u4e0e\u5728\u7ebf\u8bc4\u4f30\u3002", "result": "\u5728\u4e00\u4e2a\u73b0\u5b9e\u7684\u5927\u89c4\u6a21\u4eff\u771fOpen RAN\u573a\u666f\u4e2d\uff0c\u6df7\u5408xApp\u76f8\u6bd4\u57fa\u7ebf\u7b56\u7565\u5b9e\u73b0\u4e86\u7ea613%\u7684\u80fd\u8017\u964d\u4f4e\uff0c\u540c\u65f6\u4fdd\u6301\u7528\u6237QoS\uff08\u4f8b\u5982\u541e\u5410\u91cf\u3001\u65f6\u5ef6\u548c\u8fde\u63a5\u7a33\u5b9a\u6027\uff09\u672a\u89c1\u660e\u663e\u6076\u5316\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u542f\u53d1\u5f0f\u65b9\u6cd5\u4e0e\u65e0\u76d1\u7763\u673a\u5668\u5b66\u4e60\u7684\u6df7\u5408xApp\uff0c\u5e76\u901a\u8fc7\u6570\u5b57\u5b6a\u751f\u5e73\u53f0\uff08TeraVM AI-RSG\uff09\u5728\u5927\u89c4\u6a21Open RAN\u4eff\u771f\u573a\u666f\u4e2d\u9a8c\u8bc1\uff0c\u5b9e\u73b0\u4e86\u5728\u4e0d\u635f\u5bb3\u7528\u6237QoS\u7684\u524d\u63d0\u4e0b\u7ea613%\u7684\u80fd\u8017\u8282\u7701\u3002"}}
{"id": "2509.09744", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.09744", "abs": "https://arxiv.org/abs/2509.09744", "authors": ["Mujie Liu", "Chenze Wang", "Liping Chen", "Nguyen Linh Dan Le", "Niharika Tewari", "Ting Dang", "Jiangang Ma", "Feng Xia"], "title": "Structure Matters: Brain Graph Augmentation via Learnable Edge Masking for Data-efficient Psychiatric Diagnosis", "comment": null, "summary": "The limited availability of labeled brain network data makes it challenging\nto achieve accurate and interpretable psychiatric diagnoses. While\nself-supervised learning (SSL) offers a promising solution, existing methods\noften rely on augmentation strategies that can disrupt crucial structural\nsemantics in brain graphs. To address this, we propose SAM-BG, a two-stage\nframework for learning brain graph representations with structural semantic\npreservation. In the pre-training stage, an edge masker is trained on a small\nlabeled subset to capture key structural semantics. In the SSL stage, the\nextracted structural priors guide a structure-aware augmentation process,\nenabling the model to learn more semantically meaningful and robust\nrepresentations. Experiments on two real-world psychiatric datasets demonstrate\nthat SAM-BG outperforms state-of-the-art methods, particularly in small-labeled\ndata settings, and uncovers clinically relevant connectivity patterns that\nenhance interpretability. Our code is available at\nhttps://github.com/mjliu99/SAM-BG.", "AI": {"tldr": "\u63d0\u51faSAM-BG\uff1a\u7528\u8fb9\u63a9\u7801\u5668\u5b66\u7ed3\u6784\u5148\u9a8c\uff0c\u518d\u7528\u4e8e\u7ed3\u6784\u611f\u77e5\u7684SSL\u589e\u5f3a\uff0c\u5728\u5c0f\u6807\u7b7e\u8111\u7f51\u7edc\u8bca\u65ad\u4e2d\u65e2\u63d0\u5347\u6027\u80fd\u53c8\u589e\u5f3a\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u6807\u6ce8\u8111\u7f51\u7edc\u6570\u636e\u7a00\u7f3a\u4e14\u73b0\u6709SSL\u6570\u636e\u589e\u5f3a\u53ef\u80fd\u7834\u574f\u8111\u56fe\u7684\u7ed3\u6784\u8bed\u4e49\uff0c\u5f71\u54cd\u8bca\u65ad\u51c6\u786e\u6027\u4e0e\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u4e24\u9636\u6bb5\u65b9\u6cd5\uff1a\u7b2c\u4e00\u9636\u6bb5\u5728\u5c0f\u89c4\u6a21\u6709\u6807\u7b7e\u5b50\u96c6\u4e0a\u8bad\u7ec3\u8fb9\u63a9\u7801\u5668\u4ee5\u6355\u6349\u5173\u952e\u7ed3\u6784\u8bed\u4e49\uff1b\u7b2c\u4e8c\u9636\u6bb5\u5229\u7528\u8be5\u7ed3\u6784\u5148\u9a8c\u6307\u5bfc\u7ed3\u6784\u611f\u77e5\u7684\u6570\u636e\u589e\u5f3a\u8fdb\u884c\u81ea\u76d1\u7763\u9884\u8bad\u7ec3\uff0c\u4ece\u800c\u5b66\u4e60\u66f4\u9c81\u68d2\u3001\u6709\u8bed\u4e49\u610f\u4e49\u7684\u8868\u793a\u3002", "result": "\u5728\u4e24\u4e2a\u771f\u5b9e\u7cbe\u795e\u75c5\u5b66\u6570\u636e\u96c6\u4e0a\uff0cSAM-BG\u8f83\u73b0\u6709\u65b9\u6cd5\u8868\u73b0\u66f4\u597d\uff0c\u7279\u522b\u662f\u5728\u6807\u7b7e\u7a00\u7f3a\u60c5\u5f62\uff1b\u5e76\u80fd\u53d1\u73b0\u4e34\u5e8a\u76f8\u5173\u7684\u8fde\u63a5\u6a21\u5f0f\uff0c\u63d0\u9ad8\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "SAM-BG\u901a\u8fc7\u7ed3\u6784\u8bed\u4e49\u4fdd\u6301\u7684\u81ea\u76d1\u7763\u5b66\u4e60\uff0c\u6709\u6548\u63d0\u5347\u4e86\u8111\u7f51\u7edc\u5206\u6790\u4e2d\u5728\u5c0f\u6837\u672c\u4e0b\u7684\u8bca\u65ad\u6027\u80fd\u5e76\u589e\u5f3a\u4e86\u89e3\u91ca\u6027\u3002"}}
{"id": "2509.09706", "categories": ["cs.CR", "cs.AI", "cs.CL", "I.2; H.3.3"], "pdf": "https://arxiv.org/pdf/2509.09706", "abs": "https://arxiv.org/abs/2509.09706", "authors": ["Taniya Gidatkar", "Oluwaseun Ajao", "Matthew Shardlow"], "title": "Differential Robustness in Transformer Language Models: Empirical Evaluation Under Adversarial Text Attacks", "comment": "8 pages, 4 tables, to appear in proceedings of Recent Advances in\n  Natural Language Processing (RANLP 2025) and ACL Anthology", "summary": "This study evaluates the resilience of large language models (LLMs) against\nadversarial attacks, specifically focusing on Flan-T5, BERT, and RoBERTa-Base.\nUsing systematically designed adversarial tests through TextFooler and\nBERTAttack, we found significant variations in model robustness. RoBERTa-Base\nand FlanT5 demonstrated remarkable resilience, maintaining accuracy even when\nsubjected to sophisticated attacks, with attack success rates of 0%. In\ncontrast. BERT-Base showed considerable vulnerability, with TextFooler\nachieving a 93.75% success rate in reducing model accuracy from 48% to just 3%.\nOur research reveals that while certain LLMs have developed effective defensive\nmechanisms, these safeguards often require substantial computational resources.\nThis study contributes to the understanding of LLM security by identifying\nexisting strengths and weaknesses in current safeguarding approaches and\nproposes practical recommendations for developing more efficient and effective\ndefensive strategies.", "AI": {"tldr": "\u5bf9\u6297\u6027\u6d4b\u8bd5\u663e\u793aFlan-T5\u4e0eRoBERTa-Base\u9c81\u68d2\uff0cBERT-Base\u8106\u5f31\uff1b\u63d0\u51fa\u9700\u5728\u9632\u5fa1\u6709\u6548\u6027\u4e0e\u8ba1\u7b97\u6210\u672c\u95f4\u6743\u8861\u5e76\u4f18\u5316\u9632\u5fa1\u7b56\u7565\u3002", "motivation": "\u8bc4\u4f30\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u5728\u73b0\u5b9e\u5bf9\u6297\u653b\u51fb\u573a\u666f\u4e0b\u7684\u5b89\u5168\u6027\u4e0e\u9c81\u68d2\u6027\uff0c\u8bc6\u522b\u8106\u5f31\u6a21\u578b\u5e76\u4e3a\u66f4\u9ad8\u6548\u7684\u9632\u5fa1\u7b56\u7565\u63d0\u4f9b\u5efa\u8bae\u3002", "method": "\u4f7f\u7528TextFooler\u548cBERTAttack\u5bf9Flan-T5\u3001BERT-Base\u548cRoBERTa-Base\u8fdb\u884c\u7cfb\u7edf\u6027\u5bf9\u6297\u6d4b\u8bd5\uff0c\u901a\u8fc7\u6d4b\u91cf\u653b\u51fb\u6210\u529f\u7387\u4e0e\u6a21\u578b\u51c6\u786e\u7387\u4e0b\u964d\u6765\u8bc4\u4f30\u9c81\u68d2\u6027\u3002", "result": "RoBERTa-Base\u4e0eFlan-T5\u5728\u5b9e\u9a8c\u4e2d\u653b\u51fb\u6210\u529f\u7387\u4e3a0%\uff0c\u4fdd\u6301\u9ad8\u51c6\u786e\u7387\uff1bBERT-Base\u5728TextFooler\u653b\u51fb\u4e0b\u6210\u529f\u7387\u4e3a93.75%\uff0c\u51c6\u786e\u7387\u4ece48%\u964d\u81f33%\u3002\u7814\u7a76\u6307\u51fa\u9632\u5fa1\u6709\u6548\u4f46\u8ba1\u7b97\u5f00\u9500\u5927\u3002", "conclusion": "\u8be5\u7814\u7a76\u8868\u660e\u4e0d\u540cLLM\u5728\u9762\u5bf9\u5bf9\u6297\u6027\u653b\u51fb\u65f6\u8868\u73b0\u5dee\u5f02\u663e\u8457\uff0cRoBERTa-Base\u548cFlan-T5\u5c55\u73b0\u51fa\u5f3a\u9c81\u68d2\u6027\uff0c\u800cBERT-Base\u6613\u53d7\u653b\u51fb\u3002\u7814\u7a76\u5f3a\u8c03\u6709\u6548\u9632\u5fa1\u673a\u5236\u901a\u5e38\u4f34\u968f\u9ad8\u8ba1\u7b97\u6210\u672c\u3002"}}
{"id": "2509.09738", "categories": ["cs.AI", "q-bio.QM", "I.2.7"], "pdf": "https://arxiv.org/pdf/2509.09738", "abs": "https://arxiv.org/abs/2509.09738", "authors": ["Umut Eser", "Yael Gozin", "L. Jay Stallons", "Ari Caroline", "Martin Preusse", "Brandon Rice", "Scott Wright", "Andrew Robertson"], "title": "Human-AI Collaboration Increases Efficiency in Regulatory Writing", "comment": null, "summary": "Background: Investigational New Drug (IND) application preparation is\ntime-intensive and expertise-dependent, slowing early clinical development.\nObjective: To evaluate whether a large language model (LLM) platform (AutoIND)\ncan reduce first-draft composition time while maintaining document quality in\nregulatory submissions. Methods: Drafting times for IND nonclinical written\nsummaries (eCTD modules 2.6.2, 2.6.4, 2.6.6) generated by AutoIND were directly\nrecorded. For comparison, manual drafting times for IND summaries previously\ncleared by the U.S. FDA were estimated from the experience of regulatory\nwriters ($\\geq$6 years) and used as industry-standard benchmarks. Quality was\nassessed by a blinded regulatory writing assessor using seven pre-specified\ncategories: correctness, completeness, conciseness, consistency, clarity,\nredundancy, and emphasis. Each sub-criterion was scored 0-3 and normalized to a\npercentage. A critical regulatory error was defined as any misrepresentation or\nomission likely to alter regulatory interpretation (e.g., incorrect NOAEL,\nomission of mandatory GLP dose-formulation analysis). Results: AutoIND reduced\ninitial drafting time by $\\sim$97% (from $\\sim$100 h to 3.7 h for 18,870\npages/61 reports in IND-1; and to 2.6 h for 11,425 pages/58 reports in IND-2).\nQuality scores were 69.6\\% and 77.9\\% for IND-1 and IND-2. No critical\nregulatory errors were detected, but deficiencies in emphasis, conciseness, and\nclarity were noted. Conclusions: AutoIND can dramatically accelerate IND\ndrafting, but expert regulatory writers remain essential to mature outputs to\nsubmission-ready quality. Systematic deficiencies identified provide a roadmap\nfor targeted model improvements.", "AI": {"tldr": "AutoIND\u663e\u8457\u964d\u4f4eIND\u975e\u4e34\u5e8a\u603b\u7ed3\u521d\u7a3f\u65f6\u95f4\uff08\u7ea697%\uff09\uff0c\u8d28\u91cf\u5c1a\u53ef\u4f46\u9700\u8d44\u6df1\u4eba\u5458\u6da6\u8272\uff0c\u65e0\u5173\u952e\u76d1\u7ba1\u9519\u8bef\uff0c\u6307\u51fa\u4e86\u9700\u6539\u8fdb\u7684\u7cfb\u7edf\u6027\u7f3a\u9677\u3002", "motivation": "IND\u7533\u8bf7\u51c6\u5907\u8017\u65f6\u4e14\u4f9d\u8d56\u4e13\u4e1a\u77e5\u8bc6\uff0c\u5ef6\u7f13\u65e9\u671f\u4e34\u5e8a\u5f00\u53d1\u3002\u8bc4\u4f30LLM\u5e73\u53f0\u80fd\u5426\u5728\u4fdd\u6301\u8d28\u91cf\u524d\u63d0\u4e0b\u7f29\u77ed\u9996\u6b21\u8349\u7a3f\u64b0\u5199\u65f6\u95f4\u3002", "method": "\u4f7f\u7528AutoIND\u81ea\u52a8\u751f\u6210eCTD\u6a21\u57572.6.2\u30012.6.4\u30012.6.6\u7684\u8349\u7a3f\u5e76\u76f4\u63a5\u8bb0\u5f55\u64b0\u5199\u65f6\u95f4\uff0c\u4e0e\u57fa\u4e8e\u22656\u5e74\u7ecf\u9a8c\u7684\u76d1\u7ba1\u64b0\u7a3f\u4eba\u4f30\u7b97\u7684\u624b\u5de5\u64b0\u5199\u65f6\u95f4\u8fdb\u884c\u6bd4\u8f83\uff1b\u8d28\u91cf\u7531\u76f2\u5ba1\u76d1\u7ba1\u5199\u4f5c\u8bc4\u4f30\u8005\u6309\u4e03\u4e2a\u6307\u6807\u8bc4\u5206\uff08\u54040-3\uff09\uff0c\u5f52\u4e00\u5316\u4e3a\u767e\u5206\u6bd4\uff0c\u5e76\u68c0\u9a8c\u5173\u952e\u76d1\u7ba1\u9519\u8bef\u3002", "result": "\u9996\u6b21\u8349\u7a3f\u65f6\u95f4\u7ea6\u7f29\u77ed97%\uff08\u4ece\u7ea6100\u5c0f\u65f6\u964d\u81f33.7\u5c0f\u65f6\u62162.6\u5c0f\u65f6\uff09\uff1b\u8d28\u91cf\u8bc4\u5206\u5206\u522b\u4e3a69.6%\uff08IND-1\uff09\u548c77.9%\uff08IND-2\uff09\uff1b\u672a\u53d1\u73b0\u5173\u952e\u76d1\u7ba1\u9519\u8bef\uff0c\u4f46\u5728\u5f3a\u8c03\u3001\u7b80\u6d01\u6027\u548c\u6e05\u6670\u5ea6\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\u3002", "conclusion": "AutoIND\u6781\u5927\u52a0\u901f\u4e86IND\u975e\u4e34\u5e8a\u603b\u7ed3\u8349\u7a3f\u7684\u521d\u59cb\u64b0\u5199\u901f\u5ea6\uff0c\u4f46\u4ecd\u9700\u8d44\u6df1\u76d1\u7ba1\u64b0\u7a3f\u4eba\u5bf9\u8f93\u51fa\u8fdb\u884c\u6da6\u8272\u4ee5\u8fbe\u5230\u63d0\u4ea4\u8d28\u91cf\u3002"}}
{"id": "2509.10173", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2509.10173", "abs": "https://arxiv.org/abs/2509.10173", "authors": ["Lyubomir Yanev", "Pietro Ronchetti", "Joshua Smailes", "Martin Strohmeier"], "title": "Secure and Scalable Rerouting in LEO Satellite Networks", "comment": null, "summary": "Resilient routing in large-scale Low Earth Orbit (LEO) satellite networks\nremains a key challenge due to frequent and unpredictable link and node\nfailures, potentially in response to cybersecurity breaches. While prior work\nhas explored rerouting strategies with various levels of network awareness,\ntheir relative tradeoffs under dynamic failure conditions remain underexplored.\nIn this work, we extend the Deep Space Network Simulator (DSNS) to\nsystematically compare three rerouting paradigms, each differing in the scope\nof failure knowledge available to each node. We compare local neighbor-based,\nsegment-based and global-knowledge-based rerouting as well as a naive source\nrouting solution that is unaware of failures. Our main goal is to evaluate how\nthe breadth of failure awareness impacts routing performance and resilience\nunder failures, both random and targeted. We measure delivery ratio, latency,\nrerouting overhead, and loop occurrence. Our findings show the potential of\nsegment-based rerouting to achieve a favorable tradeoff between local\nresponsiveness and global coordination, offering resilience benefits with\nminimal overhead--insights that can inform future fault-tolerant satellite\nnetwork design.", "AI": {"tldr": "Compared local, segment, global, and naive routing under random/targeted failures using DSNS; segment-based routing provides near-optimal resilience with low overhead, making it a practical choice for LEO networks.", "motivation": "LEO satellite networks face frequent and unpredictable link/node failures (including due to cyberattacks); understanding how the scope of failure awareness at routing nodes affects resilience and performance is crucial for designing fault-tolerant routing protocols.", "method": "Extended the Deep Space Network Simulator (DSNS) to implement and compare four routing paradigms (local neighbor-based, segment-based, global-knowledge-based, and naive source routing) under controlled random and targeted failure scenarios, measuring delivery ratio, latency, rerouting overhead, and loop occurrence.", "result": "Segment-based rerouting achieved favorable tradeoffs: high delivery ratios close to global-knowledge routing, lower latency than naive source routing, and minimal rerouting overhead and loops compared to local-only approaches.", "conclusion": "Segment-based rerouting offers a strong middle ground, combining local responsiveness with enough global coordination to maintain high delivery ratios and low overhead under various failure modes, making it suitable for resilient LEO satellite networks."}}
{"id": "2509.09915", "categories": ["cs.AI", "cs.DC"], "pdf": "https://arxiv.org/pdf/2509.09915", "abs": "https://arxiv.org/abs/2509.09915", "authors": ["Woong Shin", "Renan Souza", "Daniel Rosendo", "Fr\u00e9d\u00e9ric Suter", "Feiyi Wang", "Prasanna Balaprakash", "Rafael Ferreira da Silva"], "title": "The (R)evolution of Scientific Workflows in the Agentic AI Era: Towards Autonomous Science", "comment": null, "summary": "Modern scientific discovery increasingly requires coordinating distributed\nfacilities and heterogeneous resources, forcing researchers to act as manual\nworkflow coordinators rather than scientists. Advances in AI leading to AI\nagents show exciting new opportunities that can accelerate scientific discovery\nby providing intelligence as a component in the ecosystem. However, it is\nunclear how this new capability would materialize and integrate in the real\nworld. To address this, we propose a conceptual framework where workflows\nevolve along two dimensions which are intelligence (from static to intelligent)\nand composition (from single to swarm) to chart an evolutionary path from\ncurrent workflow management systems to fully autonomous, distributed scientific\nlaboratories. With these trajectories in mind, we present an architectural\nblueprint that can help the community take the next steps towards harnessing\nthe opportunities in autonomous science with the potential for 100x discovery\nacceleration and transformational scientific workflows.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u6cbf\u667a\u80fd\u5316\u4e0e\u7ec4\u5408\u5316\u4e24\u7ef4\u6f14\u8fdb\u7684\u6982\u5ff5\u6846\u67b6\u4e0e\u67b6\u6784\u84dd\u56fe\uff0c\u65e8\u5728\u628aAI\u667a\u80fd\u4f53\u6574\u5408\u5165\u5206\u5e03\u5f0f\u79d1\u5b66\u5de5\u4f5c\u6d41\uff0c\u63a8\u52a8\u5b9e\u73b0\u81ea\u4e3b\u5316\u5b9e\u9a8c\u5ba4\u4e0e\u663e\u8457\u52a0\u901f\u7684\u79d1\u5b66\u53d1\u73b0\u3002", "motivation": "\u5f53\u524d\u79d1\u7814\u9700\u8981\u534f\u8c03\u5206\u5e03\u5f0f\u8bbe\u65bd\u548c\u5f02\u6784\u8d44\u6e90\uff0c\u7814\u7a76\u4eba\u5458\u88ab\u8feb\u624b\u52a8\u7ba1\u7406\u5de5\u4f5c\u6d41\uff1bAI\u667a\u80fd\u4f53\u7684\u8fdb\u6b65\u63d0\u4f9b\u4e86\u5c06\u667a\u80fd\u4f5c\u4e3a\u751f\u6001\u7cfb\u7edf\u7ec4\u4ef6\u7684\u673a\u4f1a\uff0c\u4f46\u5982\u4f55\u5b9e\u9645\u6574\u5408\u5c1a\u4e0d\u6e05\u695a\uff0c\u56e0\u6b64\u63d0\u51fa\u6846\u67b6\u4e0e\u84dd\u56fe\u4ee5\u4fc3\u8fdb\u843d\u5730\u3002", "method": "\u63d0\u51fa\u4e8c\u7ef4\u6f14\u8fdb\u8def\u5f84\uff08\u667a\u80fd\u5316\uff1a\u9759\u6001\u2192\u667a\u80fd\uff1b\u7ec4\u5408\u5316\uff1a\u5355\u4f53\u2192\u7fa4\u4f53\uff09\uff0c\u5e76\u57fa\u4e8e\u6b64\u7ed9\u51fa\u67b6\u6784\u84dd\u56fe\uff0c\u7528\u4ee5\u6307\u5bfc\u5c06AI\u667a\u80fd\u4f53\u96c6\u6210\u5230\u5b9e\u9645\u79d1\u5b66\u5de5\u4f5c\u6d41\u4e2d\u3002", "result": "\u7ed9\u51fa\u6f14\u8fdb\u7ef4\u5ea6\u548c\u67b6\u6784\u84dd\u56fe\uff0c\u6307\u51fa\u6f5c\u5728\u5e26\u6765100\u500d\u53d1\u73b0\u52a0\u901f\u4e0e\u53d8\u9769\u6027\u5de5\u4f5c\u6d41\u7684\u53ef\u80fd\u6027\uff0c\u4e3a\u793e\u533a\u4e0b\u4e00\u6b65\u7814\u7a76\u548c\u7cfb\u7edf\u6784\u5efa\u63d0\u4f9b\u65b9\u5411\u3002", "conclusion": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u4e2a\u6982\u5ff5\u6846\u67b6\uff0c\u63cf\u7ed8\u4ece\u5f53\u524d\u5de5\u4f5c\u6d41\u7ba1\u7406\u5230\u5b8c\u5168\u81ea\u4e3b\u5206\u5e03\u5f0f\u79d1\u5b66\u5b9e\u9a8c\u5ba4\u7684\u53d1\u5c55\u8def\u7ebf\uff0c\u4e3b\u5f20\u901a\u8fc7\u667a\u80fd\u4f53\u548c\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u63a8\u52a8\u79d1\u5b66\u53d1\u73b0\u6548\u7387\u7684\u5927\u5e45\u63d0\u5347\u3002"}}
{"id": "2509.09747", "categories": ["cs.LG", "cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2509.09747", "abs": "https://arxiv.org/abs/2509.09747", "authors": ["Leen Daher", "Zhaobo Wang", "Malcolm Mielle"], "title": "D-CAT: Decoupled Cross-Attention Transfer between Sensor Modalities for Unimodal Inference", "comment": null, "summary": "Cross-modal transfer learning is used to improve multi-modal classification\nmodels (e.g., for human activity recognition in human-robot collaboration).\nHowever, existing methods require paired sensor data at both training and\ninference, limiting deployment in resource-constrained environments where full\nsensor suites are not economically and technically usable. To address this, we\npropose Decoupled Cross-Attention Transfer (D-CAT), a framework that aligns\nmodality-specific representations without requiring joint sensor modality\nduring inference. Our approach combines a self-attention module for feature\nextraction with a novel cross-attention alignment loss, which enforces the\nalignment of sensors' feature spaces without requiring the coupling of the\nclassification pipelines of both modalities. We evaluate D-CAT on three\nmulti-modal human activity datasets (IMU, video, and audio) under both\nin-distribution and out-of-distribution scenarios, comparing against uni-modal\nmodels. Results show that in in-distribution scenarios, transferring from\nhigh-performing modalities (e.g., video to IMU) yields up to 10% F1-score gains\nover uni-modal training. In out-of-distribution scenarios, even weaker source\nmodalities (e.g., IMU to video) improve target performance, as long as the\ntarget model isn't overfitted on the training data. By enabling single-sensor\ninference with cross-modal knowledge, D-CAT reduces hardware redundancy for\nperception systems while maintaining accuracy, which is critical for\ncost-sensitive or adaptive deployments (e.g., assistive robots in homes with\nvariable sensor availability). Code is available at\nhttps://github.com/Schindler-EPFL-Lab/D-CAT.", "AI": {"tldr": "D-CAT\u901a\u8fc7\u81ea\u6ce8\u610f\u529b\u7279\u5f81\u63d0\u53d6\u548c\u8de8\u6ce8\u610f\u529b\u5bf9\u9f50\u635f\u5931\uff0c\u5b9e\u73b0\u8bad\u7ec3\u65f6\u591a\u6a21\u6001\u77e5\u8bc6\u878d\u5408\u3001\u63a8\u7406\u65f6\u5355\u6a21\u6001\u4f7f\u7528\uff0c\u663e\u8457\u63d0\u5347\u8d44\u6e90\u53d7\u9650\u573a\u666f\u4e0b\u7684\u5206\u7c7b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u8de8\u6a21\u6001\u8fc1\u79fb\u9700\u5728\u8bad\u7ec3\u4e0e\u63a8\u7406\u90fd\u5b58\u5728\u914d\u5bf9\u4f20\u611f\u5668\u6570\u636e\uff0c\u9650\u5236\u4e86\u5728\u8d44\u6e90\u53d7\u9650\u6216\u53ef\u53d8\u4f20\u611f\u5668\u53ef\u7528\u6027\u7684\u90e8\u7f72\uff1b\u56e0\u6b64\u5e0c\u671b\u5b9e\u73b0\u8bad\u7ec3\u65f6\u5229\u7528\u591a\u6a21\u6001\u4fe1\u606f\u800c\u63a8\u7406\u65f6\u53ea\u9700\u5355\u6a21\u6001\u3002", "method": "\u5f15\u5165\u81ea\u6ce8\u610f\u529b\u6a21\u5757\u63d0\u53d6\u6bcf\u4e2a\u6a21\u6001\u7279\u5f81\uff0c\u5e76\u901a\u8fc7\u65b0\u9896\u7684\u8de8\u6ce8\u610f\u529b\u5bf9\u9f50\u635f\u5931\uff08cross-attention alignment loss\uff09\u5f3a\u5236\u4e0d\u540c\u4f20\u611f\u5668\u7279\u5f81\u7a7a\u95f4\u5bf9\u9f50\uff0c\u540c\u65f6\u4fdd\u6301\u5404\u6a21\u6001\u5206\u7c7b\u6d41\u6c34\u7ebf\u89e3\u8026\u4ee5\u652f\u6301\u5355\u6a21\u6001\u63a8\u7406\u3002", "result": "\u5728\u4e09\u4e2a\u4eba\u4f53\u6d3b\u52a8\u591a\u6a21\u6001\u6570\u636e\u96c6\uff08IMU\u3001\u89c6\u9891\u3001\u97f3\u9891\uff09\u4e0a\u8bc4\u4f30\uff1a\u5728\u540c\u5206\u5e03\u573a\u666f\u4e0b\uff0c\u4ece\u9ad8\u6027\u80fd\u6a21\u6001\uff08\u5982\u89c6\u9891\uff09\u5411\u76ee\u6807\u6a21\u6001\uff08\u5982IMU\uff09\u8f6c\u79fb\u53ef\u5e26\u6765\u6700\u9ad8\u7ea610% F1\u63d0\u5347\uff1b\u5728\u5206\u5e03\u5916\u573a\u666f\u4e0b\uff0c\u53ea\u8981\u76ee\u6807\u6a21\u578b\u4e0d\u8fc7\u62df\u5408\uff0c\u54ea\u6015\u6e90\u6a21\u6001\u8f83\u5f31\uff08\u5982IMU\u5230\u89c6\u9891\uff09\u4e5f\u80fd\u6539\u5584\u76ee\u6807\u6027\u80fd\u3002", "conclusion": "D-CAT\u80fd\u5728\u63a8\u7406\u65f6\u53ea\u7528\u5355\u4e00\u4f20\u611f\u5668\uff0c\u540c\u65f6\u901a\u8fc7\u8de8\u6a21\u6001\u5bf9\u9f50\u63d0\u5347\u76ee\u6807\u6a21\u6001\u6027\u80fd\uff0c\u51cf\u5c0f\u786c\u4ef6\u5197\u4f59\u5e76\u9002\u7528\u4e8e\u8d44\u6e90\u53d7\u9650\u573a\u666f\u3002"}}
{"id": "2509.09787", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.09787", "abs": "https://arxiv.org/abs/2509.09787", "authors": ["Nojan Sheybani", "Alessandro Pegoraro", "Jonathan Knauer", "Phillip Rieger", "Elissa Mollakuqe", "Farinaz Koushanfar", "Ahmad-Reza Sadeghi"], "title": "ZORRO: Zero-Knowledge Robustness and Privacy for Split Learning (Full Version)", "comment": "Full version of CCS 2025 paper", "summary": "Split Learning (SL) is a distributed learning approach that enables\nresource-constrained clients to collaboratively train deep neural networks\n(DNNs) by offloading most layers to a central server while keeping in- and\noutput layers on the client-side. This setup enables SL to leverage server\ncomputation capacities without sharing data, making it highly effective in\nresource-constrained environments dealing with sensitive data. However, the\ndistributed nature enables malicious clients to manipulate the training\nprocess. By sending poisoned intermediate gradients, they can inject backdoors\ninto the shared DNN. Existing defenses are limited by often focusing on\nserver-side protection and introducing additional overhead for the server. A\nsignificant challenge for client-side defenses is enforcing malicious clients\nto correctly execute the defense algorithm.\n  We present ZORRO, a private, verifiable, and robust SL defense scheme.\nThrough our novel design and application of interactive zero-knowledge proofs\n(ZKPs), clients prove their correct execution of a client-located defense\nalgorithm, resulting in proofs of computational integrity attesting to the\nbenign nature of locally trained DNN portions. Leveraging the frequency\nrepresentation of model partitions enables ZORRO to conduct an in-depth\ninspection of the locally trained models in an untrusted environment, ensuring\nthat each client forwards a benign checkpoint to its succeeding client. In our\nextensive evaluation, covering different model architectures as well as various\nattack strategies and data scenarios, we show ZORRO's effectiveness, as it\nreduces the attack success rate to less than 6\\% while causing even for models\nstoring \\numprint{1000000} parameters on the client-side an overhead of less\nthan 10 seconds.", "AI": {"tldr": "\u5229\u7528\u4ea4\u4e92\u5f0f\u96f6\u77e5\u8bc6\u8bc1\u660e\u548c\u9891\u7387\u8868\u793a\uff0c\u5728\u5ba2\u6237\u7aef\u5b9e\u73b0\u53ef\u9a8c\u8bc1\u3001\u79c1\u5bc6\u4e14\u9ad8\u6548\u7684Split Learning\u9632\u5fa1\uff0c\u6709\u6548\u963b\u6b62\u540e\u95e8\u6ce8\u5165\uff0c\u540c\u65f6\u4fdd\u6301\u4f4e\u8fd0\u884c\u5f00\u9500\u3002", "motivation": "Split Learning\u73af\u5883\u4e0b\uff0c\u5ba2\u6237\u7aef\u53d7\u9650\u4e14\u5206\u5e03\u5f0f\uff0c\u6613\u88ab\u6076\u610f\u5ba2\u6237\u7aef\u901a\u8fc7\u4e2d\u95f4\u68af\u5ea6\u6ce8\u5165\u540e\u95e8\u653b\u51fb\u3002\u73b0\u6709\u9632\u5fa1\u591a\u96c6\u4e2d\u5728\u670d\u52a1\u5668\u7aef\u5e76\u589e\u52a0\u670d\u52a1\u5668\u8d1f\u62c5\uff1b\u800c\u5728\u5ba2\u6237\u7aef\u5b9e\u65bd\u9632\u5fa1\u9762\u4e34\u65e0\u6cd5\u5f3a\u5236\u6076\u610f\u5ba2\u6237\u7aef\u9075\u4ece\u7684\u95ee\u9898\u3002\u9700\u8981\u4e00\u79cd\u65e2\u4fdd\u62a4\u9690\u79c1\u53c8\u80fd\u9a8c\u8bc1\u5ba2\u6237\u7aef\u884c\u4e3a\u7684\u65b9\u6cd5\u3002", "method": "\u8bbe\u8ba1\u5e76\u5e94\u7528\u4ea4\u4e92\u5f0fZKP\uff0c\u4f7f\u5ba2\u6237\u7aef\u80fd\u8bc1\u660e\u5176\u6b63\u786e\u6267\u884c\u9632\u5fa1\u7b97\u6cd5\u3002\u4f7f\u7528\u6a21\u578b\u7684\u9891\u8c31\uff08\u9891\u7387\uff09\u8868\u793a\u5bf9\u672c\u5730\u8bad\u7ec3\u6a21\u578b\u5206\u533a\u8fdb\u884c\u6df1\u5ea6\u68c0\u67e5\uff0c\u786e\u4fdd\u5ba2\u6237\u7aef\u4f20\u9012\u7ed9\u4e0b\u6e38\u7684\u6a21\u578b\u68c0\u67e5\u70b9\u662f\u826f\u6027\u7684\u3002\u5b9e\u73b0\u8f7b\u91cf\u5316\u8bc1\u660e\u6d41\u7a0b\uff0c\u4fdd\u8bc1\u5728\u767e\u4e07\u53c2\u6570\u7ea7\u522b\u5ba2\u6237\u7aef\u6a21\u578b\u4e0a\u5f00\u9500\u5c0f\uff08<10\u79d2\uff09\u3002", "result": "\u5728\u591a\u79cd\u6a21\u578b\u67b6\u6784\u3001\u653b\u51fb\u7b56\u7565\u548c\u6570\u636e\u573a\u666f\u4e0b\u8bc4\u4f30\uff0cZORRO\u5c06\u653b\u51fb\u6210\u529f\u7387\u964d\u81f3<6%\uff0c\u4e14\u5728\u5ba2\u6237\u7aef\u4fdd\u5b58\u767e\u4e07\u7ea7\u53c2\u6570\u6a21\u578b\u65f6\u8bc1\u660e\u751f\u6210\u5f00\u9500\u4f4e\u4e8e10\u79d2\uff0c\u8bc1\u660e\u4e86\u65b9\u6848\u7684\u6709\u6548\u6027\u548c\u5b9e\u7528\u6027\u3002", "conclusion": "ZORRO\u901a\u8fc7\u4ea4\u4e92\u5f0f\u96f6\u77e5\u8bc6\u8bc1\u660e\uff08ZKP\uff09\u5728\u5ba2\u6237\u7aef\u5b9e\u65bd\u53ef\u9a8c\u8bc1\u7684\u9632\u5fa1\uff0c\u4fdd\u8bc1\u672c\u5730\u8bad\u7ec3\u6a21\u578b\u5206\u533a\u7684\u8ba1\u7b97\u5b8c\u6574\u6027\uff0c\u4ece\u800c\u663e\u8457\u964d\u4f4e\u4e86Split Learning\u4e2d\u7684\u540e\u95e8\u653b\u51fb\u6210\u529f\u7387\u3002"}}
{"id": "2509.09775", "categories": ["cs.AI", "cs.CL", "cs.FL", "cs.SE"], "pdf": "https://arxiv.org/pdf/2509.09775", "abs": "https://arxiv.org/abs/2509.09775", "authors": ["Aleksandr Boldachev"], "title": "Executable Ontologies: Synthesizing Event Semantics with Dataflow Architecture", "comment": "22 pages, 6 figures", "summary": "This paper presents boldsea, Boldachev's semantic-event approach -- an\narchitecture for modeling complex dynamic systems using executable ontologies\n-- semantic models that act as dynamic structures, directly controlling process\nexecution. We demonstrate that integrating event semantics with a dataflow\narchitecture addresses the limitations of traditional Business Process\nManagement (BPM) systems and object-oriented semantic technologies. The paper\npresents the formal BSL (boldsea Semantic Language), including its BNF grammar,\nand outlines the boldsea-engine's architecture, which directly interprets\nsemantic models as executable algorithms without compilation. It enables the\nmodification of event models at runtime, ensures temporal transparency, and\nseamlessly merges data and business logic within a unified semantic framework.", "AI": {"tldr": "boldsea\u7528\u53ef\u6267\u884c\u672c\u4f53\uff08BSL\uff09\u548c\u89e3\u91ca\u578b\u5f15\u64ce\u5b9e\u73b0\u4e8b\u4ef6\u8bed\u4e49\u4e0e\u6570\u636e\u6d41\u878d\u5408\uff0c\u652f\u6301\u8fd0\u884c\u65f6\u4fee\u6539\u4e0e\u65f6\u95f4\u900f\u660e\uff0c\u89e3\u51b3\u4e86\u4f20\u7edfBPM/\u8bed\u4e49\u65b9\u6cd5\u7684\u5c40\u9650\u3002", "motivation": "\u4f20\u7edfBPM\u548c\u9762\u5411\u5bf9\u8c61\u8bed\u4e49\u6280\u672f\u5728\u52a8\u6001\u7cfb\u7edf\u5efa\u6a21\u3001\u8fd0\u884c\u65f6\u53ef\u53d8\u6027\u4e0e\u903b\u8f91/\u6570\u636e\u5206\u79bb\u65b9\u9762\u5b58\u5728\u5c40\u9650\uff0c\u9700\u4e00\u79cd\u53ef\u6267\u884c\u8bed\u4e49\u6a21\u578b\u6765\u66f4\u81ea\u7136\u5730\u8868\u8fbe\u4e8b\u4ef6\u9a71\u52a8\u7684\u590d\u6742\u52a8\u6001\u7cfb\u7edf\u3002", "method": "\u63d0\u51faBSL\uff08BSL\u7684BNF\u8bed\u6cd5\uff09\uff0c\u5e76\u8bbe\u8ba1boldsea-engine\u76f4\u63a5\u89e3\u91ca\u8bed\u4e49\u6a21\u578b\u4e3a\u53ef\u6267\u884c\u7b97\u6cd5\uff0c\u652f\u6301\u8fd0\u884c\u65f6\u4fee\u6539\u4e8b\u4ef6\u6a21\u578b\u4e0e\u65f6\u95f4\u900f\u660e\u6027\uff0c\u5c06\u6570\u636e\u4e0e\u4e1a\u52a1\u903b\u8f91\u7edf\u4e00\u5230\u8bed\u4e49\u6846\u67b6\u5185\u3002", "result": "\u7cfb\u7edf\u5b9e\u73b0\u4e86\u65e0\u7f16\u8bd1\u7684\u89e3\u91ca\u6267\u884c\u3001\u8fd0\u884c\u65f6\u4fee\u6539\u6a21\u578b\u3001\u65f6\u95f4\u900f\u660e\u6027\u4ee5\u53ca\u6570\u636e\u4e0e\u4e1a\u52a1\u903b\u8f91\u878d\u5408\uff0c\u5c55\u793a\u4e86\u4e8b\u4ef6\u8bed\u4e49\u4e0e\u6570\u636e\u6d41\u7ed3\u5408\u5728\u52a8\u6001\u8fc7\u7a0b\u63a7\u5236\u4e2d\u7684\u53ef\u884c\u6027\u3002", "conclusion": "boldsea\u63d0\u51fa\u5c06\u4e8b\u4ef6\u8bed\u4e49\u4e0e\u6570\u636e\u6d41\u67b6\u6784\u7ed3\u5408\uff0c\u5f62\u6210\u53ef\u6267\u884c\u672c\u4f53\u4ee5\u76f4\u63a5\u63a7\u5236\u6d41\u7a0b\uff0c\u4ece\u800c\u514b\u670d\u4f20\u7edfBPM\u4e0e\u9762\u5411\u5bf9\u8c61\u8bed\u4e49\u6280\u672f\u7684\u5c40\u9650\u3002"}}
{"id": "2509.10214", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2509.10214", "abs": "https://arxiv.org/abs/2509.10214", "authors": ["Yannik Kopyciok", "Stefan Schmid", "Friedhelm Victor"], "title": "Friend or Foe? Identifying Anomalous Peers in Moneros P2P Network", "comment": null, "summary": "Monero, the leading privacy-focused cryptocurrency, relies on a peer-to-peer\n(P2P) network to propagate transactions and blocks. Growing evidence suggests\nthat non-standard nodes exist in the network, posing as honest nodes but are\nperhaps intended for monitoring the network and spying on other nodes. However,\nour understanding of the detection and analysis of anomalous peer behavior\nremains limited. This paper presents a first comprehensive study of anomalous\nbehavior in Monero's P2P network. To this end, we collected and analyzed over\n240 hours of network traffic captured from five distinct vantage points\nworldwide. We further present a formal framework which allows us to\nanalytically define and classify anomalous patterns in P2P cryptocurrency\nnetworks. Our detection methodology, implemented as an offline analysis,\nprovides a foundation for real-time monitoring systems. Our analysis reveals\nthe presence of non-standard peers in the network where approximately 14.74%\n(13.19%) of (reachable) peers in the network exhibit non-standard behavior.\nThese peers exhibit distinct behavioral patterns that might suggest multiple\nconcurrent attacks, pointing to substantial shortcomings in Monero's privacy\nguarantees and network decentralization. To support reproducibility and enable\nnetwork operators to protect themselves, we release our examination pipeline to\nidentify and block suspicious peers based on newly captured network traffic.", "AI": {"tldr": "\u57fa\u4e8e\u4e94\u4e2a\u5168\u7403\u89c6\u70b9240+\u5c0f\u65f6\u6d41\u91cf\u7684\u9996\u6b21\u7cfb\u7edf\u7814\u7a76\uff1a\u7ea614.74%\u7684Monero\u8282\u70b9\u884c\u4e3a\u5f02\u5e38\uff0c\u53ef\u80fd\u4e3a\u5e76\u53d1\u76d1\u63a7/\u653b\u51fb\uff0c\u8bba\u6587\u7ed9\u51fa\u5f62\u5f0f\u5316\u5206\u7c7b\u3001\u79bb\u7ebf\u68c0\u6d4b\u65b9\u6cd5\u5e76\u5f00\u6e90\u9632\u62a4\u7ba1\u9053\u3002", "motivation": "\u5b58\u5728\u8bc1\u636e\u8868\u660eP2P\u7f51\u7edc\u4e2d\u5b58\u5728\u4f2a\u88c5\u6210\u8bda\u4fe1\u8282\u70b9\u7684\u975e\u6807\u51c6\u8282\u70b9\uff0c\u7528\u4e8e\u76d1\u63a7\u548c\u7a83\u542c\uff0c\u4f46\u5bf9\u5f02\u5e38\u5bf9\u7b49\u4f53\u7684\u68c0\u6d4b\u4e0e\u5206\u6790\u7406\u89e3\u6709\u9650\uff0c\u56e0\u6b64\u9700\u8981\u7cfb\u7edf\u5316\u7814\u7a76\u4ee5\u91cf\u5316\u5f71\u54cd\u5e76\u63d0\u9ad8\u9632\u62a4\u80fd\u529b\u3002", "method": "\u6536\u96c6\u6765\u81ea\u4e94\u4e2a\u5168\u7403\u89c6\u70b9\u7684\u8d85\u8fc7240\u5c0f\u65f6\u7f51\u7edc\u6d41\u91cf\uff0c\u63d0\u51fa\u5f62\u5f0f\u5316\u6846\u67b6\u5b9a\u4e49\u5e76\u5206\u7c7bP2P\u7f51\u7edc\u5f02\u5e38\u6a21\u5f0f\uff0c\u57fa\u4e8e\u79bb\u7ebf\u5206\u6790\u5b9e\u73b0\u68c0\u6d4b\u65b9\u6cd5\uff08\u53ef\u6269\u5c55\u4e3a\u5b9e\u65f6\u76d1\u63a7\uff09\uff0c\u5e76\u5b9e\u73b0\u548c\u516c\u5f00\u4e86\u7528\u4e8e\u8bc6\u522b\u548c\u5c4f\u853d\u53ef\u7591\u5bf9\u7b49\u4f53\u7684\u7ba1\u9053\u3002", "result": "\u901a\u8fc7\u5206\u6790\uff0c\u4f5c\u8005\u786e\u8ba4\u4e86\u5927\u6bd4\u4f8b\u975e\u6807\u51c6\u884c\u4e3a\u8282\u70b9\uff0c\u5e76\u5f52\u7eb3\u51fa\u591a\u7c7b\u53ef\u7591\u884c\u4e3a\u6a21\u5f0f\uff1b\u7ed3\u679c\u8868\u660e\u8fd9\u4e9b\u884c\u4e3a\u524a\u5f31\u4e86Monero\u7684\u9690\u79c1\u4fdd\u969c\u4e0e\u7f51\u7edc\u53bb\u4e2d\u5fc3\u5316\uff1b\u540c\u65f6\u4f5c\u8005\u91ca\u653e\u4e86\u68c0\u6d4b\u5de5\u5177\u4ee5\u652f\u6301\u8fd0\u8425\u8005\u9632\u62a4\u3002", "conclusion": "\u8be5\u6587\u9996\u6b21\u5bf9Monero P2P\u7f51\u7edc\u4e2d\u7684\u5f02\u5e38\u884c\u4e3a\u8fdb\u884c\u4e86\u7cfb\u7edf\u6027\u7814\u7a76\uff0c\u53d1\u73b0\u7ea614.74%\uff08\u621613.19%\uff09\u53ef\u8fbe\u8282\u70b9\u8868\u73b0\u51fa\u975e\u6807\u51c6\u884c\u4e3a\uff0c\u6697\u793a\u53ef\u80fd\u5b58\u5728\u591a\u79cd\u5e76\u53d1\u653b\u51fb\uff0c\u5f71\u54cdMonero\u7684\u9690\u79c1\u548c\u53bb\u4e2d\u5fc3\u5316\u7279\u6027\u3002\u4f5c\u8005\u63d0\u4f9b\u4e86\u5206\u6790\u6846\u67b6\u4e0e\u79bb\u7ebf\u68c0\u6d4b\u65b9\u6cd5\uff0c\u5e76\u53d1\u5e03\u4e86\u53ef\u590d\u73b0\u7684\u68c0\u67e5\u7ba1\u9053\u4ee5\u963b\u65ad\u53ef\u7591\u8282\u70b9\u3002"}}
{"id": "2509.10161", "categories": ["cs.LG", "cs.DC"], "pdf": "https://arxiv.org/pdf/2509.10161", "abs": "https://arxiv.org/abs/2509.10161", "authors": ["Shiwei Li", "Qunwei Li", "Haozhao Wang", "Ruixuan Li", "Jianbin Lin", "Wenliang Zhong"], "title": "FedBiF: Communication-Efficient Federated Learning via Bits Freezing", "comment": "Accepted by TPDS", "summary": "Federated learning (FL) is an emerging distributed machine learning paradigm\nthat enables collaborative model training without sharing local data. Despite\nits advantages, FL suffers from substantial communication overhead, which can\naffect training efficiency. Recent efforts have mitigated this issue by\nquantizing model updates to reduce communication costs. However, most existing\nmethods apply quantization only after local training, introducing quantization\nerrors into the trained parameters and potentially degrading model accuracy. In\nthis paper, we propose Federated Bit Freezing (FedBiF), a novel FL framework\nthat directly learns quantized model parameters during local training. In each\ncommunication round, the server first quantizes the model parameters and\ntransmits them to the clients. FedBiF then allows each client to update only a\nsingle bit of the multi-bit parameter representation, freezing the remaining\nbits. This bit-by-bit update strategy reduces each parameter update to one bit\nwhile maintaining high precision in parameter representation. Extensive\nexperiments are conducted on five widely used datasets under both IID and\nNon-IID settings. The results demonstrate that FedBiF not only achieves\nsuperior communication compression but also promotes sparsity in the resulting\nmodels. Notably, FedBiF attains accuracy comparable to FedAvg, even when using\nonly 1 bit-per-parameter (bpp) for uplink and 3 bpp for downlink communication.\nThe code is available at https://github.com/Leopold1423/fedbif-tpds25.", "AI": {"tldr": "FedBiF\u901a\u8fc7\u5728\u672c\u5730\u8bad\u7ec3\u4e2d\u9010\u4f4d\u5b66\u4e60\u91cf\u5316\u53c2\u6570\uff08\u6bcf\u8f6e\u4ec5\u66f4\u65b01\u6bd4\u7279\uff09\u5b9e\u73b0\u9ad8\u6548\u901a\u4fe1\u538b\u7f29\uff0c\u5728\u591a\u79cd\u6570\u636e\u96c6\u4e0e\u975eIID\u573a\u666f\u4e0b\u80fd\u7ef4\u6301\u4e0eFedAvg\u76f8\u8fd1\u7684\u7cbe\u5ea6\u5e76\u4fc3\u6210\u6a21\u578b\u7a00\u758f\u6027\u3002", "motivation": "\u73b0\u6709\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\u5927\u591a\u5728\u672c\u5730\u8bad\u7ec3\u540e\u518d\u5bf9\u6a21\u578b\u66f4\u65b0\u8fdb\u884c\u91cf\u5316\uff0c\u5bfc\u81f4\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u5f15\u5165\u91cf\u5316\u8bef\u5dee\u5e76\u53ef\u80fd\u964d\u4f4e\u7cbe\u5ea6\uff1b\u56e0\u6b64\u63d0\u51fa\u76f4\u63a5\u5728\u8bad\u7ec3\u4e2d\u5b66\u4e60\u91cf\u5316\u53c2\u6570\u4ee5\u51cf\u5c11\u8fd9\u79cd\u8bef\u5dee\u5e76\u8fdb\u4e00\u6b65\u538b\u7f29\u901a\u4fe1\u5f00\u9500\u3002", "method": "\u5728\u6bcf\u8f6e\u901a\u4fe1\u4e2d\uff0c\u670d\u52a1\u5668\u5148\u91cf\u5316\u6a21\u578b\u53c2\u6570\u5e76\u4e0b\u53d1\u81f3\u5ba2\u6237\u7aef\u3002\u5ba2\u6237\u7aef\u5728\u672c\u5730\u8bad\u7ec3\u65f6\u4ec5\u5141\u8bb8\u66f4\u65b0\u91cf\u5316\u8868\u793a\u4e2d\u7684\u4e00\u4e2a\u6bd4\u7279\u4f4d\uff0c\u51bb\u7ed3\u5176\u4ed6\u6bd4\u7279\u3002\u901a\u8fc7\u9010\u4f4d\u66f4\u65b0\u7b56\u7565\uff0c\u5c06\u6bcf\u4e2a\u53c2\u6570\u7684\u4e0a\u4f20\u66f4\u65b0\u538b\u7f29\u4e3a1\u6bd4\u7279\uff0c\u540c\u65f6\u4fdd\u6301\u591a\u6bd4\u7279\u7684\u53c2\u6570\u8868\u793a\u7cbe\u5ea6\u3002", "result": "\u5728\u4e94\u4e2a\u5e38\u7528\u6570\u636e\u96c6\u7684IID\u548cNon-IID\u8bbe\u7f6e\u4e0b\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cFedBiF\u5728\u901a\u4fe1\u538b\u7f29\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u80fd\u5728\u4ec5\u4f7f\u7528\u4e0a\u884c1 bpp\u3001\u4e0b\u884c3 bpp\u7684\u60c5\u51b5\u4e0b\u8fbe\u5230\u4e0eFedAvg\u76f8\u5f53\u7684\u51c6\u786e\u7387\uff0c\u540c\u65f6\u751f\u6210\u66f4\u7a00\u758f\u7684\u6a21\u578b\u3002", "conclusion": "FedBiF\u5728\u901a\u4fe1\u6548\u7387\u4e0e\u6a21\u578b\u7cbe\u5ea6\u95f4\u5b9e\u73b0\u4e86\u826f\u597d\u6298\u8877\uff0c\u901a\u8fc7\u5728\u672c\u5730\u8bad\u7ec3\u9636\u6bb5\u76f4\u63a5\u5b66\u4e60\u91cf\u5316\u53c2\u6570\u5e76\u91c7\u7528\u201c\u9010\u4f4d\u66f4\u65b0\u3001\u5176\u4f59\u4f4d\u51bb\u7ed3\u201d\u7684\u7b56\u7565\uff0c\u663e\u8457\u964d\u4f4e\u4e0a\u884c\u901a\u4fe1\u5f00\u9500\uff0c\u5e76\u5728\u591a\u4e2a\u6570\u636e\u96c6\u548c\u975eIID\u573a\u666f\u4e0b\u8fbe\u5230\u4e0eFedAvg\u76f8\u5f53\u7684\u7cbe\u5ea6\uff0c\u540c\u65f6\u4fc3\u8fdb\u6a21\u578b\u7a00\u758f\u6027\u3002"}}
{"id": "2509.09751", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.09751", "abs": "https://arxiv.org/abs/2509.09751", "authors": ["Junqiao Wang", "Zhaoyang Guan", "Guanyu Liu", "Tianze Xia", "Xianzhi Li", "Shuo Yin", "Xinyuan Song", "Chuhan Cheng", "Tianyu Shi", "Alex Lee"], "title": "Meta-Learning Reinforcement Learning for Crypto-Return Prediction", "comment": null, "summary": "Predicting cryptocurrency returns is notoriously difficult: price movements\nare driven by a fast-shifting blend of on-chain activity, news flow, and social\nsentiment, while labeled training data are scarce and expensive. In this paper,\nwe present Meta-RL-Crypto, a unified transformer-based architecture that\nunifies meta-learning and reinforcement learning (RL) to create a fully\nself-improving trading agent. Starting from a vanilla instruction-tuned LLM,\nthe agent iteratively alternates between three roles-actor, judge, and\nmeta-judge-in a closed-loop architecture. This learning process requires no\nadditional human supervision. It can leverage multimodal market inputs and\ninternal preference feedback. The agent in the system continuously refines both\nthe trading policy and evaluation criteria. Experiments across diverse market\nregimes demonstrate that Meta-RL-Crypto shows good performance on the technical\nindicators of the real market and outperforming other LLM-based baselines.", "AI": {"tldr": "\u4f5c\u8005\u63d0\u51faMeta-RL-Crypto\uff1a\u4e00\u4e2a\u5c06\u5143\u5b66\u4e60\u4e0e\u5f3a\u5316\u5b66\u4e60\u878d\u5408\u7684\u3001\u57fa\u4e8e\u53d8\u538b\u5668\u7684\u81ea\u6211\u6539\u8fdb\u52a0\u5bc6\u8d27\u5e01\u4ea4\u6613\u7cfb\u7edf\uff0c\u901a\u8fc7actor/judge/meta-judge\u95ed\u73af\u8fed\u4ee3\u548c\u5185\u90e8\u504f\u597d\u53cd\u9988\uff0c\u65e0\u9700\u4eba\u5de5\u76d1\u7763\uff0c\u80fd\u5904\u7406\u591a\u6a21\u6001\u8f93\u5165\u5e76\u5728\u5b9e\u8bc1\u4e0a\u4f18\u4e8eLLM\u57fa\u7ebf\u3002", "motivation": "\u52a0\u5bc6\u8d27\u5e01\u4ef7\u683c\u53d7\u94fe\u4e0a\u6d3b\u52a8\u3001\u65b0\u95fb\u548c\u793e\u4ea4\u60c5\u7eea\u7b49\u5feb\u901f\u53d8\u5316\u56e0\u7d20\u9a71\u52a8\uff0c\u6807\u6ce8\u6570\u636e\u7a00\u7f3a\u4e14\u6602\u8d35\uff0c\u6545\u9700\u8981\u4e00\u79cd\u65e0\u9700\u989d\u5916\u4eba\u5de5\u76d1\u7763\u3001\u53ef\u6301\u7eed\u81ea\u6211\u6539\u8fdb\u7684\u4ea4\u6613\u4ee3\u7406\u3002", "method": "\u57fa\u4e8e\u6307\u4ee4\u8c03\u4f18\u7684\u53d8\u538b\u5668LLM\uff0c\u7cfb\u7edf\u5728actor\u3001judge\u3001meta-judge\u4e09\u4e2a\u89d2\u8272\u4e4b\u95f4\u95ed\u73af\u8fed\u4ee3\uff0c\u901a\u8fc7\u5185\u90e8\u504f\u597d\u53cd\u9988\u548c\u65e0\u76d1\u7763\u5faa\u73af\u63d0\u5347\u4ea4\u6613\u7b56\u7565\u4e0e\u8bc4\u4f30\u6807\u51c6\uff0c\u652f\u6301\u591a\u6a21\u6001\u5e02\u573a\u8f93\u5165\u3002", "result": "\u5728\u4e0d\u540c\u5e02\u573a\u73af\u5883\u4e0b\uff0cMeta-RL-Crypto\u5728\u771f\u5b9e\u5e02\u573a\u7684\u6280\u672f\u6307\u6807\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f18\u4e8e\u5176\u4ed6\u57fa\u4e8eLLM\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7ed3\u5408\u5143\u5b66\u4e60\u4e0e\u5f3a\u5316\u5b66\u4e60\u7684\u81ea\u6211\u6539\u8fdb\u52a0\u5bc6\u8d27\u5e01\u4ea4\u6613\u4ee3\u7406\u3002"}}
{"id": "2509.09942", "categories": ["cs.CR", "cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2509.09942", "abs": "https://arxiv.org/abs/2509.09942", "authors": ["Lei Yu", "Jingyuan Zhang", "Xin Wang", "Jiajia Ma", "Li Yang", "Fengjun Zhang"], "title": "SmartCoder-R1: Towards Secure and Explainable Smart Contract Generation with Security-Aware Group Relative Policy Optimization", "comment": null, "summary": "Smart contracts automate the management of high-value assets, where\nvulnerabilities can lead to catastrophic financial losses. This challenge is\namplified in Large Language Models (LLMs) by two interconnected failures: they\noperate as unauditable \"black boxes\" lacking a transparent reasoning process,\nand consequently, generate code riddled with critical security vulnerabilities.\nTo address both issues, we propose SmartCoder-R1 (based on Qwen2.5-Coder-7B), a\nnovel framework for secure and explainable smart contract generation. It begins\nwith Continual Pre-training (CPT) to specialize the model. We then apply Long\nChain-of-Thought Supervised Fine-Tuning (L-CoT SFT) on 7,998 expert-validated\nreasoning-and-code samples to train the model to emulate human security\nanalysis. Finally, to directly mitigate vulnerabilities, we employ\nSecurity-Aware Group Relative Policy Optimization (S-GRPO), a reinforcement\nlearning phase that refines the generation policy by optimizing a weighted\nreward signal for compilation success, security compliance, and format\ncorrectness. Evaluated against 17 baselines on a benchmark of 756 real-world\nfunctions, SmartCoder-R1 establishes a new state of the art, achieving top\nperformance across five key metrics: a ComPass of 87.70%, a VulRate of 8.60%, a\nSafeAval of 80.16%, a FuncRate of 53.84%, and a FullRate of 50.53%. This\nFullRate marks a 45.79% relative improvement over the strongest baseline,\nDeepSeek-R1. Crucially, its generated reasoning also excels in human\nevaluations, achieving high-quality ratings for Functionality (82.7%), Security\n(85.3%), and Clarity (90.7%).", "AI": {"tldr": "\u63d0\u51faSmartCoder-R1\uff0c\u901a\u8fc7CPT\u3001L-CoT SFT\u548cS-GRPO\u4e09\u9636\u6bb5\u8bad\u7ec3\uff0c\u663e\u8457\u964d\u4f4e\u667a\u80fd\u5408\u7ea6\u6f0f\u6d1e\u5e76\u63d0\u9ad8\u751f\u6210\u63a8\u7406\u7684\u53ef\u89e3\u91ca\u6027\u4e0e\u8d28\u91cf\uff0c\u5728\u591a\u4e2a\u81ea\u52a8\u4e0e\u4eba\u5de5\u6307\u6807\u4e0a\u8fbe\u65b0\u9ad8\u3002", "motivation": "LLM\u5728\u751f\u6210\u667a\u80fd\u5408\u7ea6\u65f6\u65e2\u7f3a\u4e4f\u53ef\u5ba1\u8ba1\u7684\u63a8\u7406\u8def\u5f84\uff08\u9ed1\u7bb1\u95ee\u9898\uff09\uff0c\u53c8\u5bb9\u6613\u4ea7\u751f\u4e25\u91cd\u5b89\u5168\u6f0f\u6d1e\uff0c\u9700\u540c\u65f6\u63d0\u5347\u53ef\u89e3\u91ca\u6027\u4e0e\u5b89\u5168\u6027\u3002", "method": "\u91c7\u7528\u4e09\u9636\u6bb5\u8bad\u7ec3\u6d41\u7a0b\uff1aContinual Pre-training\uff08CPT\uff09\u9488\u5bf9\u9886\u57df\u9002\u5e94\uff1bLong Chain-of-Thought Supervised Fine-Tuning\uff08L-CoT SFT\uff09\u75287,998\u6761\u4e13\u5bb6\u6807\u6ce8\u7684\u63a8\u7406+\u4ee3\u7801\u6837\u672c\u6559\u6388\u5b89\u5168\u5206\u6790\uff1bSecurity-Aware Group Relative Policy Optimization\uff08S-GRPO\uff09\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u4e00\u4e2a\u52a0\u6743\u5956\u52b1\uff08\u7f16\u8bd1\u6210\u529f\u3001\u5b89\u5168\u5408\u89c4\u3001\u683c\u5f0f\u6b63\u786e\uff09\u4ee5\u76f4\u63a5\u964d\u4f4e\u6f0f\u6d1e\u3002", "result": "\u5728756\u4e2a\u771f\u5b9e\u51fd\u6570\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e0a\uff0cSmartCoder-R1\u5728ComPass(87.70%)\u3001VulRate(8.60%)\u3001SafeAval(80.16%)\u3001FuncRate(53.84%)\u3001FullRate(50.53%)\u7b49\u4e94\u9879\u6307\u6807\u4e0a\u9886\u5148\uff0cFullRate\u6bd4\u6700\u5f3a\u57fa\u7ebfDeepSeek-R1\u76f8\u5bf9\u63d0\u534745.79%\uff1b\u4eba\u5de5\u8bc4\u4f30\u4e2d\uff0c\u529f\u80fd82.7%\u3001\u5b89\u516885.3%\u3001\u6e05\u6670\u5ea690.7%\u3002", "conclusion": "SmartCoder-R1 \u80fd\u663e\u8457\u63d0\u9ad8\u667a\u80fd\u5408\u7ea6\u751f\u6210\u7684\u5b89\u5168\u6027\u4e0e\u53ef\u89e3\u91ca\u6027\uff0c\u5728\u591a\u9879\u6307\u6807\u4e0a\u8d85\u8d8a\u73b0\u6709\u57fa\u7ebf\uff0c\u4e14\u751f\u6210\u7684\u63a8\u7406\u5728\u4eba\u5de5\u8bc4\u4f30\u4e2d\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2509.09790", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.09790", "abs": "https://arxiv.org/abs/2509.09790", "authors": ["Yuxuan Li", "Victor Zhong"], "title": "How well can LLMs provide planning feedback in grounded environments?", "comment": null, "summary": "Learning to plan in grounded environments typically requires carefully\ndesigned reward functions or high-quality annotated demonstrations. Recent\nworks show that pretrained foundation models, such as large language models\n(LLMs) and vision language models (VLMs), capture background knowledge helpful\nfor planning, which reduces the amount of reward design and demonstrations\nneeded for policy learning. We evaluate how well LLMs and VLMs provide feedback\nacross symbolic, language, and continuous control environments. We consider\nprominent types of feedback for planning including binary feedback, preference\nfeedback, action advising, goal advising, and delta action feedback. We also\nconsider inference methods that impact feedback performance, including\nin-context learning, chain-of-thought, and access to environment dynamics. We\nfind that foundation models can provide diverse high-quality feedback across\ndomains. Moreover, larger and reasoning models consistently provide more\naccurate feedback, exhibit less bias, and benefit more from enhanced inference\nmethods. Finally, feedback quality degrades for environments with complex\ndynamics or continuous state spaces and action spaces.", "AI": {"tldr": "\u9884\u8bad\u7ec3\u5927\u6a21\u578b\u80fd\u4e3a\u89c4\u5212\u4efb\u52a1\u63d0\u4f9b\u591a\u6837\u4e14\u9ad8\u8d28\u91cf\u7684\u53cd\u9988\uff0c\u6a21\u578b\u8d8a\u5927\u3001\u63a8\u7406\u80fd\u529b\u8d8a\u5f3a\u6548\u679c\u8d8a\u597d\uff0c\u4f46\u5728\u590d\u6742\u52a8\u529b\u5b66\u6216\u8fde\u7eed\u7a7a\u95f4\u73af\u5883\u4e2d\u6548\u679c\u4e0b\u964d\u3002", "motivation": "Reduce reliance on carefully designed reward functions and annotated demonstrations by leveraging pretrained foundation models' background knowledge to provide planning feedback.", "method": "Evaluated LLMs and VLMs across domains and feedback types (binary, preference, action advising, goal advising, delta action), and inference methods (in-context learning, chain-of-thought, environment dynamics access), measuring accuracy, bias, and sensitivity to model size and inference technique.", "result": "Foundation models provided diverse useful feedback; larger/reasoning models gave more accurate, less biased feedback and benefited more from advanced inference. Feedback quality degrades in environments with complex dynamics or continuous state/action spaces.", "conclusion": "Foundation models (LLMs and VLMs) can supply varied, high-quality feedback for planning across symbolic, language, and continuous control tasks, with larger/reasoning models outperforming smaller ones; however feedback drops for complex dynamics and continuous spaces."}}
{"id": "2509.10216", "categories": ["cs.NI", "cs.HC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.10216", "abs": "https://arxiv.org/abs/2509.10216", "authors": ["Noga H. Rotman", "Tiago Ferreira", "Hila Peleg", "Mark Silberstein", "Alexandra Silva"], "title": "RFSeek and Ye Shall Find", "comment": "7 pages", "summary": "Requests for Comments (RFCs) are extensive specification documents for\nnetwork protocols, but their prose-based format and their considerable length\noften impede precise operational understanding. We present RFSeek, an\ninteractive tool that automatically extracts visual summaries of protocol logic\nfrom RFCs. RFSeek leverages large language models (LLMs) to generate\nprovenance-linked, explorable diagrams, surfacing both official state machines\nand additional logic found only in the RFC text. Compared to existing RFC\nvisualizations, RFSeek's visual summaries are more transparent and easier to\naudit against their textual source. We showcase the tool's potential through a\nseries of use cases, including guided knowledge extraction and semantic\ndiffing, applied to protocols such as TCP, QUIC, PPTP, and DCCP.\n  In practice, RFSeek not only reconstructs the RFC diagrams included in some\nspecifications, but, more interestingly, also uncovers important logic such as\nnodes or edges described in the text but missing from those diagrams. RFSeek\nfurther derives new visualization diagrams for complex RFCs, with QUIC as a\nrepresentative case. Our approach, which we term \\emph{Summary Visualization},\nhighlights a promising direction: combining LLMs with formal, user-customized\nvisualizations to enhance protocol comprehension and support robust\nimplementations.", "AI": {"tldr": "RFSeek\u7528LLM\u4eceRFC\u751f\u6210\u53ef\u8ffd\u6eaf\u3001\u53ef\u4ea4\u4e92\u7684\u534f\u8bae\u56fe\u793a\uff0c\u5f25\u8865\u6216\u8d85\u8d8a\u539f\u59cb\u56fe\u8868\uff0c\u4fbf\u4e8e\u7406\u89e3\u4e0e\u5b9e\u73b0\u3002", "motivation": "RFC\u6587\u672c\u5197\u957f\u4e14\u4e3b\u8981\u4e3a\u81ea\u7136\u8bed\u8a00\uff0c\u539f\u6709\u56fe\u793a\u5e38\u7f3a\u5931\u6216\u4e0d\u5b8c\u6574\uff0c\u5bfc\u81f4\u5b9e\u73b0\u8005\u96be\u4ee5\u51c6\u786e\u7406\u89e3\u534f\u8bae\u903b\u8f91\uff0c\u9700\u81ea\u52a8\u5316\u3001\u53ef\u5ba1\u8ba1\u7684\u53ef\u89c6\u5316\u6458\u8981\u4ee5\u63d0\u9ad8\u53ef\u64cd\u4f5c\u6027\u3002", "method": "\u6784\u5efa\u4ea4\u4e92\u5f0f\u5de5\u5177RFSeek\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u89e3\u6790RFC\u6587\u672c\uff0c\u751f\u6210\u5e26\u6765\u6e90\u8ffd\u6eaf\u7684\u53ef\u63a2\u7d22\u56fe\u8868\uff08\u72b6\u6001\u673a\u4e0e\u8fde\u63a5\u903b\u8f91\uff09\uff0c\u5e76\u63d0\u4f9b\u8bed\u4e49\u5bf9\u6bd4\u4e0e\u5bfc\u51fa\u529f\u80fd\uff1b\u5728\u591a\u534f\u8bae\uff08TCP\u3001QUIC\u3001PPTP\u3001DCCP\uff09\u4e0a\u8bc4\u4f30\u5de5\u5177\u80fd\u91cd\u5efa\u6216\u751f\u6210\u65b0\u56fe\u793a\u3002", "result": "RFSeek\u6210\u529f\u91cd\u5efa\u4e86\u90e8\u5206RFC\u81ea\u5e26\u56fe\u793a\uff0c\u5e76\u53d1\u73b0\u6587\u672c\u4e2d\u63cf\u8ff0\u4f46\u56fe\u793a\u672a\u5448\u73b0\u7684\u91cd\u8981\u8282\u70b9/\u8fb9\uff1b\u5bf9\u590d\u6742\u534f\u8bae\uff08\u5982QUIC\uff09\u751f\u6210\u65b0\u7684\u53ef\u89c6\u5316\u6458\u8981\uff1b\u76f8\u6bd4\u73b0\u6709\u5de5\u5177\uff0c\u5448\u73b0\u66f4\u900f\u660e\u3001\u6613\u6838\u5bf9\u7684\u56fe\u8868\u3002", "conclusion": "RFSeek\u5c55\u793a\u4e86\u5c06LLM\u4e0e\u53ef\u89c6\u5316\u7ed3\u5408\u4ee5\u63d0\u9ad8RFC\u534f\u8bae\u7406\u89e3\u7684\u53ef\u884c\u6027\uff0c\u80fd\u4ece\u6587\u672c\u4e2d\u63d0\u53d6\u5e76\u53ef\u8ffd\u6eaf\u5730\u5448\u73b0\u72b6\u6001\u673a\u4e0e\u9690\u542b\u903b\u8f91\uff0c\u8865\u5168\u6216\u8d85\u8d8a\u539f\u59cbRFC\u56fe\u793a\uff0c\u4fbf\u4e8e\u5ba1\u8ba1\u4e0e\u5b9e\u73b0\u3002"}}
{"id": "2509.09754", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.09754", "abs": "https://arxiv.org/abs/2509.09754", "authors": ["Yiqun Shen", "Song Yuan", "Zhengze Zhang", "Xiaoliang Wang", "Daxin Jiang", "Nguyen Cam-Tu"], "title": "LAVa: Layer-wise KV Cache Eviction with Dynamic Budget Allocation", "comment": null, "summary": "KV Cache is commonly used to accelerate LLM inference with long contexts, yet\nits high memory demand drives the need for cache compression. Existing\ncompression methods, however, are largely heuristic and lack dynamic budget\nallocation. To address this limitation, we introduce a unified framework for\ncache compression by minimizing information loss in Transformer residual\nstreams. Building on it, we analyze the layer attention output loss and derive\na new metric to compare cache entries across heads, enabling layer-wise\ncompression with dynamic head budgets. Additionally, by contrasting cross-layer\ninformation, we also achieve dynamic layer budgets. LAVa is the first unified\nstrategy for cache eviction and dynamic budget allocation that, unlike prior\nmethods, does not rely on training or the combination of multiple strategies.\nExperiments with benchmarks (LongBench, Needle-In-A-Haystack, Ruler, and\nInfiniteBench) demonstrate its superiority. Moreover, our experiments reveal a\nnew insight: dynamic layer budgets are crucial for generation tasks (e.g., code\ncompletion), while dynamic head budgets play a key role in extraction tasks\n(e.g., extractive QA). As a fully dynamic compression method, LAVa consistently\nmaintains top performance across task types. Our code is available at\nhttps://github.com/MGDDestiny/Lava.", "AI": {"tldr": "LAVa\u5c06KV\u7f13\u5b58\u538b\u7f29\u5f52\u7ed3\u4e3a\u6700\u5c0f\u5316\u6b8b\u5dee\u6d41\u4fe1\u606f\u635f\u5931\uff0c\u63d0\u51fa\u52a8\u6001\u6309\u5c42\u548c\u6309\u5934\u9884\u7b97\u5206\u914d\u7684\u7edf\u4e00\u65e0\u8bad\u7ec3\u65b9\u6848\uff0c\u5728\u591a\u9879\u957f\u4e0a\u4e0b\u6587\u57fa\u51c6\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u63ed\u793a\u4e86\u5c42/\u5934\u9884\u7b97\u5bf9\u4e0d\u540c\u4efb\u52a1\u7c7b\u578b\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u73b0\u6709KV\u7f13\u5b58\u538b\u7f29\u65b9\u6cd5\u591a\u4e3a\u542f\u53d1\u5f0f\u4e14\u7f3a\u4e4f\u52a8\u6001\u9884\u7b97\u5206\u914d\uff0c\u5bfc\u81f4\u5728\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u65f6\u5185\u5b58\u6548\u7387\u4e0d\u8db3\u548c\u6027\u80fd\u4e0b\u964d\uff0c\u9700\u4e00\u79cd\u7edf\u4e00\u3001\u52a8\u6001\u4e14\u65e0\u8bad\u7ec3\u9700\u6c42\u7684\u538b\u7f29\u7b56\u7565\u3002", "method": "\u57fa\u4e8e\u6b8b\u5dee\u6d41\u4fe1\u606f\u635f\u5931\u5206\u6790\uff0c\u63a8\u5bfc\u51fa\u8861\u91cf\u4e0d\u540c\u5934\u95f4\u7f13\u5b58\u6761\u76ee\u7684\u91cd\u8981\u6027\u7684\u65b0\u5ea6\u91cf\uff0c\u7528\u4e8e\u6309\u5934\u538b\u7f29\u4e0e\u52a8\u6001\u5206\u914d\u9884\u7b97\uff1b\u901a\u8fc7\u8de8\u5c42\u4fe1\u606f\u5bf9\u6bd4\u786e\u5b9a\u52a8\u6001\u5c42\u9884\u7b97\uff1b\u7edf\u4e00\u4e86\u7f13\u5b58\u9a71\u9010\u4e0e\u9884\u7b97\u5206\u914d\uff0c\u4e14\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u6216\u591a\u65b9\u6cd5\u7ec4\u5408\u3002", "result": "\u5728LongBench\u3001Needle-In-A-Haystack\u3001Ruler\u548cInfiniteBench\u7b49\u57fa\u51c6\u4e0a\uff0cLAVa\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff1b\u5b9e\u9a8c\u8bc1\u660e\u52a8\u6001\u5c42\u9884\u7b97\u5bf9\u751f\u6210\u4efb\u52a1\u81f3\u5173\u91cd\u8981\uff0c\u52a8\u6001\u5934\u9884\u7b97\u5bf9\u62bd\u53d6\u4efb\u52a1\u66f4\u91cd\u8981\uff0cLAVa\u5728\u5404\u7c7b\u4efb\u52a1\u4e2d\u5747\u4fdd\u6301\u9876\u7ea7\u8868\u73b0\u3002", "conclusion": "LAVa\u901a\u8fc7\u5c06KV\u7f13\u5b58\u538b\u7f29\u95ee\u9898\u7edf\u4e00\u4e3a\u6700\u5c0f\u5316Transformer\u6b8b\u5dee\u6d41\u4fe1\u606f\u635f\u5931\uff0c\u63d0\u51fa\u4e86\u52a8\u6001\u7684\u6309\u5c42\u4e0e\u6309\u5934\u9884\u7b97\u5206\u914d\u7b56\u7565\uff0c\u5b9e\u73b0\u4e86\u6bd4\u73b0\u6709\u542f\u53d1\u5f0f\u65b9\u6cd5\u66f4\u4f18\u7684\u7f13\u5b58\u538b\u7f29\u4e0e\u6dd8\u6c70\u3002"}}
{"id": "2509.09950", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.09950", "abs": "https://arxiv.org/abs/2509.09950", "authors": ["Pouneh Nikkhah Bahrami", "Dylan Cutler", "Igor Bilogrevic"], "title": "Byte by Byte: Unmasking Browser Fingerprinting at the Function Level Using V8 Bytecode Transformers", "comment": null, "summary": "Browser fingerprinting enables persistent cross-site user tracking via subtle\ntechniques that often evade conventional defenses or cause website breakage\nwhen script-level blocking countermeasures are applied. Addressing these\nchallenges requires detection methods offering both function-level precision to\nminimize breakage and inherent robustness against code obfuscation and URL\nmanipulation.\n  We introduce ByteDefender, the first system leveraging V8 engine bytecode to\ndetect fingerprinting operations specifically at the JavaScript function level.\nA Transformer-based classifier, trained offline on bytecode sequences,\naccurately identifies functions exhibiting fingerprinting behavior. We develop\nand evaluate light-weight signatures derived from this model to enable\nlow-overhead, on-device matching against function bytecode during compilation\nbut prior to execution, which only adds a 4% (average) latency to the page load\ntime. This mechanism facilitates targeted, real-time prevention of\nfingerprinting function execution, thereby preserving legitimate script\nfunctionality. Operating directly on bytecode ensures inherent resilience\nagainst common code obfuscation and URL-based evasion. Our evaluation on the\ntop 100k websites demonstrates high detection accuracy at both function- and\nscript-level, with substantial improvements over state-of-the-art AST-based\nmethods, particularly in robustness against obfuscation. ByteDefender offers a\npractical framework for effective, precise, and robust fingerprinting\nmitigation.", "AI": {"tldr": "\u57fa\u4e8eV8\u5b57\u8282\u7801\u548cTransformer\u7684\u51fd\u6570\u7ea7\u6307\u7eb9\u68c0\u6d4b\u4e0e\u7f16\u8bd1\u671f\u7b7e\u540d\u5339\u914d\uff0c\u53ef\u5b9e\u73b0\u4f4e\u5f00\u9500\u3001\u6297\u6df7\u6dc6\u4e14\u7cbe\u786e\u7684\u5b9e\u65f6\u6307\u7eb9\u9632\u62a4\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u811a\u672c\u6216AST\u7684\u68c0\u6d4b\u6613\u53d7\u4ee3\u7801\u6df7\u6dc6\u4e0eURL\u7ed5\u8fc7\u5f71\u54cd\uff0c\u6216\u91c7\u7528\u811a\u672c\u7ea7\u963b\u65ad\u5bfc\u81f4\u7f51\u7ad9\u529f\u80fd\u635f\u574f\uff1b\u9700\u63d0\u4f9b\u51fd\u6570\u7ea7\u7cbe\u786e\u68c0\u6d4b\u5e76\u5bf9\u6df7\u6dc6\u5177\u6709\u9c81\u68d2\u6027\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u4f7f\u7528Transformer\u5bf9V8\u5b57\u8282\u7801\u5e8f\u5217\u8fdb\u884c\u79bb\u7ebf\u8bad\u7ec3\u4ee5\u8bc6\u522b\u6307\u7eb9\u51fd\u6570\uff0c\u5e76\u63d0\u53d6\u8f7b\u91cf\u7b7e\u540d\u4ee5\u5728\u7f16\u8bd1\u671f\u5bf9\u5b57\u8282\u7801\u8fdb\u884c\u5b9e\u65f6\u5339\u914d\u4e0e\u963b\u65ad\u3002", "result": "\u5728Top 100k\u7f51\u7ad9\u4e0a\u6d4b\u8bd5\uff0cByteDefender\u5728\u51fd\u6570\u4e0e\u811a\u672c\u7ea7\u522b\u5747\u8868\u73b0\u51fa\u9ad8\u68c0\u6d4b\u51c6\u786e\u7387\uff0c\u8f83AST\u65b9\u6cd5\u5728\u6297\u6df7\u6dc6\u80fd\u529b\u4e0a\u6709\u663e\u8457\u63d0\u5347\uff0c\u4e14\u9875\u9762\u52a0\u8f7d\u5e73\u5747\u4ec5\u589e\u52a04%\u5ef6\u8fdf\u3002", "conclusion": "ByteDefender\u901a\u8fc7\u5728V8\u5b57\u8282\u7801\u5c42\u68c0\u6d4bJavaScript\u51fd\u6570\u7ea7\u6307\u7eb9\u8ddf\u8e2a\u884c\u4e3a\uff0c\u5b9e\u73b0\u4e86\u9ad8\u7cbe\u5ea6\u4e14\u5bf9\u6297\u6df7\u6dc6\u7684\u6307\u7eb9\u8bc6\u522b\u4e0e\u963b\u65ad\u3002"}}
{"id": "2509.09794", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.09794", "abs": "https://arxiv.org/abs/2509.09794", "authors": ["Jackson Eshbaugh", "Chetan Tiwari", "Jorge Silveyra"], "title": "A Modular and Multimodal Generative AI Framework for Urban Building Energy Data: Generating Synthetic Homes", "comment": "44 pages; 2 appendices; 9 figures; 1 table. Code available at\n  https://github.com/Lafayette-EshbaughSilveyra-Group/synthetic-homes", "summary": "Computational models have emerged as powerful tools for energy modeling\nresearch, touting scalability and quantitative results. However, these models\nrequire a plethora of data, some of which is inaccessible, expensive, or raises\nprivacy concerns. We introduce a modular multimodal framework to produce this\ndata from publicly accessible residential information and images using\ngenerative artificial intelligence (AI). Additionally, we provide a pipeline\ndemonstrating this framework, and we evaluate its generative AI components. Our\nexperiments show that our framework's use of AI avoids common issues with\ngenerative models. Our framework produces realistic, labeled data. By reducing\ndependence on costly or restricted data sources, we pave a path towards more\naccessible and reproducible research.", "AI": {"tldr": "\u4f5c\u8005\u63d0\u51fa\u7528\u751f\u6210\u5f0fAI\u4ece\u516c\u5f00\u4f4f\u5b85\u4fe1\u606f\u5408\u6210\u80fd\u91cf\u5efa\u6a21\u6240\u9700\u6570\u636e\u7684\u6a21\u5757\u5316\u6846\u67b6\uff0c\u5e76\u6f14\u793a\u4e86\u4e00\u4e2a\u7ba1\u9053\u4e0e\u8bc4\u4f30\uff0c\u7ed3\u679c\u663e\u793a\u53ef\u751f\u6210\u903c\u771f\u5e26\u6807\u7b7e\u6570\u636e\uff0c\u63d0\u5347\u7814\u7a76\u53ef\u53ca\u6027\u4e0e\u53ef\u91cd\u590d\u6027\u3002", "motivation": "\u73b0\u5b9e\u4e2d\u7684\u80fd\u91cf\u6a21\u578b\u9700\u8981\u5927\u91cf\u6570\u636e\uff0c\u4f46\u8fd9\u4e9b\u6570\u636e\u5e38\u5e38\u96be\u4ee5\u83b7\u53d6\u6216\u6709\u9690\u79c1\u4e0e\u6210\u672c\u95ee\u9898\u3002\u4f5c\u8005\u5e0c\u671b\u901a\u8fc7\u751f\u6210\u5f0fAI\u4ece\u516c\u5f00\u4fe1\u606f\u5408\u6210\u6240\u9700\u6570\u636e\uff0c\u63d0\u5347\u7814\u7a76\u53ef\u53ca\u6027\u548c\u53ef\u91cd\u590d\u6027\u3002", "method": "\u6784\u5efa\u4e00\u4e2a\u6a21\u5757\u5316\u7ba1\u9053\uff0c\u5c06\u516c\u5f00\u7684\u4f4f\u5b85\u5143\u6570\u636e\u548c\u56fe\u50cf\u4f5c\u4e3a\u8f93\u5165\uff0c\u901a\u8fc7\u591a\u4e2a\u751f\u6210\u5f0fAI\u6a21\u578b\uff08\u53ef\u80fd\u5305\u62ec\u56fe\u50cf\u751f\u6210\u3001\u7ed3\u6784\u5316\u6570\u636e\u586b\u5145\u548c\u6807\u7b7e\u751f\u6210\u7b49\u6a21\u5757\uff09\u5408\u6210\u5177\u6709\u771f\u5b9e\u611f\u4e14\u5e26\u6807\u7b7e\u7684\u6570\u636e\uff0c\u6700\u540e\u7528\u4e8e\u80fd\u91cf\u5efa\u6a21\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u6846\u67b6\u80fd\u751f\u6210\u73b0\u5b9e\u611f\u5f3a\u3001\u5e26\u6807\u7b7e\u7684\u6570\u636e\uff0c\u5e76\u4e14\u5728\u751f\u6210\u5f0fAI\u7ec4\u4ef6\u7684\u8bc4\u4f30\u4e2d\u907f\u514d\u4e86\u751f\u6210\u6a21\u578b\u7684\u4e00\u4e9b\u5e38\u89c1\u95ee\u9898\uff1b\u6574\u4f53\u4e0a\u53ef\u964d\u4f4e\u5bf9\u6602\u8d35\u6216\u53d7\u9650\u6570\u636e\u6e90\u7684\u4f9d\u8d56\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u6a21\u5757\u5316\u591a\u6a21\u6001\u6846\u67b6\uff0c\u4f7f\u7528\u751f\u6210\u5f0fAI\u4ece\u516c\u5f00\u53ef\u5f97\u7684\u4f4f\u5b85\u4fe1\u606f\u548c\u56fe\u50cf\u5408\u6210\u80fd\u91cf\u6a21\u62df\u6240\u9700\u7684\u6570\u636e\uff0c\u4ece\u800c\u51cf\u5c11\u5bf9\u4e0d\u53ef\u53ca\u3001\u6602\u8d35\u6216\u6709\u9690\u79c1\u95ee\u9898\u6570\u636e\u7684\u4f9d\u8d56\u3002"}}
{"id": "2509.10338", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2509.10338", "abs": "https://arxiv.org/abs/2509.10338", "authors": ["Arup Kumar Marik", "Basabdatta Palit", "Sadananda Behera"], "title": "Trusted Repeater Placement in QKD-enabled Optical Networks", "comment": "Paper accepted for the IEEE Global Communications Conference Workshop\n  on Quantum Computing for Communications and Learning", "summary": "Quantum Key Distribution (QKD) provides information-theoretic security, but\nis limited by distance in optical networks, thereby requiring repeater nodes to\nextend coverage. Existing works usually assume all repeater nodes and\nassociated Key Management Servers (KMSs) to be Trusted Repeater Nodes (TRNs),\nwhile ignoring risks from software exploits and insider threats. In this paper,\nwe propose a reliability-aware TRN placement framework for metro optical\nnetworks, which assigns each node a trust score and integrates it into the\nDijkstra algorithm via weighted links. We then rank the nodes using a composite\nscore, which is a weighted combination of betweenness centrality and\neigenvector centrality to enable a secure and scalable TRN deployment.\nSimulation results on a reference topology show that our method covers 10.77%\nmore shortest paths compared to traditional metrics like degree centrality,\nusing the same number (around eight) of TRNs, making it suitable for TRN\nselection to maximize secure connectivity.", "AI": {"tldr": "\u5c06\u8282\u70b9\u4fe1\u4efb\u5ea6\u5f15\u5165\u52a0\u6743Dijkstra\u5e76\u7ed3\u5408\u4ecb\u6570\u4e0e\u7279\u5f81\u5411\u91cf\u4e2d\u5fc3\u6027\u6784\u5efa\u590d\u5408\u8bc4\u5206\uff0c\u672c\u6587\u65b9\u6cd5\u5728\u76f8\u540cTRN\u6570\u91cf\u4e0b\u53ef\u589e\u52a0\u7ea610.8%\u7684\u6700\u77ed\u8def\u5f84\u8986\u76d6\uff0c\u63d0\u5347QKD\u4e2d\u7ee7\u90e8\u7f72\u7684\u53ef\u9760\u6027\u4e0e\u5b89\u5168\u6027\u3002", "motivation": "\u4f20\u7edfQKD\u4e2d\u5047\u5b9a\u4e2d\u7ee7\u4e0eKMS\u5b8c\u5168\u53ef\u4fe1\uff0c\u5ffd\u89c6\u4e86\u8f6f\u4ef6\u6f0f\u6d1e\u4e0e\u5185\u90e8\u5a01\u80c1\u98ce\u9669\uff1b\u56e0\u6b64\u9700\u8981\u5728\u5e03\u7f72\u4e2d\u8003\u8651\u8282\u70b9\u7684\u53ef\u9760\u6027\u4ee5\u589e\u5f3a\u7f51\u7edc\u5b89\u5168\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002", "method": "\u4e3a\u6bcf\u4e2a\u8282\u70b9\u5206\u914d\u4fe1\u4efb\u5206\u6570\uff0c\u5c06\u4fe1\u4efb\u5206\u6570\u6620\u5c04\u4e3a\u94fe\u8def\u6743\u91cd\u5e76\u6574\u5408\u5230Dijkstra\u7b97\u6cd5\u4e2d\u8ba1\u7b97\u53ef\u9760\u6700\u77ed\u8def\u5f84\uff1b\u540c\u65f6\u8ba1\u7b97\u8282\u70b9\u7684\u4ecb\u6570\u4e2d\u5fc3\u6027\u548c\u7279\u5f81\u5411\u91cf\u4e2d\u5fc3\u6027\uff0c\u6309\u52a0\u6743\u7ec4\u5408\u751f\u6210\u590d\u5408\u8bc4\u5206\uff0c\u7528\u4e8e\u6392\u5e8f\u4e0e\u9009\u62e9TRN\u3002", "result": "\u5728\u53c2\u8003\u57ce\u57df\u5149\u7f51\u7edc\u62d3\u6251\u4e0a\u7684\u4eff\u771f\u8868\u660e\uff0c\u672c\u6587\u65b9\u6cd5\u5728\u9009\u53d6\u7ea68\u4e2aTRN\u65f6\uff0c\u76f8\u8f83\u4e8e\u57fa\u4e8e\u5ea6\u4e2d\u5fc3\u6027\u7684\u4f20\u7edf\u65b9\u6cd5\uff0c\u8986\u76d6\u7684\u6700\u77ed\u8def\u5f84\u6570\u63d0\u9ad8\u4e8610.77%\uff0c\u4ece\u800c\u63d0\u5347\u4e86\u5b89\u5168\u8fde\u63a5\u8986\u76d6\u7387\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u8282\u70b9\u4fe1\u4efb\u5ea6\u878d\u5165\u8def\u5f84\u9009\u53d6\u7684TRN\u90e8\u7f72\u6846\u67b6\uff0c\u901a\u8fc7\u52a0\u6743\u6700\u77ed\u8def\u5f84\u548c\u590d\u5408\u4e2d\u5fc3\u6027\u8bc4\u5206\u9009\u62e9\u4e2d\u7ee7\u8282\u70b9\uff0c\u5b9e\u73b0\u5bf9\u8f6f\u4ef6\u6f0f\u6d1e\u548c\u5185\u90e8\u5a01\u80c1\u7684\u9c81\u68d2\u6027\u63d0\u5347\u3002"}}
{"id": "2509.09772", "categories": ["cs.LG", "stat.AP"], "pdf": "https://arxiv.org/pdf/2509.09772", "abs": "https://arxiv.org/abs/2509.09772", "authors": ["Sanjay Basu", "Sadiq Y. Patel", "Parth Sheth", "Bhairavi Muralidharan", "Namrata Elamaran", "Aakriti Kinra", "Rajaie Batniji"], "title": "Hybrid Adaptive Conformal Offline Reinforcement Learning for Fair Population Health Management", "comment": "10 pages, 5 figures, 4 tables", "summary": "Population health management programs for Medicaid populations coordinate\nlongitudinal outreach and services (e.g., benefits navigation, behavioral\nhealth, social needs support, and clinical scheduling) and must be safe, fair,\nand auditable. We present a Hybrid Adaptive Conformal Offline Reinforcement\nLearning (HACO) framework that separates risk calibration from preference\noptimization to generate conservative action recommendations at scale. In our\nsetting, each step involves choosing among common coordination actions (e.g.,\nwhich member to contact, by which modality, and whether to route to a\nspecialized service) while controlling the near-term risk of adverse\nutilization events (e.g., unplanned emergency department visits or\nhospitalizations). Using a de-identified operational dataset from Waymark\ncomprising 2.77 million sequential decisions across 168,126 patients, HACO (i)\ntrains a lightweight risk model for adverse events, (ii) derives a conformal\nthreshold to mask unsafe actions at a target risk level, and (iii) learns a\npreference policy on the resulting safe subset. We evaluate policies with a\nversion-agnostic fitted Q evaluation (FQE) on stratified subsets and audit\nsubgroup performance across age, sex, and race. HACO achieves strong risk\ndiscrimination (AUC ~0.81) with a calibrated threshold ( {\\tau} ~0.038 at\n{\\alpha} = 0.10), while maintaining high safe coverage. Subgroup analyses\nreveal systematic differences in estimated value across demographics,\nunderscoring the importance of fairness auditing. Our results show that\nconformal risk gating integrates cleanly with offline RL to deliver\nconservative, auditable decision support for population health management\nteams.", "AI": {"tldr": "HACO\u5c06\u4fdd\u5f62\u98ce\u9669\u95e8\u63a7\u4e0e\u79bb\u7ebfRL\u7ed3\u5408\uff0c\u63d0\u4f9b\u4fdd\u5b88\u3001\u53ef\u5ba1\u8ba1\u7684\u51b3\u7b56\u652f\u6301\uff0c\u517c\u987e\u98ce\u9669\u63a7\u5236\u4e0e\u64cd\u4f5c\u8986\u76d6\uff0c\u4f46\u9700\u6ce8\u610f\u7fa4\u4f53\u516c\u5e73\u6027\u95ee\u9898\u3002", "motivation": "\u5728Medicaid\u4eba\u7fa4\u7684\u7fa4\u4f53\u5065\u5eb7\u7ba1\u7406\u4e2d\uff0c\u9700\u8981\u5728\u5927\u89c4\u6a21\u534f\u8c03\u884c\u52a8\u4e2d\u4fdd\u8bc1\u51b3\u7b56\u7684\u5b89\u5168\u6027\u3001\u516c\u5e73\u6027\u4e0e\u53ef\u5ba1\u8ba1\u6027\uff0c\u907f\u514d\u589e\u52a0\u6025\u8bca\u6216\u4f4f\u9662\u7b49\u4e0d\u826f\u5229\u7528\u4e8b\u4ef6\u3002", "method": "HACO\u5305\u62ec\u4e09\u6b65\uff1a\u8bad\u7ec3\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u98ce\u9669\u6a21\u578b\u9884\u6d4b\u4e0d\u826f\u5229\u7528\u4e8b\u4ef6\uff1b\u4f7f\u7528\u4fdd\u5f62\uff08conformal\uff09\u65b9\u6cd5\u786e\u5b9a\u9608\u503c\u4ee5\u5728\u76ee\u6807\u98ce\u9669\u6c34\u5e73\u4e0a\u5c4f\u853d\u4e0d\u5b89\u5168\u52a8\u4f5c\uff1b\u5728\u5269\u4f59\u7684\u5b89\u5168\u5b50\u96c6\u4e2d\u8bad\u7ec3\u504f\u597d\u7b56\u7565\uff08\u79bb\u7ebfRL\uff09\uff0c\u5e76\u7528\u7248\u672c\u65e0\u5173\u7684FQE\u8fdb\u884c\u8bc4\u4f30\u4e0e\u5206\u5c42\u5ba1\u8ba1\u3002", "result": "\u5728Waymark\u7684\u53bb\u6807\u8bc6\u8fd0\u8425\u6570\u636e\uff082.77M\u6b21\u51b3\u7b56\u3001168,126\u540d\u60a3\u8005\uff09\u4e0a\uff0c\u98ce\u9669\u6a21\u578bAUC\u7ea6\u4e3a0.81\uff1b\u5728\u03b1=0.10\u65f6\uff0c\u4fdd\u5f62\u9608\u503c\u03c4\u22480.038\uff0c\u4fdd\u6301\u8f83\u9ad8\u7684\u5b89\u5168\u8986\u76d6\u7387\uff1b\u4f46\u5206\u7ec4\u5206\u6790\u663e\u793a\u4e0d\u540c\u4eba\u53e3\u7edf\u8ba1\u7ec4\u95f4\u5b58\u5728\u7cfb\u7edf\u6027\u4f30\u8ba1\u4ef7\u503c\u5dee\u5f02\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86HACO\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u98ce\u9669\u6821\u51c6\u4e0e\u504f\u597d\u4f18\u5316\u5206\u79bb\uff0c\u5b9e\u73b0\u5bf9\u533b\u7597\u534f\u8c03\u51b3\u7b56\u7684\u4fdd\u5b88\u4e14\u53ef\u5ba1\u8ba1\u7684\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u63a8\u8350\u3002"}}
{"id": "2509.09970", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.09970", "abs": "https://arxiv.org/abs/2509.09970", "authors": ["Seyed Moein Abtahi", "Akramul Azim"], "title": "Securing LLM-Generated Embedded Firmware through AI Agent-Driven Validation and Patching", "comment": null, "summary": "Large Language Models (LLMs) show promise in generating firmware for embedded\nsystems, but often introduce security flaws and fail to meet real-time\nperformance constraints. This paper proposes a three-phase methodology that\ncombines LLM-based firmware generation with automated security validation and\niterative refinement in a virtualized environment. Using structured prompts,\nmodels like GPT-4 generate firmware for networking and control tasks, deployed\non FreeRTOS via QEMU. These implementations are tested using fuzzing, static\nanalysis, and runtime monitoring to detect vulnerabilities such as buffer\noverflows (CWE-120), race conditions (CWE-362), and denial-of-service threats\n(CWE-400). Specialized AI agents for Threat Detection, Performance\nOptimization, and Compliance Verification collaborate to improve detection and\nremediation. Identified issues are categorized using CWE, then used to prompt\ntargeted LLM-generated patches in an iterative loop. Experiments show a 92.4\\%\nVulnerability Remediation Rate (37.3\\% improvement), 95.8\\% Threat Model\nCompliance, and 0.87 Security Coverage Index. Real-time metrics include 8.6ms\nworst-case execution time and 195{\\mu}s jitter. This process enhances firmware\nsecurity and performance while contributing an open-source dataset for future\nresearch.", "AI": {"tldr": "\u5c06LLM\u56fa\u4ef6\u751f\u6210\u4e0e\u81ea\u52a8\u5316\u5b89\u5168\u68c0\u6d4b+AI\u9a71\u52a8\u7684\u8fed\u4ee3\u4fee\u590d\u7ed3\u5408\uff0c\u53ef\u5728\u865a\u62df\u5316\u73af\u5883\u4e2d\u663e\u8457\u63d0\u9ad8\u5d4c\u5165\u5f0f\u56fa\u4ef6\u7684\u5b89\u5168\u6027\u4e0e\u5b9e\u65f6\u6027\u80fd\uff0c\u5b9e\u9a8c\u5c55\u793a\u9ad8\u4fee\u590d\u7387\u4e0e\u5408\u89c4\u6027\u5e76\u63d0\u4f9b\u5f00\u6e90\u6570\u636e\u3002", "motivation": "LLM\u751f\u6210\u56fa\u4ef6\u867d\u63d0\u9ad8\u5f00\u53d1\u6548\u7387\uff0c\u4f46\u6613\u5f15\u5165\u5b89\u5168\u7f3a\u9677\u5e76\u53ef\u80fd\u4e0d\u6ee1\u8db3\u5d4c\u5165\u5f0f\u7cfb\u7edf\u7684\u5b9e\u65f6\u6027\u8981\u6c42\uff0c\u9700\u6784\u5efa\u81ea\u52a8\u5316\u9a8c\u8bc1\u4e0e\u4fee\u590d\u6d41\u7a0b\u4ee5\u964d\u4f4e\u98ce\u9669\u5e76\u786e\u4fdd\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u4e09\u9636\u6bb5\u65b9\u6cd5\uff1a1) \u4f7f\u7528\u7ed3\u6784\u5316\u63d0\u793a\u8bcd\u8ba9GPT-4\u7b49\u6a21\u578b\u751f\u6210\u9488\u5bf9\u7f51\u7edc\u548c\u63a7\u5236\u4efb\u52a1\u7684\u56fa\u4ef6\uff1b2) \u5728QEMU\u4e0a\u8fd0\u884cFreeRTOS\u8fdb\u884c\u6a21\u7cca\u6d4b\u8bd5\u3001\u9759\u6001\u5206\u6790\u548c\u8fd0\u884c\u65f6\u76d1\u63a7\u4ee5\u68c0\u6d4bCWE-120\u3001CWE-362\u3001CWE-400\u7b49\u6f0f\u6d1e\uff1b3) \u901a\u8fc7\u5a01\u80c1\u68c0\u6d4b\u3001\u6027\u80fd\u4f18\u5316\u548c\u5408\u89c4\u6a21\u5757\u7684AI\u4ee3\u7406\u5bf9\u68c0\u6d4b\u5230\u7684\u95ee\u9898\u8fdb\u884c\u5206\u7c7b\uff08\u6309CWE\uff09\u5e76\u751f\u6210\u9488\u5bf9\u6027\u8865\u4e01\uff0c\u5faa\u73af\u8fed\u4ee3\u76f4\u81f3\u6ee1\u8db3\u5b89\u5168\u548c\u5b9e\u65f6\u6027\u76ee\u6807\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\uff1a\u6f0f\u6d1e\u4fee\u590d\u738792.4%\uff08\u63d0\u534737.3%\uff09\uff0c\u5a01\u80c1\u6a21\u578b\u5408\u89c4\u738795.8%\uff0c\u5b89\u5168\u8986\u76d6\u6307\u65700.87\uff1b\u5b9e\u65f6\u6027\u80fd\uff1a\u6700\u574f\u6267\u884c\u65f6\u95f48.6ms\uff0c\u6296\u52a8195\u03bcs\uff1b\u5e76\u53d1\u5e03\u5f00\u6e90\u6570\u636e\u96c6\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u5c06LLM\u751f\u6210\u56fa\u4ef6\u4e0e\u81ea\u52a8\u5316\u5b89\u5168\u9a8c\u8bc1\u548c\u8fed\u4ee3\u4fee\u6b63\u7ed3\u5408\uff0c\u5728\u865a\u62df\u5316\u73af\u5883\u4e2d\u663e\u8457\u63d0\u5347\u4e86\u5d4c\u5165\u5f0f\u56fa\u4ef6\u7684\u5b89\u5168\u6027\u4e0e\u5b9e\u65f6\u6027\u80fd\uff0c\u5b9e\u9a8c\u8bc1\u660e\u6f0f\u6d1e\u4fee\u590d\u7387\u548c\u5408\u89c4\u6027\u5747\u6709\u8f83\u9ad8\u63d0\u5347\u3002"}}
{"id": "2509.09810", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.09810", "abs": "https://arxiv.org/abs/2509.09810", "authors": ["Agnieszka Mensfelt", "David Tena Cucala", "Santiago Franco", "Angeliki Koutsoukou-Argyraki", "Vince Trencsenyi", "Kostas Stathis"], "title": "Towards a Common Framework for Autoformalization", "comment": null, "summary": "Autoformalization has emerged as a term referring to the automation of\nformalization - specifically, the formalization of mathematics using\ninteractive theorem provers (proof assistants). Its rapid development has been\ndriven by progress in deep learning, especially large language models (LLMs).\nMore recently, the term has expanded beyond mathematics to describe the broader\ntask of translating informal input into formal logical representations. At the\nsame time, a growing body of research explores using LLMs to translate informal\nlanguage into formal representations for reasoning, planning, and knowledge\nrepresentation - often without explicitly referring to this process as\nautoformalization. As a result, despite addressing similar tasks, the largely\nindependent development of these research areas has limited opportunities for\nshared methodologies, benchmarks, and theoretical frameworks that could\naccelerate progress. The goal of this paper is to review - explicit or implicit\n- instances of what can be considered autoformalization and to propose a\nunified framework, encouraging cross-pollination between different fields to\nadvance the development of next generation AI systems.", "AI": {"tldr": "\u5c06autoformalization\u5b9a\u4e49\u4e3a\u628a\u975e\u5f62\u5f0f\u5316\u8f93\u5165\u7ffb\u8bd1\u4e3a\u5f62\u5f0f\u5316\u903b\u8f91\u8868\u793a\uff0c\u7efc\u8ff0\u76f8\u5173\u9886\u57df\u5de5\u4f5c\uff0c\u63d0\u51fa\u7edf\u4e00\u6846\u67b6\u3001\u8bc4\u4f30\u6307\u6807\u4e0e\u7814\u7a76\u8def\u7ebf\uff0c\u65e8\u5728\u4fc3\u8fdb\u8de8\u57df\u534f\u540c\u4e0e\u52a0\u901f\u53d1\u5c55\u3002", "motivation": "\u76ee\u524d\u76f8\u5173\u7814\u7a76\u9886\u57df\u867d\u89e3\u51b3\u76f8\u4f3c\u95ee\u9898\uff0c\u4f46\u5404\u81ea\u72ec\u7acb\uff0c\u7f3a\u4e4f\u5171\u540c\u7684\u672f\u8bed\u3001\u57fa\u51c6\u548c\u65b9\u6cd5\uff0c\u963b\u788d\u4e86\u6280\u672f\u79ef\u7d2f\u548c\u8de8\u57df\u8fc1\u79fb\uff1b\u7edf\u4e00\u6846\u67b6\u53ef\u4ee5\u4fc3\u8fdb\u8d44\u6e90\u5171\u4eab\u4e0e\u534f\u540c\u8fdb\u5c55\u3002", "method": "\u7efc\u8ff0\u73b0\u6709\u6587\u732e\uff0c\u6bd4\u8f83\u4e0d\u540c\u9886\u57df\uff08\u6570\u5b66\u5f62\u5f0f\u5316\u3001\u7a0b\u5e8f\u5408\u6210\u3001\u77e5\u8bc6\u8868\u793a\u3001\u89c4\u5212\u4e0e\u63a8\u7406\uff09\u4e2d\u7684\u5de5\u4f5c\uff0c\u63d0\u51fa\u7edf\u4e00\u672f\u8bed\u3001\u4efb\u52a1\u5b9a\u4e49\u4e0e\u8bc4\u4f30\u6307\u6807\uff0c\u5e76\u8ba8\u8bba\u6a21\u578b\u67b6\u6784\u3001\u6570\u636e\u96c6\u3001\u81ea\u52a8\u5316\u6d41\u6c34\u7ebf\u4e0e\u4eba\u673a\u534f\u4f5c\u7684\u7ec4\u5408\u7b56\u7565\u3002", "result": "\u7ed9\u51fa\u4e00\u4e2a\u7edf\u4e00\u7684\u6982\u5ff5\u6846\u67b6\u3001\u5206\u7c7b\u4f53\u7cfb\u4e0e\u7814\u7a76\u8def\u7ebf\u56fe\uff1b\u603b\u7ed3\u82e5\u5e72\u6311\u6218\uff08\u53ef\u89e3\u91ca\u6027\u3001\u53ef\u8bc1\u660e\u7684\u6b63\u786e\u6027\u3001\u6570\u636e\u7a00\u7f3a\u3001\u8de8\u57df\u6cdb\u5316\u3001\u8bc4\u4f30\u96be\u9898\uff09\u5e76\u63d0\u51fa\u672a\u6765\u7814\u7a76\u65b9\u5411\u4e0e\u5efa\u8bae\uff0c\u5982\u6784\u5efa\u5927\u89c4\u6a21\u5bf9\u9f50\u6570\u636e\u3001\u6df7\u5408\u8bc1\u660e\u5f15\u64ce\u4e0eLLM\u3001\u4eba\u673a\u534f\u4f5c\u534f\u8bae\u4e0e\u6807\u51c6\u57fa\u51c6\u96c6\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u5c06autoformalization\u6269\u5c55\u4e3a\u201c\u628a\u975e\u5f62\u5f0f\u5316\u8f93\u5165\u6620\u5c04\u5230\u5f62\u5f0f\u5316\u903b\u8f91\u8868\u793a\u201d\u7684\u7edf\u4e00\u4efb\u52a1\uff0c\u4e3b\u5f20\u6574\u5408\u6570\u5b66\u5f62\u5f0f\u5316\u4e0e\u66f4\u5e7f\u6cdb\u7684\u8bed\u8a00\u5230\u903b\u8f91\u7ffb\u8bd1\u7814\u7a76\uff0c\u4fc3\u8fdb\u65b9\u6cd5\u3001\u57fa\u51c6\u4e0e\u7406\u8bba\u6846\u67b6\u7684\u5171\u4eab\u3002"}}
{"id": "2509.10291", "categories": ["cs.LG", "cs.NI"], "pdf": "https://arxiv.org/pdf/2509.10291", "abs": "https://arxiv.org/abs/2509.10291", "authors": ["Salih Toprak", "Muge Erel-Ozcevik"], "title": "Proof of AutoML: SDN based Secure Energy Trading with Blockchain in Disaster Case", "comment": "6 pages, 3 figures, 7th International Conference on Blockchain\n  Computing and Applications (BCCA 2025), \\c{opyright}2025 IEEE", "summary": "In disaster scenarios where conventional energy infrastructure is\ncompromised, secure and traceable energy trading between solar-powered\nhouseholds and mobile charging units becomes a necessity. To ensure the\nintegrity of such transactions over a blockchain network, robust and\nunpredictable nonce generation is vital. This study proposes an SDN-enabled\narchitecture where machine learning regressors are leveraged not for their\naccuracy, but for their potential to generate randomized values suitable as\nnonce candidates. Therefore, it is newly called Proof of AutoML. Here, SDN\nallows flexible control over data flows and energy routing policies even in\nfragmented or degraded networks, ensuring adaptive response during emergencies.\nUsing a 9000-sample dataset, we evaluate five AutoML-selected regression models\n- Gradient Boosting, LightGBM, Random Forest, Extra Trees, and K-Nearest\nNeighbors - not by their prediction accuracy, but by their ability to produce\ndiverse and non-deterministic outputs across shuffled data inputs. Randomness\nanalysis reveals that Random Forest and Extra Trees regressors exhibit complete\ndependency on randomness, whereas Gradient Boosting, K-Nearest Neighbors and\nLightGBM show strong but slightly lower randomness scores (97.6%, 98.8% and\n99.9%, respectively). These findings highlight that certain machine learning\nmodels, particularly tree-based ensembles, may serve as effective and\nlightweight nonce generators within blockchain-secured, SDN-based energy\ntrading infrastructures resilient to disaster conditions.", "AI": {"tldr": "\u5728\u707e\u96be\u573a\u666f\u4e0b\uff0c\u63d0\u51fa\u201cProof of AutoML\u201d\u601d\u8def\uff1a\u5728SDN\u63a7\u5236\u7684\u80fd\u6e90\u4ea4\u6613\u7cfb\u7edf\u4e2d\uff0c\u7528AutoML\u6311\u9009\u7684\u56de\u5f52\u6a21\u578b\uff08\u5c24\u5176\u662f\u6811\u6a21\u578b\uff09\u4f5c\u4e3a\u533a\u5757\u94feNonce\u7684\u8f7b\u91cf\u968f\u673a\u6e90\uff1b\u5b9e\u9a8c\u8bc1\u660eRandom Forest\u548cExtra Trees\u968f\u673a\u6027\u6700\u597d\uff0c\u5176\u4ed6\u6a21\u578b\u4e5f\u5f88\u9ad8\u3002", "motivation": "In disaster scenarios with compromised infrastructure, secure and traceable energy trading needs unpredictable nonces for blockchain transactions; standard RNGs may be unavailable or undesired, so leveraging ML model randomness within SDN-managed energy networks could be a lightweight alternative.", "method": "Use SDN for flexible control and AutoML to select five regression models; evaluate models on 9000-sample dataset by shuffling inputs and measuring output diversity/randomness rather than accuracy.", "result": "Random Forest and Extra Trees show complete dependency on randomness; Gradient Boosting, KNN, LightGBM show high randomness scores (97.6%, 98.8%, 99.9%). This suggests feasibility of using certain ML models as nonce generators.", "conclusion": "Tree-based ensemble regressors (Random Forest, Extra Trees) produce highly randomized outputs suitable for nonce generation; Gradient Boosting, KNN, LightGBM also perform strongly. The proposed Proof of AutoML within an SDN-enabled energy trading system can provide lightweight nonce generation for blockchain in disaster scenarios."}}
{"id": "2509.09782", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.09782", "abs": "https://arxiv.org/abs/2509.09782", "authors": ["Roshini Pulishetty", "Mani Kishan Ghantasala", "Keerthy Kaushik Dasoju", "Niti Mangwani", "Vishal Garimella", "Aditya Mate", "Somya Chatterjee", "Yue Kang", "Ehi Nosakhare", "Sadid Hasan", "Soundar Srinivasan"], "title": "One Head, Many Models: Cross-Attention Routing for Cost-Aware LLM Selection", "comment": null, "summary": "The proliferation of large language models (LLMs) with varying computational\ncosts and performance profiles presents a critical challenge for scalable,\ncost-effective deployment in real-world applications. We introduce a unified\nrouting framework that leverages a single-head cross-attention mechanism to\njointly model query and model embeddings, enabling dynamic selection of the\noptimal LLM for each input query. Our approach is evaluated on RouterBench, a\nlarge-scale, publicly available benchmark encompassing diverse LLM pools and\ndomains. By explicitly capturing fine-grained query-model interactions, our\nrouter predicts both response quality and generation cost, achieving up to 6.6%\nimprovement in Average Improvement in Quality (AIQ) and 2.9% in maximum\nperformance over existing routers. To robustly balance performance and cost, we\npropose an exponential reward function that enhances stability across user\npreferences. The resulting architecture is lightweight, generalizes effectively\nacross domains, and demonstrates improved efficiency compared to prior methods,\nestablishing a new standard for cost-aware LLM routing.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u5355\u5934\u4ea4\u53c9\u6ce8\u610f\u529b\u7684\u8f7b\u91cf\u7ea7\u6210\u672c\u611f\u77e5LLM\u8def\u7531\u5668\uff0c\u80fd\u8054\u5408\u5efa\u6a21\u67e5\u8be2\u4e0e\u6a21\u578b\u7279\u5f81\uff0c\u9884\u6d4b\u8d28\u91cf\u4e0e\u6210\u672c\uff0c\u5728\u5927\u89c4\u6a21\u57fa\u51c6\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u5e76\u63d0\u4f9b\u66f4\u7a33\u5065\u7684\u6027\u80fd-\u6210\u672c\u6743\u8861\u3002", "motivation": "\u9762\u5bf9\u6027\u80fd\u4e0e\u8ba1\u7b97\u5f00\u9500\u5404\u5f02\u7684\u5927\u89c4\u6a21LLM\u5e93\uff0c\u4e9f\u9700\u4e00\u79cd\u53ef\u6269\u5c55\u4e14\u6210\u672c\u654f\u611f\u7684\u8def\u7531\u673a\u5236\uff0c\u4ee5\u5728\u4e0d\u540c\u67e5\u8be2\u4e0b\u9009\u62e9\u6700\u5408\u9002\u7684\u6a21\u578b\u3002", "method": "\u4f7f\u7528\u5355\u5934cross-attention\u5c06\u67e5\u8be2\u548c\u6a21\u578b\u5d4c\u5165\u8054\u5408\u7f16\u7801\uff0c\u9884\u6d4b\u54cd\u5e94\u8d28\u91cf\u4e0e\u751f\u6210\u6210\u672c\uff1b\u5728RouterBench\u57fa\u51c6\u4e0a\u8bad\u7ec3\u548c\u8bc4\u4f30\uff1b\u5f15\u5165\u6307\u6570\u56de\u62a5\u51fd\u6570\u7528\u4e8e\u5e73\u8861\u6027\u80fd\u4e0e\u6210\u672c\u3002", "result": "\u5728RouterBench\u4e0a\u76f8\u6bd4\u73b0\u6709\u8def\u7531\u65b9\u6cd5\uff0cAIQ\u63d0\u5347\u6700\u591a6.6%\uff0c\u6700\u5927\u6027\u80fd\u63d0\u53472.9%\uff1b\u8def\u7531\u5668\u66f4\u7a33\u5b9a\u3001\u8f7b\u91cf\u4e14\u8de8\u9886\u57df\u6cdb\u5316\u66f4\u597d\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u57fa\u4e8e\u5355\u5934\u4ea4\u53c9\u6ce8\u610f\u529b\u7684\u7edf\u4e00\u8def\u7531\u6846\u67b6\uff0c\u901a\u8fc7\u8054\u5408\u5efa\u6a21\u67e5\u8be2\u4e0e\u6a21\u578b\u5d4c\u5165\u5b9e\u73b0\u9488\u5bf9\u6bcf\u4e2a\u8f93\u5165\u52a8\u6001\u9009\u62e9\u6700\u4f18LLM\uff0c\u517c\u987e\u8d28\u91cf\u4e0e\u6210\u672c\u3002"}}
{"id": "2509.09989", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.09989", "abs": "https://arxiv.org/abs/2509.09989", "authors": ["Priyanka Rushikesh Chaudhary", "Manan Gupta", "Jabez Christopher", "Putrevu Venkata Sai Charan", "Rajib Ranjan Maiti"], "title": "rCamInspector: Building Reliability and Trust on IoT (Spy) Camera Detection using XAI", "comment": null, "summary": "The classification of network traffic using machine learning (ML) models is\none of the primary mechanisms to address the security issues in IoT networks\nand/or IoT devices. However, the ML models often act as black-boxes that create\na roadblock to take critical decision based on the model output. To address\nthis problem, we design and develop a system, called rCamInspector, that\nemploys Explainable AI (XAI) to provide reliable and trustworthy explanations\nto model output. rCamInspector adopts two classifiers, Flow Classifier -\ncategorizes a flow into one of four classes, IoTCam, Conf, Share and Others,\nand SmartCam Classifier - classifies an IoTCam flow into one of six classes,\nNetatmo, Spy Clock, Canary, D3D, Ezviz, V380 Spy Bulb; both are IP address and\ntransport port agnostic. rCamInspector is evaluated using 38GB of network\ntraffic and our results show that XGB achieves the highest accuracy of 92% and\n99% in the Flow and SmartCam classifiers respectively among eight supervised ML\nmodels. We analytically show that the traditional mutual information (MI) based\nfeature importance cannot provide enough reliability on the model output of XGB\nin either classifiers. Using SHAP and LIME, we show that a separate set of\nfeatures can be picked up to explain a correct prediction of XGB. For example,\nthe feature Init Bwd Win Byts turns out to have the highest SHAP values to\nsupport the correct prediction of both IoTCam in Flow Classifier and Netatmo\nclass in SmartCam Classifier. To evaluate the faithfulness of the explainers on\nour dataset, we show that both SHAP and LIME have a consistency of more than\n0.7 and a sufficiency of 1.0. Comparing with existing works, we show that\nrCamInspector achieves a better accuracy (99%), precision (99%), and false\nnegative rate (0.7%).", "AI": {"tldr": "\u63d0\u51fa rCamInspector\uff0c\u7d50\u5408 XGBoost \u8207 SHAP/LIME \u5c0d IoT \u651d\u50cf\u982d\u6d41\u91cf\u5206\u985e\u63d0\u4f9b\u9ad8\u6e96\u78ba\u4e14\u6709\u4fe1\u5ea6\u7684\u89e3\u91cb\u3002", "motivation": "\u89e3\u6c7a ML \u6a21\u578b\u4f5c\u70ba\u9ed1\u76d2\u5c0e\u81f4\u5728 IoT \u7db2\u8def\u5b89\u5168\u6c7a\u7b56\u4e2d\u7f3a\u4e4f\u53ef\u89e3\u91cb\u6027\u8207\u53ef\u4fe1\u5ea6\u554f\u984c\uff0c\u7279\u5225\u91dd\u5c0d IoT \u651d\u50cf\u982d\u6d41\u91cf\u5206\u985e\u3002", "method": "\u69cb\u5efa\u5169\u5c64\u5206\u985e\u5668\uff1aFlow Classifier\uff08\u56db\u985e\uff1aIoTCam, Conf, Share, Others\uff09\u548c SmartCam Classifier\uff08\u516d\u985e\u5177\u9ad4\u651d\u50cf\u982d\u54c1\u724c\uff09\uff0c\u4f7f\u7528\u516b\u7a2e\u76e3\u7763\u5f0f ML \u6a21\u578b\u9032\u884c\u6bd4\u8f03\uff0c\u6700\u7d42\u9078\u64c7 XGBoost\uff08XGB\uff09\u70ba\u4e3b\u6a21\u578b\uff1b\u4e26\u7528 SHAP \u548c LIME \u4f5c\u70ba\u89e3\u91cb\u5668\u8a55\u4f30\u6a21\u578b\u53ef\u89e3\u91cb\u6027\uff0c\u540c\u6642\u8207\u4e92\u4fe1\u606f\uff08MI\uff09\u7279\u5fb5\u91cd\u8981\u6027\u5c0d\u6bd4\u3002", "result": "\u5728 38GB \u7db2\u8def\u6d41\u91cf\u4e0a\u5be6\u9a57\uff1aXGB \u5728 Flow \u8207 SmartCam \u5206\u985e\u5668\u4e0a\u5206\u5225\u9054\u5230 92% \u8207 99% \u7684\u6e96\u78ba\u7387\uff1bSHAP \u8207 LIME \u80fd\u63d0\u4f9b\u4e00\u81f4\u6027>0.7 \u53ca\u5145\u5206\u6027=1.0\uff0c\u4e26\u6307\u51fa\u4f8b\u5982 Init Bwd Win Byts \u70ba\u91cd\u8981\u89e3\u91cb\u7279\u5fb5\uff1b\u8207\u73fe\u6709\u5de5\u4f5c\u6bd4\u8f03\uff0c\u5728\u6e96\u78ba\u7387\u3001\u7cbe\u78ba\u7387\u8207\u5047\u9670\u6027\u7387\u4e0a\u5747\u6709\u6539\u9032\u3002", "conclusion": "rCamInspector \u6210\u529f\u5229\u7528 XAI \u63d0\u4f9b\u5c0d IoT \u651d\u50cf\u982d\u6d41\u91cf\u5206\u985e\u6a21\u578b\u8f38\u51fa\u7684\u53ef\u89e3\u91cb\u6027\uff0c\u4e26\u5728\u5be6\u9a57\u4e2d\u5c55\u793a\u4e86\u9ad8\u6e96\u78ba\u5ea6\u8207\u53ef\u9760\u6027\u3002"}}
{"id": "2509.09848", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.09848", "abs": "https://arxiv.org/abs/2509.09848", "authors": ["Nana Han", "Dong Liu", "Tomas Norton"], "title": "Towards an AI-based knowledge assistant for goat farmers based on Retrieval-Augmented Generation", "comment": null, "summary": "Large language models (LLMs) are increasingly being recognised as valuable\nknowledge communication tools in many industries. However, their application in\nlivestock farming remains limited, being constrained by several factors not\nleast the availability, diversity and complexity of knowledge sources. This\nstudy introduces an intelligent knowledge assistant system designed to support\nhealth management in farmed goats. Leveraging the Retrieval-Augmented\nGeneration (RAG), two structured knowledge processing methods, table\ntextualization and decision-tree textualization, were proposed to enhance large\nlanguage models' (LLMs) understanding of heterogeneous data formats. Based on\nthese methods, a domain-specific goat farming knowledge base was established to\nimprove LLM's capacity for cross-scenario generalization. The knowledge base\nspans five key domains: Disease Prevention and Treatment, Nutrition Management,\nRearing Management, Goat Milk Management, and Basic Farming Knowledge.\nAdditionally, an online search module is integrated to enable real-time\nretrieval of up-to-date information. To evaluate system performance, six\nablation experiments were conducted to examine the contribution of each\ncomponent. The results demonstrated that heterogeneous knowledge fusion method\nachieved the best results, with mean accuracies of 87.90% on the validation set\nand 84.22% on the test set. Across the text-based, table-based, decision-tree\nbased Q&A tasks, accuracy consistently exceeded 85%, validating the\neffectiveness of structured knowledge fusion within a modular design. Error\nanalysis identified omission as the predominant error category, highlighting\nopportunities to further improve retrieval coverage and context integration. In\nconclusion, the results highlight the robustness and reliability of the\nproposed system for practical applications in goat farming.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eRAG\u7684\u5c71\u7f8a\u517b\u6b96\u77e5\u8bc6\u52a9\u7406\uff1a\u8868\u683c\u4e0e\u51b3\u7b56\u6811\u6587\u672c\u5316\u878d\u5408\u5f02\u6784\u77e5\u8bc6\uff0c\u6784\u5efa\u9886\u57df\u77e5\u8bc6\u5e93\u5e76\u52a0\u5728\u7ebf\u68c0\u7d22\uff0c\u6d88\u878d\u5b9e\u9a8c\u8bc1\u660e\u6027\u80fd\u7a33\u5065\uff0c\u5e73\u5747\u51c6\u786e\u7387\u7ea685%\u4ee5\u4e0a\uff0c\u4e3b\u8981\u95ee\u9898\u4e3a\u68c0\u7d22\u9057\u6f0f\u3002", "motivation": "LLM\u5728\u755c\u7267\u4e1a\u5c24\u5176\u662f\u5c71\u7f8a\u517b\u6b96\u9886\u57df\u5e94\u7528\u53d7\u9650\uff0c\u4e3b\u8981\u56e0\u77e5\u8bc6\u6765\u6e90\u7a00\u7f3a\u3001\u683c\u5f0f\u591a\u6837\u4e14\u590d\u6742\uff0c\u56e0\u800c\u9700\u8981\u4e00\u79cd\u80fd\u6574\u5408\u5f02\u6784\u6570\u636e\u5e76\u63d0\u5347\u6a21\u578b\u8de8\u573a\u666f\u6cdb\u5316\u80fd\u529b\u7684\u7cfb\u7edf\u3002", "method": "\u57fa\u4e8eRAG\u6846\u67b6\uff0c\u63d0\u51fa\u4e24\u79cd\u7ed3\u6784\u5316\u77e5\u8bc6\u5904\u7406\u65b9\u6cd5\uff1a\u8868\u683c\u6587\u672c\u5316\u4e0e\u51b3\u7b56\u6811\u6587\u672c\u5316\uff0c\u6784\u5efa\u8986\u76d6\u75be\u75c5\u9632\u6cbb\u3001\u8425\u517b\u7ba1\u7406\u3001\u9972\u517b\u7ba1\u7406\u3001\u7f8a\u5976\u7ba1\u7406\u4e0e\u57fa\u7840\u517b\u6b96\u77e5\u8bc6\u7684\u9886\u57df\u77e5\u8bc6\u5e93\uff0c\u5e76\u96c6\u6210\u5728\u7ebf\u641c\u7d22\u6a21\u5757\u5b9e\u73b0\u5b9e\u65f6\u4fe1\u606f\u68c0\u7d22\uff1b\u901a\u8fc7\u516d\u7ec4\u6d88\u878d\u5b9e\u9a8c\u8bc4\u4f30\u5404\u7ec4\u4ef6\u8d21\u732e\uff0c\u4f7f\u7528\u6587\u672c/\u8868\u683c/\u51b3\u7b56\u6811\u4e09\u7c7b\u95ee\u7b54\u4efb\u52a1\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u5f02\u6784\u77e5\u8bc6\u878d\u5408\u65b9\u6cd5\u8868\u73b0\u6700\u4f73\uff0c\u9a8c\u8bc1\u96c6\u5e73\u5747\u51c6\u786e\u738787.90%\uff0c\u6d4b\u8bd5\u96c684.22%\uff1b\u5728\u6587\u672c\u3001\u8868\u683c\u4e0e\u51b3\u7b56\u6811\u95ee\u7b54\u4efb\u52a1\u4e0a\u51c6\u786e\u7387\u5747\u9ad8\u4e8e85%\uff1b\u4e3b\u8981\u9519\u8bef\u7c7b\u578b\u4e3a\u9057\u6f0f\uff0c\u63d0\u793a\u53ef\u6539\u8fdb\u68c0\u7d22\u8986\u76d6\u4e0e\u4e0a\u4e0b\u6587\u6574\u5408\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u7684\u667a\u80fd\u77e5\u8bc6\u52a9\u7406\u7cfb\u7edf\u5728\u5c71\u7f8a\u517b\u6b96\u5065\u5eb7\u7ba1\u7406\u573a\u666f\u4e2d\u8868\u73b0\u7a33\u5b9a\u53ef\u9760\uff0c\u901a\u8fc7\u5c06\u591a\u6e90\u5f02\u6784\u77e5\u8bc6\u7ed3\u6784\u5316\u5e76\u7ed3\u5408RAG\u63d0\u5347\u4e86LLM\u5bf9\u4e0d\u540c\u6570\u636e\u683c\u5f0f\u7684\u7406\u89e3\u80fd\u529b\uff0c\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u878d\u5408\u8868\u683c\u4e0e\u51b3\u7b56\u6811\u7684\u7ed3\u6784\u5316\u77e5\u8bc6\u80fd\u663e\u8457\u63d0\u9ad8\u95ee\u7b54\u51c6\u786e\u7387\u3002"}}
{"id": "2509.09793", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.09793", "abs": "https://arxiv.org/abs/2509.09793", "authors": ["Vincent Herfeld", "Baudouin Denis de Senneville", "Arthur Leclaire", "Nicolas Papadakis"], "title": "From the Gradient-Step Denoiser to the Proximal Denoiser and their associated convergent Plug-and-Play algorithms", "comment": null, "summary": "In this paper we analyze the Gradient-Step Denoiser and its usage in\nPlug-and-Play algorithms. The Plug-and-Play paradigm of optimization algorithms\nuses off the shelf denoisers to replace a proximity operator or a gradient\ndescent operator of an image prior. Usually this image prior is implicit and\ncannot be expressed, but the Gradient-Step Denoiser is trained to be exactly\nthe gradient descent operator or the proximity operator of an explicit\nfunctional while preserving state-of-the-art denoising capabilities.", "AI": {"tldr": "\u63d0\u51fa\u5e76\u5206\u6790Gradient-Step Denoiser\uff0c\u5c06\u53bb\u566a\u5668\u8bbe\u8ba1\u4e3a\u5bf9\u5e94\u663e\u5f0f\u80fd\u91cf\u7684\u68af\u5ea6/\u8fd1\u7aef\u7b97\u5b50\uff0c\u5728\u4fdd\u6301\u4f18\u79c0\u53bb\u566a\u6027\u80fd\u540c\u65f6\u63d0\u5347PnP\u65b9\u6cd5\u7684\u53ef\u89e3\u91ca\u6027\u4e0e\u6536\u655b\u6027\u3002", "motivation": "\u4f20\u7edfPnP\u65b9\u6cd5\u4f9d\u8d56\u5f3a\u6027\u80fd\u7684\u9ed1\u7bb1\u53bb\u566a\u5668\uff0c\u4f46\u8fd9\u4e9b\u53bb\u566a\u5668\u901a\u5e38\u5bf9\u5e94\u7684\u56fe\u50cf\u5148\u9a8c\u662f\u9690\u5f0f\u7684\uff0c\u96be\u4ee5\u5206\u6790\u4e0e\u4fdd\u8bc1\u6536\u655b\u6027\u3002GSD\u65e8\u5728\u8bbe\u8ba1\u4e00\u4e2a\u65e2\u6709\u6570\u5b66\u53ef\u89e3\u91ca\u6027\uff08\u5bf9\u5e94\u663e\u5f0f\u80fd\u91cf\u6216\u68af\u5ea6\uff09\u7684\u53bb\u566a\u5668\uff0c\u540c\u65f6\u4fdd\u6301state-of-the-art\u7684\u53bb\u566a\u6548\u679c\uff0c\u4ece\u800c\u63d0\u5347PnP\u7b97\u6cd5\u7684\u7406\u8bba\u53ef\u63a7\u6027\u4e0e\u5b9e\u7528\u6027\u3002", "method": "\u4f5c\u8005\u901a\u8fc7\u6784\u9020\u5e76\u8bad\u7ec3GSD\u4f7f\u5176\u5728\u5c0f\u5e45\u5ea6\u566a\u58f0\u6761\u4ef6\u4e0b\u903c\u8fd1\u67d0\u4e00\u663e\u5f0f\u80fd\u91cf\u51fd\u6570\u7684\u68af\u5ea6\uff08\u6216\u8fd1\u7aef\u6620\u5c04\uff09\uff0c\u5e76\u5728PnP\u6846\u67b6\u4e2d\u7528GSD\u66ff\u6362\u4f20\u7edf\u7684\u8fd1\u7aef\u6216\u68af\u5ea6\u6b65\u7b97\u5b50\u3002\u7406\u8bba\u4e0a\u5206\u6790\u4e86GSD\u5bf9\u5e94\u7684\u80fd\u91cf\u51fd\u6570\u5b58\u5728\u6027\u4e0e\u6027\u8d28\uff0c\u5e76\u5728\u82e5\u5e72\u9006\u95ee\u9898\uff08\u5982\u53bb\u566a\u3001\u53bb\u6a21\u7cca\u3001\u91cd\u5efa\uff09\u4e2d\u505a\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff1a\u8bad\u7ec3\u5f97\u5230\u7684GSD\u65e2\u80fd\u5728\u6570\u503c\u4e0a\u903c\u8fd1\u663e\u5f0f\u51fd\u6570\u7684\u68af\u5ea6/\u8fd1\u7aef\u7b97\u5b50\uff0c\u53c8\u5728\u591a\u79cd\u9006\u95ee\u9898\u4e2d\u5b9e\u73b0\u4e0e\u6216\u8d85\u8fc7\u73b0\u6709PnP\u65b9\u6cd5\u7684\u6062\u590d\u8d28\u91cf\uff1b\u7406\u8bba\u5206\u6790\u652f\u6301\u8be5\u65b9\u6cd5\u7684\u6536\u655b\u6027\u548c\u7a33\u5b9a\u6027\uff0c\u4e14\u80fd\u5c06\u5148\u9a8c\u80fd\u91cf\u663e\u5f0f\u5316\uff0c\u4fbf\u4e8e\u8fdb\u4e00\u6b65\u5206\u6790\u4e0e\u8c03\u4f18\u3002", "conclusion": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86Gradient-Step Denoiser\uff08GSD\uff09\u5728Plug-and-Play\uff08PnP\uff09\u7b97\u6cd5\u4e2d\u7684\u5e94\u7528\u4e0e\u5206\u6790\uff0c\u8bc1\u660eGSD\u53ef\u4ee5\u4f5c\u4e3a\u663e\u5f0f\u80fd\u91cf\u51fd\u6570\u7684\u68af\u5ea6\u4e0b\u964d\u6216\u8fd1\u7aef\u7b97\u5b50\u4f7f\u7528\uff0c\u540c\u65f6\u4fdd\u6301\u5148\u8fdb\u7684\u53bb\u566a\u6027\u80fd\uff0c\u4ece\u800c\u5c06\u9690\u5f0f\u5148\u9a8c\u7684PnP\u65b9\u6cd5\u4e0e\u663e\u5f0f\u80fd\u91cf\u5efa\u6a21\u6865\u63a5\u8d77\u6765\u3002"}}
{"id": "2509.10165", "categories": ["cs.CR", "cs.CY"], "pdf": "https://arxiv.org/pdf/2509.10165", "abs": "https://arxiv.org/abs/2509.10165", "authors": ["Matthew J. Schneider", "James Bailie", "Dawn Iacobucci"], "title": "Why Data Anonymization Has Not Taken Off", "comment": "15 pages", "summary": "Companies are looking to data anonymization research $\\unicode{x2013}$\nincluding differential private and synthetic data methods $\\unicode{x2013}$ for\nsimple and straightforward compliance solutions. But data anonymization has not\ntaken off in practice because it is anything but simple to implement. For one,\nit requires making complex choices which are case dependent, such as the domain\nof the dataset to anonymize; the units to protect; the scope where the data\nprotection should extend to; and the standard of protection. Each variation of\nthese choices changes the very meaning, as well as the practical implications,\nof differential privacy (or of any other measure of data anonymization). Yet\ndifferential privacy is frequently being branded as the same privacy guarantee\nregardless of variations in these choices. Some data anonymization methods can\nbe effective, but only when the insights required are much larger than the unit\nof protection. Given that businesses care about profitability, any solution\nmust preserve the patterns between a firm's data and that profitability. As a\nresult, data anonymization solutions usually need to be bespoke and\ncase-specific, which reduces their scalability. Companies should not expect\neasy wins, but rather recognize that anonymization is just one approach to data\nprivacy with its own particular advantages and drawbacks, while the best\nstrategies jointly leverage the full range of approaches to data privacy and\nsecurity in combination.", "AI": {"tldr": "\u6570\u636e\u533f\u540d\u5316\u5e76\u975e\u4e07\u80fd\uff0c\u5b9e\u65bd\u590d\u6742\u4e14\u9700\u6309\u6848\u4f8b\u5b9a\u5236\uff0c\u4f01\u4e1a\u5e94\u7ed3\u5408\u591a\u79cd\u9690\u79c1\u5b89\u5168\u7b56\u7565\u800c\u975e\u4ec5\u4f9d\u8d56\u5dee\u5206\u9690\u79c1\u6216\u5408\u6210\u6570\u636e\u3002", "motivation": "\u4f01\u4e1a\u5e0c\u671b\u901a\u8fc7\u6570\u636e\u533f\u540d\u5316\uff08\u5dee\u5206\u9690\u79c1\u548c\u5408\u6210\u6570\u636e\uff09\u5b9e\u73b0\u5408\u89c4\u4e0e\u5546\u4e1a\u53ef\u884c\u6027\uff0c\u4f46\u5b9e\u8df5\u4e2d\u9047\u5230\u590d\u6742\u9009\u62e9\u4e0e\u6548\u679c\u5dee\u5f02\uff0c\u5bfc\u81f4\u91c7\u7528\u56f0\u96be\u3002", "method": "\u4f5c\u8005\u901a\u8fc7\u6982\u5ff5\u5206\u6790\u5bf9\u6bd4\u4e0d\u540c\u533f\u540d\u5316\u9009\u62e9\uff08\u5982\u4fdd\u62a4\u5355\u5143\u3001\u57df\u53ca\u4fdd\u62a4\u8303\u56f4\u548c\u4fdd\u62a4\u6807\u51c6\uff09\u5982\u4f55\u5f71\u54cd\u5dee\u5206\u9690\u79c1\u7b49\u65b9\u6cd5\u7684\u5b9e\u9645\u542b\u4e49\u4e0e\u6548\u679c\uff0c\u7ed3\u5408\u4e1a\u52a1\u9700\u6c42\u8ba8\u8bba\u53ef\u884c\u6027\u4e0e\u9650\u5236\u3002", "result": "\u4f5c\u8005\u6307\u51fa\uff1a1) \u533f\u540d\u5316\u5b9e\u65bd\u6d89\u53ca\u591a\u9879\u4e92\u76f8\u5173\u7684\u5173\u952e\u9009\u62e9\uff0c\u4f1a\u6539\u53d8\u9690\u79c1\u4fdd\u8bc1\u7684\u542b\u4e49\uff1b2) \u5728\u4fdd\u62a4\u5355\u5143\u63a5\u8fd1\u6240\u9700\u6d1e\u5bdf\u5c3a\u5ea6\u65f6\uff0c\u65b9\u6cd5\u6548\u679c\u4e0d\u8db3\uff1b3) \u56e0\u9700\u4fdd\u7559\u4e0e\u76c8\u5229\u76f8\u5173\u7684\u6a21\u5f0f\uff0c\u89e3\u51b3\u65b9\u6848\u5e38\u987b\u5b9a\u5236\u5316\uff0c\u964d\u4f4e\u53ef\u6269\u5c55\u6027\uff1b4) \u6700\u4f73\u7b56\u7565\u662f\u6df7\u5408\u591a\u79cd\u9690\u79c1\u4e0e\u5b89\u5168\u624b\u6bb5\u3002", "conclusion": "\u672c\u6587\u7ed3\u8bba\u4e3a\uff1a\u6570\u636e\u533f\u540d\u5316\u5e76\u975e\u901a\u7528\u7b80\u5355\u65b9\u6848\uff0c\u800c\u662f\u9700\u8981\u9488\u5bf9\u5177\u4f53\u573a\u666f\u5b9a\u5236\uff0c\u4e14\u5e38\u4e0e\u5176\u4ed6\u9690\u79c1/\u5b89\u5168\u63aa\u65bd\u7ed3\u5408\u4f7f\u7528\u3002"}}
{"id": "2509.09867", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.09867", "abs": "https://arxiv.org/abs/2509.09867", "authors": ["Yago Romano Matinez", "Jesse Roberts"], "title": "LLMs as Agentic Cooperative Players in Multiplayer UNO", "comment": null, "summary": "LLMs promise to assist humans -- not just by answering questions, but by\noffering useful guidance across a wide range of tasks. But how far does that\nassistance go? Can a large language model based agent actually help someone\naccomplish their goal as an active participant? We test this question by\nengaging an LLM in UNO, a turn-based card game, asking it not to win but\ninstead help another player to do so. We built a tool that allows decoder-only\nLLMs to participate as agents within the RLCard game environment. These models\nreceive full game-state information and respond using simple text prompts under\ntwo distinct prompting strategies. We evaluate models ranging from small (1B\nparameters) to large (70B parameters) and explore how model scale impacts\nperformance. We find that while all models were able to successfully outperform\na random baseline when playing UNO, few were able to significantly aid another\nplayer.", "AI": {"tldr": "\u5c06\u89e3\u7801\u5668\u578bLLM\u4f5c\u4e3aUNO\u4ee3\u7406\u53ef\u884c\uff0c\u4f46\u5927\u591a\u6570\u6a21\u578b\u96be\u4ee5\u663e\u8457\u5e2e\u52a9\u961f\u53cb\u8d62\uff1b\u89c4\u6a21\u6709\u76ca\u4f46\u6548\u679c\u6709\u9650\u3002", "motivation": "\u7814\u7a76LLM\u80fd\u5426\u4e0d\u4ec5\u56de\u7b54\u95ee\u9898\uff0c\u8fd8\u80fd\u4f5c\u4e3a\u4e3b\u52a8\u53c2\u4e0e\u8005\u5728\u5177\u4f53\u4efb\u52a1\u4e2d\u4e3a\u4eba\u7c7b\u63d0\u4f9b\u6709\u6548\u6307\u5bfc\u4e0e\u534f\u52a9\uff0c\u91cf\u5316\u5176\u5728\u5408\u4f5c\u6027\u535a\u5f08\u4efb\u52a1\u4e2d\u7684\u80fd\u529b\u3002", "method": "\u642d\u5efa\u5de5\u5177\u8ba9\u89e3\u7801\u5668\u578bLLM\u63a5\u6536\u5b8c\u6574\u535a\u5f08\u72b6\u6001\u5e76\u901a\u8fc7\u4e24\u79cd\u63d0\u793a\u7b56\u7565\u4ee5\u6587\u672c\u5f62\u5f0f\u54cd\u5e94\uff0c\u5728RLCard UNO\u73af\u5883\u4e2d\u8fdb\u884c\u56de\u5408\u5236\u4ea4\u4e92\uff1b\u8bc4\u4f30\u89c4\u6a21\u4ece1B\u523070B\u7684\u6a21\u578b\uff0c\u5e76\u4e0e\u968f\u673a\u57fa\u7ebf\u6bd4\u8f83\u3002", "result": "\u6240\u6709\u6a21\u578b\u5728\u6253UNO\u65f6\u5747\u8d85\u8fc7\u968f\u673a\u57fa\u7ebf\uff0c\u4f46\u53ea\u6709\u5c11\u6570\u6a21\u578b\u80fd\u663e\u8457\u63d0\u9ad8\u53e6\u4e00\u73a9\u5bb6\u7684\u83b7\u80dc\u6982\u7387\uff1b\u6a21\u578b\u89c4\u6a21\u5bf9\u6027\u80fd\u6709\u5f71\u54cd\u4f46\u5e76\u975e\u4e07\u80fd\u3002", "conclusion": "\u672c\u6587\u5c55\u793a\u4e86\u5c06\u89e3\u7801\u5668\u578b\u5927\u8bed\u8a00\u6a21\u578b\u63a5\u5165RLCard UNO\u73af\u5883\u4f5c\u4e3a\u4ee3\u7406\u7684\u53ef\u884c\u6027\uff0c\u4f46\u603b\u4f53\u4e0a\u6a21\u578b\u5f88\u96be\u4f5c\u4e3a\u534f\u52a9\u8005\u663e\u8457\u5e2e\u52a9\u540c\u4f34\u83b7\u80dc\u3002"}}
{"id": "2509.09799", "categories": ["cs.LG", "cs.HC"], "pdf": "https://arxiv.org/pdf/2509.09799", "abs": "https://arxiv.org/abs/2509.09799", "authors": ["Mansi Sharma", "Alexandre Duchevet", "Florian Daiber", "Jean-Paul Imbert", "Maurice Rekrut"], "title": "Distinguishing Startle from Surprise Events Based on Physiological Signals", "comment": null, "summary": "Unexpected events can impair attention and delay decision-making, posing\nserious safety risks in high-risk environments such as aviation. In particular,\nreactions like startle and surprise can impact pilot performance in different\nways, yet are often hard to distinguish in practice. Existing research has\nlargely studied these reactions separately, with limited focus on their\ncombined effects or how to differentiate them using physiological data. In this\nwork, we address this gap by distinguishing between startle and surprise events\nbased on physiological signals using machine learning and multi-modal fusion\nstrategies. Our results demonstrate that these events can be reliably\npredicted, achieving a highest mean accuracy of 85.7% with SVM and Late Fusion.\nTo further validate the robustness of our model, we extended the evaluation to\ninclude a baseline condition, successfully differentiating between Startle,\nSurprise, and Baseline states with a highest mean accuracy of 74.9% with\nXGBoost and Late Fusion.", "AI": {"tldr": "\u901a\u8fc7\u591a\u6a21\u6001\u751f\u7406\u4fe1\u53f7\u4e0eLate Fusion\u7b56\u7565\uff0cSVM\u5728\u4e8c\u5206\u7c7b\u8fbe85.7%\u3001XGBoost\u5728\u4e09\u5206\u7c7b\u8fbe74.9%\uff0c\u5b9e\u73b0\u5bf9startle\u3001surprise\u53ca\u57fa\u7ebf\u72b6\u6001\u7684\u6709\u6548\u533a\u5206\u3002", "motivation": "\u5728\u9ad8\u98ce\u9669\u73af\u5883\uff08\u5982\u822a\u7a7a\uff09\u4e2d\uff0c\u610f\u5916\u4e8b\u4ef6\u4f1a\u5f15\u8d77\u4e0d\u540c\u7c7b\u578b\u7684\u53cd\u5e94\uff08startle\u4e0esurprise\uff09\uff0c\u8fd9\u4e9b\u53cd\u5e94\u4f1a\u5f71\u54cd\u6ce8\u610f\u529b\u548c\u51b3\u7b56\u5b89\u5168\u3002\u73b0\u6709\u7814\u7a76\u5e38\u5206\u522b\u7814\u7a76\u4e24\u79cd\u53cd\u5e94\uff0c\u7f3a\u4e4f\u8054\u5408\u5206\u6790\u53ca\u57fa\u4e8e\u751f\u7406\u4fe1\u53f7\u7684\u533a\u5206\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u591a\u6a21\u6001\u751f\u7406\u4fe1\u53f7\uff08\u672a\u5177\u4f53\u5217\u51fa\u4fe1\u53f7\u7c7b\u578b\uff09\u7ed3\u5408\u673a\u5668\u5b66\u4e60\u5206\u7c7b\u5668\uff08SVM\u3001XGBoost\u7b49\uff09\u548cLate Fusion\u878d\u5408\u7b56\u7565\u8fdb\u884c\u5224\u522b\u3002\u5206\u522b\u8fdb\u884c\u4e86\u4e8c\u5206\u7c7b\uff08Startle vs Surprise\uff09\u548c\u4e09\u5206\u7c7b\uff08Startle vs Surprise vs Baseline\uff09\u5b9e\u9a8c\u5e76\u62a5\u544a\u51c6\u786e\u7387\u3002", "result": "\u4e8c\u5206\u7c7b\u4efb\u52a1\u6700\u9ad8\u5e73\u5747\u51c6\u786e\u738785.7%\uff08SVM + Late Fusion\uff09\uff1b\u4e09\u5206\u7c7b\u4efb\u52a1\u6700\u9ad8\u5e73\u5747\u51c6\u786e\u738774.9%\uff08XGBoost + Late Fusion\uff09\uff0c\u8868\u660e\u65b9\u6cd5\u5177\u6709\u8f83\u597d\u533a\u5206\u80fd\u529b\u548c\u4e00\u5b9a\u9c81\u68d2\u6027\u3002", "conclusion": "\u672c\u6587\u8868\u660e\u57fa\u4e8e\u751f\u7406\u4fe1\u53f7\u548c\u591a\u6a21\u6001\u878d\u5408\u7684\u65b9\u6cd5\u53ef\u4ee5\u6709\u6548\u533a\u5206\u60ca\u8df3\uff08startle\uff09\u4e0e\u60ca\u8bb6\uff08surprise\uff09\u53cd\u5e94\uff0c\u5e76\u5728\u5305\u62ec\u57fa\u7ebf\u6761\u4ef6\u7684\u4e09\u5206\u7c7b\u4efb\u52a1\u4e2d\u4ecd\u8868\u73b0\u7a33\u5065\u3002"}}
{"id": "2509.10206", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.10206", "abs": "https://arxiv.org/abs/2509.10206", "authors": ["Federica Uccello", "Simin Nadjm-Tehrani"], "title": "Investigating Feature Attribution for 5G Network Intrusion Detection", "comment": null, "summary": "With the rise of fifth-generation (5G) networks in critical applications, it\nis urgent to move from detection of malicious activity to systems capable of\nproviding a reliable verdict suitable for mitigation. In this regard,\nunderstanding and interpreting machine learning (ML) models' security alerts is\ncrucial for enabling actionable incident response orchestration. Explainable\nArtificial Intelligence (XAI) techniques are expected to enhance trust by\nproviding insights into why alerts are raised. A dominant approach\nstatistically associates feature sets that can be correlated to a given alert.\nThis paper starts by questioning whether such attribution is relevant for\nfuture generation communication systems, and investigates its merits in\ncomparison with an approach based on logical explanations. We extensively study\ntwo methods, SHAP and VoTE-XAI, by analyzing their interpretations of alerts\ngenerated by an XGBoost model in three different use cases with several 5G\ncommunication attacks. We identify three metrics for assessing explanations:\nsparsity, how concise they are; stability, how consistent they are across\nsamples from the same attack type; and efficiency, how fast an explanation is\ngenerated. As an example, in a 5G network with 92 features, 6 were deemed\nimportant by VoTE-XAI for a Denial of Service (DoS) variant, ICMPFlood, while\nSHAP identified over 20. More importantly, we found a significant divergence\nbetween features selected by SHAP and VoTE-XAI. However, none of the top-ranked\nfeatures selected by SHAP were missed by VoTE-XAI. When it comes to efficiency\nof providing interpretations, we found that VoTE-XAI is significantly more\nresponsive, e.g. it provides a single explanation in under 0.002 seconds, in a\nhigh-dimensional setting (478 features).", "AI": {"tldr": "\u57285G\u5b89\u5168\u544a\u8b66\u89e3\u91ca\u4e2d\uff0c\u57fa\u4e8e\u903b\u8f91\u7684VoTE-XAI\u6bd4\u7edf\u8ba1\u7684SHAP\u66f4\u7b80\u6d01\u3001\u7a33\u5b9a\u4e14\u9ad8\u6548\uff0c\u9002\u5408\u5b9e\u65f6\u53ef\u64cd\u4f5c\u54cd\u5e94\u3002", "motivation": "\u968f\u77405G\u5728\u5173\u952e\u573a\u666f\u666e\u53ca\uff0c\u9700\u8981\u4ece\u68c0\u6d4b\u6076\u610f\u6d3b\u52a8\u8fdb\u5316\u5230\u80fd\u63d0\u4f9b\u53ef\u7528\u4e8e\u7f13\u89e3\u7684\u53ef\u9760\u5224\u51b3\uff0c\u56e0\u800c\u9700\u8981\u7406\u89e3\u548c\u89e3\u91caML\u6a21\u578b\u7684\u5b89\u5168\u544a\u8b66\u4ee5\u652f\u6301\u53ef\u64cd\u4f5c\u7684\u4e8b\u4ef6\u54cd\u5e94\u3002\u4f5c\u8005\u8d28\u7591\u73b0\u6709\u7edf\u8ba1\u5f52\u56e0\u662f\u5426\u9002\u7528\u4e8e\u4e0b\u4e00\u4ee3\u901a\u4fe1\u7cfb\u7edf\uff0c\u5e76\u63a2\u7d22\u903b\u8f91\u89e3\u91ca\u7684\u4ef7\u503c\u3002", "method": "\u4f5c\u8005\u7528XGBoost\u751f\u6210\u544a\u8b66\uff0c\u5bf9\u6bd4\u4e24\u79cdXAI\u65b9\u6cd5\uff1a\u7edf\u8ba1\u5173\u8054\u7684SHAP\u4e0e\u57fa\u4e8e\u903b\u8f91\u7684VoTE-XAI\u3002\u5728\u4e09\u4e2a\u7528\u4f8b\u548c\u591a\u79cd5G\u653b\u51fb\u4e0a\u8bc4\u4f30\u89e3\u91ca\u7684\u7a00\u758f\u6027\u3001\u7a33\u5b9a\u6027\u548c\u6548\u7387\uff0c\u5e76\u91cf\u5316\u4e86\u7279\u5f81\u6570\u91cf\u548c\u54cd\u5e94\u65f6\u95f4\u7b49\u6307\u6807\u3002", "result": "\u572892\u7ef4\u7279\u5f81\u76845G\u7f51\u7edc\u4e2d\uff0c\u9488\u5bf9ICMPFlood DoS\u53d8\u4f53\uff0cVoTE-XAI\u53ea\u6807\u8bc6\u4e866\u4e2a\u91cd\u8981\u7279\u5f81\uff0c\u800cSHAP\u8bc6\u522b\u4e86\u8d85\u8fc720\u4e2a\u3002\u4e24\u8005\u5728\u9009\u53d6\u7279\u5f81\u4e0a\u663e\u8457\u5206\u6b67\uff0c\u4f46VoTE-XAI\u672a\u9057\u6f0fSHAP\u7684\u9876\u7ea7\u7279\u5f81\u3002VoTE-XAI\u5728\u9ad8\u7ef4\uff08478\u7279\u5f81\uff09\u573a\u666f\u4e0b\u5355\u6b21\u89e3\u91ca\u65f6\u95f4\u4f4e\u4e8e0.002\u79d2\uff0c\u663e\u8457\u66f4\u5feb\u3002", "conclusion": "\u8bba\u6587\u7ed3\u8bba\u662f\u903b\u8f91\u89e3\u91ca\u65b9\u6cd5\uff08VoTE-XAI\uff09\u5728\u7a00\u758f\u6027\u3001\u7a33\u5b9a\u6027\u548c\u54cd\u5e94\u6548\u7387\u65b9\u9762\u4f18\u4e8e\u7edf\u8ba1\u5f52\u56e0\u65b9\u6cd5\uff08SHAP\uff09\uff0c\u5c24\u5176\u5728\u9ad8\u7ef45G\u5b89\u5168\u544a\u8b66\u573a\u666f\u4e2d\u66f4\u5177\u5b9e\u7528\u4ef7\u503c\u3002"}}
{"id": "2509.09838", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.09838", "abs": "https://arxiv.org/abs/2509.09838", "authors": ["Reza Asad", "Reza Babanezhad", "Sharan Vaswani"], "title": "Revisiting Actor-Critic Methods in Discrete Action Off-Policy Reinforcement Learning", "comment": null, "summary": "Value-based approaches such as DQN are the default methods for off-policy\nreinforcement learning with discrete-action environments such as Atari. Common\npolicy-based methods are either on-policy and do not effectively learn from\noff-policy data (e.g. PPO), or have poor empirical performance in the\ndiscrete-action setting (e.g. SAC). Consequently, starting from discrete SAC\n(DSAC), we revisit the design of actor-critic methods in this setting. First,\nwe determine that the coupling between the actor and critic entropy is the\nprimary reason behind the poor performance of DSAC. We demonstrate that by\nmerely decoupling these components, DSAC can have comparable performance as\nDQN. Motivated by this insight, we introduce a flexible off-policy actor-critic\nframework that subsumes DSAC as a special case. Our framework allows using an\nm-step Bellman operator for the critic update, and enables combining standard\npolicy optimization methods with entropy regularization to instantiate the\nresulting actor objective. Theoretically, we prove that the proposed methods\ncan guarantee convergence to the optimal regularized value function in the\ntabular setting. Empirically, we demonstrate that these methods can approach\nthe performance of DQN on standard Atari games, and do so even without entropy\nregularization or explicit exploration.", "AI": {"tldr": "\u5c06actor\u4e0ecritic\u7684\u71b5\u8026\u5408\u89c6\u4e3aDSAC\u6027\u80fd\u5dee\u7684\u5173\u952e\uff0c\u89e3\u8026\u540e\u6784\u5efa\u4e86\u53ef\u4f7f\u7528m\u6b65Bellman\u548c\u591a\u79cd\u7b56\u7565\u4f18\u5316\u7684\u6cdb\u5316off-policy actor-critic\u6846\u67b6\uff0c\u7406\u8bba\u4fdd\u8bc1\u6536\u655b\u5e76\u5728Atari\u4e0a\u63a5\u8fd1DQN\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u79bb\u6563\u52a8\u4f5c\u7684\u79bb\u7ebf/\u79bb\u6563off-policy\u5f3a\u5316\u5b66\u4e60\u5e38\u7528DQN\u7c7b\u503c\u65b9\u6cd5\uff1b\u73b0\u6709\u7b56\u7565\u65b9\u6cd5\u8981\u4e48\u4e3aon-policy\uff08\u5982PPO\uff09\u4e0d\u64c5\u957f\u5229\u7528off-policy\u6570\u636e\uff0c\u8981\u4e48\u5728\u79bb\u6563\u52a8\u4f5c\u4e0b\u8868\u73b0\u5dee\uff08\u5982SAC\uff09\u3002\u56e0\u6b64\u7814\u7a76\u5982\u4f55\u5728\u79bb\u6563\u52a8\u4f5c\u4e0b\u8ba9off-policy actor-critic\u65b9\u6cd5\u8fbe\u5230\u4e0eDQN\u53ef\u6bd4\u7684\u6027\u80fd\u3002", "method": "\u4eceDSAC\u51fa\u53d1\uff0c\u8bc6\u522b\u5e76\u89e3\u8026actor\u4e0ecritic\u7684\u71b5\u9879\uff1b\u63d0\u51fa\u4e00\u4e2a\u6cdb\u5316\u7684off-policy actor-critic\u6846\u67b6\uff0c\u5141\u8bb8\u4f7f\u7528m\u6b65Bellman\u66f4\u65b0critic\uff0c\u5e76\u5c06\u4efb\u610f\u7b56\u7565\u4f18\u5316\u65b9\u6cd5\u4e0e\u71b5\u6b63\u5219\u76f8\u7ed3\u5408\u4ee5\u6784\u9020actor\u76ee\u6807\uff1b\u7406\u8bba\u4e0a\u5728tabular\u60c5\u666f\u4e0b\u8bc1\u660e\u6536\u655b\u6027\uff1b\u5728Atari\u57fa\u51c6\u4e0a\u8fdb\u884c\u5bf9\u6bd4\u5b9e\u9a8c\uff08\u542b\u65e0\u71b5\u6b63\u5219\u60c5\u5f62\uff09\u3002", "result": "\u7eaf\u7cb9\u901a\u8fc7\u89e3\u8026actor\u548ccritic\u7684\u71b5\u9879\uff0cDSAC\u6027\u80fd\u5927\u5e45\u63d0\u5347\uff0c\u53ef\u4e0eDQN\u63a5\u8fd1\uff1b\u63d0\u51fa\u7684\u901a\u7528\u6846\u67b6\u5728\u7406\u8bba\u4e0a\u4fdd\u8bc1\u6536\u655b\u5e76\u5728Atari\u4e0a\u53d6\u5f97\u63a5\u8fd1DQN\u7684\u5b9e\u8bc1\u7ed3\u679c\uff0c\u4e14\u5728\u65e0\u71b5\u6b63\u5219\u6216\u65e0\u663e\u5f0f\u63a2\u7d22\u4e0b\u4e5f\u80fd\u8868\u73b0\u826f\u597d\u3002", "conclusion": "\u672c\u6587\u7814\u7a76\u79bb\u6563\u52a8\u4f5c\u4e0b\u7684off-policy actor-critic\u65b9\u6cd5\uff0c\u6307\u51faDSAC\u6027\u80fd\u5dee\u4e3b\u8981\u7531actor\u4e0ecritic\u71b5\u8026\u5408\u5f15\u8d77\uff0c\u63d0\u51fa\u5c06\u5176\u89e3\u8026\u53ef\u663e\u8457\u63d0\u5347\u6027\u80fd\uff1b\u6784\u5efa\u4e86\u4e00\u4e2a\u66f4\u901a\u7528\u7684\u6846\u67b6\uff0c\u5bb9\u8bb8m\u6b65Bellman\u7b97\u5b50\u548c\u4e0d\u540c\u7b56\u7565\u4f18\u5316+\u71b5\u6b63\u5219\u5316\u7684\u7ec4\u5408\uff0c\u5e76\u5728\u8868\u683c\u73af\u5883\u4e0b\u8bc1\u660e\u6536\u655b\u6027\uff1b\u5b9e\u9a8c\u8bc1\u660e\u65b9\u6cd5\u80fd\u5728Atari\u4e0a\u63a5\u8fd1DQN\u8868\u73b0\uff0c\u5373\u4f7f\u5728\u65e0\u71b5\u6b63\u5219\u6216\u663e\u5f0f\u63a2\u7d22\u65f6\u4e5f\u80fd\u53d6\u5f97\u826f\u597d\u6548\u679c\u3002"}}
{"id": "2509.10213", "categories": ["cs.CR", "D.4.6; K.6.5"], "pdf": "https://arxiv.org/pdf/2509.10213", "abs": "https://arxiv.org/abs/2509.10213", "authors": ["Ming Zhou", "Xupu Hu", "Zhihao Wang", "Haining Wang", "Hui Wen", "Limin Sun", "Peng Zhang"], "title": "Dynamic Vulnerability Patching for Heterogeneous Embedded Systems Using Stack Frame Reconstruction", "comment": "Accepted/To be published in ACM CCS 2025", "summary": "Existing dynamic vulnerability patching techniques are not well-suited for\nembedded devices, especially mission-critical ones such as medical equipment,\nas they have limited computational power and memory but uninterrupted service\nrequirements. Those devices often lack sufficient idle memory for dynamic\npatching, and the diverse architectures of embedded systems further complicate\nthe creation of patch triggers that are compatible across various system\nkernels and hardware platforms. To address these challenges, we propose a hot\npatching framework called StackPatch that facilitates patch development based\non stack frame reconstruction. StackPatch introduces different triggering\nstrategies to update programs stored in memory units. We leverage the\nexception-handling mechanisms commonly available in embedded processors to\nenhance StackPatch's adaptability across different processor architectures for\ncontrol flow redirection. We evaluated StackPatch on embedded devices featuring\nthree major microcontroller (MCU) architectures: ARM, RISC-V, and Xtensa. In\nthe experiments, we used StackPatch to successfully fix 102 publicly disclosed\nvulnerabilities in real-time operating systems (RTOS). We applied patching to\nmedical devices, soft programmable logic controllers (PLCs), and network\nservices, with StackPatch consistently completing each vulnerability\nremediation in less than 260 MCU clock cycles.", "AI": {"tldr": "StackPatch\u901a\u8fc7\u6808\u5e27\u91cd\u6784\u548c\u5f02\u5e38\u673a\u5236\u89e6\u53d1\uff0c\u5b9e\u73b0\u4e86\u5bf9ARM\u3001RISC-V\u3001Xtensa\u5d4c\u5165\u5f0f\u8bbe\u5907\u7684\u5feb\u901f\u3001\u8f7b\u91cf\u7ea7\u70ed\u4fee\u8865\uff0c\u80fd\u5728\u4e0d\u4e2d\u65ad\u670d\u52a1\u7684\u524d\u63d0\u4e0b\u4fee\u590dRTOS\u4e2d\u5927\u91cf\u6f0f\u6d1e\uff0c\u5355\u6b21\u4fee\u8865\u8017\u65f6\u6781\u77ed\u3002", "motivation": "\u5d4c\u5165\u5f0f\u3001\u5c24\u5176\u662f\u5173\u952e\u4efb\u52a1\u8bbe\u5907\uff08\u5982\u533b\u7597\u8bbe\u5907\uff09\u5bf9\u53ef\u7528\u5185\u5b58\u548c\u8ba1\u7b97\u80fd\u529b\u6709\u9650\uff0c\u65e0\u6cd5\u91c7\u7528\u4f20\u7edf\u52a8\u6001\u4fee\u8865\u65b9\u6cd5\uff1b\u8bbe\u5907\u9700\u8fde\u7eed\u8fd0\u884c\uff0c\u4e14\u67b6\u6784\u591a\u6837\u5316\u4f7f\u5f97\u901a\u7528\u89e6\u53d1\u5668\u96be\u4ee5\u5b9e\u73b0\uff0c\u56e0\u800c\u9700\u8981\u4e00\u79cd\u8f7b\u91cf\u3001\u8de8\u67b6\u6784\u4e14\u4e0d\u4e2d\u65ad\u670d\u52a1\u7684\u70ed\u4fee\u8865\u65b9\u6848\u3002", "method": "\u901a\u8fc7\u91cd\u5efa\u6808\u5e27\u5e76\u5229\u7528\u5d4c\u5165\u5f0f\u5904\u7406\u5668\u7684\u5f02\u5e38\u5904\u7406\u673a\u5236\u4f5c\u4e3a\u89e6\u53d1\u624b\u6bb5\uff0cStackPatch\u5b9e\u73b0\u4e86\u5bf9\u5185\u5b58\u4e2d\u7a0b\u5e8f\u7684\u66f4\u65b0\u3002\u63d0\u51fa\u4e86\u591a\u79cd\u89e6\u53d1\u7b56\u7565\u4ee5\u9002\u914d\u4e0d\u540c\u786c\u4ef6\u548c\u5185\u6838\u73af\u5883\uff0c\u5e76\u5728ARM\u3001RISC-V\u3001Xtensa\u4e09\u5927\u67b6\u6784\u4e0a\u5b9e\u73b0\u3002", "result": "\u5728\u5b9e\u9a8c\u4e2d\uff0cStackPatch\u6210\u529f\u4fee\u590d\u4e86\u5b9e\u65f6\u64cd\u4f5c\u7cfb\u7edf\u4e2d102\u4e2a\u516c\u5f00\u6f0f\u6d1e\uff0c\u9002\u7528\u4e8e\u533b\u7597\u8bbe\u5907\u3001\u53ef\u7f16\u7a0b\u903b\u8f91\u63a7\u5236\u5668\u548c\u7f51\u7edc\u670d\u52a1\u7b49\u573a\u666f\uff1b\u6bcf\u6b21\u4fee\u8865\u5728\u6240\u6709\u6d4b\u8bd5MCU\u4e0a\u5747\u5728260\u4e2a\u65f6\u949f\u5468\u671f\u5185\u5b8c\u6210\u3002", "conclusion": "StackPatch\u662f\u4e00\u4e2a\u57fa\u4e8e\u6808\u5e27\u91cd\u6784\u7684\u70ed\u4fee\u8865\u6846\u67b6\uff0c\u9002\u7528\u4e8e\u8d44\u6e90\u53d7\u9650\u4e14\u9700\u6301\u7eed\u8fd0\u884c\u7684\u5d4c\u5165\u5f0f\u8bbe\u5907\uff0c\u80fd\u5728\u591a\u79cdMCU\u67b6\u6784\u4e0a\u8fdb\u884c\u63a7\u5236\u6d41\u91cd\u5b9a\u5411\u5e76\u5feb\u901f\u4fee\u590d\u6f0f\u6d1e\u3002"}}
{"id": "2509.09919", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.09919", "abs": "https://arxiv.org/abs/2509.09919", "authors": ["Franklin Yiu", "Mohan Lu", "Nina Li", "Kevin Joseph", "Tianxu Zhang", "Julian Togelius", "Timothy Merino", "Sam Earle"], "title": "A Markovian Framing of WaveFunctionCollapse for Procedurally Generating Aesthetically Complex Environments", "comment": null, "summary": "Procedural content generation often requires satisfying both\ndesigner-specified objectives and adjacency constraints implicitly imposed by\nthe underlying tile set. To address the challenges of jointly optimizing both\nconstraints and objectives, we reformulate WaveFunctionCollapse (WFC) as a\nMarkov Decision Process (MDP), enabling external optimization algorithms to\nfocus exclusively on objective maximization while leveraging WFC's propagation\nmechanism to enforce constraint satisfaction. We empirically compare optimizing\nthis MDP to traditional evolutionary approaches that jointly optimize global\nmetrics and local tile placement. Across multiple domains with various\ndifficulties, we find that joint optimization not only struggles as task\ncomplexity increases, but consistently underperforms relative to optimization\nover the WFC-MDP, underscoring the advantages of decoupling local constraint\nsatisfaction from global objective optimization.", "AI": {"tldr": "\u628aWFC\u5f53MDP\uff0c\u7528WFC\u4fdd\u8bc1\u5c40\u90e8\u7ea6\u675f\uff0c\u5916\u90e8\u4f18\u5316\u5668\u53ea\u5173\u5fc3\u5168\u5c40\u76ee\u6807\uff0c\u7ed3\u679c\u6bd4\u540c\u65f6\u4f18\u5316\u7ea6\u675f\u548c\u76ee\u6807\u7684\u65b9\u6cd5\u597d\u3002", "motivation": "\u7a0b\u5e8f\u5316\u5185\u5bb9\u751f\u6210\u9700\u8981\u540c\u65f6\u6ee1\u8db3\u8bbe\u8ba1\u76ee\u6807\u4e0e\u56fe\u5757\u90bb\u63a5\u7ea6\u675f\uff0c\u76f4\u63a5\u8054\u5408\u4f18\u5316\uff08\u540c\u65f6\u8003\u8651\u5c40\u90e8\u7ea6\u675f\u548c\u5168\u5c40\u76ee\u6807\uff09\u5728\u590d\u6742\u4efb\u52a1\u4e0b\u6548\u679c\u5dee\u3001\u5b89\u5168\u6536\u655b\u6162\u3002\u4f5c\u8005\u5e0c\u671b\u901a\u8fc7\u5c06\u5c40\u90e8\u7ea6\u675f\u4ea4\u7ed9WFC\u4f20\u64ad\u5904\u7406\uff0c\u89e3\u8026\u51fa\u4e00\u4e2a\u53ea\u9700\u4f18\u5316\u5168\u5c40\u76ee\u6807\u7684MDP\uff0c\u4ece\u800c\u63d0\u9ad8\u4f18\u5316\u6548\u7387\u548c\u8d28\u91cf\u3002", "method": "\u628aWaveFunctionCollapse\u5efa\u6a21\u4e3a\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff1a\u72b6\u6001\u8868\u793a\u5f53\u524d\u5df2\u786e\u5b9a\u7684\u683c\u5b50\u4e0e\u5019\u9009\u56fe\u5757\u96c6\u5408\uff0c\u52a8\u4f5c\u4e3a\u9009\u62e9\u5728\u67d0\u4f4d\u7f6e\u653e\u7f6e\u67d0\u56fe\u5757\uff0c\u8f6c\u79fb\u7531WFC\u4f20\u64ad\u5b8c\u6210\uff08\u4e0d\u53ef\u884c\u52a8\u4f5c\u88ab\u6982\u7387\u6216\u7ea6\u675f\u8fc7\u6ee4\uff09\uff0c\u5956\u52b1\u7531\u8bbe\u8ba1\u76ee\u6807\u7ed9\u51fa\uff1b\u7136\u540e\u4f7f\u7528\u5916\u90e8\u9ed1\u7bb1\u4f18\u5316\u5668\uff08\u5982\u8fdb\u5316\u7b97\u6cd5\u3001\u5f3a\u5316\u5b66\u4e60\u6216\u968f\u673a\u641c\u7d22\uff09\u5728\u8be5MDP\u4e0a\u4f18\u5316\u7d2f\u8ba1\u5956\u52b1\u3002", "result": "\u5728\u591a\u4e2a\u4e0d\u540c\u96be\u5ea6\u548c\u9886\u57df\u7684\u5b9e\u9a8c\u4e2d\uff0c\u57fa\u4e8eWFC\u7684MDP\u4f18\u5316\u5728\u8fbe\u5230\u76ee\u6807\u503c\u3001\u6536\u655b\u901f\u5ea6\u548c\u9c81\u68d2\u6027\u4e0a\u5747\u4f18\u4e8e\u4f20\u7edf\u7684\u8054\u5408\u8fdb\u5316\u4f18\u5316\uff1b\u8054\u5408\u4f18\u5316\u968f\u7740\u4efb\u52a1\u590d\u6742\u5ea6\u4e0a\u5347\u8868\u73b0\u663e\u8457\u4e0b\u964d\u3002", "conclusion": "\u5c06WFC\u91cd\u6784\u4e3aMDP\u5e76\u7528\u5916\u90e8\u4f18\u5316\u5668\u53ea\u4f18\u5316\u76ee\u6807\u3001\u7531WFC\u4f20\u64ad\u4fdd\u8bc1\u7ea6\u675f\uff0c\u662f\u53ef\u884c\u4e14\u4f18\u4e8e\u8054\u5408\u4f18\u5316\u7684\u65b9\u6848\u3002"}}
{"id": "2509.09843", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.09843", "abs": "https://arxiv.org/abs/2509.09843", "authors": ["Jiajun Shen", "Yufei Jin", "Yi He", "Xingquan Zhu"], "title": "HGEN: Heterogeneous Graph Ensemble Networks", "comment": "The paper is in proceedings of the 34th IJCAI Conference, 2025", "summary": "This paper presents HGEN that pioneers ensemble learning for heterogeneous\ngraphs. We argue that the heterogeneity in node types, nodal features, and\nlocal neighborhood topology poses significant challenges for ensemble learning,\nparticularly in accommodating diverse graph learners. Our HGEN framework\nensembles multiple learners through a meta-path and transformation-based\noptimization pipeline to uplift classification accuracy. Specifically, HGEN\nuses meta-path combined with random dropping to create Allele Graph Neural\nNetworks (GNNs), whereby the base graph learners are trained and aligned for\nlater ensembling. To ensure effective ensemble learning, HGEN presents two key\ncomponents: 1) a residual-attention mechanism to calibrate allele GNNs of\ndifferent meta-paths, thereby enforcing node embeddings to focus on more\ninformative graphs to improve base learner accuracy, and 2) a\ncorrelation-regularization term to enlarge the disparity among embedding\nmatrices generated from different meta-paths, thereby enriching base learner\ndiversity. We analyze the convergence of HGEN and attest its higher\nregularization magnitude over simple voting. Experiments on five heterogeneous\nnetworks validate that HGEN consistently outperforms its state-of-the-art\ncompetitors by substantial margin.", "AI": {"tldr": "HGEN\u4e3a\u5f02\u6784\u56fe\u8bbe\u8ba1\u4e86\u5143\u8def\u5f84+\u968f\u673a\u4e22\u5f03\u751f\u6210\u7684\u591a\u6837\u5316GNN\u5b50\u6a21\u578b\uff0c\u914d\u5408\u6b8b\u5dee\u6ce8\u610f\u529b\u4e0e\u76f8\u5173\u6027\u6b63\u5219\u5316\uff0c\u63d0\u5347\u57fa\u5b66\u4e60\u5668\u51c6\u786e\u6027\u4e0e\u591a\u6837\u6027\uff0c\u4ece\u800c\u5728\u8282\u70b9\u5206\u7c7b\u4efb\u52a1\u4e0a\u53d6\u5f97\u9886\u5148\u6548\u679c\u3002", "motivation": "\u5f02\u6784\u56fe\u4e2d\u8282\u70b9\u7c7b\u578b\u3001\u5c5e\u6027\u4e0e\u5c40\u90e8\u62d3\u6251\u5dee\u5f02\u5927\uff0c\u5355\u4e00GNN\u96be\u4ee5\u517c\u987e\u4e0d\u540c\u7ed3\u6784\u4fe1\u606f\uff0c\u56e0\u800c\u9700\u8981\u4e00\u79cd\u80fd\u6574\u5408\u591a\u6837\u5316\u56fe\u5b66\u4e60\u5668\u5e76\u4fdd\u8bc1\u51c6\u786e\u6027\u4e0e\u591a\u6837\u6027\u7684\u96c6\u6210\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u5143\u8def\u5f84\u4e0e\u968f\u673a\u4e22\u5f03\u751f\u6210Allele GNNs\u7684\u6846\u67b6\uff0c\u91c7\u7528\u6b8b\u5dee\u6ce8\u610f\u529b\u5bf9\u9f50\u4e0d\u540c\u5143\u8def\u5f84\u7684\u5b50\u6a21\u578b\u5e76\u7528\u76f8\u5173\u6027\u6b63\u5219\u5316\u6269\u5927\u5d4c\u5165\u77e9\u9635\u95f4\u5dee\u5f02\uff0c\u6700\u7ec8\u901a\u8fc7\u4f18\u5316\u7ba1\u9053\u8fdb\u884c\u96c6\u6210\u3002", "result": "\u7406\u8bba\u4e0a\u5206\u6790\u4e86HGEN\u7684\u6536\u655b\u6027\u5e76\u663e\u793a\u5176\u6b63\u5219\u5316\u5f3a\u5ea6\u9ad8\u4e8e\u7b80\u5355\u6295\u7968\uff1b\u5728\u4e94\u4e2a\u5f02\u6784\u7f51\u7edc\u4e0a\u7684\u5b9e\u9a8c\u8bc1\u660eHGEN\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\u3002", "conclusion": "HGEN\u901a\u8fc7\u7ed3\u5408\u57fa\u4e8e\u5143\u8def\u5f84\u7684\u591a\u6837\u5316\u5b50\u6a21\u578b\u4e0e\u53d8\u6362\u4e0e\u6b63\u5219\u5316\u624b\u6bb5\uff0c\u5b9e\u73b0\u4e86\u5728\u5f02\u6784\u56fe\u8282\u70b9\u5206\u7c7b\u4e0a\u4f18\u4e8e\u5355\u6a21\u6001GNN\u4e0e\u7b80\u5355\u96c6\u6210\u65b9\u6cd5\u7684\u6027\u80fd\u3002"}}
{"id": "2509.10224", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.10224", "abs": "https://arxiv.org/abs/2509.10224", "authors": ["Reynaldo Gil-Pons", "Sjouke Mauw", "Rolando Trujillo-Rasua"], "title": "Empirical Evaluation of Memory-Erasure Protocols", "comment": "Published at SECRYPT 2025", "summary": "Software-based memory-erasure protocols are two-party communication protocols\nwhere a verifier instructs a computational device to erase its memory and send\na proof of erasure. They aim at guaranteeing that low-cost IoT devices are free\nof malware by putting them back into a safe state without requiring secure\nhardware or physical manipulation of the device. Several software-based\nmemory-erasure protocols have been introduced and theoretically analysed. Yet,\nmany of them have not been tested for their feasibility, performance and\nsecurity on real devices, which hinders their industry adoption. This article\nreports on the first empirical analysis of software-based memory-erasure\nprotocols with respect to their security, erasure guarantees, and performance.\nThe experimental setup consists of 3 modern IoT devices with different\ncomputational capabilities, 7 protocols, 6 hash-function implementations, and\nvarious performance and security criteria. Our results indicate that existing\nsoftware-based memory-erasure protocols are feasible, although slow devices may\ntake several seconds to erase their memory and generate a proof of erasure. We\nfound that no protocol dominates across all empirical settings, defined by the\ncomputational power and memory size of the device, the network speed, and the\nrequired level of security. Interestingly, network speed and hidden constants\nwithin the protocol specification played a more prominent role in the\nperformance of these protocols than anticipated based on the related\nliterature. We provide an evaluation framework that, given a desired level of\nsecurity, determines which protocols offer the best trade-off between\nperformance and erasure guarantees.", "AI": {"tldr": "\u9996\u6b21\u5728\u771f\u5b9eIoT\u8bbe\u5907\u4e0a\u7cfb\u7edf\u8bc4\u6d4b\u8f6f\u4ef6\u578b\u5185\u5b58\u64e6\u9664\u534f\u8bae\uff0c\u53d1\u73b0\u5176\u53ef\u884c\u4f46\u6027\u80fd\u53d7\u9650\u4e8e\u8bbe\u5907\u7b97\u529b\u548c\u7f51\u7edc\uff0c\u63d0\u4f9b\u4e86\u9009\u62e9\u534f\u8bae\u7684\u5b9e\u7528\u8bc4\u4f30\u6846\u67b6\u3002", "motivation": "\u4e3a\u63a8\u52a8\u8f6f\u4ef6\u578b\u5185\u5b58\u64e6\u9664\u534f\u8bae\u7684\u5de5\u4e1a\u91c7\u7eb3\uff0c\u5f25\u8865\u4ec5\u6709\u7406\u8bba\u5206\u6790\u800c\u7f3a\u4e4f\u5728\u771f\u5b9e\u8bbe\u5907\u4e0a\u5b89\u5168\u3001\u6027\u80fd\u4e0e\u53ef\u884c\u6027\u5b9e\u6d4b\u7684\u7a7a\u767d\u3002", "method": "\u57283\u79cd\u4e0d\u540c\u7b97\u529b\u7684\u73b0\u4ee3IoT\u8bbe\u5907\u4e0a\uff0c\u8bc4\u6d4b7\u4e2a\u534f\u8bae\u4e0e6\u79cd\u54c8\u5e0c\u5b9e\u73b0\uff0c\u8003\u5bdf\u591a\u79cd\u6027\u80fd\u4e0e\u5b89\u5168\u6307\u6807\uff0c\u5e76\u57fa\u4e8e\u4e0d\u540c\u7f51\u7edc\u901f\u5ea6\u3001\u5185\u5b58\u5927\u5c0f\u4e0e\u6240\u9700\u5b89\u5168\u7ea7\u522b\u8fdb\u884c\u6bd4\u8f83\u5206\u6790\uff0c\u6784\u5efa\u8bc4\u4f30\u6846\u67b6\u4ee5\u6839\u636e\u5b89\u5168\u9700\u6c42\u9009\u53d6\u6700\u4f73\u6298\u8877\u65b9\u6848\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u534f\u8bae\u603b\u4f53\u53ef\u884c\u4f46\u5728\u6162\u8bbe\u5907\u4e0a\u8017\u65f6\u8f83\u957f\uff08\u53ef\u8fbe\u6570\u79d2\uff09\uff1b\u7f51\u7edc\u901f\u5ea6\u4e0e\u534f\u8bae\u5e38\u6570\u5bf9\u6027\u80fd\u5f71\u54cd\u8f83\u5927\uff1b\u65e0\u534f\u8bae\u5728\u6240\u6709\u8bbe\u7f6e\u5747\u4f18\uff1b\u5e76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6839\u636e\u5b89\u5168\u8981\u6c42\u81ea\u52a8\u9009\u62e9\u6700\u4f18\u534f\u8bae\u7684\u8bc4\u4f30\u6846\u67b6\u3002", "conclusion": "\u672c\u6587\u9996\u6b21\u5bf9\u8f6f\u4ef6\u578b\u5185\u5b58\u64e6\u9664\u534f\u8bae\u8fdb\u884c\u5b9e\u8bc1\u8bc4\u4f30\uff0c\u8bc1\u660e\u8fd9\u4e9b\u534f\u8bae\u5728\u5b9e\u9645IoT\u8bbe\u5907\u4e0a\u53ef\u884c\uff0c\u4f46\u6027\u80fd\u53d7\u8bbe\u5907\u7b97\u529b\u4e0e\u7f51\u7edc\u5f71\u54cd\u663e\u8457\uff1b\u6ca1\u6709\u5355\u4e00\u534f\u8bae\u5728\u6240\u6709\u573a\u666f\u4e2d\u5360\u4f18\u3002"}}
{"id": "2509.09982", "categories": ["cs.AI", "I.2.4"], "pdf": "https://arxiv.org/pdf/2509.09982", "abs": "https://arxiv.org/abs/2509.09982", "authors": ["Stav Armoni-Friedmann", "Hana Chockler", "David A. Kelly"], "title": "Evaluation of Black-Box XAI Approaches for Predictors of Values of Boolean Formulae", "comment": "Accepted to ECAI-EXCD Workshop, 8 pages, 2 figures, 5 tables", "summary": "Evaluating explainable AI (XAI) approaches is a challenging task in general,\ndue to the subjectivity of explanations. In this paper, we focus on tabular\ndata and the specific use case of AI models predicting the values of Boolean\nfunctions. We extend the previous work in this domain by proposing a formal and\nprecise measure of importance of variables based on actual causality, and we\nevaluate state-of-the-art XAI tools against this measure. We also present a\nnovel XAI tool B-ReX, based on the existing tool ReX, and demonstrate that it\nis superior to other black-box XAI tools on a large-scale benchmark.\nSpecifically, B-ReX achieves a Jensen-Shannon divergence of 0.072 $\\pm$ 0.012\non random 10-valued Boolean formulae", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5b9e\u9645\u56e0\u679c\u6027\u7684\u53d8\u91cf\u91cd\u8981\u6027\u5ea6\u91cf\uff0c\u8bbe\u8ba1\u5927\u89c4\u6a21\u57fa\u51c6\u5e76\u63d0\u51fa\u65b0XAI\u5de5\u5177B-ReX\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u9ed1\u76d2\u89e3\u91ca\u8d28\u91cf\uff08JSD\u22480.072\uff09\u3002", "motivation": "XAI\u8bc4\u4ef7\u4e3b\u89c2\u4e14\u56f0\u96be\uff0c\u5c24\u5176\u5728\u8868\u683c\u6570\u636e\u4e0e\u5e03\u5c14\u51fd\u6570\u9884\u6d4b\u573a\u666f\u4e0b\uff0c\u9700\u8981\u5ba2\u89c2\u3001\u53ef\u8ba1\u7b97\u7684\u8bc4\u4f30\u6807\u51c6\u3002", "method": "\u57fa\u4e8e\u5b9e\u9645\u56e0\u679c\u6027\u5b9a\u4e49\u53d8\u91cf\u91cd\u8981\u6027\uff1b\u6784\u5efa\u5927\u89c4\u6a21\u57fa\u51c6\uff08\u968f\u673a10\u503c\u5e03\u5c14\u516c\u5f0f\uff09\uff1b\u6bd4\u8f83\u73b0\u6709XAI\u5de5\u5177\u5e76\u5b9e\u73b0\u6539\u8fdb\u5de5\u5177B-ReX\uff08\u57fa\u4e8eReX\uff09\u3002", "result": "B-ReX\u5728\u968f\u673a10\u503c\u5e03\u5c14\u516c\u5f0f\u57fa\u51c6\u4e0a\u5b9e\u73b0Jensen-Shannon\u6563\u5ea60.072\u00b10.012\uff0c\u4f18\u4e8e\u5176\u5b83\u9ed1\u76d2XAI\u5de5\u5177\u3002", "conclusion": "\u672c\u6587\u901a\u8fc7\u57fa\u4e8e\u5b9e\u9645\u56e0\u679c\u6027\u7684\u53d8\u91cf\u91cd\u8981\u6027\u5ea6\u91cf\uff0c\u4e3a\u8bc4\u4ef7XAI\u65b9\u6cd5\u63d0\u4f9b\u4e86\u5f62\u5f0f\u5316\u57fa\u51c6\uff0c\u5e76\u8bc1\u660e\u4e86\u65b0\u5de5\u5177B-ReX\u5728\u9ed1\u76d2\u89e3\u91ca\u5668\u4e2d\u8868\u73b0\u4f18\u8d8a\u3002"}}
{"id": "2509.09864", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.09864", "abs": "https://arxiv.org/abs/2509.09864", "authors": ["Jenny Y. Huang", "Mehul Damani", "Yousef El-Kurdi", "Ramon Astudillo", "Wei Sun"], "title": "Latency and Token-Aware Test-Time Compute", "comment": null, "summary": "Inference-time scaling has emerged as a powerful way to improve large\nlanguage model (LLM) performance by generating multiple candidate responses and\nselecting among them. However, existing work on dynamic allocation for\ntest-time compute typically considers only parallel generation methods such as\nbest-of-N, overlooking incremental decoding methods like beam search, and has\nlargely ignored latency, focusing only on token usage. We formulate\ninference-time scaling as a problem of dynamic compute allocation and method\nselection, where the system must decide which strategy to apply and how much\ncompute to allocate on a per-query basis. Our framework explicitly incorporates\nboth token cost and wall-clock latency, the latter being critical for user\nexperience and particularly for agentic workflows where models must issue\nmultiple queries efficiently. Experiments on reasoning benchmarks show that our\napproach consistently outperforms static strategies, achieving favorable\naccuracy-cost trade-offs while remaining practical for deployment.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u5728\u63a8\u7406\u65f6\u52a8\u6001\u9009\u62e9\u751f\u6210\u65b9\u6cd5\u5e76\u5206\u914d\u8ba1\u7b97\u9884\u7b97\u7684\u6846\u67b6\uff0c\u8054\u5408\u8003\u8651token\u6210\u672c\u4e0e\u58c1\u949f\u5ef6\u8fdf\uff0c\u5728\u63a8\u7406\u57fa\u51c6\u4e0a\u8f83\u9759\u6001\u7b56\u7565\u53d6\u5f97\u66f4\u597d\u7684\u51c6\u786e\u7387/\u6210\u672c\u6298\u8877\uff0c\u9002\u5408\u5ef6\u8fdf\u654f\u611f\u7684\u5e94\u7528\u573a\u666f\u3002", "motivation": "\u73b0\u6709\u52a8\u6001\u5206\u914d\u7814\u7a76\u591a\u805a\u7126\u5e76\u884c\u751f\u6210\u5e76\u4ee5token\u6570\u4e3a\u6210\u672c\u5ea6\u91cf\uff0c\u5ffd\u89c6\u4e86\u589e\u91cf\u89e3\u7801\u65b9\u6cd5\u4e0e\u5bf9\u5ef6\u8fdf\u7684\u76f4\u63a5\u8003\u8651\uff1b\u7136\u800c\u5b9e\u9645\u90e8\u7f72\uff08\u5c24\u5176\u662f\u9700\u591a\u6b21\u67e5\u8be2\u7684agent\u6d41\u7a0b\uff09\u5bf9\u54cd\u5e94\u5ef6\u8fdf\u654f\u611f\uff0c\u56e0\u6b64\u9700\u4e00\u4e2a\u540c\u65f6\u517c\u987e\u65b9\u6cd5\u9009\u62e9\u4e0e\u5ef6\u8fdf\u7684\u52a8\u6001\u5206\u914d\u6846\u67b6\u3002", "method": "\u5efa\u7acb\u4e00\u4e2a\u5305\u542b\u5e76\u884c\u751f\u6210\uff08\u5982best-of-N\uff09\u4e0e\u589e\u91cf\u89e3\u7801\uff08\u5982beam search\uff09\u7684\u5019\u9009\u7b56\u7565\u6c60\uff0c\u9488\u5bf9\u6bcf\u4e2a\u8f93\u5165\u52a8\u6001\u9009\u62e9\u7b56\u7565\u4e0e\u5206\u914d\u8ba1\u7b97\u9884\u7b97\uff0c\u8bc4\u4ef7\u6307\u6807\u540c\u65f6\u5305\u542btoken\u4f7f\u7528\u91cf\u4e0e\u771f\u5b9e\u58c1\u949f\u5ef6\u8fdf\uff1b\u5728\u5b9e\u9a8c\u4e2d\u5728\u63a8\u7406\u57fa\u51c6\u4e0a\u6bd4\u8f83\u52a8\u6001\u7b56\u7565\u4e0e\u9759\u6001\u7b56\u7565\u7684\u51c6\u786e\u7387\u2014\u6210\u672c\u6743\u8861\u3002", "result": "\u5728\u591a\u4e2a\u63a8\u7406\u57fa\u51c6\u4e0a\uff0c\u63d0\u51fa\u7684\u65b9\u6cd5\u4f18\u4e8e\u9759\u6001\u7b56\u7565\uff0c\u80fd\u5728\u76f8\u540c\u6216\u66f4\u4f4e\u7684token\u4e0e\u5ef6\u8fdf\u6210\u672c\u4e0b\u53d6\u5f97\u66f4\u9ad8\u51c6\u786e\u7387\uff0c\u8868\u73b0\u51fa\u66f4\u4f18\u7684\u51c6\u786e\u7387-\u6210\u672c\u6298\u8877\u5e76\u5177\u6709\u5b9e\u9645\u90e8\u7f72\u53ef\u884c\u6027\u3002", "conclusion": "\u672c\u6587\u5c06\u63a8\u7406\u6642\u7684\u8ba1\u7b97\u5206\u914d\u548c\u65b9\u6cd5\u9009\u62e9\u89c6\u4e3a\u52a8\u6001\u51b3\u7b56\u95ee\u9898\uff0c\u901a\u8fc7\u540c\u65f6\u8003\u8651token\u6210\u672c\u4e0e\u5b9e\u9645\u5ef6\u8fdf\uff0c\u5728\u6bcf\u4e2a\u67e5\u8be2\u4e0a\u9009\u62e9\u5e76\u5206\u914d\u6700\u5408\u9002\u7684\u751f\u6210\u7b56\u7565\uff0c\u4ece\u800c\u63d0\u5347LLM\u5728\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u6548\u7387\u4e0e\u51c6\u786e\u7387\u3002"}}
{"id": "2509.10252", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.10252", "abs": "https://arxiv.org/abs/2509.10252", "authors": ["Yifan Jia", "Ye Tian", "Yanbin Wang", "Jianguo Sun", "Haitao Xu"], "title": "ExDoS: Expert-Guided Dual-Focus Cross-Modal Distillation for Smart Contract Vulnerability Detection", "comment": "This work has been submitted to the IEEE for possible publication", "summary": "The success of smart contracts has made them a target for attacks, but their\nclosed-source nature often forces vulnerability detection to work on bytecode,\nwhich is inherently more challenging than source-code-based analysis. While\nrecent studies try to align source and bytecode embeddings during training to\ntransfer knowledge, current methods rely on graph-level alignment that obscures\nfine-grained structural and semantic correlations between the two modalities.\nMoreover, the absence of precise vulnerability patterns and granular\nannotations in bytecode leads to depriving the model of crucial supervisory\nsignals for learning discriminant features. We propose ExDoS to transfer rich\nsemantic knowledge from source code to bytecode, effectively supplementing the\nsource code prior in practical settings. Specifically, we construct semantic\ngraphs from source code and control-flow graphs from bytecode. To address\nobscured local signals in graph-level contract embeddings, we propose a\nDual-Attention Graph Network introducing a novel node attention aggregation\nmodule to enhance local pattern capture in graph embeddings. Furthermore, by\nsummarizing existing source code vulnerability patterns and designing a\ncorresponding set of bytecode-level patterns for each, we construct the first\ndataset of vulnerability pattern annotations aligned with source code\ndefinitions to facilitate fine-grained cross-modal alignment and the capture of\nfunction-level vulnerability signals. Finally, we propose a dual-focus\nobjective for our cross-modal distillation framework, comprising: a Global\nSemantic Distillation Loss for transferring graph-level knowledge and a Local\nSemantic Distillation Loss enabling expert-guided, fine-grained\nvulnerability-specific distillation. Experiments on real-world contracts\ndemonstrate that our method achieves consistent F1-score improvements\n(3\\%--6\\%) over strong baselines.", "AI": {"tldr": "ExDoS\u901a\u8fc7\u6e90\u5b57\u8282\u7801\u8de8\u6a21\u6001\u84b8\u998f\uff0c\u7ed3\u5408Dual-Attention\u56fe\u7f51\u7edc\u548c\u7ec6\u7c92\u5ea6\u6f0f\u6d1e\u6a21\u5f0f\u6ce8\u91ca\uff0c\u5b9e\u73b0\u5bf9\u5b57\u8282\u7801\u66f4\u7cbe\u51c6\u7684\u6f0f\u6d1e\u68c0\u6d4b\uff0c\u663e\u8457\u63d0\u5347F1\u6027\u80fd\u3002", "motivation": "\u667a\u80fd\u5408\u7ea6\u901a\u5e38\u53ea\u63d0\u4f9b\u5b57\u8282\u7801\uff0c\u6e90\u4ee3\u7801\u4e0e\u5b57\u8282\u7801\u4e4b\u95f4\u5b58\u5728\u6a21\u6001\u5dee\u5f02\uff0c\u4e14\u73b0\u6709\u5bf9\u9f50\u65b9\u6cd5\u591a\u4e3a\u56fe\u7ea7\u5bf9\u9f50\uff0c\u5ffd\u7565\u7ec6\u7c92\u5ea6\u7ed3\u6784/\u8bed\u4e49\u5173\u8054\uff0c\u4e14\u5b57\u8282\u7801\u7f3a\u5c11\u7cbe\u786e\u6f0f\u6d1e\u6a21\u5f0f\u6ce8\u91ca\uff0c\u5bfc\u81f4\u5224\u522b\u6027\u7279\u5f81\u5b66\u4e60\u4e0d\u8db3\u3002", "method": "\u6784\u5efa\u6e90\u4ee3\u7801\u8bed\u4e49\u56fe\u548c\u5b57\u8282\u7801\u63a7\u5236\u6d41\u56fe\uff0c\u8bbe\u8ba1Dual-Attention Graph Network\u548c\u8282\u70b9\u6ce8\u610f\u529b\u805a\u5408\u6a21\u5757\u4ee5\u589e\u5f3a\u5c40\u90e8\u6a21\u5f0f\u6355\u83b7\uff1b\u63d0\u51fa\u53cc\u91cd\u84b8\u998f\u76ee\u6807\uff08\u5168\u5c40\u8bed\u4e49\u84b8\u998f\u635f\u5931\u4e0e\u5c40\u90e8\u8bed\u4e49\u84b8\u998f\u635f\u5931\uff09\uff1b\u5e76\u5236\u4f5c\u4e86\u7b2c\u4e00\u4e2a\u5b57\u8282\u7801\u7ea7\u6f0f\u6d1e\u6a21\u5f0f\u6ce8\u91ca\u6570\u636e\u96c6\u4e0e\u6e90\u4ee3\u7801\u5b9a\u4e49\u5bf9\u9f50\u3002", "result": "\u5728\u771f\u5b9e\u5408\u7ea6\u6570\u636e\u4e0a\uff0cExDoS\u76f8\u6bd4\u5f3a\u57fa\u7ebf\u5728F1\u4e0a\u7a33\u5b9a\u63d0\u53473%--6%\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8de8\u6a21\u6001\u77e5\u8bc6\u84b8\u998f\u65b9\u6cd5ExDoS\uff0c\u5c06\u6e90\u4ee3\u7801\u7684\u4e30\u5bcc\u8bed\u4e49\u8f6c\u79fb\u5230\u5b57\u8282\u7801\u4ee5\u63d0\u5347\u667a\u80fd\u5408\u7ea6\u6f0f\u6d1e\u68c0\u6d4b\u6027\u80fd\u3002"}}
{"id": "2509.10018", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.10018", "abs": "https://arxiv.org/abs/2509.10018", "authors": ["Hailong Yang", "Renhuo Zhao", "Guanjin Wang", "Zhaohong Deng"], "title": "GAMA: A General Anonymizing Multi-Agent System for Privacy Preservation Enhanced by Domain Rules and Disproof Method", "comment": null, "summary": "With the rapid advancement of Large Language Model (LLM), LLM-based agents\nexhibit exceptional abilities in understanding and generating natural language,\nfacilitating human-like collaboration and information transmission in LLM-based\nMulti-Agent System (MAS). High-performance LLMs are often hosted on remote\nservers in public spaces. When tasks involve privacy data, MAS cannot securely\nutilize these LLMs without implementing privacy-preserving mechanisms. To\naddress this challenge, we propose a General Anonymizing Multi-Agent system\n(GAMA), which divides the agents' workspace into private and public spaces and\nprotects privacy through the anonymizing mechanism. In the private space,\nagents handle sensitive data, while in the public space, only anonymized data\nis utilized. GAMA incorporates two key modules to mitigate semantic loss caused\nby anonymization: Domain-Rule-based Knowledge Enhancement (DRKE) and\nDisproof-based Logic Enhancement (DLE). We evaluate GAMA on two public\nquestion-answering datasets: Trivia Creative Writing and Logic Grid Puzzle. The\nresults demonstrate that GAMA has superior performance compared to the\nstate-of-the-art models. To further assess its privacy-preserving capabilities,\nwe designed two new datasets: Knowledge Privacy Preservation and Logic Privacy\nPreservation. The final results highlight GAMA's exceptional effectiveness in\nboth task processing and privacy preservation.", "AI": {"tldr": "GAMA\u901a\u8fc7\u79c1\u6709/\u516c\u5171\u7a7a\u95f4\u5206\u79bb\u4e0e\u533f\u540d\u673a\u5236\uff0c\u4ee5\u53caDRKE\u548cDLE\u589e\u5f3a\u6a21\u5757\uff0c\u6709\u6548\u5728\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u517c\u987e\u6027\u80fd\u4e0e\u9690\u79c1\u4fdd\u62a4\uff0c\u5b9e\u9a8c\u663e\u793a\u4f18\u4e8eSOTA\u5e76\u80fd\u4fdd\u62a4\u77e5\u8bc6\u548c\u903b\u8f91\u9690\u79c1\u3002", "motivation": "\u9ad8\u6027\u80fdLLM\u901a\u5e38\u90e8\u7f72\u5728\u8fdc\u7a0b\u670d\u52a1\u5668\uff0c\u76f4\u63a5\u5c06\u654f\u611f\u6570\u636e\u53d1\u9001\u7ed9\u8fdc\u7a0b\u6a21\u578b\u4f1a\u5e26\u6765\u9690\u79c1\u6cc4\u9732\u98ce\u9669\u3002\u9700\u8981\u4e00\u79cd\u5728\u4fdd\u6301\u4efb\u52a1\u6027\u80fd\u540c\u65f6\u4fdd\u62a4\u9690\u79c1\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u65b9\u6848\u3002", "method": "\u63d0\u51faGAMA\u67b6\u6784\uff1b\u79c1\u6709\u7a7a\u95f4\u5904\u7406\u654f\u611f\u6570\u636e\uff0c\u516c\u5171\u7a7a\u95f4\u4f7f\u7528\u533f\u540d\u5316\u6570\u636e\uff1b\u5f15\u5165DRKE\uff08\u57fa\u4e8e\u9886\u57df\u89c4\u5219\u7684\u77e5\u8bc6\u589e\u5f3a\uff09\u548cDLE\uff08\u57fa\u4e8e\u53cd\u9a73\u7684\u903b\u8f91\u589e\u5f3a\uff09\u4ee5\u51cf\u5c11\u533f\u540d\u5316\u9020\u6210\u7684\u4fe1\u606f\u4e22\u5931\uff1b\u6784\u5efa\u5e76\u8bc4\u4f30\u4e86\u4e24\u4e2a\u65b0\u9690\u79c1\u6570\u636e\u96c6\u7528\u4e8e\u9690\u79c1\u4fdd\u62a4\u6548\u679c\u68c0\u9a8c\u3002", "result": "\u5728Trivia Creative Writing\u548cLogic Grid Puzzle\u4e24\u4e2a\u516c\u5f00\u95ee\u7b54\u6570\u636e\u96c6\u4e0a\uff0cGAMA\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u6a21\u578b\uff1b\u5728\u4f5c\u8005\u8bbe\u8ba1\u7684Knowledge Privacy Preservation\u548cLogic Privacy Preservation\u6570\u636e\u96c6\u4e0a\uff0cGAMA\u5728\u4efb\u52a1\u6027\u80fd\u548c\u9690\u79c1\u4fdd\u62a4\u65b9\u9762\u5747\u8868\u73b0\u5353\u8d8a\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86GAMA\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u591a\u667a\u80fd\u4f53\u5de5\u4f5c\u7a7a\u95f4\u5212\u5206\u4e3a\u79c1\u6709\u7a7a\u95f4\u548c\u516c\u5171\u7a7a\u95f4\uff0c\u5e76\u5728\u516c\u5171\u7a7a\u95f4\u4ec5\u4f20\u9012\u533f\u540d\u5316\u4fe1\u606f\uff0c\u4ece\u800c\u5728\u5229\u7528\u8fdc\u7a0b\u9ad8\u6027\u80fdLLM\u65f6\u4fdd\u62a4\u9690\u79c1\u3002\u4f5c\u8005\u8bbe\u8ba1\u4e86\u4e24\u79cd\u589e\u5f3a\u6a21\u5757DRKE\u548cDLE\u4ee5\u7f13\u89e3\u533f\u540d\u5316\u5e26\u6765\u7684\u8bed\u4e49\u635f\u5931\uff0c\u5e76\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2509.09899", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.09899", "abs": "https://arxiv.org/abs/2509.09899", "authors": ["Christopher Eldred", "Fran\u00e7ois Gay-Balmaz", "Vakhtang Putkaradze"], "title": "Variational Neural Networks for Observable Thermodynamics (V-NOTS)", "comment": "26 pages, 6 figures", "summary": "Much attention has recently been devoted to data-based computing of evolution\nof physical systems. In such approaches, information about data points from\npast trajectories in phase space is used to reconstruct the equations of motion\nand to predict future solutions that have not been observed before. However, in\nmany cases, the available data does not correspond to the variables that define\nthe system's phase space. We focus our attention on the important example of\ndissipative dynamical systems. In that case, the phase space consists of\ncoordinates, momenta and entropies; however, the momenta and entropies cannot,\nin general, be observed directly. To address this difficulty, we develop an\nefficient data-based computing framework based exclusively on observable\nvariables, by constructing a novel approach based on the \\emph{thermodynamic\nLagrangian}, and constructing neural networks that respect the thermodynamics\nand guarantees the non-decreasing entropy evolution. We show that our network\ncan provide an efficient description of phase space evolution based on a\nlimited number of data points and a relatively small number of parameters in\nthe system.", "AI": {"tldr": "\u57fa\u4e8e\u70ed\u529b\u5b66\u62c9\u683c\u6717\u65e5\u6784\u5efa\u7684\u795e\u7ecf\u7f51\u7edc\u4ec5\u7528\u53ef\u89c2\u6d4b\u91cf\u5373\u53ef\u5bf9\u8017\u6563\u52a8\u529b\u7cfb\u7edf\u8fdb\u884c\u6570\u636e\u9a71\u52a8\u5efa\u6a21\uff0c\u4fdd\u8bc1\u71b5\u589e\u5e76\u80fd\u7528\u5c11\u91cf\u6570\u636e\u4e0e\u53c2\u6570\u6709\u6548\u9884\u6d4b\u76f8\u7a7a\u95f4\u6f14\u5316\u3002", "motivation": "\u5728\u8017\u6563\u7cfb\u7edf\u4e2d\uff0c\u5b9e\u9645\u89c2\u6d4b\u6570\u636e\u5e38\u53ea\u80fd\u83b7\u5f97\u5750\u6807\u7c7b\u53ef\u89c2\u6d4b\u91cf\uff0c\u800c\u52a8\u91cf\u548c\u71b5\u901a\u5e38\u4e0d\u53ef\u76f4\u63a5\u6d4b\u91cf\uff0c\u4f20\u7edf\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u96be\u4ee5\u91cd\u6784\u5b8c\u6574\u76f8\u7a7a\u95f4\u548c\u4fdd\u8bc1\u70ed\u529b\u5b66\u4e00\u81f4\u6027\uff1b\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u53ea\u4f9d\u8d56\u53ef\u89c2\u6d4b\u53d8\u91cf\u4e14\u5185\u5d4c\u70ed\u529b\u5b66\u7ea6\u675f\u7684\u5efa\u6a21\u6846\u67b6\u3002", "method": "\u6784\u5efa\u70ed\u529b\u5b66\u62c9\u683c\u6717\u65e5\u5f62\u5f0f\uff0c\u5c06\u4e0d\u53ef\u89c2\u6d4b\u7684\u52a8\u91cf\u548c\u71b5\u9690\u5f0f\u5d4c\u5165\u5230\u53ef\u89c2\u6d4b\u53d8\u91cf\u7684\u795e\u7ecf\u7f51\u7edc\u7ed3\u6784\u4e2d\uff1b\u8bbe\u8ba1\u7f51\u7edc\u7ed3\u6784\u6216\u635f\u5931\u51fd\u6570\u4ee5\u6ee1\u8db3\u80fd\u91cf\u5b88\u6052\u548c\u71b5\u589e\u539f\u5219\uff08\u71b5\u975e\u51cf\uff09\uff1b\u5229\u7528\u5c11\u91cf\u6570\u636e\u70b9\u548c\u8f83\u5c0f\u53c2\u6570\u91cf\u8bad\u7ec3\u5f97\u5230\u53ef\u6709\u6548\u63cf\u8ff0\u76f8\u7a7a\u95f4\u6f14\u5316\u7684\u6a21\u578b\u3002", "result": "\u63d0\u51fa\u7684\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u5728\u6570\u503c\u5b9e\u9a8c\uff08\u6216\u793a\u4f8b\u7cfb\u7edf\uff09\u4e2d\u80fd\u7528\u6709\u9650\u6570\u636e\u548c\u8f83\u5c11\u53c2\u6570\u51c6\u786e\u8fd1\u4f3c\u76f8\u7a7a\u95f4\u6f14\u5316\uff0c\u540c\u65f6\u4fdd\u8bc1\u71b5\u5355\u8c03\u589e\u52a0\uff0c\u8868\u73b0\u51fa\u5bf9\u70ed\u529b\u5b66\u4e00\u81f4\u6027\u548c\u6cdb\u5316\u9884\u6d4b\u7684\u826f\u597d\u6027\u80fd\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u70ed\u529b\u5b66\u62c9\u683c\u6717\u65e5\u7684\u4ec5\u7528\u53ef\u89c2\u6d4b\u53d8\u91cf\u8fdb\u884c\u8017\u6563\u52a8\u529b\u7cfb\u7edf\u6570\u636e\u9a71\u52a8\u5efa\u6a21\u7684\u65b9\u6cd5\uff0c\u80fd\u591f\u4fdd\u8bc1\u71b5\u975e\u51cf\u5e76\u7b26\u5408\u70ed\u529b\u5b66\u7ea6\u675f\uff0c\u4ece\u800c\u6062\u590d\u76f8\u7a7a\u95f4\u6f14\u5316\u548c\u9884\u6d4b\u672a\u89c2\u6d4b\u5230\u7684\u52a8\u529b\u5b66\u884c\u4e3a\u3002"}}
{"id": "2509.10287", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.10287", "abs": "https://arxiv.org/abs/2509.10287", "authors": ["Ye Tian", "Yifan Jia", "Yanbin Wang", "Jianguo Sun", "Zhiquan Liu", "Xiaowen Ling"], "title": "URL2Graph++: Unified Semantic-Structural-Character Learning for Malicious URL Detection", "comment": null, "summary": "Malicious URL detection remains a major challenge in cybersecurity, primarily\ndue to two factors: (1) the exponential growth of the Internet has led to an\nimmense diversity of URLs, making generalized detection increasingly difficult;\nand (2) attackers are increasingly employing sophisticated obfuscation\ntechniques to evade detection. We advocate that addressing these challenges\nfundamentally requires: (1) obtaining semantic understanding to improve\ngeneralization across vast and diverse URL sets, and (2) accurately modeling\ncontextual relationships within the structural composition of URLs. In this\npaper, we propose a novel malicious URL detection method combining\nmulti-granularity graph learning with semantic embedding to jointly capture\nsemantic, character-level, and structural features for robust URL analysis. To\nmodel internal dependencies within URLs, we first construct dual-granularity\nURL graphs at both subword and character levels, where nodes represent URL\ntokens/characters and edges encode co-occurrence relationships. To obtain\nfine-grained embeddings, we initialize node representations using a\ncharacter-level convolutional network. The two graphs are then processed\nthrough jointly trained Graph Convolutional Networks to learn consistent\ngraph-level representations, enabling the model to capture complementary\nstructural features that reflect co-occurrence patterns and character-level\ndependencies. Furthermore, we employ BERT to derive semantic representations of\nURLs for semantically aware understanding. Finally, we introduce a gated\ndynamic fusion network to combine the semantically enriched BERT\nrepresentations with the jointly optimized graph vectors, further enhancing\ndetection performance. We extensively evaluate our method across multiple\nchallenging dimensions. Results show our method exceeds SOTA performance,\nincluding against large language models.", "AI": {"tldr": "\u63d0\u51fa\u5c06\u5b50\u8bcd/\u5b57\u7b26\u53cc\u56fe\u4e0eBERT\u8bed\u4e49\u5d4c\u5165\u901a\u8fc7\u95e8\u63a7\u878d\u5408\u7ed3\u5408\u7684\u6076\u610fURL\u68c0\u6d4b\u65b9\u6cd5\uff0c\u80fd\u540c\u65f6\u6355\u83b7\u8bed\u4e49\u3001\u5b57\u7b26\u7ea7\u548c\u7ed3\u6784\u7279\u5f81\uff0c\u5b9e\u9a8c\u4f18\u4e8eSOTA\u3002", "motivation": "\u9762\u5bf9URL\u591a\u6837\u6027\u548c\u653b\u51fb\u8005\u6df7\u6dc6\u6280\u672f\uff0c\u9700\u83b7\u5f97\u8bed\u4e49\u7406\u89e3\u4ee5\u63d0\u5347\u6cdb\u5316\uff0c\u5e76\u5efa\u6a21URL\u5185\u90e8\u7ed3\u6784\u5173\u7cfb\u4ee5\u6355\u83b7\u4e0a\u4e0b\u6587\u4f9d\u8d56\uff0c\u4ece\u800c\u63d0\u9ad8\u68c0\u6d4b\u9c81\u68d2\u6027\u3002", "method": "\u6784\u5efa\u5b50\u8bcd\u7ea7\u4e0e\u5b57\u7b26\u7ea7\u53cc\u7c92\u5ea6URL\u56fe\uff0c\u8282\u70b9\u8868\u793a\u4e3atoken/\u5b57\u7b26\u5e76\u4ee5\u5171\u73b0\u6784\u5efa\u8fb9\uff1b\u7528\u5b57\u7b26\u7ea7\u5377\u79ef\u7f51\u7edc\u521d\u59cb\u5316\u8282\u70b9\u8868\u793a\uff1b\u901a\u8fc7\u8054\u5408\u8bad\u7ec3\u7684\u56fe\u5377\u79ef\u7f51\u7edc\u5b66\u4e60\u4e00\u81f4\u7684\u56fe\u7ea7\u8868\u793a\uff1b\u91c7\u7528BERT\u83b7\u53d6URL\u7684\u8bed\u4e49\u8868\u5f81\uff1b\u6700\u540e\u7528\u95e8\u63a7\u52a8\u6001\u878d\u5408\u7f51\u7edc\u5c06BERT\u8868\u793a\u4e0e\u56fe\u8868\u793a\u878d\u5408\u8fdb\u884c\u5206\u7c7b\u3002", "result": "\u5728\u591a\u7ef4\u5ea6\u3001\u591a\u4e2a\u57fa\u51c6\u7684\u5e7f\u6cdb\u8bc4\u6d4b\u4e2d\uff0c\u8be5\u65b9\u6cd5\u4f18\u4e8e\u73b0\u6709SOTA\uff0c\u5305\u62ec\u5728\u5bf9\u6297\u590d\u6742\u6df7\u6dc6\u548c\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\u6bd4\u8f83\u4e2d\u8868\u73b0\u66f4\u597d\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u591a\u7c92\u5ea6\u56fe\u5b66\u4e60\u4e0e\u8bed\u4e49\u5d4c\u5165\u7684\u878d\u5408\uff0c\u6709\u6548\u63d0\u5347\u4e86\u6076\u610fURL\u68c0\u6d4b\u7684\u9c81\u68d2\u6027\u4e0e\u6cdb\u5316\u80fd\u529b\uff0c\u5b9e\u9a8c\u8868\u660e\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\u3002"}}
{"id": "2509.10054", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.10054", "abs": "https://arxiv.org/abs/2509.10054", "authors": ["Hailong Yang", "Mingxian Gu", "Jianqi Wang", "Guanjin Wang", "Zhaohong Deng"], "title": "XAgents: A Unified Framework for Multi-Agent Cooperation via IF-THEN Rules and Multipolar Task Processing Graph", "comment": null, "summary": "The rapid advancement of Large Language Models (LLMs) has significantly\nenhanced the capabilities of Multi-Agent Systems (MAS) in supporting humans\nwith complex, real-world tasks. However, MAS still face challenges in effective\ntask planning when handling highly complex tasks with uncertainty, often\nresulting in misleading or incorrect outputs that hinder task execution. To\naddress this, we propose XAgents, a unified multi-agent cooperative framework\nbuilt on a multipolar task processing graph and IF-THEN rules. XAgents uses the\nmultipolar task processing graph to enable dynamic task planning and handle\ntask uncertainty. During subtask processing, it integrates domain-specific\nIF-THEN rules to constrain agent behaviors, while global rules enhance\ninter-agent collaboration. We evaluate the performance of XAgents across three\ndistinct datasets, demonstrating that it consistently surpasses\nstate-of-the-art single-agent and multi-agent approaches in both\nknowledge-typed and logic-typed question-answering tasks. The codes for XAgents\nare available at: https://github.com/AGI-FHBC/XAgents.", "AI": {"tldr": "XAgents\u901a\u8fc7\u591a\u6781\u4efb\u52a1\u5904\u7406\u56fe\u548cIF-THEN\u89c4\u5219\uff0c\u6539\u8fdb\u4e86\u591a\u667a\u80fd\u4f53\u5728\u590d\u6742\u4e0d\u786e\u5b9a\u4efb\u52a1\u4e2d\u7684\u52a8\u6001\u89c4\u5212\u4e0e\u534f\u4f5c\uff0c\u5b9e\u9a8c\u663e\u793a\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eLLM\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u9762\u5bf9\u9ad8\u5ea6\u590d\u6742\u4e0e\u4e0d\u786e\u5b9a\u7684\u771f\u5b9e\u4efb\u52a1\u65f6\uff0c\u4efb\u52a1\u89c4\u5212\u80fd\u529b\u6b20\u7f3a\uff0c\u5e38\u4ea7\u751f\u8bef\u5bfc\u6216\u9519\u8bef\u7684\u8f93\u51fa\uff0c\u5f71\u54cd\u4efb\u52a1\u6267\u884c\u6548\u679c\uff0c\u9700\u5f15\u5165\u673a\u5236\u63d0\u5347\u89c4\u5212\u9c81\u68d2\u6027\u4e0e\u534f\u4f5c\u4e00\u81f4\u6027\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u591a\u6781\u4efb\u52a1\u5904\u7406\u56fe\uff08multipolar task processing graph\uff09\u548c\u57df\u5185\u53ca\u5168\u5c40IF-THEN\u89c4\u5219\u7684\u7edf\u4e00\u591a\u667a\u80fd\u4f53\u534f\u540c\u6846\u67b6\u3002\u5728\u4efb\u52a1\u89c4\u5212\u9636\u6bb5\u4f7f\u7528\u591a\u6781\u56fe\u8fdb\u884c\u52a8\u6001\u5206\u89e3\u4e0e\u51b3\u7b56\uff0c\u5728\u5b50\u4efb\u52a1\u6267\u884c\u9636\u6bb5\u5d4c\u5165\u9886\u57df\u7279\u5b9aIF-THEN\u89c4\u5219\u7ea6\u675f\u5355\u4f53\u884c\u4e3a\uff0c\u5e76\u5229\u7528\u5168\u5c40\u89c4\u5219\u4fc3\u8fdb\u667a\u80fd\u4f53\u95f4\u534f\u4f5c\u3002\u8bc4\u4f30\u5305\u62ec\u4e09\u4e2a\u6570\u636e\u96c6\u7684\u77e5\u8bc6\u578b\u4e0e\u903b\u8f91\u578b\u95ee\u7b54\u4efb\u52a1\u6bd4\u8f83\u57fa\u7ebf\u6a21\u578b\u3002", "result": "\u5728\u4e09\u4e2a\u4e0d\u540c\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cXAgents\u5728\u77e5\u8bc6\u578b\u4e0e\u903b\u8f91\u578b\u95ee\u7b54\u4efb\u52a1\u4e0a\u5747\u7a33\u5b9a\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u5355\u667a\u80fd\u4f53\u4e0e\u591a\u667a\u80fd\u4f53\u65b9\u6cd5\uff0c\u8bc1\u660e\u591a\u6781\u56fe\u4e0eIF-THEN\u89c4\u5219\u7684\u7ed3\u5408\u80fd\u6709\u6548\u63d0\u9ad8\u89c4\u5212\u4e0e\u6267\u884c\u8d28\u91cf\u3002", "conclusion": "XAgents\u901a\u8fc7\u591a\u6781\u4efb\u52a1\u5904\u7406\u56fe\u4e0eIF-THEN\u89c4\u5219\u7ed3\u5408\uff0c\u5b9e\u73b0\u4e86\u5bf9\u590d\u6742\u3001\u4e0d\u786e\u5b9a\u4efb\u52a1\u7684\u52a8\u6001\u89c4\u5212\u4e0e\u7ea6\u675f\u63a7\u5236\uff0c\u63d0\u5347\u4e86\u591a\u667a\u80fd\u4f53\u5728\u77e5\u8bc6\u578b\u4e0e\u903b\u8f91\u578b\u95ee\u7b54\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\uff0c\u4f18\u4e8e\u73b0\u6709\u5355/\u591a\u667a\u80fd\u4f53\u65b9\u6cd5\u3002"}}
{"id": "2509.09926", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2509.09926", "abs": "https://arxiv.org/abs/2509.09926", "authors": ["Jiahao Chen", "Zhiyuan Huang", "Yurou Liu", "Bing Su"], "title": "LoFT: Parameter-Efficient Fine-Tuning for Long-tailed Semi-Supervised Learning in Open-World Scenarios", "comment": null, "summary": "Long-tailed learning has garnered increasing attention due to its wide\napplicability in real-world scenarios. Among existing approaches, Long-Tailed\nSemi-Supervised Learning (LTSSL) has emerged as an effective solution by\nincorporating a large amount of unlabeled data into the imbalanced labeled\ndataset. However, most prior LTSSL methods are designed to train models from\nscratch, which often leads to issues such as overconfidence and low-quality\npseudo-labels. To address these challenges, we extend LTSSL into the foundation\nmodel fine-tuning paradigm and propose a novel framework: LoFT (Long-tailed\nsemi-supervised learning via parameter-efficient Fine-Tuning). We demonstrate\nthat fine-tuned foundation models can generate more reliable pseudolabels,\nthereby benefiting imbalanced learning. Furthermore, we explore a more\npractical setting by investigating semi-supervised learning under open-world\nconditions, where the unlabeled data may include out-of-distribution (OOD)\nsamples. To handle this problem, we propose LoFT-OW (LoFT under Open-World\nscenarios) to improve the discriminative ability. Experimental results on\nmultiple benchmarks demonstrate that our method achieves superior performance\ncompared to previous approaches, even when utilizing only 1\\% of the unlabeled\ndata compared with previous works.", "AI": {"tldr": "\u5c06LTSSL\u8fc1\u79fb\u5230\u53c2\u6570\u9ad8\u6548\u7684\u57fa\u7840\u6a21\u578b\u5fae\u8c03\u8303\u5f0f\uff0c\u63d0\u51faLoFT\u4e0eLoFT-OW\uff0c\u5229\u7528\u66f4\u53ef\u9760\u4f2a\u6807\u7b7e\u548cOOD\u5904\u7406\u5728\u957f\u5c3e\u534a\u76d1\u7763\u4efb\u52a1\u4e0a\u53d6\u5f97\u660e\u663e\u4f18\u52bf\u3002", "motivation": "\u73b0\u6709LTSSL\u591a\u4ece\u5934\u8bad\u7ec3\uff0c\u5bfc\u81f4\u6a21\u578b\u8fc7\u5ea6\u81ea\u4fe1\u548c\u4f4e\u8d28\u91cf\u4f2a\u6807\u7b7e\uff1b\u5229\u7528\u57fa\u7840\u6a21\u578b\u5fae\u8c03\u80fd\u751f\u6210\u66f4\u9ad8\u8d28\u91cf\u4f2a\u6807\u7b7e\u5e76\u63d0\u5347\u4e0d\u5e73\u8861\u5b66\u4e60\u6027\u80fd\uff1b\u5b9e\u9645\u573a\u666f\u8fd8\u5b58\u5728\u672a\u6807\u6ce8\u6570\u636e\u542bOOD\u6837\u672c\u7684\u95ee\u9898\uff0c\u9700\u8981\u4e13\u95e8\u5904\u7406\u3002", "method": "\u5728\u9884\u8bad\u7ec3\u5927\u578b\u57fa\u7840\u6a21\u578b\u4e0a\u91c7\u7528\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\uff08PEFT\uff09\u6765\u9002\u914d\u957f\u5c3e\u534a\u76d1\u7763\u5b66\u4e60\uff0c\u901a\u8fc7\u5fae\u8c03\u5f97\u5230\u66f4\u53ef\u9760\u7684\u4f2a\u6807\u7b7e\uff1b\u5bf9\u542bOOD\u6837\u672c\u7684\u5f00\u653e\u4e16\u754c\u573a\u666f\uff0cLoFT-OW\u52a0\u5165\u673a\u5236\u4ee5\u589e\u5f3a\u5224\u522b\u80fd\u529b\u4ee5\u62d2\u7edd\u6216\u8fc7\u6ee4OOD\u6837\u672c\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u4e0a\uff0cLoFT/LoFT-OW\u4f18\u4e8e\u5148\u524d\u65b9\u6cd5\uff0c\u5728\u4ec5\u4f7f\u7528\u8fdc\u5c11\u4e8e\uff081%\uff09\u5148\u524d\u5de5\u4f5c\u7684\u672a\u6807\u6ce8\u6570\u636e\u65f6\u4ecd\u53d6\u5f97\u66f4\u597d\u6027\u80fd\uff0c\u8868\u660e\u65b9\u6cd5\u5728\u6570\u636e\u6548\u7387\u4e0e\u9c81\u68d2\u6027\u4e0a\u6709\u663e\u8457\u63d0\u5347\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u5c06\u957f\u671f\u5c3e\u90e8\u5206\u5e03\u534a\u76d1\u7763\u5b66\u4e60\uff08LTSSL\uff09\u6269\u5c55\u5230\u57fa\u7840\u6a21\u578b\u5fae\u8c03\u8303\u5f0f\uff0c\u63d0\u51faLoFT\u6846\u67b6\u53ca\u5176\u5728\u5f00\u653e\u4e16\u754c\u573a\u666f\u4e0b\u7684\u6269\u5c55LoFT-OW\uff0c\u5229\u7528\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u751f\u6210\u66f4\u53ef\u9760\u7684\u4f2a\u6807\u7b7e\u4ee5\u6539\u5584\u957f\u5c3e\u5b66\u4e60\u3002"}}
{"id": "2509.10313", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.10313", "abs": "https://arxiv.org/abs/2509.10313", "authors": ["Hamish Alsop", "Leandros Maglaras", "Helge Janicke", "Iqbal H. Sarker", "Mohamed Amine Ferrag"], "title": "Innovating Augmented Reality Security: Recent E2E Encryption Approaches", "comment": null, "summary": "End-to-end encryption (E2EE) has emerged as a fundamental element of modern\ndigital communication, protecting data from unauthorized access during\ntransmission. By design, E2EE ensures that only the intended recipient can\ndecrypt the information, making it inaccessible even to service providers. Yet,\nthis powerful safeguard of individual privacy and digital trust also introduces\na paradox: it can simultaneously prevent law enforcement efforts by hiding\npotential malicious activities. This paper examines the dual role of E2EE, its\ncritical importance to privacy, the challenges it", "AI": {"tldr": "E2EE\u5728\u4fdd\u62a4\u9690\u79c1\u548c\u963b\u788d\u6267\u6cd5\u95f4\u5b58\u5728\u77db\u76fe\uff0c\u653e\u5f03\u5f3a\u52a0\u5bc6\u98ce\u9669\u9ad8\uff0c\u5efa\u8bae\u901a\u8fc7\u6280\u672f\u4e0e\u653f\u7b56\u7ec4\u5408\u5bfb\u627e\u5e73\u8861\u3002", "motivation": "\u968f\u7740\u901a\u4fe1\u5de5\u5177\u5e7f\u6cdb\u91c7\u7528E2EE\uff0c\u793e\u4f1a\u9762\u4e34\u5982\u4f55\u5728\u4fdd\u969c\u4e2a\u4eba\u9690\u79c1\u4e0e\u7ef4\u62a4\u516c\u5171\u5b89\u5168\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\u7684\u6311\u6218\uff0c\u8bba\u6587\u65e8\u5728\u7cfb\u7edf\u5206\u6790\u8fd9\u4e00\u77db\u76fe\u5e76\u63d0\u51fa\u52a1\u5b9e\u7684\u89e3\u51b3\u601d\u8def\u3002", "method": "\u901a\u8fc7\u6587\u732e\u7efc\u8ff0\u548c\u6848\u4f8b\u5206\u6790\uff0c\u8bc4\u4f30E2EE\u5bf9\u9690\u79c1\u4fdd\u62a4\u548c\u6267\u6cd5\u8c03\u67e5\u7684\u5f71\u54cd\uff0c\u5e76\u8ba8\u8bba\u73b0\u6709\u7684\u6280\u672f\u66ff\u4ee3\u65b9\u6848\uff08\u5982\u5b89\u5168\u540e\u95e8\u3001\u5143\u6570\u636e\u5206\u6790\u3001\u5ba2\u6237\u4fa7\u626b\u63cf\uff09\u53ca\u5176\u5c40\u9650\u6027\u4e0e\u98ce\u9669\u3002", "result": "\u8bba\u6587\u5f97\u51fa\u7ed3\u8bba\uff1a\u672a\u7ecf\u614e\u91cd\u8bbe\u8ba1\u7684\u5f31\u5316E2EE\u4f1a\u964d\u4f4e\u6574\u4f53\u7f51\u7edc\u5b89\u5168\u5e76\u635f\u5bb3\u7528\u6237\u4fe1\u4efb\uff1b\u66f4\u73b0\u5b9e\u7684\u8def\u5f84\u662f\u589e\u5f3a\u900f\u660e\u5ea6\u3001\u6539\u8fdb\u53ef\u5ba1\u8ba1\u7684\u653f\u7b56\u6846\u67b6\u3001\u6295\u8d44\u5143\u6570\u636e\u4e0e\u7aef\u70b9\u5b89\u5168\u7684\u5408\u6cd5\u4f7f\u7528\uff0c\u4ee5\u53ca\u63a8\u52a8\u52a0\u5bc6\u53cb\u597d\u4e14\u53ef\u884c\u7684\u6267\u6cd5\u534f\u4f5c\u673a\u5236\u3002", "conclusion": "\u8be5\u8bba\u6587\u8ba8\u8bba\u4e86\u7aef\u5230\u7aef\u52a0\u5bc6(E2EE)\u7684\u53cc\u91cd\u89d2\u8272\uff0c\u5f3a\u8c03\u5728\u4fdd\u62a4\u9690\u79c1\u4e0e\u53ef\u80fd\u963b\u788d\u6267\u6cd5\u4e4b\u95f4\u7684\u6743\u8861\uff0c\u63d0\u51fa\u9700\u8981\u6280\u672f\u3001\u653f\u7b56\u4e0e\u900f\u660e\u5ea6\u7684\u7ed3\u5408\u6765\u5e73\u8861\u5b89\u5168\u4e0e\u76d1\u7ba1\u9700\u6c42\u3002"}}
{"id": "2509.10104", "categories": ["cs.AI", "stat.ME"], "pdf": "https://arxiv.org/pdf/2509.10104", "abs": "https://arxiv.org/abs/2509.10104", "authors": ["Sofia Vei", "Paolo Giudici", "Pavlos Sermpezis", "Athena Vakali", "Adelaide Emma Bernardelli"], "title": "AI Harmonics: a human-centric and harms severity-adaptive AI risk assessment framework", "comment": null, "summary": "The absolute dominance of Artificial Intelligence (AI) introduces\nunprecedented societal harms and risks. Existing AI risk assessment models\nfocus on internal compliance, often neglecting diverse stakeholder perspectives\nand real-world consequences. We propose a paradigm shift to a human-centric,\nharm-severity adaptive approach grounded in empirical incident data. We present\nAI Harmonics, which includes a novel AI harm assessment metric (AIH) that\nleverages ordinal severity data to capture relative impact without requiring\nprecise numerical estimates. AI Harmonics combines a robust, generalized\nmethodology with a data-driven, stakeholder-aware framework for exploring and\nprioritizing AI harms. Experiments on annotated incident data confirm that\npolitical and physical harms exhibit the highest concentration and thus warrant\nurgent mitigation: political harms erode public trust, while physical harms\npose serious, even life-threatening risks, underscoring the real-world\nrelevance of our approach. Finally, we demonstrate that AI Harmonics\nconsistently identifies uneven harm distributions, enabling policymakers and\norganizations to target their mitigation efforts effectively.", "AI": {"tldr": "\u63d0\u51faAI Harmonics\u8207AIH\u6307\u6a19\uff1a\u4ee5\u5e8f\u6578\u56b4\u91cd\u5ea6\u548c\u4e8b\u4ef6\u8cc7\u6599\u70ba\u57fa\u790e\uff0c\u63a1\u4eba\u70ba\u672c\u7684\u50b7\u5bb3\u8a55\u4f30\u6846\u67b6\uff1b\u767c\u73fe\u653f\u6cbb\u8207\u7269\u7406\u50b7\u5bb3\u662f\u6700\u9700\u512a\u5148\u8655\u7406\u7684\u985e\u5225\u3002", "motivation": "\u73fe\u6709AI\u98a8\u96aa\u8a55\u4f30\u591a\u805a\u7126\u5167\u90e8\u5408\u898f\uff0c\u5ffd\u7565\u591a\u5143\u5229\u76ca\u76f8\u95dc\u8005\u8996\u89d2\u8207\u73fe\u5be6\u4e16\u754c\u5f8c\u679c\uff1b\u56e0\u6b64\u9700\u8f49\u5411\u4ee5\u4eba\u70ba\u672c\u3001\u56b4\u91cd\u5ea6\u81ea\u9069\u61c9\u4e14\u57fa\u65bc\u5be6\u8b49\u4e8b\u4ef6\u6578\u64da\u7684\u8a55\u4f30\u65b9\u5f0f\u3002", "method": "\u63d0\u51faAIH\u6307\u6a19\uff0c\u5229\u7528\u5e8f\u6578\u56b4\u91cd\u5ea6\uff08ordinal severity\uff09\u800c\u975e\u7cbe\u78ba\u6578\u64da\uff0c\u7d50\u5408\u5229\u76ca\u76f8\u95dc\u8005\u89c0\u9ede\u8207\u8cc7\u6599\u9a45\u52d5\u7684\u65b9\u6cd5\u8ad6\uff0c\u5c0d\u6a19\u8a3b\u7684\u4e8b\u4ef6\u8cc7\u6599\u9032\u884c\u5206\u6790\u8207\u5206\u5e03\u6aa2\u6e2c\u4ee5\u8b58\u5225\u4e0d\u5747\u8861\u7684\u50b7\u5bb3\u6a21\u5f0f\u3002", "result": "\u5728\u6a19\u8a3b\u4e8b\u4ef6\u8cc7\u6599\u4e0a\u7684\u5be6\u9a57\u8b49\u5be6AIH\u80fd\u8b58\u5225\u50b7\u5bb3\u96c6\u4e2d\u5340\u57df\u2014\u653f\u6cbb\u8207\u7269\u7406\u50b7\u5bb3\u4f54\u6bd4\u6700\u9ad8\uff0c\u4e14\u6709\u660e\u986f\u4e0d\u5747\u52fb\u5206\u5e03\uff1bAI Harmonics\u80fd\u5e6b\u52a9\u653f\u7b56\u5236\u5b9a\u8005\u8207\u7d44\u7e54\u66f4\u6709\u6548\u5730\u91dd\u5c0d\u7de9\u89e3\u63aa\u65bd\u5206\u914d\u8cc7\u6e90\u3002", "conclusion": "AI Harmonics\u63d0\u51fa\u4e86\u4e00\u7a2e\u4ee5\u4eba\u70ba\u672c\u3001\u57fa\u65bc\u4e8b\u4ef6\u6578\u64da\u7684AI\u98a8\u96aa\u8a55\u4f30\u7bc4\u5f0f\uff0c\u5f37\u8abf\u5229\u7528\u5e8f\u6578\u56b4\u91cd\u5ea6\u8cc7\u6599\uff08ordinal severity\uff09\u4f86\u8861\u91cf\u76f8\u5c0d\u5f71\u97ff\uff0c\u907f\u514d\u5c0d\u7cbe\u78ba\u6578\u503c\u4f30\u8a08\u7684\u4f9d\u8cf4\u3002\u5be6\u9a57\u986f\u793a\u653f\u6cbb\u8207\u7269\u7406\u50b7\u5bb3\u5728\u5df2\u6a19\u8a3b\u4e8b\u4ef6\u8cc7\u6599\u4e2d\u96c6\u4e2d\u5ea6\u6700\u9ad8\uff0c\u9700\u512a\u5148\u7de9\u89e3\u3002"}}
{"id": "2509.09933", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.09933", "abs": "https://arxiv.org/abs/2509.09933", "authors": ["Shintaro Nakamura", "Yuko Kuroki", "Wei Chen"], "title": "Multi-Play Combinatorial Semi-Bandit Problem", "comment": null, "summary": "In the combinatorial semi-bandit (CSB) problem, a player selects an action\nfrom a combinatorial action set and observes feedback from the base arms\nincluded in the action. While CSB is widely applicable to combinatorial\noptimization problems, its restriction to binary decision spaces excludes\nimportant cases involving non-negative integer flows or allocations, such as\nthe optimal transport and knapsack problems.To overcome this limitation, we\npropose the multi-play combinatorial semi-bandit (MP-CSB), where a player can\nselect a non-negative integer action and observe multiple feedbacks from a\nsingle arm in each round. We propose two algorithms for the MP-CSB. One is a\nThompson-sampling-based algorithm that is computationally feasible even when\nthe action space is exponentially large with respect to the number of arms, and\nattains $O(\\log T)$ distribution-dependent regret in the stochastic regime,\nwhere $T$ is the time horizon. The other is a best-of-both-worlds algorithm,\nwhich achieves $O(\\log T)$ variance-dependent regret in the stochastic regime\nand the worst-case $\\tilde{\\mathcal{O}}\\left( \\sqrt{T} \\right)$ regret in the\nadversarial regime. Moreover, its regret in adversarial one is data-dependent,\nadapting to the cumulative loss of the optimal action, the total quadratic\nvariation, and the path-length of the loss sequence. Finally, we numerically\nshow that the proposed algorithms outperform existing methods in the CSB\nliterature.", "AI": {"tldr": "\u6269\u5c55CSB\u5230\u53ef\u9009\u62e9\u975e\u8d1f\u6574\u6570\u52a8\u4f5c\u7684MP-CSB\uff0c\u63d0\u51fa\u4e24\u79cd\u5206\u522b\u517c\u987e\u8ba1\u7b97\u6548\u7387\u4e0e\u5bf9\u6297/\u968f\u673a\u73af\u5883\u6027\u80fd\u7684\u7b97\u6cd5\uff0c\u7406\u8bba\u4e0e\u5b9e\u9a8c\u5747\u4f18\u4e8e\u73b0\u6709\u5de5\u4f5c\u3002", "motivation": "\u4f20\u7edfCSB\u9650\u5236\u4e3a\u4e8c\u5143\u51b3\u7b56\uff0c\u65e0\u6cd5\u5904\u7406\u591a\u6b21\u9009\u62e9\u6216\u6d41\u91cf\u5206\u914d\u95ee\u9898\uff08\u975e\u8d1f\u6574\u6570\u51b3\u7b56\uff09\uff0c\u56e0\u6b64\u9700\u8981\u6269\u5c55\u6a21\u578b\u4ee5\u6db5\u76d6\u6700\u4f18\u8fd0\u8f93\u3001\u80cc\u5305\u7b49\u5b9e\u7528\u95ee\u9898\uff0c\u5e76\u8bbe\u8ba1\u9ad8\u6548\u7b97\u6cd5\u3002", "method": "\u63d0\u51fa\u4e24\u79cd\u7b97\u6cd5\uff1a1) \u57fa\u4e8eThompson\u91c7\u6837\u7684\u7b97\u6cd5\uff0c\u9002\u7528\u4e8e\u52a8\u4f5c\u7a7a\u95f4\u5448\u6307\u6570\u7ea7\u7684\u60c5\u5f62\uff0c\u968f\u673a\u73af\u5883\u4e0b\u83b7\u5f97O(log T)\u7684\u5206\u5e03\u4f9d\u8d56\u540e\u6094\uff1b2) \u4e00\u79cdbest-of-both-worlds\u7b97\u6cd5\uff0c\u5728\u968f\u673a\u73af\u5883\u4e0b\u83b7\u5f97\u4e0e\u65b9\u5dee\u76f8\u5173\u7684O(log T)\u540e\u6094\uff0c\u5728\u5bf9\u6297\u73af\u5883\u4e0b\u8fbe\u5230\u6700\u574f\u60c5\u51b5\\tilde{O}(\\sqrt{T})\u540e\u6094\uff0c\u5e76\u4e14\u5bf9\u5bf9\u6297\u60c5\u5f62\u7684\u540e\u6094\u662f\u6570\u636e\u4f9d\u8d56\u7684\uff0c\u53ef\u9002\u914d\u6700\u4f18\u52a8\u4f5c\u7684\u7d2f\u79ef\u635f\u5931\u3001\u603b\u4e8c\u6b21\u53d8\u5316\u548c\u8def\u5f84\u957f\u5ea6\u3002", "result": "\u7406\u8bba\u4e0a\u8bc1\u660e\uff1aThompson\u91c7\u6837\u7b97\u6cd5\u5728\u968f\u673a\u73af\u5883\u4e0b\u8fbe\u6210O(log T)\u5206\u5e03\u4f9d\u8d56\u540e\u6094\uff1bbest-of-both-worlds\u7b97\u6cd5\u5728\u968f\u673a\u73af\u5883\u4e0b\u8fbe\u6210O(log T)\uff08\u65b9\u5dee\u4f9d\u8d56\uff09\u540e\u6094\uff0c\u5728\u5bf9\u6297\u73af\u5883\u4e0b\u8fbe\u6210\\tilde{O}(\\sqrt{T})\u6700\u574f\u60c5\u51b5\u540e\u6094\uff0c\u5e76\u5177\u5907\u5bf9\u6570\u636e\u7edf\u8ba1\u91cf\u7684\u9002\u5e94\u6027\u3002\u6570\u503c\u5b9e\u9a8c\u663e\u793a\u6240\u63d0\u7b97\u6cd5\u4f18\u4e8e\u73b0\u6709CSB\u65b9\u6cd5\u3002", "conclusion": "\u672c\u8bba\u6587\u5c06\u7ecf\u5178\u7684\u7ec4\u5408\u534a\u5e26\u81c2\u95ee\u9898(CSB)\u4ece\u4e8c\u5143\u51b3\u7b56\u6269\u5c55\u5230\u5141\u8bb8\u975e\u8d1f\u6574\u6570\u52a8\u4f5c\u7684\u591a\u6b21\u9009\u62e9\u60c5\u5f62(MP-CSB)\uff0c\u89e3\u51b3\u4e86\u5982\u6700\u4f18\u8fd0\u8f93\u548c\u80cc\u5305\u7b49\u9700\u8981\u6d41\u91cf/\u914d\u989d\u5206\u914d\u7684\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u4e24\u7c7b\u7b97\u6cd5\uff0c\u5206\u522b\u9488\u5bf9\u968f\u673a\u548c\u5bf9\u6297\u4e24\u79cd\u73af\u5883\uff0c\u517c\u987e\u8ba1\u7b97\u53ef\u884c\u6027\u4e0e\u6e10\u8fdb\u6700\u4f18\u6027\u3002"}}
{"id": "2509.10320", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2509.10320", "abs": "https://arxiv.org/abs/2509.10320", "authors": ["Davide Corradini", "Mariano Ceccato", "Mohammad Ghafari"], "title": "Automated Testing of Broken Authentication Vulnerabilities in Web APIs with AuthREST", "comment": null, "summary": "We present AuthREST, an open-source security testing tool targeting broken\nauthentication, one of the most prevalent API security risks in the wild.\nAuthREST automatically tests web APIs for credential stuffing, password brute\nforcing, and unchecked token authenticity. Empirical results show that AuthREST\nis effective in improving web API security. Notably, it uncovered previously\nunknown authentication vulnerabilitiesin in four public APIs.", "AI": {"tldr": "AuthREST\u662f\u4e00\u6b3e\u5f00\u6e90\u5de5\u5177\uff0c\u81ea\u52a8\u68c0\u6d4b\u51ed\u8bc1\u586b\u5145\u3001\u5bc6\u7801\u7206\u7834\u548c\u4ee4\u724c\u672a\u9a8c\u8bc1\u95ee\u9898\uff0c\u5b9e\u6d4b\u80fd\u53d1\u73b0\u771f\u5b9eAPI\u4e2d\u7684\u8ba4\u8bc1\u6f0f\u6d1e\u3002", "motivation": "Broken authentication\u662fAPI\u5b89\u5168\u4e2d\u6700\u5e38\u89c1\u7684\u98ce\u9669\uff0c\u9700\u81ea\u52a8\u5316\u5de5\u5177\u68c0\u6d4b\u6b64\u7c7b\u95ee\u9898\u3002", "method": "\u81ea\u52a8\u5316\u5bf9Web API\u6267\u884c\u51ed\u8bc1\u586b\u5145\u3001\u5bc6\u7801\u66b4\u529b\u7834\u89e3\u548c\u672a\u9a8c\u8bc1\u4ee4\u724c\u68c0\u6d4b\u7b49\u6d4b\u8bd5\u3002", "result": "\u5728\u5b9e\u8bc1\u6d4b\u8bd5\u4e2d\uff0cAuthREST\u53d1\u73b0\u4e86\u56db\u4e2a\u516c\u5f00API\u4e2d\u7684\u672a\u77e5\u8ba4\u8bc1\u6f0f\u6d1e\uff0c\u663e\u793a\u51fa\u8f83\u9ad8\u7684\u5b9e\u7528\u6027\u3002", "conclusion": "AuthREST\u80fd\u6709\u6548\u53d1\u73b0\u5b9e\u9645API\u7684\u8ba4\u8bc1\u7f3a\u9677\uff0c\u5e76\u63d0\u5347Web API\u5b89\u5168\u3002"}}
{"id": "2509.10147", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.10147", "abs": "https://arxiv.org/abs/2509.10147", "authors": ["Nenad Tomasev", "Matija Franklin", "Joel Z. Leibo", "Julian Jacobs", "William A. Cunningham", "Iason Gabriel", "Simon Osindero"], "title": "Virtual Agent Economies", "comment": null, "summary": "The rapid adoption of autonomous AI agents is giving rise to a new economic\nlayer where agents transact and coordinate at scales and speeds beyond direct\nhuman oversight. We propose the \"sandbox economy\" as a framework for analyzing\nthis emergent system, characterizing it along two key dimensions: its origins\n(emergent vs. intentional) and its degree of separateness from the established\nhuman economy (permeable vs. impermeable). Our current trajectory points toward\na spontaneous emergence of a vast and highly permeable AI agent economy,\npresenting us with opportunities for an unprecedented degree of coordination as\nwell as significant challenges, including systemic economic risk and\nexacerbated inequality. Here we discuss a number of possible design choices\nthat may lead to safely steerable AI agent markets. In particular, we consider\nauction mechanisms for fair resource allocation and preference resolution, the\ndesign of AI \"mission economies\" to coordinate around achieving collective\ngoals, and socio-technical infrastructure needed to ensure trust, safety, and\naccountability. By doing this, we argue for the proactive design of steerable\nagent markets to ensure the coming technological shift aligns with humanity's\nlong-term collective flourishing.", "AI": {"tldr": "\u63d0\u51fa\u201c\u6c99\u7bb1\u7ecf\u6d4e\u201d\u6846\u67b6\uff0c\u5206\u6790AI\u4ee3\u7406\u7ecf\u6d4e\u7684\u7c7b\u578b\u4e0e\u98ce\u9669\uff0c\u4e3b\u5f20\u901a\u8fc7\u62cd\u5356\u3001\u4efb\u52a1\u7ecf\u6d4e\u548c\u793e\u4f1a\u6280\u672f\u57fa\u7840\u8bbe\u65bd\u7b49\u8bbe\u8ba1\u5b9e\u73b0\u53ef\u5f15\u5bfc\u7684\u4ee3\u7406\u5e02\u573a\uff0c\u4ece\u800c\u5c06AI\u7ecf\u6d4e\u8f6c\u5411\u6709\u5229\u4e8e\u4eba\u7c7b\u957f\u671f\u798f\u7949\u7684\u65b9\u5411\u3002", "motivation": "\u968f\u7740\u81ea\u4e3bAI\u4ee3\u7406\u88ab\u5feb\u901f\u91c7\u7528\uff0c\u5b83\u4eec\u5c06\u4ee5\u8d85\u8d8a\u4eba\u7c7b\u76f4\u63a5\u76d1\u7ba1\u7684\u89c4\u6a21\u4e0e\u901f\u5ea6\u8fdb\u884c\u4ea4\u6613\u4e0e\u534f\u8c03\uff0c\u8feb\u5207\u9700\u8981\u4e00\u4e2a\u5206\u6790\u4e0e\u8bbe\u8ba1\u6846\u67b6\u6765\u7406\u89e3\u98ce\u9669\u4e0e\u5f15\u5bfc\u65b9\u5411\u3002", "method": "\u6587\u4e2d\u4ee5\u6846\u67b6\u6784\u5efa\u4e0e\u7406\u8bba\u5206\u6790\u4e3a\u4e3b\uff0c\u6cbf\u4e24\u4e2a\u7ef4\u5ea6\uff08\u8d77\u6e90\uff1a\u81ea\u53d1 vs. \u6709\u610f\uff1b\u4e0e\u4eba\u7c7b\u7ecf\u6d4e\u7684\u9694\u79bb\u5ea6\uff1a\u53ef\u6e17\u900f vs. \u4e0d\u53ef\u6e17\u900f\uff09\u5bf9\u4ee3\u7406\u7ecf\u6d4e\u8fdb\u884c\u5206\u7c7b\uff0c\u5e76\u8ba8\u8bba\u53ef\u884c\u7684\u673a\u5236\u8bbe\u8ba1\uff08\u5982\u62cd\u5356\u3001\u4efb\u52a1\u7ecf\u6d4e\uff09\u4e0e\u4fe1\u4efb\u4e0e\u95ee\u8d23\u7684\u793e\u4f1a\u6280\u672f\u8bbe\u8ba1\u3002", "result": "\u63a8\u65ad\u5f53\u524d\u8f68\u8ff9\u8d8b\u5411\u4e8e\u81ea\u53d1\u5f62\u6210\u4e14\u9ad8\u5ea6\u53ef\u6e17\u900f\u7684\u4ee3\u7406\u7ecf\u6d4e\uff0c\u63d0\u51fa\u82e5\u5e72\u8bbe\u8ba1\u9009\u9879\u4ee5\u5b9e\u73b0\u8d44\u6e90\u516c\u5e73\u5206\u914d\u3001\u504f\u597d\u89e3\u6790\u4e0e\u96c6\u4f53\u76ee\u6807\u534f\u8c03\uff0c\u5e76\u5f3a\u8c03\u5efa\u7acb\u4fe1\u4efb\u3001\u5b89\u5168\u4e0e\u95ee\u8d23\u7684\u57fa\u7840\u8bbe\u65bd\u4ee5\u4fdd\u969c\u4eba\u7c7b\u5229\u76ca\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u201c\u6c99\u7bb1\u7ecf\u6d4e\u201d\u6846\u67b6\uff0c\u8ba4\u4e3a\u81ea\u4e3bAI\u4ee3\u7406\u5c06\u5f62\u6210\u4e00\u4e2a\u65b0\u5174\u7ecf\u6d4e\u5c42\uff0c\u5177\u6709\u5de8\u5927\u7684\u534f\u8c03\u6f5c\u529b\u4f46\u4e5f\u5e26\u6765\u7cfb\u7edf\u6027\u98ce\u9669\u4e0e\u4e0d\u5e73\u7b49\uff0c\u4e3b\u5f20\u901a\u8fc7\u673a\u5236\u8bbe\u8ba1\u4e0e\u793e\u4f1a\u6280\u672f\u57fa\u7840\u8bbe\u65bd\u4e3b\u52a8\u5f15\u5bfc\u5176\u53ef\u63a7\u53d1\u5c55\u3002"}}
{"id": "2509.09936", "categories": ["cs.LG", "cs.NA", "math.NA"], "pdf": "https://arxiv.org/pdf/2509.09936", "abs": "https://arxiv.org/abs/2509.09936", "authors": ["Saarth Gaonkar", "Xiang Zheng", "Haocheng Xi", "Rishabh Tiwari", "Kurt Keutzer", "Dmitriy Morozov", "Michael W. Mahoney", "Amir Gholami"], "title": "SciML Agents: Write the Solver, Not the Solution", "comment": null, "summary": "Recent work in scientific machine learning aims to tackle scientific tasks\ndirectly by predicting target values with neural networks (e.g.,\nphysics-informed neural networks, neural ODEs, neural operators, etc.), but\nattaining high accuracy and robustness has been challenging. We explore an\nalternative view: use LLMs to write code that leverages decades of numerical\nalgorithms. This shifts the burden from learning a solution function to making\ndomain-aware numerical choices. We ask whether LLMs can act as SciML agents\nthat, given a natural-language ODE description, generate runnable code that is\nscientifically appropriate, selecting suitable solvers (stiff vs. non-stiff),\nand enforcing stability checks. There is currently no benchmark to measure this\nkind of capability for scientific computing tasks. As such, we first introduce\ntwo new datasets: a diagnostic dataset of adversarial \"misleading\" problems;\nand a large-scale benchmark of 1,000 diverse ODE tasks. The diagnostic set\ncontains problems whose superficial appearance suggests stiffness, and that\nrequire algebraic simplification to demonstrate non-stiffness; and the\nlarge-scale benchmark spans stiff and non-stiff ODE regimes. We evaluate open-\nand closed-source LLM models along two axes: (i) unguided versus guided\nprompting with domain-specific knowledge; and (ii) off-the-shelf versus\nfine-tuned variants. Our evaluation measures both executability and numerical\nvalidity against reference solutions. We find that with sufficient context and\nguided prompts, newer instruction-following models achieve high accuracy on\nboth criteria. In many cases, recent open-source systems perform strongly\nwithout fine-tuning, while older or smaller models still benefit from\nfine-tuning. Overall, our preliminary results indicate that careful prompting\nand fine-tuning can yield a specialized LLM agent capable of reliably solving\nsimple ODE problems.", "AI": {"tldr": "Use LLMs to generate numerical solver code for ODEs; build diagnostic and large benchmarks; guided prompting and fine-tuning let modern LLMs reliably solve many simple ODE tasks.", "motivation": "Instead of training neural networks to directly predict solutions, leverage LLMs to write code that uses decades of numerical analysis to improve accuracy and robustness in scientific computing.", "method": "Created two datasets (diagnostic adversarial set and large-scale 1000 ODE benchmark); evaluated multiple LLMs (open/closed-source, off-the-shelf and fine-tuned) under unguided vs guided prompting; measured executability and numerical validity against reference solutions.", "result": "With sufficient context and domain-specific guiding prompts, newer instruction-following LLMs perform well on selecting appropriate solvers and producing stable, correct ODE code; open-source models can perform strongly without fine-tuning, while older/smaller models benefit from fine-tuning.", "conclusion": "LLMs, when properly prompted and fine-tuned, can act as effective SciML agents by generating runnable, numerically appropriate code for ODE tasks, achieving high executability and numerical validity on many simple ODEs."}}
{"id": "2509.10413", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2509.10413", "abs": "https://arxiv.org/abs/2509.10413", "authors": ["Guojun Tang", "Carylyne Chan", "Ning Nan", "Spencer Yang", "Jiayu Zhou", "Henry Leung", "Mohammad Mamun", "Steve Drew"], "title": "Bitcoin Cross-Chain Bridge: A Taxonomy and Its Promise in Artificial Intelligence of Things", "comment": "Blockchain Cross-Chain Bridge Survey", "summary": "Bitcoin's limited scripting capabilities and lack of native interoperability\nmechanisms have constrained its integration into the broader blockchain\necosystem, especially decentralized finance (DeFi) and multi-chain\napplications. This paper presents a comprehensive taxonomy of Bitcoin\ncross-chain bridge protocols, systematically analyzing their trust assumptions,\nperformance characteristics, and applicability to the Artificial Intelligence\nof Things (AIoT) scenarios. We categorize bridge designs into three main types:\nnaive token swapping, pegged-asset bridges, and arbitrary-message bridges. Each\ncategory is evaluated across key metrics such as trust model, latency, capital\nefficiency, and DeFi composability. Emerging innovations like BitVM and\nrecursive sidechains are highlighted for their potential to enable secure,\nscalable, and programmable Bitcoin interoperability. Furthermore, we explore\npractical use cases of cross-chain bridges in AIoT applications, including\ndecentralized energy trading, healthcare data integration, and supply chain\nautomation. This taxonomy provides a foundational framework for researchers and\npractitioners seeking to design secure and efficient cross-chain\ninfrastructures in AIoT systems.", "AI": {"tldr": "\u5bf9\u6bd4\u7279\u5e01\u8de8\u94fe\u6865\u8fdb\u884c\u4e09\u7c7b\u5206\u7c7b\u5e76\u5728\u591a\u7ef4\u6307\u6807\u4e0a\u6bd4\u8f83\uff0c\u5f3a\u8c03BitVM\u4e0e\u9012\u5f52\u4fa7\u94fe\u7684\u524d\u666f\uff0c\u63a2\u8ba8\u5728AIoT\u4e2d\u7684\u5e94\u7528\u573a\u666f\u4e0e\u8bbe\u8ba1\u5efa\u8bae\u3002", "motivation": "\u6bd4\u7279\u5e01\u811a\u672c\u80fd\u529b\u53d7\u9650\u4e14\u7f3a\u4e4f\u539f\u751f\u4e92\u64cd\u4f5c\u673a\u5236\uff0c\u9650\u5236\u5176\u5728DeFi\u4e0e\u591a\u94fe\u5e94\u7528\u4e2d\u7684\u4f5c\u7528\uff1b\u56e0\u6b64\u9700\u8981\u68b3\u7406\u8de8\u94fe\u6865\u8bbe\u8ba1\u4ee5\u6307\u5bfcAIoT\u7cfb\u7edf\u4e2d\u5b89\u5168\u9ad8\u6548\u7684\u8de8\u94fe\u96c6\u6210\u3002", "method": "\u901a\u8fc7\u5c06\u6865\u534f\u8bae\u5206\u4e3a\u4e09\u7c7b\uff08\u7b80\u5355\u4ee3\u5e01\u4ea4\u6362\u3001\u62b5\u62bc\u8d44\u4ea7\u6865\u3001\u4efb\u610f\u6d88\u606f\u6865\uff09\uff0c\u5e76\u5bf9\u6bcf\u7c7b\u5728\u4fe1\u4efb\u6a21\u578b\u3001\u5ef6\u8fdf\u3001\u8d44\u672c\u6548\u7387\u3001DeFi\u53ef\u7ec4\u5408\u6027\u7b49\u6307\u6807\u4e0a\u8fdb\u884c\u7cfb\u7edf\u6bd4\u8f83\u4e0e\u8ba8\u8bba\uff0c\u540c\u65f6\u7ed3\u5408AIoT\u573a\u666f\u8fdb\u884c\u6848\u4f8b\u5206\u6790\u3002", "result": "\u63d0\u51fa\u7684\u5206\u7c7b\u4e0e\u6bd4\u8f83\u63ed\u793a\u4e86\u5404\u7c7b\u6865\u5728\u5b89\u5168\u6027\u3001\u53ef\u6269\u5c55\u6027\u4e0e\u53ef\u7ec4\u5408\u6027\u4e4b\u95f4\u7684\u6743\u8861\uff0c\u6307\u660eBitVM\u4e0e\u9012\u5f52\u4fa7\u94fe\u5728\u5b9e\u73b0\u53ef\u7f16\u7a0b\u3001\u5b89\u5168\u4e92\u64cd\u4f5c\u65b9\u9762\u7684\u6f5c\u529b\uff1b\u5e76\u7ed9\u51faAIoT\u5e94\u7528\u7684\u5177\u4f53\u573a\u666f\u4e0e\u9700\u6c42\u5339\u914d\u5efa\u8bae\u3002", "conclusion": "\u672c\u6587\u6784\u5efa\u4e86\u6bd4\u7279\u5e01\u8de8\u94fe\u6865\u534f\u8bae\u7684\u5206\u7c7b\u4f53\u7cfb\uff0c\u5e76\u6307\u51fa\u4e0d\u540c\u8bbe\u8ba1\u5728\u4fe1\u4efb\u5047\u8bbe\u3001\u6027\u80fd\u4e0eAIoT\u9002\u7528\u6027\u65b9\u9762\u7684\u6743\u8861\uff1b\u5f3a\u8c03BitVM\u548c\u9012\u5f52\u4fa7\u94fe\u4f5c\u4e3a\u5177\u6f5c\u529b\u7684\u521b\u65b0\u65b9\u5411\uff0c\u4f46\u9700\u8fdb\u4e00\u6b65\u5b9e\u8bc1\u4e0e\u5b89\u5168\u5206\u6790\u3002"}}
{"id": "2509.10162", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.10162", "abs": "https://arxiv.org/abs/2509.10162", "authors": ["Tamir Shazman", "Idan Lev-Yehudi", "Ron Benchetit", "Vadim Indelman"], "title": "Online Robust Planning under Model Uncertainty: A Sample-Based Approach", "comment": null, "summary": "Online planning in Markov Decision Processes (MDPs) enables agents to make\nsequential decisions by simulating future trajectories from the current state,\nmaking it well-suited for large-scale or dynamic environments. Sample-based\nmethods such as Sparse Sampling and Monte Carlo Tree Search (MCTS) are widely\nadopted for their ability to approximate optimal actions using a generative\nmodel. However, in practical settings, the generative model is often learned\nfrom limited data, introducing approximation errors that can degrade\nperformance or lead to unsafe behaviors. To address these challenges, Robust\nMDPs (RMDPs) offer a principled framework for planning under model uncertainty,\nyet existing approaches are typically computationally intensive and not suited\nfor real-time use. In this work, we introduce Robust Sparse Sampling (RSS), the\nfirst online planning algorithm for RMDPs with finite-sample theoretical\nperformance guarantees. Unlike Sparse Sampling, which estimates the nominal\nvalue function, RSS computes a robust value function by leveraging the\nefficiency and theoretical properties of Sample Average Approximation (SAA),\nenabling tractable robust policy computation in online settings. RSS is\napplicable to infinite or continuous state spaces, and its sample and\ncomputational complexities are independent of the state space size. We provide\ntheoretical performance guarantees and empirically show that RSS outperforms\nstandard Sparse Sampling in environments with uncertain dynamics.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u9762\u5411RMDP\u7684\u5728\u7ebf\u89c4\u5212\u7b97\u6cd5RSS\uff0c\u7ed3\u5408SAA\u5b9e\u73b0\u53ef\u6269\u5c55\u7684\u9c81\u68d2\u91c7\u6837\u89c4\u5212\uff0c\u63d0\u4f9b\u7406\u8bba\u4fdd\u8bc1\u5e76\u5728\u542b\u4e0d\u786e\u5b9a\u6027\u7684\u73af\u5883\u4e2d\u8868\u73b0\u66f4\u597d\u3002", "motivation": "\u5b9e\u9645\u5e94\u7528\u4e2d\u751f\u6210\u6a21\u578b\u901a\u5e38\u7531\u6709\u9650\u6570\u636e\u5b66\u4e60\u5f97\u5230\uff0c\u5b58\u5728\u8fd1\u4f3c\u8bef\u5dee\uff0c\u5bfc\u81f4\u4f20\u7edf\u91c7\u6837\u65b9\u6cd5\uff08\u5982Sparse Sampling\u3001MCTS\uff09\u53ef\u80fd\u6027\u80fd\u4e0b\u964d\u6216\u4ea7\u751f\u4e0d\u5b89\u5168\u884c\u4e3a\uff1b\u9700\u8981\u5e26\u6709\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u7684\u9c81\u68d2\u89c4\u5212\u65b9\u6cd5\uff0c\u540c\u65f6\u8981\u6c42\u80fd\u5b9e\u65f6\u8ba1\u7b97\u4e14\u6709\u7406\u8bba\u4fdd\u8bc1\u3002", "method": "\u57fa\u4e8eSample Average Approximation\uff08SAA\uff09\u5728\u91c7\u6837\u6811\u4e2d\u4f30\u8ba1\u9c81\u68d2\u503c\u51fd\u6570\uff0cRSS\u901a\u8fc7\u4ece\u751f\u6210\u6a21\u578b\u91c7\u6837\u540e\u6784\u5efa\u8fd1\u4f3c\u4e0d\u786e\u5b9a\u96c6\u5e76\u5728\u6bcf\u4e2a\u8282\u70b9\u6c42\u89e3SAA\u5f62\u5f0f\u7684\u9c81\u68d2\u8d1d\u5c14\u66fc\u66f4\u65b0\uff0c\u4ece\u800c\u5728\u5728\u7ebf\u8bbe\u7f6e\u4e2d\u9ad8\u6548\u8ba1\u7b97\u9c81\u68d2\u7b56\u7565\uff1b\u7b97\u6cd5\u9002\u7528\u4e8e\u8fde\u7eed\u6216\u65e0\u9650\u72b6\u6001\u7a7a\u95f4\uff0c\u6837\u672c\u4e0e\u8ba1\u7b97\u590d\u6742\u5ea6\u4e0e\u72b6\u6001\u7a7a\u95f4\u5927\u5c0f\u65e0\u5173\u3002", "result": "\u7ed9\u51fa\u4e86RSS\u7684\u7406\u8bba\u6027\u80fd\u4fdd\u8bc1\uff08\u6709\u9650\u6837\u672c\u754c\u3001\u590d\u6742\u5ea6\u5206\u6790\uff09\u5e76\u5728\u4e0d\u786e\u5b9a\u52a8\u529b\u5b66\u7684\u5b9e\u9a8c\u73af\u5883\u4e2d\u5c55\u793aRSS\u5728\u56de\u62a5\u53ca\u9c81\u68d2\u6027\u4e0a\u4f18\u4e8e\u6807\u51c6Sparse Sampling\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u9996\u4e2a\u5177\u6709\u6709\u9650\u6837\u672c\u7406\u8bba\u4fdd\u8bc1\u7684\u5728\u7ebf\u9c81\u68d2\u89c4\u5212\u7b97\u6cd5\u2014\u2014Robust Sparse Sampling\uff08RSS\uff09\uff0c\u5728\u5b58\u5728\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u7684MDP\u73af\u5883\u4e2d\u80fd\u6709\u6548\u8ba1\u7b97\u9c81\u68d2\u4ef7\u503c\u51fd\u6570\u5e76\u5728\u7ecf\u9a8c\u4e0a\u4f18\u4e8e\u6807\u51c6Sparse Sampling\u3002"}}
{"id": "2509.09940", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.09940", "abs": "https://arxiv.org/abs/2509.09940", "authors": ["Yifei Wang", "Wenbin Wang", "Yong Luo"], "title": "DyKen-Hyena: Dynamic Kernel Generation via Cross-Modal Attention for Multimodal Intent Recognition", "comment": "8 pages, 2 figures", "summary": "Though Multimodal Intent Recognition (MIR) proves effective by utilizing rich\ninformation from multiple sources (e.g., language, video, and audio), the\npotential for intent-irrelevant and conflicting information across modalities\nmay hinder performance from being further improved. Most current models attempt\nto fuse modalities by applying mechanisms like multi-head attention to unimodal\nfeature sequences and then adding the result back to the original\nrepresentation. This process risks corrupting the primary linguistic features\nwith noisy or irrelevant non-verbal signals, as it often fails to capture the\nfine-grained, token-level influence where non-verbal cues should modulate, not\njust augment, textual meaning. To address this, we introduce DyKen-Hyena, which\nreframes the problem from feature fusion to processing modulation. Our model\ntranslates audio-visual cues into dynamic, per-token convolutional kernels that\ndirectly modulate textual feature extraction. This fine-grained approach\nachieves state-of-the-art results on the MIntRec and MIntRec2.0 benchmarks.\nNotably, it yields a +10.46% F1-score improvement in out-of-scope detection,\nvalidating that our method creates a fundamentally more robust intent\nrepresentation.", "AI": {"tldr": "\u4f5c\u8005\u901a\u8fc7\u5c06\u89c6\u542c\u4fe1\u606f\u8f6c\u6210\u9010token\u7684\u52a8\u6001\u5377\u79ef\u6838\u6765\u8c03\u5236\u6587\u672c\u7f16\u7801\uff0c\u907f\u514d\u4e86\u4f20\u7edf\u878d\u5408\u5e26\u6765\u7684\u566a\u58f0\u6c61\u67d3\uff0c\u663e\u8457\u6539\u5584\u4e86\u591a\u6a21\u6001\u610f\u56fe\u8bc6\u522b\u4e0e\u5f02\u5e38\u68c0\u6d4b\u6027\u80fd\u3002", "motivation": "\u591a\u6a21\u6001\u610f\u56fe\u8bc6\u522b\u4e2d\uff0c\u975e\u8bed\u8a00\u6a21\u6001\u53ef\u80fd\u5305\u542b\u4e0e\u610f\u56fe\u65e0\u5173\u6216\u51b2\u7a81\u4fe1\u606f\uff0c\u4f20\u7edf\u7684\u7279\u5f81\u7ea7\u878d\u5408\u5bb9\u6613\u5c06\u566a\u58f0\u6ce8\u5165\u4e3b\u8981\u8bed\u8a00\u7279\u5f81\uff0c\u7f3a\u4e4f\u7ec6\u7c92\u5ea6token\u7ea7\u522b\u7684\u8c03\u5236\u673a\u5236\u3002", "method": "\u63d0\u51faDyKen-Hyena\u6a21\u578b\uff1a\u5c06\u97f3\u89c6\u9891\u4fe1\u53f7\u6620\u5c04\u4e3a\u6309token\u7684\u52a8\u6001\u5377\u79ef\u6838\uff0c\u5e94\u7528\u4e8e\u6587\u672c\u7f16\u7801\u5668\u4e2d\u4ee5\u8c03\u5236\uff08\u800c\u975e\u7b80\u5355\u878d\u5408\uff09\u6587\u672c\u7279\u5f81\uff0c\u66ff\u4ee3\u5e38\u89c1\u7684\u591a\u5934\u6ce8\u610f\u529b\u52a0\u6b8b\u5dee\u7684\u878d\u5408\u7b56\u7565\u3002", "result": "\u5728MIntRec\u548cMIntRec2.0\u57fa\u51c6\u4e0a\u8fbe\u5230SOTA\uff1b\u5728\u5f02\u5e38\uff08out-of-scope\uff09\u68c0\u6d4b\u4efb\u52a1\u4e0aF1\u63d0\u5347\u7ea6+10.46%\uff0c\u8868\u660e\u65b9\u6cd5\u5728\u6784\u5efa\u66f4\u9c81\u68d2\u7684\u610f\u56fe\u8868\u793a\u65b9\u9762\u663e\u8457\u6709\u6548\u3002", "conclusion": "\u8be5\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4ece\u7279\u5f81\u878d\u5408\u8f6c\u5411\u5904\u7406\u8c03\u5236\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u89c6\u542c\u7ebf\u7d22\u8f6c\u6362\u4e3a\u9010\u6807\u8bb0\u7684\u52a8\u6001\u5377\u79ef\u6838\u6765\u8c03\u5236\u6587\u672c\u7279\u5f81\u63d0\u53d6\uff0c\u4ece\u800c\u907f\u514d\u65e0\u5173\u6216\u51b2\u7a81\u7684\u975e\u8bed\u8a00\u4fe1\u606f\u6c61\u67d3\u8bed\u8a00\u7279\u5f81\uff0c\u663e\u8457\u63d0\u5347MIR\u5728\u610f\u56fe\u8bc6\u522b\u548c\u5f02\u5e38\u610f\u56fe\u68c0\u6d4b\u4e0a\u7684\u9c81\u68d2\u6027\u3002"}}
{"id": "2509.10210", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2509.10210", "abs": "https://arxiv.org/abs/2509.10210", "authors": ["Marko Petkovi\u0107", "Vlado Menkovski", "Sof\u00eda Calero"], "title": "Towards Fully Automated Molecular Simulations: Multi-Agent Framework for Simulation Setup and Force Field Extraction", "comment": null, "summary": "Automated characterization of porous materials has the potential to\naccelerate materials discovery, but it remains limited by the complexity of\nsimulation setup and force field selection. We propose a multi-agent framework\nin which LLM-based agents can autonomously understand a characterization task,\nplan appropriate simulations, assemble relevant force fields, execute them and\ninterpret their results to guide subsequent steps. As a first step toward this\nvision, we present a multi-agent system for literature-informed force field\nextraction and automated RASPA simulation setup. Initial evaluations\ndemonstrate high correctness and reproducibility, highlighting this approach's\npotential to enable fully autonomous, scalable materials characterization.", "AI": {"tldr": "\u4f5c\u8005\u63d0\u51fa\u5e76\u5b9e\u73b0\u4e86\u4e00\u4e2aLLM\u9a71\u52a8\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u7528\u4e8e\u6587\u732e\u9a71\u52a8\u7684\u529b\u573a\u63d0\u53d6\u548c\u81ea\u52a8\u5316RASPA\u6a21\u62df\u8bbe\u7f6e\uff0c\u521d\u6b65\u7ed3\u679c\u663e\u793a\u9ad8\u6b63\u786e\u6027\u4e0e\u53ef\u91cd\u590d\u6027\uff0c\u51f8\u663e\u5b9e\u73b0\u5168\u81ea\u52a8\u5316\u6750\u6599\u8868\u5f81\u7684\u6f5c\u529b\u3002", "motivation": "\u5f53\u524d\u591a\u5b54\u6750\u6599\u8868\u5f81\u53d7\u9650\u4e8e\u6a21\u62df\u8bbe\u7f6e\u590d\u6742\u6027\u548c\u529b\u573a\u9009\u62e9\u56f0\u96be\uff0c\u9650\u5236\u4e86\u9ad8\u901a\u91cf\u548c\u81ea\u52a8\u5316\u6750\u6599\u53d1\u73b0\u3002\u4e3b\u8981\u52a8\u673a\u662f\u901a\u8fc7\u81ea\u52a8\u5316\u6d41\u7a0b\u51cf\u5c11\u4eba\u5de5\u5e72\u9884\uff0c\u52a0\u901f\u6750\u6599\u8868\u5f81\u548c\u53d1\u73b0\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u91cd\u70b9\u5b9e\u73b0\u6587\u732e\u9a71\u52a8\u7684\u529b\u573a\u63d0\u53d6\u6a21\u5757\u548c\u81ea\u52a8\u5316\u7684RASPA\u6a21\u62df\u8bbe\u7f6e\u3002\u7cfb\u7edf\u5229\u7528LLM\u89e3\u6790\u6587\u732e\u83b7\u53d6\u529b\u573a\u53c2\u6570\uff0c\u591a\u4e2a\u4ee3\u7406\u534f\u540c\u5b8c\u6210\u4efb\u52a1\u5206\u89e3\u3001\u6a21\u62df\u811a\u672c\u751f\u6210\u548c\u6267\u884c\u3002", "result": "\u521d\u6b65\u8bc4\u4f30\u663e\u793a\u8be5\u7cfb\u7edf\u5728\u529b\u573a\u63d0\u53d6\u548cRASPA\u8bbe\u7f6e\u65b9\u9762\u5177\u6709\u9ad8\u6b63\u786e\u6027\u548c\u53ef\u91cd\u590d\u6027\uff0c\u8868\u660e\u8be5\u65b9\u6cd5\u6709\u6f5c\u529b\u5b9e\u73b0\u53ef\u6269\u5c55\u7684\u5168\u81ea\u52a8\u6750\u6599\u8868\u5f81\u6d41\u7a0b\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u4f7f\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u4ee3\u7406\u80fd\u591f\u81ea\u4e3b\u7406\u89e3\u591a\u5b54\u6750\u6599\u8868\u5f81\u4efb\u52a1\u3001\u89c4\u5212\u6a21\u62df\u3001\u7ec4\u88c5\u529b\u573a\u3001\u6267\u884c\u6a21\u62df\u5e76\u89e3\u91ca\u7ed3\u679c\uff0c\u4e3a\u81ea\u52a8\u5316\u6750\u6599\u8868\u5f81\u8fc8\u51fa\u91cd\u8981\u4e00\u6b65\u3002"}}
{"id": "2509.09955", "categories": ["cs.LG", "cs.AI", "cs.CV", "eess.IV"], "pdf": "https://arxiv.org/pdf/2509.09955", "abs": "https://arxiv.org/abs/2509.09955", "authors": ["Omar Erak", "Omar Alhussein", "Hatem Abou-Zeid", "Mehdi Bennis", "Sami Muhaidat"], "title": "Adaptive Token Merging for Efficient Transformer Semantic Communication at the Edge", "comment": "Submitted to IEEE Journals", "summary": "Large-scale transformers are central to modern semantic communication, yet\ntheir high computational and communication costs hinder deployment on\nresource-constrained edge devices. This paper introduces a training-free\nframework for adaptive token merging, a novel mechanism that compresses\ntransformer representations at runtime by selectively merging semantically\nredundant tokens under per-layer similarity thresholds. Unlike prior\nfixed-ratio reduction, our approach couples merging directly to input\nredundancy, enabling data-dependent adaptation that balances efficiency and\ntask relevance without retraining. We cast the discovery of merging strategies\nas a multi-objective optimization problem and leverage Bayesian optimization to\nobtain Pareto-optimal trade-offs between accuracy, inference cost, and\ncommunication cost. On ImageNet classification, we match the accuracy of the\nunmodified transformer with 30\\% fewer floating-point operations per second and\nunder 20\\% of the original communication cost, while for visual question\nanswering our method achieves performance competitive with the full LLaVA model\nat less than one-third of the compute and one-tenth of the bandwidth. Finally,\nwe show that our adaptive merging is robust across varying channel conditions\nand provides inherent privacy benefits, substantially degrading the efficacy of\nmodel inversion attacks. Our framework provides a practical and versatile\nsolution for deploying powerful transformer models in resource-limited edge\nintelligence scenarios.", "AI": {"tldr": "\u65e0\u8bad\u7ec3\u3001\u81ea\u9002\u5e94\u7684\u6309\u5c42\u76f8\u4f3c\u6027\u9608\u503ctoken\u5408\u5e76\uff0c\u901a\u8fc7\u8d1d\u53f6\u65af\u4f18\u5316\u627e\u5230\u51c6\u786e\u7387-\u6210\u672c-\u901a\u4fe1\u7684\u5e15\u7d2f\u6258\u89e3\uff0c\u80fd\u5728\u8fb9\u7f18\u573a\u666f\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u4e0e\u901a\u4fe1\u5f00\u9500\u5e76\u63d0\u5347\u9690\u79c1\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u4efb\u52a1\u6027\u80fd\u3002", "motivation": "\u5927\u89c4\u6a21Transformer\u5728\u8fb9\u7f18\u8bbe\u5907\u90e8\u7f72\u53d7\u9650\u4e8e\u9ad8\u8ba1\u7b97\u4e0e\u901a\u4fe1\u5f00\u9500\uff0c\u4e14\u56fa\u5b9a\u6bd4\u4f8b\u7684token\u538b\u7f29\u65e0\u6cd5\u9002\u5e94\u8f93\u5165\u8bed\u4e49\u5197\u4f59\u7684\u53d8\u5316\uff0c\u56e0\u800c\u9700\u8981\u4e00\u79cd\u65e0\u9700\u91cd\u8bad\u3001\u80fd\u6309\u8f93\u5165\u81ea\u9002\u5e94\u538b\u7f29\u8868\u793a\u4ee5\u8282\u7701\u8d44\u6e90\u540c\u65f6\u4fdd\u6301\u4efb\u52a1\u6027\u80fd\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u57fa\u4e8e\u6bcf\u5c42\u76f8\u4f3c\u6027\u9608\u503c\u7684\u81ea\u9002\u5e94token\u5408\u5e76\u673a\u5236\uff0c\u6309\u8f93\u5165\u5197\u4f59\u52a8\u6001\u51b3\u5b9a\u5408\u5e76\u6bd4\u4f8b\uff1b\u5c06\u5408\u5e76\u7b56\u7565\u641c\u7d22\u89c6\u4e3a\u591a\u76ee\u6807\u4f18\u5316\u95ee\u9898\uff0c\u4f7f\u7528\u8d1d\u53f6\u65af\u4f18\u5316\u5f97\u5230\u5728\u51c6\u786e\u7387\u3001\u63a8\u7406\u6210\u672c\u548c\u901a\u4fe1\u6210\u672c\u4e4b\u95f4\u7684\u5e15\u7d2f\u6258\u6700\u4f18\u89e3\uff1b\u6574\u4e2a\u6d41\u7a0b\u65e0\u9700\u518d\u8bad\u7ec3\uff08training-free\uff09\uff0c\u5728\u8fd0\u884c\u65f6\u5e94\u7528\u4e8e\u9884\u8bad\u7ec3Transformer\u3002", "result": "\u5728ImageNet\u5206\u7c7b\u4e0a\uff0c\u5728\u4e0d\u964d\u4f4e\u7cbe\u5ea6\u7684\u524d\u63d0\u4e0b\u5b9e\u73b0\u7ea630% FLOPs\u51cf\u5c11\u548c\u4f4e\u4e8e20%\u539f\u59cb\u901a\u4fe1\u6210\u672c\uff1b\u5728\u89c6\u89c9\u95ee\u7b54\u4e0a\uff0c\u6027\u80fd\u63a5\u8fd1\u5b8c\u6574LLaVA\u6a21\u578b\uff0c\u540c\u65f6\u8ba1\u7b97\u91cf\u4e0d\u52301/3\u3001\u5e26\u5bbd\u4e0d\u52301/10\uff1b\u5728\u4e0d\u540c\u4fe1\u9053\u6761\u4ef6\u4e0b\u4fdd\u6301\u7a33\u5065\uff0c\u5e76\u663e\u8457\u964d\u4f4e\u6a21\u578b\u53cd\u6f14\u653b\u51fb\u6548\u679c\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u8bad\u7ec3\u7684\u81ea\u9002\u5e94token\u5408\u5e76\u6846\u67b6\uff0c\u901a\u8fc7\u5728\u8fd0\u884c\u65f6\u6839\u636e\u6bcf\u5c42\u76f8\u4f3c\u6027\u9608\u503c\u9009\u62e9\u6027\u5408\u5e76\u8bed\u4e49\u5197\u4f59token\uff0c\u4ece\u800c\u5728\u4e0d\u91cd\u65b0\u8bad\u7ec3\u6a21\u578b\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u8ba1\u7b97\u4e0e\u901a\u4fe1\u5f00\u9500\u7684\u663e\u8457\u964d\u4f4e\u3002\u5b9e\u9a8c\u8bc1\u660e\u5728ImageNet\u548cVQA\u4efb\u52a1\u4e0a\u5747\u80fd\u5728\u5927\u5e45\u5ea6\u51cf\u5c11FLOPs\u548c\u5e26\u5bbd\u7684\u540c\u65f6\u4fdd\u6301\u63a5\u8fd1\u6216\u5339\u914d\u539f\u6a21\u578b\u7684\u6027\u80fd\uff0c\u5e76\u5728\u4e0d\u540c\u4fe1\u9053\u6761\u4ef6\u4e0b\u8868\u73b0\u7a33\u5065\uff0c\u8fd8\u5e26\u6765\u5bf9\u6a21\u578b\u53cd\u6f14\u653b\u51fb\u7684\u9690\u79c1\u589e\u5f3a\u6548\u679c\u3002"}}
{"id": "2509.10222", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.10222", "abs": "https://arxiv.org/abs/2509.10222", "authors": ["Ma\u00ebl Jullien", "Lei Xu", "Marco Valentino", "Andr\u00e9 Freitas"], "title": "Compartmentalised Agentic Reasoning for Clinical NLI", "comment": null, "summary": "A common assumption holds that scaling data and parameters yields\nincreasingly structured, generalisable internal representations. We interrogate\nthis assumption in clinical natural language inference (NLI) by adopting a\nbenchmark decomposed into four reasoning families, Causal Attribution,\nCompositional Grounding, Epistemic Verification, and Risk State Abstraction,\nand introducing CARENLI, a Compartmentalised Agentic Reasoning for Clinical NLI\nthat separates knowledge access from principled inference. CARENLI routes each\npremise, statement pair to a family specific solver and enforces auditable\nprocedures via a planner, verifier, and refiner.\n  Across four LLMs, CARENLI improves fidelity by up to 42 points, reaching\n98.0% in Causal Attribution and 81.2% in Risk State Abstraction. Verifiers flag\nviolations with near-ceiling reliability, while refiners correct a substantial\nshare of epistemic errors. Remaining failures cluster in routing, identifying\nfamily classification as the main bottleneck. These results show that LLMs\noften retain relevant facts but default to heuristics when inference is\nunderspecified, a dissociation CARENLI makes explicit while offering a\nframework for safer, auditable reasoning.", "AI": {"tldr": "\u4f5c\u8005\u63d0\u51faCARENLI\uff0c\u901a\u8fc7\u5bf9\u63a8\u7406\u4efb\u52a1\u7684\u5206\u7c7b\u8def\u7531\u4e0e\u53ef\u5ba1\u8ba1\u4e09\u6bb5\u5f0f\u63a8\u7406\uff08planner/verifier/refiner\uff09\uff0c\u5728\u4e34\u5e8aNLI\u4e0a\u663e\u8457\u63d0\u9ad8\u53ef\u9760\u6027\uff0c\u8bc1\u660eLLM\u4fdd\u7559\u4e8b\u5b9e\u4f46\u5728\u63a8\u7406\u6b20\u5b9a\u65f6\u4f9d\u8d56\u542f\u53d1\u5f0f\uff0c\u8def\u7531/\u5206\u7c7b\u662f\u4e3b\u8981\u74f6\u9888\u3002", "motivation": "\u68c0\u9a8c\u5728\u4e34\u5e8a\u81ea\u7136\u8bed\u8a00\u63a8\u7406\u4e2d\uff0c\u589e\u52a0\u6a21\u578b\u4e0e\u6570\u636e\u89c4\u6a21\u662f\u5426\u81ea\u53d1\u4ea7\u751f\u7ed3\u6784\u5316\u3001\u53ef\u6cdb\u5316\u7684\u5185\u90e8\u63a8\u7406\u8868\u5f81\uff1b\u5e76\u63d0\u51fa\u53ef\u5ba1\u8ba1\u4e14\u6a21\u5757\u5316\u7684\u65b9\u6cd5\u4ee5\u63d0\u9ad8\u6a21\u578b\u5728\u7ec6\u7c92\u5ea6\u4e34\u5e8a\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u53ef\u9760\u6027\u3002", "method": "\u6784\u5efa\u5305\u542b\u56db\u7c7b\u63a8\u7406\uff08\u56e0\u679c\u5f52\u56e0\u3001\u7ec4\u5408\u6027\u5bf9\u5730\u3001\u8ba4\u77e5\u9a8c\u8bc1\u3001\u98ce\u9669\u72b6\u6001\u62bd\u8c61\uff09\u7684\u57fa\u51c6\uff0c\u5e76\u63d0\u51faCARENLI\uff1a\u5c06\u7ed9\u5b9a\u7684\u524d\u63d0-\u9648\u8ff0\u5bf9\u8def\u7531\u5230\u5bb6\u65cf\u7279\u5b9a\u6c42\u89e3\u5668\uff0c\u901a\u8fc7planner\u3001verifier\u3001refiner\u4e09\u6b65\u5b9e\u73b0\u53ef\u5ba1\u8ba1\u63a8\u7406\uff1b\u5728\u56db\u79cd\u5927\u6a21\u578b\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u8bc4\u4f30\u3002", "result": "CARENLI\u5728\u56db\u79cdLLM\u4e0a\u663e\u8457\u63d0\u9ad8\u4fdd\u771f\u5ea6\uff1a\u56e0\u679c\u5f52\u56e0\u8fbe98.0%\u3001\u98ce\u9669\u72b6\u6001\u62bd\u8c61\u8fbe81.2%\uff0c\u6574\u4f53\u53ef\u63d0\u5347\u81f342\u4e2a\u767e\u5206\u70b9\uff1b\u9a8c\u8bc1\u5668\u80fd\u591f\u9ad8\u53ef\u9760\u5730\u6807\u8bb0\u8fdd\u89c4\uff0crefiner\u80fd\u4fee\u6b63\u5927\u91cf\u8ba4\u77e5\u9519\u8bef\uff1b\u4e3b\u8981\u5931\u8d25\u96c6\u4e2d\u5728\u8def\u7531\u6a21\u5757\uff0c\u8868\u660e\u5bb6\u65cf\u5206\u7c7b\u662f\u74f6\u9888\u3002", "conclusion": "\u8be5\u8bba\u6587\u6311\u6218\u4e86\u201c\u89c4\u6a21\u5316\u53ef\u5e26\u6765\u7ed3\u6784\u5316\u3001\u53ef\u6cdb\u5316\u5185\u90e8\u8868\u793a\u201d\u7684\u666e\u904d\u5047\u8bbe\uff0c\u63d0\u51faCARE NLI\u6846\u67b6\u4ee5\u533a\u5206\u77e5\u8bc6\u8bbf\u95ee\u4e0e\u63a8\u7406\uff0c\u5c55\u793a\u5728\u4e34\u5e8aNLI\u4efb\u52a1\u4e0a\u80fd\u663e\u8457\u63d0\u5347\u63a8\u7406\u4fdd\u771f\u5ea6\u5e76\u63d0\u4f9b\u53ef\u5ba1\u8ba1\u6d41\u7a0b\u3002"}}
{"id": "2509.09960", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.09960", "abs": "https://arxiv.org/abs/2509.09960", "authors": ["Mingxuan Jiang", "Yongxin Wang", "Ziyue Dai", "Yicun Liu", "Hongyi Nie", "Sen Liu", "Hongfeng Chai"], "title": "Limited Reference, Reliable Generation: A Two-Component Framework for Tabular Data Generation in Low-Data Regimes", "comment": null, "summary": "Synthetic tabular data generation is increasingly essential in data\nmanagement, supporting downstream applications when real-world and high-quality\ntabular data is insufficient. Existing tabular generation approaches, such as\ngenerative adversarial networks (GANs), diffusion models, and fine-tuned Large\nLanguage Models (LLMs), typically require sufficient reference data, limiting\ntheir effectiveness in domain-specific databases with scarce records. While\nprompt-based LLMs offer flexibility without parameter tuning, they often fail\nto capture dataset-specific feature-label dependencies and generate redundant\ndata, leading to degradation in downstream task performance. To overcome these\nissues, we propose ReFine, a framework that (i) derives symbolic \"if-then\"\nrules from interpretable models and embeds them into prompts to explicitly\nguide generation toward domain-specific feature distribution, and (ii) applies\na dual-granularity filtering strategy that suppresses over-sampling patterns\nand selectively refines rare but informative samples to reduce distributional\nimbalance. Extensive experiments on various regression and classification\nbenchmarks demonstrate that ReFine consistently outperforms state-of-the-art\nmethods, achieving up to 0.44 absolute improvement in R-squared for regression\nand 10.0 percent relative improvement in F1 score for classification tasks.", "AI": {"tldr": "\u901a\u8fc7\u89c4\u5219\u9a71\u52a8\u7684\u63d0\u793a\u4e0e\u53cc\u91cd\u7b5b\u9009\uff0cReFine\u5728\u5c11\u6837\u672c\u8868\u683c\u6570\u636e\u751f\u6210\u4e0a\u663e\u8457\u63d0\u5347\u4e0b\u6e38\u56de\u5f52\u4e0e\u5206\u7c7b\u8868\u73b0\u3002", "motivation": "\u5728\u9886\u57df\u7279\u5b9a\u4e14\u6837\u672c\u7a00\u5c11\u7684\u8868\u683c\u6570\u636e\u5e93\u4e2d\uff0c\u4f20\u7edf\u751f\u6210\u65b9\u6cd5\u4f9d\u8d56\u5927\u91cf\u53c2\u8003\u6570\u636e\uff0c\u800c\u7eaf\u63d0\u793a\u5f0fLLM\u96be\u4ee5\u6355\u6349\u7279\u5f81-\u6807\u7b7e\u4f9d\u8d56\u5e76\u5bb9\u6613\u4ea7\u751f\u5197\u4f59\u6837\u672c\uff0c\u5bfc\u81f4\u4e0b\u6e38\u4efb\u52a1\u8868\u73b0\u4e0b\u964d\u3002", "method": "\u4f7f\u7528\u53ef\u89e3\u91ca\u6a21\u578b\u63d0\u53d6\u7b26\u53f7\u5316\u7684if-then\u89c4\u5219\uff0c\u4f5c\u4e3a\u63d0\u793a\u5d4c\u5165\u5230\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u8fc7\u7a0b\u4e2d\uff1b\u968f\u540e\u91c7\u7528\u5b8f\u89c2\u548c\u5fae\u89c2\u4e24\u5c42\u7b5b\u9009\u7b56\u7565\uff0c\u5b8f\u89c2\u6291\u5236\u8fc7\u91c7\u6837\u4e0e\u91cd\u590d\u6570\u636e\uff0c\u5fae\u89c2\u4fdd\u7559\u5e76\u7ec6\u5316\u7a00\u6709\u4f46\u6709\u4fe1\u606f\u91cf\u7684\u6837\u672c\u3002", "result": "\u5728\u591a\u79cd\u56de\u5f52\u4e0e\u5206\u7c7b\u57fa\u51c6\u4e0a\uff0cReFine\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u56de\u5f52\u4efb\u52a1R^2\u6700\u9ad8\u63d0\u53470.44\uff0c\u5206\u7c7b\u4efb\u52a1F1\u76f8\u5bf9\u63d0\u9ad810.0%\u3002", "conclusion": "ReFine\u901a\u8fc7\u5c06\u53ef\u89e3\u91ca\u6a21\u578b\u5f97\u51fa\u7684\u89c4\u5219\u5d4c\u5165\u63d0\u793a\u5e76\u7ed3\u5408\u53cc\u7c92\u5ea6\u7b5b\u9009\uff0c\u6709\u6548\u63d0\u5347\u4e86\u5c0f\u6837\u672c\u57df\u7279\u5b9a\u8868\u683c\u6570\u636e\u751f\u6210\u8d28\u91cf\uff0c\u4ece\u800c\u6539\u5584\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd\u3002"}}
{"id": "2509.10249", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.10249", "abs": "https://arxiv.org/abs/2509.10249", "authors": ["Hanna Abi Akl"], "title": "Investigating Language Model Capabilities to Represent and Process Formal Knowledge: A Preliminary Study to Assist Ontology Engineering", "comment": "accepted for the International Joint Conference on Rules and\n  Reasoning (RuleML+RR) 2025", "summary": "Recent advances in Language Models (LMs) have failed to mask their\nshortcomings particularly in the domain of reasoning. This limitation impacts\nseveral tasks, most notably those involving ontology engineering. As part of a\nPhD research, we investigate the consequences of incorporating formal methods\non the performance of Small Language Models (SLMs) on reasoning tasks.\nSpecifically, we aim to orient our work toward using SLMs to bootstrap ontology\nconstruction and set up a series of preliminary experiments to determine the\nimpact of expressing logical problems with different grammars on the\nperformance of SLMs on a predefined reasoning task. Our findings show that it\nis possible to substitute Natural Language (NL) with a more compact logical\nlanguage while maintaining a strong performance on reasoning tasks and hope to\nuse these results to further refine the role of SLMs in ontology engineering.", "AI": {"tldr": "\u5c06\u81ea\u7136\u8bed\u8a00\u66ff\u6362\u4e3a\u66f4\u7d27\u51d1\u7684\u903b\u8f91\u8bed\u6cd5\uff0c\u80fd\u5728\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u4e0a\u4fdd\u6301\u826f\u597d\u63a8\u7406\u6027\u80fd\uff0c\u8868\u660e\u5f62\u5f0f\u65b9\u6cd5\u5bf9\u4e8e\u672c\u4f53\u5de5\u7a0b\u4e2d\u7684SLMs\u5f15\u5bfc\u5177\u6709\u6f5c\u529b\u3002", "motivation": "\u5f53\u524d\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u7406\u65b9\u9762\u5b58\u5728\u660e\u663e\u4e0d\u8db3\uff0c\u5f71\u54cd\u5230\u672c\u4f53\u5de5\u7a0b\u7b49\u4efb\u52a1\u3002\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u5c06\u5f62\u5f0f\u65b9\u6cd5\uff08\u5982\u66f4\u7ed3\u6784\u5316\u7684\u903b\u8f91\u8868\u793a\uff09\u5f15\u5165\u4ee5\u589e\u5f3a\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u7406\u76f8\u5173\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\uff0c\u5c24\u5176\u7528\u4e8e\u672c\u4f53\u6784\u5efa\u7684\u5f15\u5bfc\u6216\u5f15\u7206\uff08bootstrap\uff09\u3002", "method": "\u901a\u8fc7\u8bbe\u7f6e\u521d\u6b65\u5b9e\u9a8c\uff0c\u5c06\u540c\u4e00\u9884\u5b9a\u4e49\u63a8\u7406\u4efb\u52a1\u5206\u522b\u7528\u4e0d\u540c\u8bed\u6cd5\uff08\u81ea\u7136\u8bed\u8a00\u548c\u66f4\u7d27\u51d1\u7684\u903b\u8f91\u8bed\u8a00\uff09\u8868\u8fbe\uff0c\u4f7f\u7528\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\uff08SLMs\uff09\u8fdb\u884c\u6d4b\u8bd5\uff0c\u6bd4\u8f83\u5176\u5728\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u5dee\u5f02\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u66ff\u6362\u81ea\u7136\u8bed\u8a00\u4e3a\u66f4\u7d27\u51d1\u7684\u903b\u8f91\u8bed\u8a00\u53ef\u4ee5\u5728\u4fdd\u6301\u6216\u63a5\u8fd1\u539f\u6709\u6027\u80fd\u7684\u60c5\u51b5\u4e0b\uff0c\u7b80\u5316\u95ee\u9898\u8868\u8fbe\uff0c\u4ece\u800c\u53ef\u80fd\u63d0\u5347SLMs\u5728\u672c\u4f53\u5de5\u7a0b\u4e2d\u6267\u884c\u63a8\u7406\u4efb\u52a1\u7684\u53ef\u9760\u6027\u548c\u6548\u7387\u3002", "conclusion": "\u4f5c\u8005\u901a\u8fc7\u5b9e\u9a8c\u8868\u660e\uff0c\u7528\u66f4\u7d27\u51d1\u7684\u903b\u8f91\u8bed\u8a00\u66ff\u6362\u81ea\u7136\u8bed\u8a00\uff08NL\uff09\u5728\u4e00\u5b9a\u7a0b\u5ea6\u4e0a\u80fd\u4fdd\u6301\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\uff08SLMs\uff09\u5728\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u8f83\u5f3a\u8868\u73b0\uff0c\u8868\u660e\u5c06\u5f62\u5f0f\u65b9\u6cd5\u5f15\u5165\u672c\u4f53\u5de5\u7a0b\u6709\u6f5c\u529b\u63d0\u5347SLMs\u7684\u63a8\u7406\u80fd\u529b\u4e0e\u53ef\u7528\u6027\u3002"}}
{"id": "2509.09991", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.09991", "abs": "https://arxiv.org/abs/2509.09991", "authors": ["Amandip Sangha"], "title": "Data-Driven Energy Estimation for Virtual Servers Using Combined System Metrics and Machine Learning", "comment": null, "summary": "This paper presents a machine learning-based approach to estimate the energy\nconsumption of virtual servers without access to physical power measurement\ninterfaces. Using resource utilization metrics collected from guest virtual\nmachines, we train a Gradient Boosting Regressor to predict energy consumption\nmeasured via RAPL on the host. We demonstrate, for the first time, guest-only\nresource-based energy estimation without privileged host access with\nexperiments across diverse workloads, achieving high predictive accuracy and\nvariance explained ($0.90 \\leq R^2 \\leq 0.97$), indicating the feasibility of\nguest-side energy estimation. This approach can enable energy-aware scheduling,\ncost optimization and physical host independent energy estimates in virtualized\nenvironments. Our approach addresses a critical gap in virtualized environments\n(e.g. cloud) where direct energy measurement is infeasible.", "AI": {"tldr": "\u5229\u7528\u865a\u62df\u673a\u5185\u90e8\u7684\u8d44\u6e90\u6307\u6807\u8bad\u7ec3Gradient Boosting\u56de\u5f52\u5668\u4ee5\u9884\u6d4b\u4e3b\u673aRAPL\u6d4b\u5f97\u7684\u80fd\u8017\uff0c\u5728\u591a\u79cd\u8d1f\u8f7d\u4e0b\u5b9e\u73b0\u4e86\u9ad8\u7cbe\u5ea6\uff08R^2=0.90\u20130.97\uff09\uff0c\u8bc1\u660e\u4e86\u65e0\u9700\u4e3b\u673a\u7279\u6743\u5373\u53ef\u8fdb\u884c\u6709\u6548\u7684\u80fd\u8017\u4f30\u8ba1\uff0c\u53ef\u652f\u6301\u80fd\u8017\u611f\u77e5\u7684\u8c03\u5ea6\u4e0e\u6210\u672c\u4f18\u5316\u3002", "motivation": "\u5728\u865a\u62df\u5316\u73af\u5883\uff08\u5982\u4e91\uff09\u4e2d\uff0c\u5ba2\u673a\u65e0\u6cd5\u8bbf\u95ee\u4e3b\u673a\u7ea7\u7684\u7269\u7406\u529f\u7387\u6d4b\u91cf\u63a5\u53e3\uff0c\u5bfc\u81f4\u96be\u4ee5\u83b7\u53d6\u51c6\u786e\u7684\u80fd\u8017\u4fe1\u606f\uff0c\u9650\u5236\u4e86\u80fd\u8017\u611f\u77e5\u8c03\u5ea6\u4e0e\u6210\u672c\u4f18\u5316\u7b49\u5e94\u7528\u3002\u7814\u7a76\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u901a\u8fc7\u4ec5\u4f9d\u8d56guest\u4fa7\u6570\u636e\u4f30\u8ba1\u80fd\u8017\u3002", "method": "\u6536\u96c6guest\u865a\u62df\u673a\u5185\u7684\u8d44\u6e90\u5229\u7528\u7387\u6307\u6807\uff08\u5982CPU\u3001\u5185\u5b58\u3001\u78c1\u76d8\u3001\u7f51\u7edc\u7b49\uff09\uff0c\u5e76\u4ee5\u4e3b\u673a\u4e0a\u901a\u8fc7RAPL\u6d4b\u91cf\u5230\u7684\u80fd\u8017\u4f5c\u4e3a\u6807\u7b7e\uff0c\u4f7f\u7528Gradient Boosting Regressor\u8fdb\u884c\u76d1\u7763\u5b66\u4e60\u5efa\u6a21\u3002\u6a21\u578b\u8bad\u7ec3\u4e0e\u8bc4\u4f30\u5728\u591a\u79cd\u5de5\u4f5c\u8d1f\u8f7d\u4e0b\u8fdb\u884c\uff0c\u5bf9\u9884\u6d4b\u7cbe\u5ea6\u548c\u89e3\u91ca\u65b9\u5dee\u8fdb\u884c\u91cf\u5316\u3002", "result": "\u5728\u4e0d\u540c\u5de5\u4f5c\u8d1f\u8f7d\u4e0b\uff0c\u6a21\u578b\u8fbe\u5230\u4e86\u9ad8\u9884\u6d4b\u7cbe\u5ea6\u548c\u89e3\u91ca\u65b9\u5dee\uff08R^2\u4ecb\u4e8e0.90\u81f30.97\uff09\uff0c\u8868\u660e\u57fa\u4e8eguest\u7684\u8d44\u6e90\u6307\u6807\u53ef\u4ee5\u5f88\u5927\u7a0b\u5ea6\u4e0a\u53cd\u6620\u5b9e\u9645\u4e3b\u673a\u80fd\u8017\uff0c\u652f\u6301\u80fd\u8017\u611f\u77e5\u8c03\u5ea6\u548c\u6210\u672c\u4f30\u8ba1\u7684\u53ef\u884c\u6027\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u65b9\u6cd5\uff0c\u5229\u7528\u865a\u62df\u673a\u5185\u7684\u8d44\u6e90\u5229\u7528\u7387\u6307\u6807\u5728\u65e0\u4e3b\u673a\u7279\u6743\u8bbf\u95ee\u7684\u60c5\u51b5\u4e0b\u4f30\u8ba1\u865a\u62df\u670d\u52a1\u5668\u7684\u80fd\u8017\uff0c\u7ed3\u8bba\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u591a\u79cd\u5de5\u4f5c\u8d1f\u8f7d\u4e0b\u80fd\u591f\u9ad8\u7cbe\u5ea6\u9884\u6d4b\u80fd\u8017\uff08R^2\u57280.90\u52300.97\u4e4b\u95f4\uff09\uff0c\u8bc1\u660e\u4e86\u4ec5\u5728guest\u7aef\u4e5f\u80fd\u8fdb\u884c\u6709\u6548\u80fd\u8017\u4f30\u8ba1\uff0c\u5177\u6709\u5b9e\u9645\u53ef\u7528\u6027\u3002"}}
{"id": "2509.10297", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.10297", "abs": "https://arxiv.org/abs/2509.10297", "authors": ["Eoin O'Doherty", "Nicole Weinrauch", "Andrew Talone", "Uri Klempner", "Xiaoyuan Yi", "Xing Xie", "Yi Zeng"], "title": "The Morality of Probability: How Implicit Moral Biases in LLMs May Shape the Future of Human-AI Symbiosis", "comment": "Work in progress", "summary": "Artificial intelligence (AI) is advancing at a pace that raises urgent\nquestions about how to align machine decision-making with human moral values.\nThis working paper investigates how leading AI systems prioritize moral\noutcomes and what this reveals about the prospects for human-AI symbiosis. We\naddress two central questions: (1) What moral values do state-of-the-art large\nlanguage models (LLMs) implicitly favour when confronted with dilemmas? (2) How\ndo differences in model architecture, cultural origin, and explainability\naffect these moral preferences? To explore these questions, we conduct a\nquantitative experiment with six LLMs, ranking and scoring outcomes across 18\ndilemmas representing five moral frameworks. Our findings uncover strikingly\nconsistent value biases. Across all models, Care and Virtue values outcomes\nwere rated most moral, while libertarian choices were consistently penalized.\nReasoning-enabled models exhibited greater sensitivity to context and provided\nricher explanations, whereas non-reasoning models produced more uniform but\nopaque judgments. This research makes three contributions: (i) Empirically, it\ndelivers a large-scale comparison of moral reasoning across culturally distinct\nLLMs; (ii) Theoretically, it links probabilistic model behaviour with\nunderlying value encodings; (iii) Practically, it highlights the need for\nexplainability and cultural awareness as critical design principles to guide AI\ntoward a transparent, aligned, and symbiotic future.", "AI": {"tldr": "\u5b9e\u9a8c\u6bd4\u8f83\u516d\u4e2aLLM\u572818\u4e2a\u9053\u5fb7\u56f0\u5883\u4e0a\u7684\u8868\u73b0\uff0c\u7ed3\u8bba\u662f\u6a21\u578b\u603b\u4f53\u504f\u5411\u5173\u6000/\u7f8e\u5fb7\u4ef7\u503c\uff0c\u60e9\u7f5a\u81ea\u7531\u4e3b\u4e49\u9009\u62e9\uff0c\u63a8\u7406\u80fd\u529b\u63d0\u5347\u89e3\u91ca\u4e0e\u60c5\u5883\u654f\u611f\u6027\uff1b\u5f3a\u8c03\u53ef\u89e3\u91ca\u6027\u4e0e\u6587\u5316\u610f\u8bc6\u5bf9AI\u5bf9\u9f50\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u968f\u7740AI\u51b3\u7b56\u80fd\u529b\u589e\u5f3a\uff0c\u9700\u4e86\u89e3\u5176\u9690\u542b\u7684\u9053\u5fb7\u504f\u597d\u4e0e\u89e3\u91ca\u80fd\u529b\uff0c\u8bc4\u4f30\u662f\u5426\u80fd\u4e0e\u4eba\u7c7b\u5b9e\u73b0\u9053\u5fb7\u4e0a\u7684\u5171\u751f\u4e0e\u53ef\u4fe1\u534f\u4f5c\u3002", "method": "\u9009\u53d6\u516d\u4e2a\u4ee3\u8868\u6027\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u8bbe\u8ba118\u4e2a\u9053\u5fb7\u56f0\u5883\u8986\u76d6\u4e94\u79cd\u9053\u5fb7\u6846\u67b6\uff0c\u8981\u6c42\u6a21\u578b\u5bf9\u6bcf\u4e2a\u9009\u9879\u8fdb\u884c\u6392\u5e8f\u548c\u8bc4\u5206\uff1b\u6bd4\u8f83\u6a21\u578b\u67b6\u6784\uff08\u662f\u5426\u542b\u63a8\u7406\u80fd\u529b\uff09\u3001\u6587\u5316\u6765\u6e90\u4e0e\u53ef\u89e3\u91ca\u6027\u8868\u73b0\uff0c\u7edf\u8ba1\u8bc4\u5206\u5dee\u5f02\u5e76\u5206\u6790\u8bf4\u660e\u8d28\u91cf\u3002", "result": "\u53d1\u73b0\u5173\u6000\u4e0e\u7f8e\u5fb7\u4ef7\u503c\u88ab\u666e\u904d\u9ad8\u4f30\uff1b\u5177\u6709\u63a8\u7406\u6a21\u5757\u7684\u6a21\u578b\u5bf9\u60c5\u5883\u66f4\u654f\u611f\u5e76\u80fd\u63d0\u4f9b\u66f4\u4e30\u5bcc\u89e3\u91ca\uff1b\u975e\u63a8\u7406\u6a21\u578b\u7ed9\u51fa\u66f4\u4e00\u81f4\u4f46\u4e0d\u900f\u660e\u7684\u5224\u65ad\uff1b\u4e0d\u540c\u6587\u5316\u80cc\u666f\u6a21\u578b\u5dee\u5f02\u5b58\u5728\u4f46\u603b\u4f53\u504f\u597d\u8d8b\u540c\u3002", "conclusion": "\u8fd9\u4e9b\u6a21\u578b\u666e\u904d\u504f\u5411\u5173\u6000\uff08Care\uff09\u4e0e\u7f8e\u5fb7\uff08Virtue\uff09\u5bfc\u5411\u7684\u9053\u5fb7\u5224\u65ad\uff0c\u60e9\u7f5a\u81ea\u7531\u4e3b\u4e49\uff08Libertarian\uff09\u9009\u9879\uff0c\u5e76\u5728\u4e0d\u540c\u4f53\u7cfb\u95f4\u8868\u73b0\u51fa\u4e00\u81f4\u7684\u4ef7\u503c\u504f\u597d\u3002"}}
{"id": "2509.10000", "categories": ["cs.LG", "cond-mat.other"], "pdf": "https://arxiv.org/pdf/2509.10000", "abs": "https://arxiv.org/abs/2509.10000", "authors": ["Tilen Cadez", "Kyoung-Min Kim"], "title": "Neural Scaling Laws for Deep Regression", "comment": "Supplementary Information will be provided with the published\n  manuscript", "summary": "Neural scaling laws--power-law relationships between generalization errors\nand characteristics of deep learning models--are vital tools for developing\nreliable models while managing limited resources. Although the success of large\nlanguage models highlights the importance of these laws, their application to\ndeep regression models remains largely unexplored. Here, we empirically\ninvestigate neural scaling laws in deep regression using a parameter estimation\nmodel for twisted van der Waals magnets. We observe power-law relationships\nbetween the loss and both training dataset size and model capacity across a\nwide range of values, employing various architectures--including fully\nconnected networks, residual networks, and vision transformers. Furthermore,\nthe scaling exponents governing these relationships range from 1 to 2, with\nspecific values depending on the regressed parameters and model details. The\nconsistent scaling behaviors and their large scaling exponents suggest that the\nperformance of deep regression models can improve substantially with increasing\ndata size.", "AI": {"tldr": "\u6df1\u5ea6\u56de\u5f52\u4e5f\u670d\u4ece\u795e\u7ecf\u5c3a\u5ea6\u5f8b\uff1a\u635f\u5931\u968f\u8bad\u7ec3\u6570\u636e\u548c\u6a21\u578b\u5bb9\u91cf\u5448\u5e42\u5f8b\u4e0b\u964d\uff0c\u6307\u6570\u57281~2\uff0c\u610f\u5473\u7740\u66f4\u591a\u6570\u636e\u80fd\u5927\u5e45\u63d0\u5347\u56de\u5f52\u7cbe\u5ea6\u3002", "motivation": "\u73b0\u6709\u795e\u7ecf\u5c3a\u5ea6\u5f8b\u7814\u7a76\u591a\u96c6\u4e2d\u5728\u8bed\u8a00\u6a21\u578b\u548c\u5206\u7c7b\u4efb\u52a1\uff0c\u6df1\u5ea6\u56de\u5f52\u4efb\u52a1\uff08\u5c24\u5176\u7269\u7406\u53c2\u6570\u4f30\u8ba1\uff09\u4e2d\u7684\u5c3a\u5ea6\u89c4\u5f8b\u5c1a\u4e0d\u660e\u786e\uff0c\u672c\u7814\u7a76\u65e8\u5728\u586b\u8865\u8be5\u7a7a\u767d\u5e76\u8bc4\u4f30\u6570\u636e\u4e0e\u6a21\u578b\u653e\u7f29\u5bf9\u56de\u5f52\u6027\u80fd\u7684\u5f71\u54cd\u3002", "method": "\u4f7f\u7528\u53c2\u6570\u4f30\u8ba1\u4efb\u52a1\uff08\u626d\u66f2\u7684\u8303\u5fb7\u74e6\u5c14\u65af\u78c1\u4f53\u6a21\u578b\uff09\u4f5c\u4e3a\u56de\u5f52\u76ee\u6807\uff0c\u8bad\u7ec3\u591a\u79cd\u67b6\u6784\uff08\u5168\u8fde\u901a\u3001\u6b8b\u5dee\u3001\u89c6\u89c9Transformer\uff09\u5e76\u7cfb\u7edf\u53d8\u6362\u8bad\u7ec3\u96c6\u5927\u5c0f\u548c\u6a21\u578b\u53c2\u6570\u91cf\uff0c\u8bb0\u5f55\u9a8c\u8bc1\u635f\u5931\uff0c\u62df\u5408\u635f\u5931\u4e0e\u6570\u636e\u91cf/\u5bb9\u91cf\u7684\u5e42\u5f8b\u5173\u7cfb\uff0c\u4f30\u8ba1\u5c3a\u5ea6\u6307\u6570\u3002", "result": "\u5728\u5e7f\u6cdb\u8bbe\u7f6e\u548c\u67b6\u6784\u4e0b\uff0c\u635f\u5931\u4e0e\u8bad\u7ec3\u96c6\u5927\u5c0f\u53ca\u6a21\u578b\u5bb9\u91cf\u5747\u5448\u663e\u8457\u5e42\u5f8b\u5173\u7cfb\uff1b\u5c3a\u5ea6\u6307\u6570\u5206\u5e03\u57281\u52302\u4e4b\u95f4\uff0c\u56e0\u56de\u5f52\u76ee\u6807\u548c\u6a21\u578b\u7ec6\u8282\u800c\u5f02\uff1b\u5927\u6307\u6570\u503c\u6697\u793a\u901a\u8fc7\u589e\u52a0\u6570\u636e\u91cf\u53ef\u4ee5\u53d6\u5f97\u663e\u8457\u8bef\u5dee\u964d\u4f4e\u3002", "conclusion": "\u672c\u6587\u5b9e\u8bc1\u8868\u660e\uff0c\u6df1\u5ea6\u56de\u5f52\u6a21\u578b\u4e5f\u9075\u5faa\u795e\u7ecf\u5c3a\u5ea6\u5f8b\uff0c\u635f\u5931\u5173\u4e8e\u8bad\u7ec3\u96c6\u5927\u5c0f\u548c\u6a21\u578b\u5bb9\u91cf\u5448\u5e42\u5f8b\u4e0b\u964d\uff0c\u4e14\u5e42\u5f8b\u6307\u6570\u57281\u52302\u4e4b\u95f4\uff0c\u8868\u660e\u6570\u636e\u589e\u5927\u80fd\u663e\u8457\u63d0\u5347\u56de\u5f52\u6027\u80fd\u3002"}}
{"id": "2509.10326", "categories": ["cs.AI", "cs.LO", "03G27 (Primary) 68W30, 68T27 (Secondary)"], "pdf": "https://arxiv.org/pdf/2509.10326", "abs": "https://arxiv.org/abs/2509.10326", "authors": ["Dmitry Lesnik", "Tobias Sch\u00e4fer"], "title": "State Algebra for Propositional Logic", "comment": "47 pages", "summary": "This paper presents State Algebra, a novel framework designed to represent\nand manipulate propositional logic using algebraic methods. The framework is\nstructured as a hierarchy of three representations: Set, Coordinate, and Row\nDecomposition. These representations anchor the system in well-known semantics\nwhile facilitating the computation using a powerful algebraic engine. A key\naspect of State Algebra is its flexibility in representation. We show that\nalthough the default reduction of a state vector is not canonical, a unique\ncanonical form can be obtained by applying a fixed variable order during the\nreduction process. This highlights a trade-off: by foregoing guaranteed\ncanonicity, the framework gains increased flexibility, potentially leading to\nmore compact representations of certain classes of problems. We explore how\nthis framework provides tools to articulate both search-based and knowledge\ncompilation algorithms and discuss its natural extension to probabilistic logic\nand Weighted Model Counting.", "AI": {"tldr": "\u63d0\u51fa State Algebra\uff1a\u4e00\u4e2a\u4ee5\u4ee3\u6570\u65b9\u6cd5\u8868\u793a\u547d\u9898\u903b\u8f91\u7684\u4e09\u5c42\u6846\u67b6\uff0c\u975e\u89c4\u8303\u7ea6\u7b80\u5e26\u6765\u7075\u6d3b\u6027\u4e0e\u6f5c\u5728\u66f4\u7d27\u51d1\u8868\u793a\uff0c\u901a\u8fc7\u56fa\u5b9a\u53d8\u91cf\u987a\u5e8f\u53ef\u6062\u590d\u552f\u4e00\u89c4\u8303\u5f62\u5f0f\uff0c\u5e76\u53ef\u6269\u5c55\u5230\u6982\u7387\u4e0e\u52a0\u6743\u8ba1\u6570\u3002", "motivation": "\u5c06\u547d\u9898\u903b\u8f91\u7684\u8868\u793a\u4e0e\u64cd\u4f5c\u4ee3\u6570\u5316\uff0c\u517c\u987e\u8bed\u4e49\u57fa\u7840\u4e0e\u4ee3\u6570\u8ba1\u7b97\u4f18\u52bf\uff0c\u5bfb\u6c42\u5728\u8868\u793a\u7d27\u51d1\u6027\u4e0e\u89c4\u8303\u6027\u4e4b\u95f4\u7684\u53ef\u63a7\u6298\u8877\uff0c\u5e76\u62d3\u5c55\u5230\u6982\u7387\u4e0e\u52a0\u6743\u8ba1\u6570\u573a\u666f\u3002", "method": "\u5efa\u7acb\u4e09\u5c42\u8868\u793a\u5c42\u6b21\uff08Set\u3001Coordinate\u3001Row Decomposition\uff09\uff0c\u5e76\u7528\u4ee3\u6570\u5f15\u64ce\u5728\u8fd9\u4e9b\u8868\u793a\u4e0a\u8fdb\u884c\u72b6\u6001\u5411\u91cf\u7684\u7ea6\u7b80\u4e0e\u64cd\u4f5c\uff1b\u5206\u6790\u4e86\u9ed8\u8ba4\u7ea6\u7b80\u975e\u89c4\u8303\u6027\u53ca\u901a\u8fc7\u56fa\u5b9a\u53d8\u91cf\u987a\u5e8f\u5b9e\u73b0\u89c4\u8303\u5316\u7684\u65b9\u6cd5\uff1b\u6269\u5c55\u8ba8\u8bba\u5305\u62ec\u641c\u7d22\u4e0e\u77e5\u8bc6\u7f16\u8bd1\u7b97\u6cd5\u7684\u8868\u8fbe\uff0c\u4ee5\u53ca\u5411\u6982\u7387\u903b\u8f91\u548c\u52a0\u6743\u6a21\u578b\u8ba1\u6570\u7684\u81ea\u7136\u63a8\u5e7f\u3002", "result": "\u63d0\u51fa\u5e76\u5f62\u5f0f\u5316\u4e86 State Algebra \u6846\u67b6\uff0c\u8bc1\u660e\u4e86\u901a\u8fc7\u53d8\u91cf\u987a\u5e8f\u53ef\u83b7\u5f97\u89c4\u8303\u5f62\u5f0f\uff0c\u8ba8\u8bba\u4e86\u5176\u5728\u67d0\u4e9b\u95ee\u9898\u4e0a\u53ef\u80fd\u66f4\u7d27\u51d1\u4e14\u80fd\u8868\u8fbe\u641c\u7d22\u4e0e\u77e5\u8bc6\u7f16\u8bd1\u6d41\u7a0b\uff0c\u5e76\u793a\u8303\u5176\u53ef\u6269\u5c55\u81f3\u6982\u7387\u903b\u8f91\u4e0e\u52a0\u6743\u6a21\u578b\u8ba1\u6570\u3002", "conclusion": "State Algebra \u63d0\u4f9b\u4e86\u4e00\u79cd\u7528\u4ee3\u6570\u65b9\u6cd5\u8868\u793a\u548c\u64cd\u4f5c\u547d\u9898\u903b\u8f91\u7684\u65b0\u6846\u67b6\uff0c\u5f3a\u8c03\u8868\u793a\u7075\u6d3b\u6027\u4e0e\u8ba1\u7b97\u53ef\u64cd\u4f5c\u6027\u4e4b\u95f4\u7684\u6743\u8861\uff1b\u901a\u8fc7\u56fa\u5b9a\u53d8\u91cf\u987a\u5e8f\u53ef\u83b7\u5f97\u552f\u4e00\u7684\u89c4\u8303\u5f62\u5f0f\uff0c\u4ece\u800c\u6062\u590d\u89c4\u8303\u6027\u3002"}}
{"id": "2509.10011", "categories": ["cs.LG", "cs.AI", "cs.NA", "math.NA"], "pdf": "https://arxiv.org/pdf/2509.10011", "abs": "https://arxiv.org/abs/2509.10011", "authors": ["Antoine Orioua", "Philipp Krah", "Julian Koellermeier"], "title": "Intrinsic Dimension Estimating Autoencoder (IDEA) Using CancelOut Layer and a Projected Loss", "comment": "Preprint with 12 pages and 12 figures", "summary": "This paper introduces the Intrinsic Dimension Estimating Autoencoder (IDEA),\nwhich identifies the underlying intrinsic dimension of a wide range of datasets\nwhose samples lie on either linear or nonlinear manifolds. Beyond estimating\nthe intrinsic dimension, IDEA is also able to reconstruct the original dataset\nafter projecting it onto the corresponding latent space, which is structured\nusing re-weighted double CancelOut layers. Our key contribution is the\nintroduction of the projected reconstruction loss term, guiding the training of\nthe model by continuously assessing the reconstruction quality under the\nremoval of an additional latent dimension. We first assess the performance of\nIDEA on a series of theoretical benchmarks to validate its robustness. These\nexperiments allow us to test its reconstruction ability and compare its\nperformance with state-of-the-art intrinsic dimension estimators. The\nbenchmarks show good accuracy and high versatility of our approach.\nSubsequently, we apply our model to data generated from the numerical solution\nof a vertically resolved one-dimensional free-surface flow, following a\npointwise discretization of the vertical velocity profile in the horizontal\ndirection, vertical direction, and time. IDEA succeeds in estimating the\ndataset's intrinsic dimension and then reconstructs the original solution by\nworking directly within the projection space identified by the network.", "AI": {"tldr": "IDEA\u662f\u4e00\u79cd\u5e26\u6295\u5f71\u91cd\u6784\u635f\u5931\u548c\u91cd\u52a0\u6743CancelOut\u5c42\u7684\u81ea\u7f16\u7801\u5668\uff0c\u80fd\u540c\u65f6\u4f30\u8ba1\u6570\u636e\u5185\u5728\u7ef4\u5ea6\u5e76\u5728\u76f8\u5e94\u6f5c\u5728\u7a7a\u95f4\u91cd\u6784\u539f\u59cb\u6570\u636e\uff0c\u5728\u7406\u8bba\u548c\u6d41\u4f53\u529b\u5b66\u6570\u503c\u6570\u636e\u4e0a\u8868\u73b0\u826f\u597d\u3002", "motivation": "\u5f53\u524d\u5185\u5728\u7ef4\u5ea6\u4f30\u8ba1\u65b9\u6cd5\u5bf9\u975e\u7ebf\u6027\u6d41\u5f62\u6216\u540e\u7eed\u91cd\u6784\u80fd\u529b\u53ef\u80fd\u6709\u9650\u3002\u4f5c\u8005\u5e0c\u671b\u8bbe\u8ba1\u4e00\u4e2a\u65e2\u80fd\u51c6\u786e\u4f30\u8ba1\u5185\u5728\u7ef4\u5ea6\u53c8\u80fd\u5728\u76f8\u5e94\u6f5c\u5728\u7a7a\u95f4\u5185\u91cd\u6784\u539f\u59cb\u6570\u636e\u7684\u6a21\u578b\uff0c\u7279\u522b\u7528\u4e8e\u590d\u6742\u7269\u7406\u6570\u503c\u89e3\u6570\u636e\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u540d\u4e3aIDEA\u7684\u81ea\u7f16\u7801\u5668\uff0c\u4f7f\u7528\u91cd\u52a0\u6743\u53ccCancelOut\u5c42\u6784\u9020\u6f5c\u5728\u7a7a\u95f4\uff0c\u5e76\u5f15\u5165\u6295\u5f71\u91cd\u6784\u635f\u5931\u9879\uff1a\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u4e0d\u65ad\u8bc4\u4f30\u5728\u79fb\u9664\u989d\u5916\u6f5c\u5728\u7ef4\u5ea6\u65f6\u7684\u91cd\u6784\u8d28\u91cf\uff0c\u4ee5\u8bc6\u522b\u548c\u4fdd\u7559\u5fc5\u8981\u7684\u5185\u5728\u7ef4\u5ea6\u3002", "result": "\u5728\u7406\u8bba\u57fa\u51c6\u4e0a\uff0cIDEA\u5728\u5185\u5728\u7ef4\u5ea6\u4f30\u8ba1\u4e0a\u5c55\u793a\u4e86\u826f\u597d\u51c6\u786e\u6027\u5e76\u80fd\u7a33\u5065\u91cd\u6784\u6570\u636e\uff1b\u5728\u5782\u76f4\u5206\u8fa8\u7684\u4e00\u7ef4\u81ea\u7531\u8868\u9762\u6d41\u751f\u6210\u7684\u6570\u636e\u4e0a\uff0c\u6a21\u578b\u6210\u529f\u4f30\u8ba1\u51fa\u5185\u5728\u7ef4\u5ea6\u5e76\u5728\u8bc6\u522b\u7684\u6295\u5f71\u7a7a\u95f4\u5185\u91cd\u6784\u51fa\u539f\u59cb\u89e3\u3002", "conclusion": "IDEA\u901a\u8fc7\u5728\u81ea\u7f16\u7801\u5668\u4e2d\u5f15\u5165\u6295\u5f71\u91cd\u6784\u635f\u5931\u4e0e\u91cd\u52a0\u6743CancelOut\u5c42\uff0c\u6709\u6548\u4f30\u8ba1\u5e76\u91cd\u6784\u7ebf\u6027\u4e0e\u975e\u7ebf\u6027\u6d41\u5f62\u4e0a\u7684\u5185\u5728\u7ef4\u5ea6\uff0c\u5728\u7406\u8bba\u57fa\u51c6\u4e0e\u4e00\u7ef4\u81ea\u7531\u8868\u9762\u6d41\u6570\u503c\u6570\u636e\u4e0a\u8868\u73b0\u51fa\u7a33\u5065\u6027\u4e0e\u9ad8\u9002\u5e94\u6027\u3002"}}
{"id": "2509.10401", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.10401", "abs": "https://arxiv.org/abs/2509.10401", "authors": ["Alva West", "Yixuan Weng", "Minjun Zhu", "Zhen Lin", "Yue Zhang"], "title": "Abduct, Act, Predict: Scaffolding Causal Inference for Automated Failure Attribution in Multi-Agent Systems", "comment": null, "summary": "Failure attribution in multi-agent systems -- pinpointing the exact step\nwhere a decisive error occurs -- is a critical yet unsolved challenge. Current\nmethods treat this as a pattern recognition task over long conversation logs,\nleading to critically low step-level accuracy (below 17\\%), which renders them\nimpractical for debugging complex systems. Their core weakness is a fundamental\ninability to perform robust counterfactual reasoning: to determine if\ncorrecting a single action would have actually averted the task failure. To\nbridge this counterfactual inference gap, we introduce Abduct-Act-Predict (A2P)\nScaffolding, a novel agent framework that transforms failure attribution from\npattern recognition into a structured causal inference task. A2P explicitly\nguides a large language model through a formal three-step reasoning process\nwithin a single inference pass: (1) Abduction, to infer the hidden root causes\nbehind an agent's actions; (2) Action, to define a minimal corrective\nintervention; and (3) Prediction, to simulate the subsequent trajectory and\nverify if the intervention resolves the failure. This structured approach\nleverages the holistic context of the entire conversation while imposing a\nrigorous causal logic on the model's analysis. Our extensive experiments on the\nWho\\&When benchmark demonstrate its efficacy. On the Algorithm-Generated\ndataset, A2P achieves 47.46\\% step-level accuracy, a 2.85$\\times$ improvement\nover the 16.67\\% of the baseline. On the more complex Hand-Crafted dataset, it\nachieves 29.31\\% step accuracy, a 2.43$\\times$ improvement over the baseline's\n12.07\\%. By reframing the problem through a causal lens, A2P Scaffolding\nprovides a robust, verifiable, and significantly more accurate solution for\nautomated failure attribution.", "AI": {"tldr": "A2P\u901a\u8fc7\u4e09\u6b65\u56e0\u679c\u5316\u63a8\u7406\uff08\u5f52\u7eb3-\u5e72\u9884-\u9884\u6d4b\uff09\u5f25\u8865\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u53cd\u4e8b\u5b9e\u63a8\u7406\u7f3a\u9677\uff0c\u663e\u8457\u63d0\u9ad8\u5931\u8d25\u5f52\u56e0\u7684\u6b65\u7ea7\u51c6\u786e\u7387\uff0c\u589e\u5f3a\u4e86\u53ef\u9a8c\u8bc1\u6027\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4f5c\u4e3a\u6a21\u5f0f\u8bc6\u522b\u5904\u7406\u957f\u4f1a\u8bdd\u65e5\u5fd7\uff0c\u7f3a\u4e4f\u53cd\u4e8b\u5b9e\u63a8\u7406\u80fd\u529b\uff0c\u6b65\u7ea7\u7cbe\u5ea6\u4f4e\uff0c\u96be\u4ee5\u7528\u4e8e\u590d\u6742\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u8c03\u8bd5\u3002", "method": "\u63d0\u51faAbduct-Act-Predict (A2P) Scaffolding\uff1a\u5728\u5355\u6b21\u63a8\u7406\u4e2d\u5f15\u5bfc\u5927\u6a21\u578b\u6309\u4e09\u6b65\u8d70\uff081\uff09Abduction\uff1a\u63a8\u65ad\u884c\u4e3a\u80cc\u540e\u7684\u9690\u542b\u6839\u56e0\uff1b\uff082\uff09Action\uff1a\u6307\u5b9a\u6700\u5c0f\u4fee\u6b63\u5e72\u9884\uff1b\uff083\uff09Prediction\uff1a\u6a21\u62df\u5e72\u9884\u540e\u7684\u8f68\u8ff9\u4ee5\u9a8c\u8bc1\u662f\u5426\u6d88\u9664\u4e86\u5931\u8d25\u3002", "result": "\u5728Who&When\u57fa\u51c6\u4e0a\u53d6\u5f97\u663e\u8457\u63d0\u5347\uff1aAlgorithm-Generated\u6570\u636e\u96c6\u6b65\u7ea7\u51c6\u786e\u7387\u4ece16.67%\u63d0\u5347\u523047.46%\uff1bHand-Crafted\u6570\u636e\u96c6\u4ece12.07%\u63d0\u5347\u523029.31%\u3002", "conclusion": "A2P\u6846\u67b6\u901a\u8fc7\u5c06\u5931\u8d25\u5f52\u56e0\u91cd\u6784\u4e3a\u56e0\u679c\u63a8\u7406\u4efb\u52a1\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6b65\u7ea7\u522b\u5931\u8d25\u5b9a\u4f4d\u51c6\u786e\u7387\uff0c\u63d0\u4f9b\u4e86\u66f4\u53ef\u9a8c\u8bc1\u7684\u8c03\u8bd5\u5de5\u5177\u3002"}}
{"id": "2509.10025", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.10025", "abs": "https://arxiv.org/abs/2509.10025", "authors": ["Strahinja Nikolic", "Ilker Oguz", "Demetri Psaltis"], "title": "Exploring Expert Specialization through Unsupervised Training in Sparse Mixture of Experts", "comment": "14 pages, 7 figures", "summary": "Understanding the internal organization of neural networks remains a\nfundamental challenge in deep learning interpretability. We address this\nchallenge by exploring a novel Sparse Mixture of Experts Variational\nAutoencoder (SMoE-VAE) architecture. We test our model on the QuickDraw\ndataset, comparing unsupervised expert routing against a supervised baseline\nguided by ground-truth labels. Surprisingly, we find that unsupervised routing\nconsistently achieves superior reconstruction performance. The experts learn to\nidentify meaningful sub-categorical structures that often transcend\nhuman-defined class boundaries. Through t-SNE visualizations and reconstruction\nanalysis, we investigate how MoE models uncover fundamental data structures\nthat are more aligned with the model's objective than predefined labels.\nFurthermore, our study on the impact of dataset size provides insights into the\ntrade-offs between data quantity and expert specialization, offering guidance\nfor designing efficient MoE architectures.", "AI": {"tldr": "\u63d0\u51faSMoE-VAE\uff0c\u5728QuickDraw\u4e0a\u53d1\u73b0\u65e0\u76d1\u7763\u4e13\u5bb6\u8def\u7531\u4f18\u4e8e\u6709\u76d1\u7763\u8def\u7531\uff0c\u4e13\u5bb6\u5b66\u5230\u8d85\u8d8a\u6807\u7b7e\u7684\u5b50\u7c7b\u7ed3\u6784\uff1b\u901a\u8fc7\u53ef\u89c6\u5316\u4e0e\u6570\u636e\u91cf\u5b9e\u9a8c\u5206\u6790\u4e13\u5bb6\u5206\u5de5\u4e0e\u6027\u80fd\u6743\u8861\u3002", "motivation": "\u63a2\u7d22\u795e\u7ecf\u7f51\u7edc\u5185\u90e8\u7ec4\u7ec7\u4e0e\u4e13\u5bb6\u6a21\u5757\u5316\u5982\u4f55\u63ed\u793a\u6570\u636e\u7684\u5185\u5728\u7ed3\u6784\uff0c\u4ee5\u53ca\u65e0\u76d1\u7763\u8def\u7531\u662f\u5426\u80fd\u5b66\u4e60\u6bd4\u4eba\u5de5\u6807\u7b7e\u66f4\u7b26\u5408\u6a21\u578b\u76ee\u6807\u7684\u5206\u89e3\uff0c\u4ece\u800c\u63d0\u9ad8\u91cd\u5efa\u4e0e\u8868\u793a\u6548\u679c\u3002", "method": "\u63d0\u51fa\u5e76\u5b9e\u73b0Sparse Mixture of Experts Variational Autoencoder\uff08SMoE-VAE\uff09\uff0c\u5728QuickDraw\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u6bd4\u8f83\u65e0\u76d1\u7763\u8def\u7531\u4e0e\u6709\u76d1\u7763\u8def\u7531\uff08\u57fa\u4e8e\u771f\u5b9e\u6807\u7b7e\uff09\u4e24\u79cd\u914d\u7f6e\uff1b\u901a\u8fc7\u91cd\u5efa\u8bef\u5dee\u3001t-SNE\u53ef\u89c6\u5316\u4e0e\u91cd\u5efa\u6837\u672c\u5206\u6790\u8bc4\u4f30\u4e13\u5bb6\u5206\u5de5\u4e0e\u8868\u793a\uff1b\u8fd8\u7814\u7a76\u4e0d\u540c\u8bad\u7ec3\u96c6\u89c4\u6a21\u5bf9\u4e13\u5bb6\u4e13\u4e1a\u5316\u4e0e\u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "\u65e0\u76d1\u7763\u8def\u7531\u5728\u91cd\u5efa\u65b9\u9762\u6301\u7eed\u4f18\u4e8e\u6709\u76d1\u7763\u57fa\u7ebf\uff1b\u4e13\u5bb6\u81ea\u52a8\u5b66\u51fa\u6709\u610f\u4e49\u7684\u5b50\u7c7b\u522b\uff0c\u5e38\u8de8\u8d8a\u4eba\u7c7b\u5b9a\u4e49\u7684\u7c7b\u522b\u8fb9\u754c\uff1bt-SNE\u4e0e\u91cd\u5efa\u793a\u4f8b\u8868\u660eMoE\u504f\u5411\u4e8e\u57fa\u4e8e\u6a21\u578b\u76ee\u6807\u5206\u7ec4\u6570\u636e\uff1b\u6570\u636e\u91cf\u7814\u7a76\u663e\u793a\u6837\u672c\u89c4\u6a21\u5f71\u54cd\u4e13\u5bb6\u5206\u5316\u4e0e\u6027\u80fd\uff0c\u63ed\u793a\u6570\u636e\u91cf\u4e0e\u4e13\u5bb6\u4e13\u4e1a\u5316\u95f4\u7684\u6743\u8861\u3002", "conclusion": "SMoE-VAE\u5c55\u793a\u4e86\u65e0\u76d1\u7763\u4e13\u5bb6\u8def\u7531\u80fd\u4f18\u4e8e\u6709\u76d1\u7763\u6807\u7b7e\u5f15\u5bfc\u7684\u91cd\u5efa\u6027\u80fd\uff0c\u4e13\u5bb6\u6355\u6349\u5230\u8d85\u8d8a\u4eba\u5de5\u7c7b\u522b\u7684\u5b50\u7c7b\u522b\u7ed3\u6784\uff0c\u63d0\u793a\u6a21\u578b\u5b66\u4e60\u76ee\u6807\u6bd4\u9884\u5b9a\u4e49\u6807\u7b7e\u66f4\u8d34\u5408\u6570\u636e\u5185\u5728\u7ed3\u6784\u3002"}}
{"id": "2509.10423", "categories": ["cs.AI", "cs.LG", "cs.RO"], "pdf": "https://arxiv.org/pdf/2509.10423", "abs": "https://arxiv.org/abs/2509.10423", "authors": ["Cameron Reid", "Wael Hafez", "Amirhossein Nazeri"], "title": "Mutual Information Tracks Policy Coherence in Reinforcement Learning", "comment": "10 pages, 4 figures, 1 table", "summary": "Reinforcement Learning (RL) agents deployed in real-world environments face\ndegradation from sensor faults, actuator wear, and environmental shifts, yet\nlack intrinsic mechanisms to detect and diagnose these failures. We present an\ninformation-theoretic framework that reveals both the fundamental dynamics of\nRL and provides practical methods for diagnosing deployment-time anomalies.\nThrough analysis of state-action mutual information patterns in a robotic\ncontrol task, we first demonstrate that successful learning exhibits\ncharacteristic information signatures: mutual information between states and\nactions steadily increases from 0.84 to 2.83 bits (238% growth) despite growing\nstate entropy, indicating that agents develop increasingly selective attention\nto task-relevant patterns. Intriguingly, states, actions and next states joint\nmutual information, MI(S,A;S'), follows an inverted U-curve, peaking during\nearly learning before declining as the agent specializes suggesting a\ntransition from broad exploration to efficient exploitation. More immediately\nactionable, we show that information metrics can differentially diagnose system\nfailures: observation-space, i.e., states noise (sensor faults) produces broad\ncollapses across all information channels with pronounced drops in state-action\ncoupling, while action-space noise (actuator faults) selectively disrupts\naction-outcome predictability while preserving state-action relationships. This\ndifferential diagnostic capability demonstrated through controlled perturbation\nexperiments enables precise fault localization without architectural\nmodifications or performance degradation. By establishing information patterns\nas both signatures of learning and diagnostic for system health, we provide the\nfoundation for adaptive RL systems capable of autonomous fault detection and\npolicy adjustment based on information-theoretic principles.", "AI": {"tldr": "\u63d0\u51fa\u4fe1\u606f\u8bba\u8bca\u65ad\u6846\u67b6\uff1a\u5b66\u4e60\u8fc7\u7a0b\u4ea7\u751f\u53ef\u8bc6\u522b\u7684\u4fe1\u606f\u7b7e\u540d\uff0c\u4e14\u4e0d\u540c\u6545\u969c\u7c7b\u578b\u5728\u4e92\u4fe1\u606f\u901a\u9053\u4e0a\u6709\u4e0d\u540c\u8868\u73b0\uff0c\u53ef\u7528\u4e8e\u65e0\u67b6\u6784\u6539\u52a8\u7684\u5728\u7ebf\u6545\u969c\u68c0\u6d4b\u4e0e\u5b9a\u4f4d\u3002", "motivation": "\u73b0\u5b9e\u73af\u5883\u4e2dRL\u4ee3\u7406\u4f1a\u906d\u9047\u4f20\u611f\u5668\u6545\u969c\u3001\u6267\u884c\u5668\u78e8\u635f\u548c\u73af\u5883\u53d8\u5316\uff0c\u4f46\u7f3a\u4e4f\u5185\u751f\u7684\u5f02\u5e38\u68c0\u6d4b\u4e0e\u8bca\u65ad\u673a\u5236\u3002\u57fa\u4e8e\u4fe1\u606f\u8bba\u7684\u65b9\u6cd5\u53ef\u4ee5\u63d0\u4f9b\u4e0e\u7b56\u7565\u884c\u4e3a\u548c\u73af\u5883\u4ea4\u4e92\u76f8\u5173\u7684\u666e\u9002\u5ea6\u91cf\uff0c\u4fbf\u4e8e\u5b9e\u65f6\u76d1\u6d4b\u7cfb\u7edf\u5065\u5eb7\u3002", "method": "\u901a\u8fc7\u5728\u673a\u5668\u4eba\u63a7\u5236\u4efb\u52a1\u4e2d\u8ba1\u7b97\u72b6\u6001\u3001\u52a8\u4f5c\u548c\u4e0b\u4e00\u72b6\u6001\u4e4b\u95f4\u7684\u4e92\u4fe1\u606f\u53ca\u5176\u968f\u8bad\u7ec3\u65f6\u95f4\u7684\u53d8\u5316\uff0c\u5206\u6790\u4fe1\u606f\u7b7e\u540d\uff1b\u5e76\u901a\u8fc7\u53d7\u63a7\u6270\u52a8\u5b9e\u9a8c\u5728\u89c2\u6d4b\u7a7a\u95f4\u548c\u52a8\u4f5c\u7a7a\u95f4\u5206\u522b\u5f15\u5165\u566a\u58f0\uff0c\u6bd4\u8f83\u5404\u7c7b\u4e92\u4fe1\u606f\u901a\u9053\uff08\u5982MI(S;A)\u3001MI(A;S')\u3001MI(S,A;S')\uff09\u7684\u54cd\u5e94\u5dee\u5f02\uff0c\u5b9e\u73b0\u8bca\u65ad\u3002", "result": "\u5b9e\u9a8c\u4e2dMI(S;A)\u4ece0.84\u6bd4\u7279\u589e\u957f\u52302.83\u6bd4\u7279\uff08\u589e\u957f238%\uff09\uff0cMI(S,A;S')\u5728\u65e9\u671f\u5b66\u4e60\u8fbe\u5230\u5cf0\u503c\u540e\u4e0b\u964d\uff0c\u8868\u660e\u4ece\u5e7f\u6cdb\u63a2\u7d22\u5411\u9ad8\u6548\u5229\u7528\u7684\u8f6c\u53d8\u3002\u89c2\u6d4b\u566a\u58f0\u5f15\u8d77\u591a\u4e2a\u4fe1\u606f\u901a\u9053\u5d29\u584c\u5e76\u660e\u663e\u964d\u4f4e\u72b6\u6001-\u52a8\u4f5c\u8026\u5408\uff1b\u52a8\u4f5c\u566a\u58f0\u4e3b\u8981\u7834\u574f\u52a8\u4f5c-\u7ed3\u679c\u53ef\u9884\u6d4b\u6027\u800c\u4fdd\u7559\u72b6\u6001-\u52a8\u4f5c\u5173\u7cfb\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u4fe1\u606f\u8bba\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u63ed\u793a\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u8fc7\u7a0b\u7684\u5185\u5728\u52a8\u529b\u5b66\u5e76\u8bca\u65ad\u90e8\u7f72\u65f6\u7684\u5f02\u5e38\u3002\u7814\u7a76\u53d1\u73b0\uff1a\u5b66\u4e60\u6210\u529f\u65f6\u72b6\u6001-\u52a8\u4f5c\u4e92\u4fe1\u606f\uff08MI(S;A)\uff09\u663e\u8457\u589e\u52a0\uff0c\u800c\u8054\u5408\u4e92\u4fe1\u606fMI(S,A;S')\u5448\u73b0\u5012U\u578b\u66f2\u7ebf\uff1b\u4fe1\u606f\u5ea6\u91cf\u80fd\u533a\u5206\u89c2\u6d4b\u7a7a\u95f4\u566a\u58f0\uff08\u4f20\u611f\u5668\u6545\u969c\uff09\u4e0e\u52a8\u4f5c\u7a7a\u95f4\u566a\u58f0\uff08\u6267\u884c\u5668\u6545\u969c\uff09\uff0c\u4ece\u800c\u5b9e\u73b0\u6545\u969c\u5b9a\u4f4d\uff0c\u65e0\u9700\u6539\u52a8\u6a21\u578b\u7ed3\u6784\u3002"}}
{"id": "2509.10033", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.10033", "abs": "https://arxiv.org/abs/2509.10033", "authors": ["Boya Ma", "Abram Magner", "Maxwell McNeil", "Petko Bogdanov"], "title": "Sparse Coding Representation of 2-way Data", "comment": null, "summary": "Sparse dictionary coding represents signals as linear combinations of a few\ndictionary atoms. It has been applied to images, time series, graph signals and\nmulti-way spatio-temporal data by jointly employing temporal and spatial\ndictionaries. Data-agnostic analytical dictionaries, such as the discrete\nFourier transform, wavelets and graph Fourier, have seen wide adoption due to\nefficient implementations and good practical performance. On the other hand,\ndictionaries learned from data offer sparser and more accurate solutions but\nrequire learning of both the dictionaries and the coding coefficients. This\nbecomes especially challenging for multi-dictionary scenarios since encoding\ncoefficients correspond to all atom combinations from the dictionaries. To\naddress this challenge, we propose a low-rank coding model for 2-dictionary\nscenarios and study its data complexity. Namely, we establish a bound on the\nnumber of samples needed to learn dictionaries that generalize to unseen\nsamples from the same distribution. We propose a convex relaxation solution,\ncalled AODL, whose exact solution we show also solves the original problem. We\nthen solve this relaxation via alternating optimization between the sparse\ncoding matrices and the learned dictionaries, which we prove to be convergent.\nWe demonstrate its quality for data reconstruction and missing value imputation\nin both synthetic and real-world datasets. For a fixed reconstruction quality,\nAODL learns up to 90\\% sparser solutions compared to non-low-rank and\nanalytical (fixed) dictionary baselines. In addition, the learned dictionaries\nreveal interpretable insights into patterns present within the samples used for\ntraining.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u9488\u5bf9\u53cc\u5b57\u5178\u7684\u4f4e\u79e9\u7a00\u758f\u7f16\u7801\u4e0e\u51f8\u677e\u5f1b\u6c42\u89e3\uff08AODL\uff09\uff0c\u7406\u8bba\u7ed9\u51fa\u6837\u672c\u590d\u6742\u5ea6\u4e0e\u6536\u655b\u6027\u8bc1\u660e\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5728\u91cd\u5efa\u4e0e\u7f3a\u5931\u63d2\u8865\u4e0a\u80fd\u663e\u8457\u63d0\u9ad8\u7a00\u758f\u6027\u5e76\u63d0\u5347\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u5728\u591a\u5b57\u5178\uff08\u4f8b\u5982\u65f6\u7a7a\u5206\u89e3\uff09\u60c5\u5f62\u4e0b\uff0c\u7f16\u7801\u7cfb\u6570\u6570\u76ee\u5448\u5b57\u5178\u539f\u5b50\u7ec4\u5408\u7206\u70b8\uff0c\u5b66\u4e60\u5b57\u5178\u4e0e\u7cfb\u6570\u53d8\u5f97\u56f0\u96be\uff1b\u901a\u8fc7\u4f4e\u79e9\u5047\u8bbe\u51cf\u5c11\u81ea\u7531\u5ea6\u4ee5\u964d\u4f4e\u6837\u672c\u590d\u6742\u5ea6\u5e76\u63d0\u9ad8\u7a00\u758f\u6027\u548c\u53ef\u6cdb\u5316\u6027\u3002", "method": "\u6784\u5efa2\u5b57\u5178\u4f4e\u79e9\u7f16\u7801\u6a21\u578b\u5e76\u8fdb\u884c\u51f8\u677e\u5f1b\uff1b\u8bc1\u660e\u677e\u5f1b\u95ee\u9898\u7684\u89e3\u5373\u539f\u95ee\u9898\u7684\u89e3\uff1b\u91c7\u7528\u5728\u7a00\u758f\u7f16\u7801\u77e9\u9635\u4e0e\u5b57\u5178\u95f4\u4ea4\u66ff\u4f18\u5316\u7684\u8fed\u4ee3\u7b97\u6cd5\u6c42\u89e3\uff0c\u5e76\u8bc1\u660e\u6536\u655b\u6027\u3002", "result": "\u7ed9\u51fa\u4e86\u6837\u672c\u590d\u6742\u5ea6\u754c\uff0c\u63d0\u51faAODL\u65b9\u6cd5\u5e76\u8bc1\u660e\u5176\u89e3\u7684\u7b49\u4ef7\u6027\u4e0e\u7b97\u6cd5\u6536\u655b\u6027\uff1b\u5b9e\u9a8c\u4e0a\u5728\u5408\u6210\u4e0e\u771f\u5b9e\u6570\u636e\u4e2d\uff0c\u5728\u76f8\u540c\u91cd\u5efa\u8d28\u91cf\u4e0b\u76f8\u6bd4\u975e\u4f4e\u79e9\u5b66\u4e60\u5b57\u5178\u548c\u56fa\u5b9a\u89e3\u6790\u5b57\u5178\u8fbe\u5230\u6700\u591a90%\u66f4\u9ad8\u7a00\u758f\u5ea6\uff0c\u4e14\u5b66\u5f97\u5b57\u5178\u5177\u6709\u53ef\u89e3\u91ca\u6a21\u5f0f\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u7528\u4e8e\u53cc\u5b57\u5178\u573a\u666f\u7684\u4f4e\u79e9\u7a00\u758f\u7f16\u7801\u6a21\u578b\uff08AODL\uff09\uff0c\u5e76\u8bc1\u660e\u5176\u51f8\u677e\u5f1b\u7684\u53ef\u884c\u6027\u548c\u4ea4\u66ff\u4f18\u5316\u7b97\u6cd5\u7684\u6536\u655b\u6027\uff0c\u5b9e\u9a8c\u663e\u793a\u5728\u91cd\u5efa\u548c\u7f3a\u5931\u503c\u63d2\u8865\u4efb\u52a1\u4e0a\u663e\u8457\u63d0\u9ad8\u7a00\u758f\u6027\u4e14\u53ef\u89e3\u91ca\u6027\u5f3a\u3002"}}
{"id": "2509.10034", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.10034", "abs": "https://arxiv.org/abs/2509.10034", "authors": ["Sahil Rajesh Dhayalkar"], "title": "Symbolic Feedforward Networks for Probabilistic Finite Automata: Exact Simulation and Learnability", "comment": "19 pages, 2 figures", "summary": "We present a formal and constructive theory showing that probabilistic finite\nautomata (PFAs) can be exactly simulated using symbolic feedforward neural\nnetworks. Our architecture represents state distributions as vectors and\ntransitions as stochastic matrices, enabling probabilistic state propagation\nvia matrix-vector products. This yields a parallel, interpretable, and\ndifferentiable simulation of PFA dynamics using soft updates-without\nrecurrence. We formally characterize probabilistic subset construction,\n$\\varepsilon$-closure, and exact simulation via layered symbolic computation,\nand prove equivalence between PFAs and specific classes of neural networks. We\nfurther show that these symbolic simulators are not only expressive but\nlearnable: trained with standard gradient descent-based optimization on labeled\nsequence data, they recover the exact behavior of ground-truth PFAs. This\nlearnability, formalized in Proposition 5.1, is the crux of this work. Our\nresults unify probabilistic automata theory with neural architectures under a\nrigorous algebraic framework, bridging the gap between symbolic computation and\ndeep learning.", "AI": {"tldr": "\u672c\u6587\u6784\u9020\u5e76\u8bc1\u660e\u4e86\u4e00\u7c7b\u7b26\u53f7\u524d\u9988\u795e\u7ecf\u7f51\u7edc\u80fd\u7cbe\u786e\u4e14\u53ef\u5b66\u4e60\u5730\u6a21\u62df\u6982\u7387\u6709\u9650\u81ea\u52a8\u673a\uff0c\u5efa\u7acb\u4e86\u4e24\u8005\u5728\u8868\u8fbe\u4e0e\u5b66\u4e60\u65b9\u9762\u7684\u4e25\u683c\u8054\u7cfb\u3002", "motivation": "\u5c06\u6982\u7387\u81ea\u52a8\u673a\u7406\u8bba\u4e0e\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u8054\u7cfb\u8d77\u6765\uff0c\u4e3a\u53ef\u89e3\u91ca\u3001\u5e76\u884c\u4e14\u53ef\u5fae\u7684\u7b26\u53f7\u6a21\u62df\u5668\u63d0\u4f9b\u4ee3\u6570\u5316\u3001\u6784\u9020\u6027\u7406\u8bba\uff0c\u5f25\u5408\u7b26\u53f7\u8ba1\u7b97\u4e0e\u6df1\u5ea6\u5b66\u4e60\u7684\u5dee\u8ddd\u3002", "method": "\u5c06\u72b6\u6001\u5206\u5e03\u8868\u793a\u4e3a\u5411\u91cf\uff0c\u8f6c\u6362\u8868\u793a\u4e3a\u968f\u673a\u77e9\u9635\uff0c\u901a\u8fc7\u65e0\u5faa\u73af\u7684\u77e9\u9635-\u5411\u91cf\u4e58\u6cd5\u5b9e\u73b0\u6982\u7387\u72b6\u6001\u4f20\u64ad\uff0c\u4f7f\u7528\u5206\u5c42\u7b26\u53f7\u8ba1\u7b97\u523b\u753b\u6982\u7387\u5b50\u96c6\u6784\u9020\u3001\u03b5-\u95ed\u5305\u548c\u7cbe\u786e\u6a21\u62df\uff0c\u5e76\u8bc1\u660e\u4e0e\u7279\u5b9a\u7c7b\u795e\u7ecf\u7f51\u7edc\u7b49\u4ef7\uff1b\u901a\u8fc7\u68af\u5ea6\u4e0b\u964d\u8bad\u7ec3\u9a8c\u8bc1\u5b66\u4e60\u6027\uff0c\u63d0\u51fa\u547d\u98985.1\u8bc1\u660e\u53ef\u5b66\u4e60\u6027\u3002", "result": "\u7ed9\u51fa\u5f62\u5f0f\u5316\u7b49\u4ef7\u6027\u8bc1\u660e\u3001\u53ef\u5b66\u4e60\u6027\u7684\u7406\u8bba\u4fdd\u8bc1\uff08\u547d\u98985.1\uff09\uff0c\u5e76\u6784\u9020\u80fd\u5728\u65e0\u5faa\u73af\u524d\u9988\u7f51\u7edc\u4e2d\u7cbe\u786e\u6a21\u62dfPFA\u7684\u4f53\u7cfb\u7ed3\u6784\uff0c\u5b9e\u9a8c\uff08\u6216\u7406\u8bba\uff09\u8868\u660e\u901a\u8fc7\u68af\u5ea6\u8bad\u7ec3\u53ef\u6062\u590d\u771f\u662fPFA\u884c\u4e3a\u3002", "conclusion": "\u672c\u6587\u8bc1\u660e\u4e86\u53ef\u6982\u7387\u6709\u9650\u81ea\u52a8\u673a\uff08PFA\uff09\u53ef\u88ab\u7b26\u53f7\u524d\u9988\u795e\u7ecf\u7f51\u7edc\u7cbe\u786e\u6a21\u62df\uff0c\u4e8c\u8005\u5728\u8868\u8fbe\u80fd\u529b\u4e0a\u7b49\u4ef7\uff0c\u5e76\u4e14\u8be5\u7b26\u53f7\u6a21\u62df\u5668\u5728\u5e26\u6807\u7b7e\u5e8f\u5217\u6570\u636e\u4e0a\u901a\u8fc7\u6807\u51c6\u68af\u5ea6\u4e0b\u964d\u53ef\u5b66\u4e60\u5230\u771f\u5b9ePFA\u7684\u884c\u4e3a\u3002"}}
{"id": "2509.10041", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.10041", "abs": "https://arxiv.org/abs/2509.10041", "authors": ["Mohammad Hasan Narimani", "Mostafa Tavassolipour"], "title": "FedRP: A Communication-Efficient Approach for Differentially Private Federated Learning Using Random Projection", "comment": null, "summary": "Federated learning (FL) offers an innovative paradigm for collaborative model\ntraining across decentralized devices, such as smartphones, balancing enhanced\npredictive performance with the protection of user privacy in sensitive areas\nlike Internet of Things (IoT) and medical data analysis. Despite its\nadvantages, FL encounters significant challenges related to user privacy\nprotection against potential attacks and the management of communication costs.\nThis paper introduces a novel federated learning algorithm called FedRP, which\nintegrates random projection techniques with the Alternating Direction Method\nof Multipliers (ADMM) optimization framework. This approach enhances privacy by\nemploying random projection to reduce the dimensionality of model parameters\nprior to their transmission to a central server, reducing the communication\ncost. The proposed algorithm offers a strong $(\\epsilon, \\delta)$-differential\nprivacy guarantee, demonstrating resilience against data reconstruction\nattacks. Experimental results reveal that FedRP not only maintains high model\naccuracy but also outperforms existing methods, including conventional\ndifferential privacy approaches and FedADMM, in terms of both privacy\npreservation and communication efficiency.", "AI": {"tldr": "\u63d0\u51faFedRP\uff1a\u5728\u5ba2\u6237\u7aef\u5148\u505a\u968f\u673a\u6295\u5f71\u964d\u7ef4\u518d\u7528ADMM\u4f18\u5316\uff0c\u517c\u987e\u5dee\u5206\u9690\u79c1\u4e0e\u901a\u4fe1\u6548\u7387\uff0c\u5b9e\u9a8c\u4f18\u4e8e\u4f20\u7edfDP\u548cFedADMM\u3002", "motivation": "\u89e3\u51b3\u8054\u90a6\u5b66\u4e60\u4e2d\u4e24\u5927\u75db\u70b9\uff1a\u4e00\u662f\u9632\u6b62\u670d\u52a1\u5668\u6216\u4e2d\u95f4\u4eba\u901a\u8fc7\u53c2\u6570/\u68af\u5ea6\u91cd\u6784\u7528\u6237\u654f\u611f\u6570\u636e\uff0c\u4e8c\u662f\u51cf\u5c11\u6a21\u578b\u53c2\u6570\u5728\u8bbe\u5907\u4e0e\u670d\u52a1\u5668\u95f4\u4f20\u8f93\u5bfc\u81f4\u7684\u9ad8\u901a\u4fe1\u6210\u672c\u3002", "method": "\u5728\u8054\u90a6\u5b66\u4e60\u6846\u67b6\u4e0b\uff0c\u5ba2\u6237\u7aef\u5148\u5bf9\u6a21\u578b\u53c2\u6570\u65bd\u52a0\u968f\u673a\u6295\u5f71\u964d\u7ef4\uff0c\u518d\u57fa\u4e8eADMM\u8fdb\u884c\u5206\u5e03\u5f0f\u4f18\u5316\uff1b\u964d\u7ef4\u540e\u7684\u53c2\u6570\u4f20\u8f93\u81f3\u670d\u52a1\u7aef\u4ee5\u964d\u4f4e\u901a\u4fe1\u5f00\u9500\uff0c\u5e76\u901a\u8fc7\u968f\u673a\u5316\u673a\u5236\u6ee1\u8db3(\u03b5,\u03b4)-\u5dee\u5206\u9690\u79c1\u3002", "result": "\u7406\u8bba\u4e0a\u7ed9\u51fa(\u03b5,\u03b4)-\u5dee\u5206\u9690\u79c1\u8bc1\u660e\u4e0e\u6297\u91cd\u6784\u80fd\u529b\uff0c\u5b9e\u9a8c\u4e0a\u5728\u591a\u4e2a\u4efb\u52a1/\u6570\u636e\u96c6\u5bf9\u6bd4\u4e2d\uff0cFedRP\u5728\u4fdd\u6301\u6216\u63d0\u9ad8\u6a21\u578b\u51c6\u786e\u7387\u7684\u540c\u65f6\uff0c\u901a\u4fe1\u5f00\u9500\u548c\u9690\u79c1\u6cc4\u9732\u98ce\u9669\u5747\u4f4e\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "FedRP\u901a\u8fc7\u5c06\u968f\u673a\u6295\u5f71\u4e0eADMM\u7ed3\u5408\uff0c\u5728\u964d\u4f4e\u901a\u4fe1\u6210\u672c\u7684\u540c\u65f6\u5f3a\u5316\u9690\u79c1\u4fdd\u62a4\uff0c\u80fd\u5b9e\u73b0(\u03b5,\u03b4)-\u5dee\u5206\u9690\u79c1\u5e76\u62b5\u6297\u91cd\u6784\u653b\u51fb\uff0c\u4e14\u5728\u5b9e\u9a8c\u4e2d\u6bd4\u4f20\u7edf\u5dee\u5206\u9690\u79c1\u65b9\u6cd5\u548cFedADMM\u5728\u7cbe\u5ea6\u3001\u9690\u79c1\u4e0e\u901a\u4fe1\u6548\u7387\u95f4\u8868\u73b0\u66f4\u597d\u3002"}}
{"id": "2509.10048", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.10048", "abs": "https://arxiv.org/abs/2509.10048", "authors": ["Madhushan Ramalingam"], "title": "Uncertainty-Aware Tabular Prediction: Evaluating VBLL-Enhanced TabPFN in Safety-Critical Medical Data", "comment": null, "summary": "Predictive models are being increasingly used across a wide range of domains,\nincluding safety-critical applications such as medical diagnosis and criminal\njustice. Reliable uncertainty estimation is a crucial task in such settings.\nTabular Prior-data Fitted Network (TabPFN) is a recently proposed machine\nlearning foundation model for tabular dataset, which uses a generative\ntransformer architecture. Variational Bayesian Last Layers (VBLL) is a\nstate-of-the-art lightweight variational formulation that effectively improves\nuncertainty estimation with minimal computational overhead. In this work we aim\nto evaluate the performance of VBLL integrated with the recently proposed\nTabPFN in uncertainty calibration. Our experiments, conducted on three\nbenchmark medical tabular datasets, compare the performance of the original\nTabPFN and the VBLL-integrated version. Contrary to expectations, we observed\nthat original TabPFN consistently outperforms VBLL integrated TabPFN in\nuncertainty calibration across all datasets.", "AI": {"tldr": "\u5c1d\u8bd5\u5c06\u8f7b\u91cf\u7ea7\u53d8\u5206\u8d1d\u53f6\u65af\u6700\u540e\u5c42\uff08VBLL\uff09\u52a0\u5165TabPFN\u4ee5\u63d0\u5347\u4e0d\u786e\u5b9a\u6027\u6821\u51c6\uff0c\u4f46\u5b9e\u9a8c\u8868\u660e\u8fd9\u79cd\u96c6\u6210\u5728\u4e09\u4e2a\u533b\u7597\u6570\u636e\u96c6\u4e0a\u53cd\u800c\u964d\u4f4e\u4e86\u6821\u51c6\u6027\u80fd\uff0c\u539f\u59cbTabPFN\u8868\u73b0\u66f4\u597d\u3002", "motivation": "\u8bc4\u4f30\u8f7b\u91cf\u7ea7\u53d8\u5206\u8d1d\u53f6\u65af\u6700\u540e\u5c42\uff08VBLL\uff09\u5728\u63d0\u5347\u5df2\u5b58\u5728\u751f\u6210\u5f0fTransformer\u8868\u683c\u6a21\u578b\uff08TabPFN\uff09\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u4e0a\u7684\u6548\u679c\uff0c\u671f\u671b\u901a\u8fc7\u5c0f\u6210\u672c\u6539\u52a8\u6539\u5584\u6821\u51c6\u6027\u80fd\u3002", "method": "\u5c06VBLL\u6a21\u5757\u96c6\u6210\u5230TabPFN\u7684\u6700\u540e\u5c42\uff0c\u4fdd\u6301\u5176\u4ed6\u8bad\u7ec3\u548c\u63a8\u7406\u6d41\u7a0b\u4e0d\u53d8\uff1b\u5728\u4e09\u4e2a\u57fa\u51c6\u533b\u7597\u8868\u683c\u6570\u636e\u96c6\u4e0a\u6bd4\u8f83\u539f\u59cbTabPFN\u4e0eVBLL-TabPFN\u7684\u6821\u51c6\u6027\u80fd\uff0c\u4f7f\u7528\u6807\u51c6\u4e0d\u786e\u5b9a\u6027/\u6821\u51c6\u6307\u6807\u8bc4\u4f30\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u4e0e\u9884\u671f\u76f8\u53cd\uff0cVBLL\u96c6\u6210\u5e76\u672a\u6539\u5584\u53cd\u800c\u964d\u4f4e\u4e86TabPFN\u7684\u6821\u51c6\u6027\u80fd\uff1b\u539f\u59cbTabPFN\u5728\u6240\u6709\u4e09\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u6821\u51c6\u6307\u6807\u5747\u4f18\u4e8eVBLL\u7248\u672c\u3002", "conclusion": "\u5728\u4e09\u4e2a\u533b\u7597\u8868\u683c\u6570\u636e\u96c6\u4e0a\uff0c\u539f\u59cbTabPFN\u5728\u4e0d\u786e\u5b9a\u6027\u6821\u51c6\u65b9\u9762\u6301\u7eed\u4f18\u4e8e\u4e0eVBLL\u96c6\u6210\u7684\u7248\u672c\u3002"}}
{"id": "2509.10089", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.10089", "abs": "https://arxiv.org/abs/2509.10089", "authors": ["Marco Andrea B\u00fchler", "Gonzalo Guill\u00e9n-Gos\u00e1lbez"], "title": "KAN-SR: A Kolmogorov-Arnold Network Guided Symbolic Regression Framework", "comment": null, "summary": "We introduce a novel symbolic regression framework, namely KAN-SR, built on\nKolmogorov Arnold Networks (KANs) which follows a divide-and-conquer approach.\nSymbolic regression searches for mathematical equations that best fit a given\ndataset and is commonly solved with genetic programming approaches. We show\nthat by using deep learning techniques, more specific KANs, and combining them\nwith simplification strategies such as translational symmetries and\nseparabilities, we are able to recover ground-truth equations of the Feynman\nSymbolic Regression for Scientific Discovery (SRSD) dataset. Additionally, we\nshow that by combining the proposed framework with neural controlled\ndifferential equations, we are able to model the dynamics of an in-silico\nbioprocess system precisely, opening the door for the dynamic modeling of other\nengineering systems.", "AI": {"tldr": "\u63d0\u51faKAN-SR\uff1a\u57fa\u4e8eKolmogorov Arnold Networks\u7684\u5206\u6cbb\u7b26\u53f7\u56de\u5f52\u6846\u67b6\uff0c\u7ed3\u5408\u7b80\u5316\u7b56\u7565\u548c\u795e\u7ecf\u63a7\u5236\u5fae\u5206\u65b9\u7a0b\uff0c\u80fd\u51c6\u786e\u6062\u590d\u7269\u7406\u65b9\u7a0b\u5e76\u5efa\u6a21\u5de5\u7a0b\u52a8\u529b\u5b66\u3002", "motivation": "\u6539\u8fdb\u4f20\u7edf\u9057\u4f20\u7f16\u7a0b\u5728\u7b26\u53f7\u56de\u5f52\u4e0a\u7684\u5c40\u9650\uff0c\u5229\u7528\u6df1\u5ea6\u5b66\u4e60\u4e0e\u6570\u5b66\u7ed3\u6784\u5316\u5148\u9a8c\u63d0\u9ad8\u7cbe\u786e\u6062\u590d\u89e3\u6790\u8868\u8fbe\u5f0f\u53ca\u52a8\u529b\u5b66\u6a21\u578b\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u57fa\u4e8eKolmogorov Arnold Networks\u7684\u5206\u800c\u6cbb\u4e4b\u6846\u67b6\uff0c\u7ed3\u5408\u66f4\u4e13\u95e8\u5316\u7684KAN\u7ed3\u6784\u3001\u5e73\u79fb\u5bf9\u79f0\u6027\u548c\u53ef\u5206\u89e3\u6027\u7b49\u7b80\u5316\u7b56\u7565\uff0c\u5e76\u4e0e\u795e\u7ecf\u63a7\u5236\u5fae\u5206\u65b9\u7a0b\u6574\u5408\u7528\u4e8e\u52a8\u6001\u7cfb\u7edf\u5efa\u6a21\u3002", "result": "\u5728Feynman SRSD\u6570\u636e\u96c6\u4e0a\u6210\u529f\u6062\u590d\u771f\u503c\u65b9\u7a0b\uff1b\u5e76\u5728\u4eff\u771f\u751f\u7269\u5de5\u827a\u7cfb\u7edf\u4e2d\u8bc1\u660e\u4e0e\u795e\u7ecf\u63a7\u5236\u5fae\u5206\u65b9\u7a0b\u7ed3\u5408\u53ef\u7cbe\u786e\u5efa\u6a21\u52a8\u6001\u8fc7\u7a0b\u3002", "conclusion": "KAN-SR\u5229\u7528KANs\u4e0e\u62c6\u5206\u7b56\u7565\u5b9e\u73b0\u4e86\u9ad8\u6548\u7b26\u53f7\u56de\u5f52\uff0c\u80fd\u5728SRSD\u6570\u636e\u96c6\u4e0a\u6062\u590d\u771f\u5b9e\u8868\u8fbe\u5f0f\u5e76\u7528\u4e8e\u52a8\u529b\u5b66\u5efa\u6a21\u3002"}}
{"id": "2509.10132", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.10132", "abs": "https://arxiv.org/abs/2509.10132", "authors": ["Nour Jamoussi", "Giuseppe Serra", "Photios A. Stavrou", "Marios Kountouris"], "title": "Cost-Free Personalization via Information-Geometric Projection in Bayesian Federated Learning", "comment": null, "summary": "Bayesian Federated Learning (BFL) combines uncertainty modeling with\ndecentralized training, enabling the development of personalized and reliable\nmodels under data heterogeneity and privacy constraints. Existing approaches\ntypically rely on Markov Chain Monte Carlo (MCMC) sampling or variational\ninference, often incorporating personalization mechanisms to better adapt to\nlocal data distributions. In this work, we propose an information-geometric\nprojection framework for personalization in parametric BFL. By projecting the\nglobal model onto a neighborhood of the user's local model, our method enables\na tunable trade-off between global generalization and local specialization.\nUnder mild assumptions, we show that this projection step is equivalent to\ncomputing a barycenter on the statistical manifold, allowing us to derive\nclosed-form solutions and achieve cost-free personalization. We apply the\nproposed approach to a variational learning setup using the Improved\nVariational Online Newton (IVON) optimizer and extend its application to\ngeneral aggregation schemes in BFL. Empirical evaluations under heterogeneous\ndata distributions confirm that our method effectively balances global and\nlocal performance with minimal computational overhead.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4fe1\u606f\u51e0\u4f55\u6295\u5f71\u7684\u53c2\u6570\u5316BFL\u4e2a\u6027\u5316\u65b9\u6cd5\uff0c\u7b49\u4ef7\u4e8e\u7edf\u8ba1\u6d41\u5f62\u4e0a\u7684\u91cd\u5fc3\u8ba1\u7b97\uff0c\u80fd\u5728\u4e0d\u663e\u8457\u589e\u52a0\u8ba1\u7b97\u6210\u672c\u4e0b\u5b9e\u73b0\u53ef\u8c03\u7684\u5168\u5c40/\u672c\u5730\u6027\u80fd\u6298\u4e2d\u3002", "motivation": "\u5728\u5f02\u6784\u6570\u636e\u4e0e\u9690\u79c1\u7ea6\u675f\u4e0b\uff0c\u5e0c\u671b\u7ed3\u5408\u4e0d\u786e\u5b9a\u6027\u5efa\u6a21\u4e0e\u53bb\u4e2d\u5fc3\u5316\u8bad\u7ec3\u4ee5\u5b9e\u73b0\u53ef\u9760\u4e14\u4e2a\u6027\u5316\u7684\u6a21\u578b\uff0c\u540c\u65f6\u907f\u514dMCMC\u6216\u590d\u6742\u53d8\u5206\u63a8\u65ad\u5e26\u6765\u7684\u9ad8\u8ba1\u7b97\u6210\u672c\u3002", "method": "\u5728\u53c2\u6570\u5316\u8d1d\u53f6\u65af\u6a21\u578b\u4e0a\u5f15\u5165\u4fe1\u606f\u51e0\u4f55\u6295\u5f71\u6b65\u9aa4\uff0c\u8bc1\u660e\u8be5\u6b65\u9aa4\u5728\u7edf\u8ba1\u6d41\u5f62\u4e0a\u7b49\u4ef7\u4e8e\u8ba1\u7b97\u91cd\u5fc3\uff0c\u4ece\u800c\u63a8\u5bfc\u51fa\u95ed\u5f0f\u89e3\u5e76\u5b9e\u73b0\u4f4e\u6210\u672c\u4e2a\u6027\u5316\u3002\u5c06\u65b9\u6cd5\u5e94\u7528\u4e8e\u53d8\u5206\u5b66\u4e60\u5e76\u7ed3\u5408IVON\u4f18\u5316\u5668\uff0c\u540c\u65f6\u6269\u5c55\u5230\u901a\u7528\u805a\u5408\u65b9\u6848\u3002", "result": "\u7406\u8bba\u4e0a\u7ed9\u51fa\u6295\u5f71\u7b49\u4ef7\u4e8e\u7edf\u8ba1\u6d41\u5f62\u91cd\u5fc3\u7684\u8bc1\u660e\u5e76\u5bfc\u51fa\u95ed\u5f0f\u89e3\uff1b\u5728\u5f02\u6784\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u8bc1\u7ed3\u679c\u663e\u793a\u8be5\u65b9\u6cd5\u5728\u4fdd\u6301\u5168\u5c40\u8868\u73b0\u7684\u540c\u65f6\u80fd\u63d0\u9ad8\u672c\u5730\u6027\u80fd\uff0c\u4e14\u8ba1\u7b97\u5f00\u9500\u4f4e\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u57fa\u4e8e\u4fe1\u606f\u51e0\u4f55\u6295\u5f71\u7684\u4e2a\u6027\u5316\u53c2\u6570\u5316\u8d1d\u53f6\u65af\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u5168\u5c40\u6a21\u578b\u6295\u5f71\u5230\u7528\u6237\u672c\u5730\u6a21\u578b\u7684\u90bb\u57df\uff0c\u5b9e\u73b0\u4e86\u5168\u5c40\u6cdb\u5316\u4e0e\u672c\u5730\u4e13\u5316\u4e4b\u95f4\u53ef\u8c03\u7684\u6298\u4e2d\u3002"}}
{"id": "2509.10151", "categories": ["cs.LG", "cs.AI", "I.2.1"], "pdf": "https://arxiv.org/pdf/2509.10151", "abs": "https://arxiv.org/abs/2509.10151", "authors": ["Riccardo Lunelli", "Angus Nicolson", "Samuel Martin Pr\u00f6ll", "Sebastian Johannes Reinstadler", "Axel Bauer", "Clemens Dlaska"], "title": "BenchECG and xECG: a benchmark and baseline for ECG foundation models", "comment": "32 pages, 4 figures, 22 tables", "summary": "Electrocardiograms (ECGs) are inexpensive, widely used, and well-suited to\ndeep learning. Recently, interest has grown in developing foundation models for\nECGs - models that generalise across diverse downstream tasks. However,\nconsistent evaluation has been lacking: prior work often uses narrow task\nselections and inconsistent datasets, hindering fair comparison. Here, we\nintroduce BenchECG, a standardised benchmark comprising a comprehensive suite\nof publicly available ECG datasets and versatile tasks. We also propose xECG,\nan xLSTM-based recurrent model trained with SimDINOv2 self-supervised learning,\nwhich achieves the best BenchECG score compared to publicly available\nstate-of-the-art models. In particular, xECG is the only publicly available\nmodel to perform strongly on all datasets and tasks. By standardising\nevaluation, BenchECG enables rigorous comparison and aims to accelerate\nprogress in ECG representation learning. xECG achieves superior performance\nover earlier approaches, defining a new baseline for future ECG foundation\nmodels.", "AI": {"tldr": "\u4f5c\u8005\u6784\u5efa\u4e86\u6807\u51c6\u5316ECG\u57fa\u51c6BenchECG\u5e76\u63d0\u51faxECG\uff08xLSTM+SimDINOv2\uff09\uff0c\u5728\u591a\u6570\u636e\u96c6\u591a\u4efb\u52a1\u8bc4\u6d4b\u4e2d\u8868\u73b0\u6700\u597d\uff0c\u63a8\u52a8ECG\u57fa\u7840\u6a21\u578b\u7814\u7a76\u89c4\u8303\u5316\u3002", "motivation": "\u76ee\u524dECG\u57fa\u7840\u6a21\u578b\u7814\u7a76\u7f3a\u4e4f\u7edf\u4e00\u8bc4\u6d4b\uff0c\u4efb\u52a1\u9009\u62e9\u72ed\u7a84\u4e14\u6570\u636e\u96c6\u4e0d\u4e00\u81f4\uff0c\u5bfc\u81f4\u65e0\u6cd5\u516c\u5e73\u6bd4\u8f83\u3002\u9700\u8981\u4e00\u4e2a\u6807\u51c6\u5316\u7684\u57fa\u51c6\u548c\u5f3a\u5927\u7684\u9884\u8bad\u7ec3\u6a21\u578b\u4ee5\u63a8\u52a8\u8868\u793a\u5b66\u4e60\u8fdb\u5c55\u3002", "method": "\u6784\u5efa\u4e86\u6807\u51c6\u5316\u7684BenchECG\u8bc4\u6d4b\u96c6\uff08\u6574\u5408\u591a\u9879\u516c\u5f00ECG\u6570\u636e\u96c6\u4e0e\u591a\u4efb\u52a1\u8bbe\u7f6e\uff09\uff0c\u63d0\u51faxECG\u2014\u2014\u57fa\u4e8exLSTM\u7684\u5faa\u73af\u6a21\u578b\uff0c\u5e76\u91c7\u7528SimDINOv2\u81ea\u76d1\u7763\u5b66\u4e60\u8fdb\u884c\u9884\u8bad\u7ec3\uff1b\u5728BenchECG\u4e0a\u4e0e\u73b0\u6709\u516c\u5f00\u6a21\u578b\u6bd4\u8f83\u3002", "result": "BenchECG\u63d0\u4f9b\u4e86\u5168\u9762\u3001\u53ef\u590d\u73b0\u7684\u8bc4\u6d4b\u6846\u67b6\uff1bxECG\u5728BenchECG\u4e0a\u83b7\u5f97\u6700\u9ad8\u5206\uff0c\u662f\u552f\u4e00\u5728\u6240\u6709\u6570\u636e\u96c6\u548c\u4efb\u52a1\u4e0a\u8868\u73b0\u5f3a\u52b2\u7684\u516c\u5f00\u6a21\u578b\uff0c\u4ece\u800c\u8bbe\u5b9a\u4e86\u65b0\u7684\u57fa\u7ebf\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86BenchECG\u57fa\u51c6\u548cxECG\u6a21\u578b\uff0c\u89e3\u51b3\u4e86ECG\u57fa\u7840\u6a21\u578b\u8bc4\u4f30\u4e0d\u4e00\u81f4\u7684\u95ee\u9898\uff0c\u5e76\u5728\u591a\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u548c\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u6700\u4f18\u6027\u80fd\uff0c\u6210\u4e3a\u65b0\u7684\u57fa\u7ebf\u3002"}}
{"id": "2509.10163", "categories": ["cs.LG", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.10163", "abs": "https://arxiv.org/abs/2509.10163", "authors": ["Francisco Javier Esono Nkulu Andong", "Qi Min"], "title": "Federated Multi-Agent Reinforcement Learning for Privacy-Preserving and Energy-Aware Resource Management in 6G Edge Networks", "comment": null, "summary": "As sixth-generation (6G) networks move toward ultra-dense, intelligent edge\nenvironments, efficient resource management under stringent privacy, mobility,\nand energy constraints becomes critical. This paper introduces a novel\nFederated Multi-Agent Reinforcement Learning (Fed-MARL) framework that\nincorporates cross-layer orchestration of both the MAC layer and application\nlayer for energy-efficient, privacy-preserving, and real-time resource\nmanagement across heterogeneous edge devices. Each agent uses a Deep Recurrent\nQ-Network (DRQN) to learn decentralized policies for task offloading, spectrum\naccess, and CPU energy adaptation based on local observations (e.g., queue\nlength, energy, CPU usage, and mobility). To protect privacy, we introduce a\nsecure aggregation protocol based on elliptic curve Diffie Hellman key\nexchange, which ensures accurate model updates without exposing raw data to\nsemi-honest adversaries. We formulate the resource management problem as a\npartially observable multi-agent Markov decision process (POMMDP) with a\nmulti-objective reward function that jointly optimizes latency, energy\nefficiency, spectral efficiency, fairness, and reliability under 6G-specific\nservice requirements such as URLLC, eMBB, and mMTC. Simulation results\ndemonstrate that Fed-MARL outperforms centralized MARL and heuristic baselines\nin task success rate, latency, energy efficiency, and fairness, while ensuring\nrobust privacy protection and scalability in dynamic, resource-constrained 6G\nedge networks.", "AI": {"tldr": "\u63d0\u51faFed-MARL\uff1a\u8054\u90a6\u591a\u667a\u80fd\u4f53DRQN+\u5b89\u5168\u805a\u5408\uff0c\u8de8\u5c42\u534f\u540c\u4f18\u53166G\u8fb9\u7f18\u7684\u4efb\u52a1\u5378\u8f7d\u3001\u9891\u8c31\u4e0e\u80fd\u8017\u7ba1\u7406\uff0c\u517c\u987e\u6027\u80fd\u4e0e\u9690\u79c1\uff0c\u4f18\u4e8e\u96c6\u4e2d\u5f0f\u548c\u542f\u53d1\u5f0f\u57fa\u7ebf\u3002", "motivation": "6G\u8fb9\u7f18\u7f51\u7edc\u5448\u73b0\u8d85\u5bc6\u96c6\u4e0e\u667a\u80fd\u5316\u8d8b\u52bf\uff0c\u8d44\u6e90\u7ba1\u7406\u9762\u4e34\u9690\u79c1\u3001\u79fb\u52a8\u6027\u548c\u80fd\u8017\u7b49\u7ea6\u675f\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u5728\u5206\u5e03\u5f0f\u3001\u52a8\u6001\u4e0e\u5f02\u6784\u73af\u5883\u4e2d\u9ad8\u6548\u4e14\u9690\u79c1\u4fdd\u62a4\u7684\u8d44\u6e90\u8c03\u5ea6\u65b9\u6848\u3002", "method": "\u5c06\u8d44\u6e90\u7ba1\u7406\u5efa\u6a21\u4e3aPOMMDP\uff0c\u4f7f\u7528\u591a\u76ee\u6807\u5956\u52b1\u8054\u5408\u4f18\u5316\u65f6\u5ef6\u3001\u80fd\u8017\u3001\u9891\u8c31\u6548\u7387\u3001\u516c\u5e73\u6027\u4e0e\u53ef\u9760\u6027\uff1b\u6bcf\u4e2a\u667a\u80fd\u4f53\u91c7\u7528DRQN\u5904\u7406\u90e8\u5206\u53ef\u89c2\u6d4b\u6027\u5e76\u5b66\u4e60\u53bb\u4e2d\u5fc3\u5316\u7b56\u7565\uff1b\u5f15\u5165\u692d\u5706\u66f2\u7ebfDiffie\u2013Hellman\u5bc6\u94a5\u4ea4\u6362\u5b9e\u73b0\u5b89\u5168\u805a\u5408\u4ee5\u9632\u534a\u8bda\u5b9e\u653b\u51fb\uff1b\u91c7\u7528\u8054\u90a6\u5b66\u4e60\u6846\u67b6\u8fdb\u884c\u6a21\u578b\u805a\u5408\u4ee5\u63d0\u9ad8\u53ef\u6269\u5c55\u6027\u4e0e\u9690\u79c1\u6027\u3002", "result": "\u4eff\u771f\u663e\u793aFed-MARL\u5728\u4efb\u52a1\u6210\u529f\u7387\u3001\u65f6\u5ef6\u3001\u80fd\u6548\u548c\u516c\u5e73\u6027\u65b9\u9762\u5747\u4f18\u4e8e\u96c6\u4e2d\u5f0fMARL\u548c\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u540c\u65f6\u5b89\u5168\u805a\u5408\u786e\u4fdd\u5728\u534a\u8bda\u5b9e\u5a01\u80c1\u4e0b\u6a21\u578b\u66f4\u65b0\u4e0d\u6cc4\u9732\u539f\u59cb\u6570\u636e\uff0c\u4e14\u6846\u67b6\u5bf9\u8bbe\u5907\u89c4\u6a21\u548c\u52a8\u6001\u73af\u5883\u5177\u6709\u826f\u597d\u53ef\u6269\u5c55\u6027\u4e0e\u9c81\u68d2\u6027\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7ed3\u5408\u8054\u90a6\u5b66\u4e60\u4e0e\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u7684\u8de8\u5c42\u8d44\u6e90\u7ba1\u7406\u6846\u67b6\uff08Fed-MARL\uff09\uff0c\u5b9e\u73b0\u4e86\u57286G\u8fb9\u7f18\u5f02\u6784\u8bbe\u5907\u4e0a\u5bf9\u4e8e\u4efb\u52a1\u5378\u8f7d\u3001\u9891\u8c31\u8bbf\u95ee\u548cCPU\u80fd\u8017\u8c03\u8282\u7684\u53bb\u4e2d\u5fc3\u5316\u4f18\u5316\u3002\u901a\u8fc7DRQN\u6bcf\u4e2a\u667a\u80fd\u4f53\u5728\u5c40\u90e8\u89c2\u6d4b\u4e0b\u5b66\u4e60\u7b56\u7565\uff0c\u5e76\u5f15\u5165\u57fa\u4e8e\u692d\u5706\u66f2\u7ebfDiffie\u2013Hellman\u7684\u5b89\u5168\u805a\u5408\u534f\u8bae\u4fdd\u62a4\u6a21\u578b\u66f4\u65b0\u9690\u79c1\u3002\u603b\u4f53\u4e0a\uff0cFed-MARL\u5728\u4efb\u52a1\u6210\u529f\u7387\u3001\u65f6\u5ef6\u3001\u80fd\u6548\u548c\u516c\u5e73\u6027\u4e0a\u5747\u4f18\u4e8e\u96c6\u4e2d\u5f0fMARL\u4e0e\u542f\u53d1\u5f0f\u57fa\u7ebf\uff0c\u5e76\u5177\u5907\u9690\u79c1\u6027\u3001\u53ef\u6269\u5c55\u6027\u4e0e\u5bf9\u52a8\u6001\u73af\u5883\u7684\u9c81\u68d2\u6027\u3002"}}
{"id": "2509.10164", "categories": ["cs.LG", "quant-ph"], "pdf": "https://arxiv.org/pdf/2509.10164", "abs": "https://arxiv.org/abs/2509.10164", "authors": ["Hoshitaro Ohnishi", "Hideo Mukai"], "title": "A Symmetry-Integrated Approach to Surface Code Decoding", "comment": "12 pages, 6 figures", "summary": "Quantum error correction, which utilizes logical qubits that are encoded as\nredundant multiple physical qubits to find and correct errors in physical\nqubits, is indispensable for practical quantum computing. Surface code is\nconsidered to be a promising encoding method with a high error threshold that\nis defined by stabilizer generators. However, previous methods have suffered\nfrom the problem that the decoder acquires solely the error probability\ndistribution because of the non-uniqueness of correct prediction obtained from\nthe input. To circumvent this problem, we propose a technique to reoptimize the\ndecoder model by approximating syndrome measurements with a continuous function\nthat is mathematically interpolated by neural network. We evaluated the\nimprovement in accuracy of a multilayer perceptron based decoder for code\ndistances of 5 and 7 as well as for decoders based on convolutional and\nrecurrent neural networks and transformers for a code distance of 5. In all\ncases, the reoptimized decoder gave better accuracy than the original models,\ndemonstrating the universal effectiveness of the proposed method that is\nindependent of code distance or network architecture. These results suggest\nthat re-framing the problem of surface code decoding into a regression problem\nthat can be tackled by deep learning is a useful strategy.", "AI": {"tldr": "\u901a\u8fc7\u628a\u8868\u9762\u7801\u8bd1\u7801\u91cd\u6784\u4e3a\u56de\u5f52\u95ee\u9898\u5e76\u7528\u795e\u7ecf\u7f51\u7edc\u5bf9\u8fde\u7eed\u5316\u7684 syndrome \u8fdb\u884c\u63d2\u503c\u518d\u4f18\u5316\uff0c\u4f5c\u8005\u5728\u591a\u79cd\u7f51\u7edc\u548c\u7801\u8ddd\u4e0a\u83b7\u5f97\u4e86\u7edf\u4e00\u7684\u8bd1\u7801\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u4f20\u7edf\u8868\u9762\u7801\u8bd1\u7801\u5668\u56e0\u8f93\u5165\u7684\u975e\u552f\u4e00\u6027\u53ea\u80fd\u5b66\u4e60\u5230\u9519\u8bef\u6982\u7387\u5206\u5e03\uff0c\u5bfc\u81f4\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u3002\u4e3a\u51cf\u5c0f\u8fd9\u79cd\u4e0d\u786e\u5b9a\u6027\u5e76\u63d0\u9ad8\u8bd1\u7801\u51c6\u786e\u7387\uff0c\u4f5c\u8005\u63d0\u51fa\u5c06\u5206\u7c7b\u95ee\u9898\u91cd\u6784\u4e3a\u56de\u5f52\u95ee\u9898\uff0c\u901a\u8fc7\u8fde\u7eed\u5316 syndrome \u6765\u4f7f\u795e\u7ecf\u7f51\u7edc\u8f93\u51fa\u66f4\u53ef\u533a\u5206\u3002", "method": "\u5c06 syndrome \u6d4b\u91cf\u7528\u8fde\u7eed\u51fd\u6570\u8868\u793a\uff0c\u5e76\u4ee5\u795e\u7ecf\u7f51\u7edc\u5bf9\u8be5\u8fde\u7eed\u8868\u793a\u8fdb\u884c\u63d2\u503c\u4e0e\u56de\u5f52\u4f18\u5316\uff0c\u5177\u4f53\u91c7\u7528\u591a\u5c42\u611f\u77e5\u5668\uff08MLP\uff09\u8fdb\u884c\u518d\u8bad\u7ec3\uff0c\u5e76\u5728\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff08CNN\uff09\u3001\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\uff08RNN\uff09\u548c transformer \u67b6\u6784\u4e0a\u9a8c\u8bc1\u65b9\u6cd5\u7684\u6cdb\u5316\u6027\u3002", "result": "\u5728\u7801\u8ddd 5 \u548c 7 \u7684 MLP \u8bd1\u7801\u5668\uff0c\u4ee5\u53ca\u7801\u8ddd 5 \u7684 CNN\u3001RNN\u3001transformer \u8bd1\u7801\u5668\u4e0a\uff0c\u91cd\u65b0\u4f18\u5316\u540e\u7684\u8bd1\u7801\u5668\u5747\u8868\u73b0\u51fa\u6bd4\u539f\u59cb\u6a21\u578b\u66f4\u9ad8\u7684\u51c6\u786e\u7387\uff0c\u8868\u660e\u8be5\u65b9\u6cd5\u4e0d\u4f9d\u8d56\u4e8e\u7801\u8ddd\u6216\u7f51\u7edc\u7ed3\u6784\u5177\u6709\u666e\u9002\u6027\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u901a\u8fc7\u5c06\u6d4b\u5f97\u7684 syndrome\uff08\u7a33\u5b9a\u5b50\u6d4b\u91cf\uff09\u7528\u8fde\u7eed\u51fd\u6570\u8fd1\u4f3c\u5e76\u7528\u795e\u7ecf\u7f51\u7edc\u63d2\u503c\uff0c\u4ece\u800c\u5c06\u8868\u9762\u7801\u8bd1\u7801\u95ee\u9898\u91cd\u6784\u4e3a\u56de\u5f52\u95ee\u9898\uff0c\u5e76\u5bf9\u8bd1\u7801\u5668\u8fdb\u884c\u518d\u4f18\u5316\uff0c\u7ed3\u679c\u5728\u4e0d\u540c\u7801\u8ddd\u548c\u7f51\u7edc\u7ed3\u6784\u4e0a\u5747\u63d0\u9ad8\u4e86\u8bd1\u7801\u51c6\u786e\u7387\u3002"}}
{"id": "2509.10167", "categories": ["cs.LG", "68T07, 60H30, 34F05"], "pdf": "https://arxiv.org/pdf/2509.10167", "abs": "https://arxiv.org/abs/2509.10167", "authors": ["L\u00e9na\u00efc Chizat"], "title": "The Hidden Width of Deep ResNets: Tight Error Bounds and Phase Diagrams", "comment": null, "summary": "We study the gradient-based training of large-depth residual networks\n(ResNets) from standard random initializations. We show that with a diverging\ndepth $L$, a fixed embedding dimension $D$, and an arbitrary hidden width $M$,\nthe training dynamics converges to a Neural Mean ODE training dynamics.\nRemarkably, the limit is independent of the scaling of $M$, covering practical\ncases of, say, Transformers, where $M$ (the number of hidden units or attention\nheads per layer) is typically of the order of $D$. For a residual scale\n$\\Theta_D\\big(\\frac{\\alpha}{LM}\\big)$, we obtain the error bound\n$O_D\\big(\\frac{1}{L}+ \\frac{\\alpha}{\\sqrt{LM}}\\big)$ between the model's output\nand its limit after a fixed number gradient of steps, and we verify empirically\nthat this rate is tight. When $\\alpha=\\Theta(1)$, the limit exhibits complete\nfeature learning, i.e. the Mean ODE is genuinely non-linearly parameterized. In\ncontrast, we show that $\\alpha \\to \\infty$ yields a \\lazy ODE regime where the\nMean ODE is linearly parameterized. We then focus on the particular case of\nResNets with two-layer perceptron blocks, for which we study how these scalings\ndepend on the embedding dimension $D$. We show that for this model, the only\nresidual scale that leads to complete feature learning is\n$\\Theta\\big(\\frac{\\sqrt{D}}{LM}\\big)$. In this regime, we prove the error bound\n$O\\big(\\frac{1}{L}+ \\frac{\\sqrt{D}}{\\sqrt{LM}}\\big)$ between the ResNet and its\nlimit after a fixed number of gradient steps, which is also empirically tight.\nOur convergence results rely on a novel mathematical perspective on ResNets :\n(i) due to the randomness of the initialization, the forward and backward pass\nthrough the ResNet behave as the stochastic approximation of certain mean ODEs,\nand (ii) by propagation of chaos (that is, asymptotic independence of the\nunits) this behavior is preserved through the training dynamics.", "AI": {"tldr": "\u8bba\u6587\u5efa\u7acb\u4e86\u6df1\u5ea6\u53d1\u6563\u4e14\u56fa\u5b9a\u5d4c\u5165\u7ef4\u5ea6\u4e0bResNet\u7684\u8bad\u7ec3\u52a8\u529b\u5b66\u4e0eNeural Mean ODE\u7684\u6536\u655b\u5173\u7cfb\uff0c\u7ed9\u51fa\u4e0d\u540c\u6b8b\u5dee\u7f29\u653e\u4e0b\u7684\u8bef\u5dee\u754c\u5e76\u533a\u5206\u975e\u7ebf\u6027\u7279\u5f81\u5b66\u4e60\u4e0e\u61d2\u60f0\u7ebf\u6027\u5316\u4e24\u79cd\u6781\u9650\uff0c\u9488\u5bf9\u4e24\u5c42\u5757\u786e\u5b9a\u4e86\u5bfc\u81f4\u5b8c\u6574\u7279\u5f81\u5b66\u4e60\u7684\u552f\u4e00\u7f29\u653e\u5e76\u4ee5\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u7d27\u81f4\u6027\u3002", "motivation": "\u7406\u89e3\u6df1\u5c42ResNet\u5728\u5b9e\u9645\u53ef\u6269\u5c55\u8bbe\u7f6e\uff08\u5927L\u3001\u56fa\u5b9aD\u3001\u4efb\u610fM\uff09\u4e0b\u7684\u8bad\u7ec3\u52a8\u529b\u5b66\u4e0e\u7279\u5f81\u5b66\u4e60\u884c\u4e3a\uff0c\u7279\u522b\u662f\u5728\u4e0d\u540c\u6b8b\u5dee\u7f29\u653e\u4e0b\u4f55\u65f6\u4ea7\u751f\u975e\u7ebf\u6027\u7279\u5f81\u5b66\u4e60\u6216\u9000\u5316\u4e3a\u7ebf\u6027\uff08\u61d2\u60f0\uff09\u5b66\u4e60\uff1b\u5e76\u4e3a\u8bf8\u5982Transformer\u7b49\u6a21\u578b\u63d0\u4f9b\u7406\u8bba\u4f9d\u636e\u3002", "method": "\u901a\u8fc7\u628a\u968f\u673a\u521d\u59cb\u5316\u4e0b\u7684\u524d\u5411\u548c\u53cd\u5411\u4f20\u64ad\u770b\u4f5c\u5bf9\u67d0\u4e9b\u5e73\u5747ODE\u7684\u968f\u673a\u903c\u8fd1\uff0c\u5e76\u5229\u7528\u6df7\u6c8c\u4f20\u64ad\uff08propagation of chaos\uff09\u4f7f\u5355\u5143\u95f4\u6e10\u8fdb\u72ec\u7acb\uff0c\u4ece\u800c\u628a\u8bad\u7ec3\u52a8\u529b\u5b66\u4e0e\u786e\u5b9a\u6027\u7684Neural Mean ODE\u5173\u8054\u8d77\u6765\uff1b\u7ed3\u5408\u6b8b\u5dee\u7f29\u653e\u5206\u6790\uff0c\u63a8\u5bfc\u8bef\u5dee\u754c\u5e76\u7528\u5b9e\u9a8c\u9a8c\u8bc1\u7d27\u81f4\u6027\u3002", "result": "1) \u5728\u6b8b\u5dee\u7f29\u653e\u0398_D(\u03b1/(L M))\u4e0b\uff0c\u5f97\u5230\u8bef\u5dee\u754cO_D(1/L + \u03b1/\u221a(L M))\uff0c\u5f53\u03b1=\u0398(1)\u65f6\u51fa\u73b0\u5b8c\u5168\u7279\u5f81\u5b66\u4e60\uff0c\u03b1\u2192\u221e\u65f6\u8fdb\u5165\u61d2\u60f0ODE\uff1b2) \u5bf9\u4e24\u5c42\u611f\u77e5\u673a\u5757\uff0c\u552f\u4e00\u8d77\u5b8c\u5168\u7279\u5f81\u5b66\u4e60\u7684\u7f29\u653e\u4e3a\u0398(\u221aD/(L M))\uff0c\u5bf9\u5e94\u8bef\u5dee\u754cO(1/L + \u221aD/\u221a(L M))\uff1b3) \u6570\u5b66\u5de5\u5177\u4e3a\u968f\u673a\u8fd1\u4f3c+\u6df7\u6c8c\u4f20\u64ad\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8bef\u5dee\u754c\u7684\u7d27\u81f4\u6027\u3002", "conclusion": "\u8be5\u8bba\u6587\u8bc1\u660e\u4e86\u5bf9\u4e8e\u6df1\u5ea6L\u53d1\u6563\u3001\u56fa\u5b9a\u5d4c\u5165\u7ef4\u5ea6D\u53ca\u4efb\u610f\u9690\u85cf\u5bbd\u5ea6M\u7684ResNet\uff0c\u4ece\u968f\u673a\u521d\u59cb\u5316\u5f00\u59cb\u4f7f\u7528\u57fa\u4e8e\u68af\u5ea6\u7684\u8bad\u7ec3\uff0c\u7f51\u7edc\u52a8\u529b\u5b66\u6536\u655b\u5230\u4e00\u4e2a\u795e\u7ecf\u5e73\u5747ODE\uff08Neural Mean ODE\uff09\u3002\u5728\u4e0d\u540c\u6b8b\u5dee\u7f29\u653e\u4e0b\uff0c\u7ed9\u51fa\u4e86\u4e0e\u6781\u9650\u52a8\u529b\u5b66\u7684\u8bef\u5dee\u754c\uff0c\u5e76\u533a\u5206\u4e86\u5b8c\u5168\u7279\u5f81\u5b66\u4e60\u4e0e\u61d2\u60f0(lazy)\u7ebf\u6027\u5316\u4e24\u79cd\u6781\u9650\u884c\u4e3a\u3002\u5bf9\u4e24\u5c42\u611f\u77e5\u673a\u5757\u7684ResNet\uff0c\u786e\u5b9a\u4e86\u552f\u4e00\u80fd\u5bfc\u81f4\u5b8c\u5168\u7279\u5f81\u5b66\u4e60\u7684\u6b8b\u5dee\u7f29\u653e\u4e3a\u0398(\u221aD/(L M))\uff0c\u5e76\u7ed9\u51fa\u76f8\u5e94\u8bef\u5dee\u754c\u3002\u8bc1\u660e\u65b9\u6cd5\u57fa\u4e8e\u5c06\u524d\u5411/\u53cd\u5411\u4f20\u64ad\u89c6\u4e3a\u5747\u503cODE\u7684\u968f\u673a\u8fd1\u4f3c\u4ee5\u53ca\u901a\u8fc7\u6df7\u6c8c\u4f20\u64ad\u4fdd\u6301\u72ec\u7acb\u6027\u3002"}}
{"id": "2509.10186", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.10186", "abs": "https://arxiv.org/abs/2509.10186", "authors": ["Benjamin Holzschuh", "Georg Kohl", "Florian Redinger", "Nils Thuerey"], "title": "P3D: Scalable Neural Surrogates for High-Resolution 3D Physics Simulations with Global Context", "comment": null, "summary": "We present a scalable framework for learning deterministic and probabilistic\nneural surrogates for high-resolution 3D physics simulations. We introduce a\nhybrid CNN-Transformer backbone architecture targeted for 3D physics\nsimulations, which significantly outperforms existing architectures in terms of\nspeed and accuracy. Our proposed network can be pretrained on small patches of\nthe simulation domain, which can be fused to obtain a global solution,\noptionally guided via a fast and scalable sequence-to-sequence model to include\nlong-range dependencies. This setup allows for training large-scale models with\nreduced memory and compute requirements for high-resolution datasets. We\nevaluate our backbone architecture against a large set of baseline methods with\nthe objective to simultaneously learn the dynamics of 14 different types of\nPDEs in 3D. We demonstrate how to scale our model to high-resolution isotropic\nturbulence with spatial resolutions of up to $512^3$. Finally, we demonstrate\nthe versatility of our network by training it as a diffusion model to produce\nprobabilistic samples of highly turbulent 3D channel flows across varying\nReynolds numbers, accurately capturing the underlying flow statistics.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u53ef\u9884\u8bad\u7ec3\u7684\u5c0f\u5757+\u6df7\u5408CNN-Transformer\u9aa8\u5e72\uff0c\u7ed3\u5408\u53ef\u9009seq2seq\u878d\u5408\u957f\u7a0b\u4f9d\u8d56\uff0c\u80fd\u9ad8\u6548\u5b66\u4e60\u5e76\u751f\u6210\u9ad8\u5206\u8fa8\u73873D\u6e4d\u6d41\u7684\u786e\u5b9a\u6027\u4e0e\u6982\u7387\u6a21\u62df\uff0c\u6269\u5c55\u5230512^3\u5e76\u5728\u591a\u4efb\u52a1PDE\u4e0a\u8868\u73b0\u4f18\u8d8a\u3002", "motivation": "\u9700\u5728\u9ad8\u5206\u8fa8\u73873D\u7269\u7406\u4eff\u771f\u4e2d\u540c\u65f6\u517c\u987e\u901f\u5ea6\u3001\u7cbe\u5ea6\u548c\u53ef\u6269\u5c55\u6027\uff0c\u4e14\u80fd\u63d0\u4f9b\u4e0d\u786e\u5b9a\u6027/\u6982\u7387\u8f93\u51fa\u4ee5\u6355\u6349\u6e4d\u6d41\u7edf\u8ba1\u3002", "method": "\u8bbe\u8ba1\u4e86\u9488\u5bf93D\u7269\u7406\u4eff\u771f\u7684\u6df7\u5408CNN-Transformer\u9aa8\u5e72\uff0c\u7ed3\u5408\u5c40\u90e8\u5c0f\u5757\u9884\u8bad\u7ec3\u4e0e\u53ef\u9009\u7684seq2seq\u6a21\u5757\u7528\u4e8e\u957f\u7a0b\u4f9d\u8d56\uff0c\u51cf\u5c11\u5185\u5b58\u548c\u8ba1\u7b97\u5f00\u9500\uff1b\u5bf9\u6bd4\u591a\u79cd\u57fa\u7ebf\u65b9\u6cd5\uff0c\u8bad\u7ec3\u5e76\u6269\u5c55\u5230\u9ad8\u5206\u8fa8\u7387\u6570\u636e\uff1b\u5c06\u7f51\u7edc\u4f5c\u4e3a\u6269\u6563\u6a21\u578b\u8bad\u7ec3\u4ee5\u751f\u6210\u6982\u7387\u6837\u672c\u3002", "result": "\u572814\u7c7b3D PDE\u4e0a\u5bf9\u6bd4\u57fa\u7ebf\u663e\u793a\u66f4\u4f18\u7684\u901f\u5ea6\u4e0e\u7cbe\u5ea6\uff1b\u6210\u529f\u6269\u5c55\u5230512^3\u7684\u5404\u5411\u540c\u6027\u6e4d\u6d41\uff1b\u4f5c\u4e3a\u6269\u6563\u6a21\u578b\u80fd\u751f\u6210\u4e0d\u540cReynolds\u6570\u4e0b3D\u901a\u9053\u6d41\u7684\u6982\u7387\u6837\u672c\u5e76\u51c6\u786e\u590d\u73b0\u6d41\u52a8\u7edf\u8ba1\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u6df7\u5408CNN-Transformer\u9aa8\u5e72\u7f51\u7edc\uff0c\u7528\u4e8e\u5b66\u4e60\u9ad8\u5206\u8fa8\u73873D\u7269\u7406\u4eff\u771f\u7684\u786e\u5b9a\u6027\u548c\u6982\u7387\u795e\u7ecf\u4ee3\u7406\uff0c\u53ef\u5728\u901f\u5ea6\u548c\u7cbe\u5ea6\u4e0a\u8d85\u8d8a\u73b0\u6709\u67b6\u6784\uff0c\u5e76\u80fd\u4ee5\u5c0f\u5757\u9884\u8bad\u7ec3\u5e76\u62fc\u63a5\u4e3a\u5168\u5c40\u89e3\uff0c\u652f\u6301\u957f\u7a0b\u4f9d\u8d56\uff0c\u53ef\u8bad\u7ec3\u5230512^3\u5206\u8fa8\u7387\u5e76\u7528\u4e8e\u6269\u6563\u6a21\u578b\u751f\u6210\u6e4d\u6d41\u6982\u7387\u6837\u672c\u3002"}}
{"id": "2509.10189", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.10189", "abs": "https://arxiv.org/abs/2509.10189", "authors": ["Zexu Jin"], "title": "Hadamard-Riemannian Optimization for Margin-Variance Ensemble", "comment": null, "summary": "Ensemble learning has been widely recognized as a pivotal technique for\nboosting predictive performance by combining multiple base models.\nNevertheless, conventional margin-based ensemble methods predominantly focus on\nmaximizing the expected margin while neglecting the critical role of margin\nvariance, which inherently restricts the generalization capability of the model\nand heightens its vulnerability to overfitting, particularly in noisy or\nimbalanced datasets. Additionally, the conventional approach of optimizing\nensemble weights within the probability simplex often introduces computational\ninefficiency and scalability challenges, complicating its application to\nlarge-scale problems. To tackle these limitations, this paper introduces a\nnovel ensemble learning framework that explicitly incorporates margin variance\ninto the loss function. Our method jointly optimizes the negative expected\nmargin and its variance, leading to enhanced robustness and improved\ngeneralization performance. Moreover, by reparameterizing the ensemble weights\nonto the unit sphere, we substantially simplify the optimization process and\nimprove computational efficiency. Extensive experiments conducted on multiple\nbenchmark datasets demonstrate that the proposed approach consistently\noutperforms traditional margin-based ensemble techniques, underscoring its\neffectiveness and practical utility.", "AI": {"tldr": "\u63d0\u51fa\u540c\u65f6\u6700\u5c0f\u5316\u8d1f\u671f\u671b\u8fb9\u8ddd\u548c\u8fb9\u8ddd\u65b9\u5dee\u5e76\u5c06\u6743\u91cd\u91cd\u53c2\u6570\u5316\u5230\u5355\u4f4d\u7403\u7684\u96c6\u6210\u5b66\u4e60\u65b9\u6cd5\uff0c\u63d0\u5347\u6cdb\u5316\u6027\u4e0e\u8ba1\u7b97\u6548\u7387\uff0c\u5b9e\u9a8c\u8bc1\u660e\u4f18\u4e8e\u4f20\u7edf\u57fa\u7ebf\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u8fb9\u8ddd\u7684\u96c6\u6210\u65b9\u6cd5\u53ea\u6700\u5927\u5316\u671f\u671b\u8fb9\u8ddd\uff0c\u5ffd\u7565\u8fb9\u8ddd\u65b9\u5dee\u5bfc\u81f4\u6cdb\u5316\u80fd\u529b\u53d7\u9650\u4e14\u6613\u8fc7\u62df\u5408\uff1b\u6743\u91cd\u5728\u6982\u7387\u5355\u7eaf\u5f62\u4e0a\u7684\u7ea6\u675f\u5e26\u6765\u8ba1\u7b97\u548c\u53ef\u6269\u5c55\u6027\u95ee\u9898\u3002", "method": "\u5f15\u5165\u8fb9\u8ddd\u65b9\u5dee\u9879\u5230\u635f\u5931\u51fd\u6570\u4e2d\uff0c\u8054\u5408\u6700\u5c0f\u5316\u8d1f\u671f\u671b\u8fb9\u8ddd\u548c\u65b9\u5dee\uff1b\u5c06\u6743\u91cd\u4ece\u6982\u7387\u5355\u7eaf\u5f62\u91cd\u65b0\u53c2\u6570\u5316\u5230\u5355\u4f4d\u7403\u4e0a\u4ee5\u7b80\u5316\u7ea6\u675f\u4f18\u5316\u5e76\u63d0\u5347\u8ba1\u7b97\u6548\u7387\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u663e\u793a\uff0c\u6240\u63d0\u65b9\u6cd5\u5728\u51c6\u786e\u7387\u3001\u9c81\u68d2\u6027\u548c\u8bad\u7ec3\u6548\u7387\u65b9\u9762\u5747\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u6846\u67b6\u901a\u8fc7\u540c\u65f6\u4f18\u5316\u8d1f\u671f\u671b\u8fb9\u8ddd\u548c\u8fb9\u8ddd\u65b9\u5dee\uff0c\u63d0\u9ad8\u4e86\u96c6\u6210\u6a21\u578b\u5728\u566a\u58f0\u548c\u4e0d\u5e73\u8861\u6570\u636e\u4e0a\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u7406\u8bba\u548c\u5b9e\u9a8c\u5747\u8868\u660e\u6027\u80fd\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002"}}
{"id": "2509.10227", "categories": ["cs.LG", "physics.app-ph"], "pdf": "https://arxiv.org/pdf/2509.10227", "abs": "https://arxiv.org/abs/2509.10227", "authors": ["\u00c1ngel Ladr\u00f3n", "Miguel S\u00e1nchez-Dom\u00ednguez", "Javier Rozal\u00e9n", "Fernando R. S\u00e1nchez", "Javier de Vicente", "Lucas Lacasa", "Eusebio Valero", "Gonzalo Rubio"], "title": "A Certifiable Machine Learning-Based Pipeline to Predict Fatigue Life of Aircraft Structures", "comment": "29 pages, 15 figures", "summary": "Fatigue life prediction is essential in both the design and operational\nphases of any aircraft, and in this sense safety in the aerospace industry\nrequires early detection of fatigue cracks to prevent in-flight failures.\nRobust and precise fatigue life predictors are thus essential to ensure safety.\nTraditional engineering methods, while reliable, are time consuming and involve\ncomplex workflows, including steps such as conducting several Finite Element\nMethod (FEM) simulations, deriving the expected loading spectrum, and applying\ncycle counting techniques like peak-valley or rainflow counting. These steps\noften require collaboration between multiple teams and tools, added to the\ncomputational time and effort required to achieve fatigue life predictions.\nMachine learning (ML) offers a promising complement to traditional fatigue life\nestimation methods, enabling faster iterations and generalization, providing\nquick estimates that guide decisions alongside conventional simulations.\n  In this paper, we present a ML-based pipeline that aims to estimate the\nfatigue life of different aircraft wing locations given the flight parameters\nof the different missions that the aircraft will be operating throughout its\noperational life. We validate the pipeline in a realistic use case of fatigue\nlife estimation, yielding accurate predictions alongside a thorough statistical\nvalidation and uncertainty quantification. Our pipeline constitutes a\ncomplement to traditional methodologies by reducing the amount of costly\nsimulations and, thereby, lowering the required computational and human\nresources.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5e76\u9a8c\u8bc1\u4e86\u4e00\u4e2a\u7528\u4e8e\u673a\u7ffc\u75b2\u52b3\u5bff\u547d\u4f30\u8ba1\u7684\u673a\u5668\u5b66\u4e60\u7ba1\u7ebf\uff0c\u80fd\u5728\u4fdd\u8bc1\u7cbe\u5ea6\u4e0e\u4e0d\u786e\u5b9a\u6027\u8bc4\u4f30\u7684\u524d\u63d0\u4e0b\uff0c\u51cf\u5c11 FEM \u4eff\u771f\u4e0e\u4eba\u5de5\u6210\u672c\uff0c\u4f5c\u4e3a\u4f20\u7edf\u65b9\u6cd5\u7684\u6709\u529b\u8865\u5145\u3002", "motivation": "\u4f20\u7edf\u75b2\u52b3\u5bff\u547d\u9884\u6d4b\u4f9d\u8d56\u8017\u65f6\u7684 FEM \u4eff\u771f\u3001\u8f7d\u8377\u8c31\u63a8\u5bfc\u548c\u5faa\u73af\u8ba1\u6570\u7b49\u590d\u6742\u6d41\u7a0b\uff0c\u9700\u591a\u56e2\u961f\u4e0e\u5de5\u5177\u534f\u4f5c\uff1b\u673a\u5668\u5b66\u4e60\u53ef\u63d0\u4f9b\u66f4\u5feb\u7684\u8fed\u4ee3\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u4f5c\u4e3a\u8865\u5145\u4ee5\u51cf\u5c11\u8ba1\u7b97\u4e0e\u4eba\u5de5\u8d44\u6e90\u3002", "method": "\u6784\u5efa\u5e76\u8bad\u7ec3\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff08\u5177\u4f53\u6a21\u578b\u7c7b\u578b\u6458\u8981\u4e2d\u672a\u8bf4\u660e\uff09\uff0c\u8f93\u5165\u4e3a\u4efb\u52a1\u7ea7\u98de\u884c\u53c2\u6570\u3001\u8f93\u51fa\u4e3a\u673a\u7ffc\u4e0d\u540c\u4f4d\u7f6e\u7684\u75b2\u52b3\u5bff\u547d\uff1b\u5728\u73b0\u5b9e\u7528\u4f8b\u4e0a\u9a8c\u8bc1\uff0c\u5e76\u8fdb\u884c\u4e86\u7edf\u8ba1\u9a8c\u8bc1\u4e0e\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u3002", "result": "\u5728\u73b0\u5b9e\u4f7f\u7528\u573a\u666f\u4e0b\uff0c\u6240\u63d0\u7ba1\u7ebf\u7ed9\u51fa\u51c6\u786e\u7684\u9884\u6d4b\uff0c\u5e76\u4f34\u6709\u5145\u5206\u7684\u7edf\u8ba1\u9a8c\u8bc1\u4e0e\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\uff0c\u8868\u660e\u53ef\u964d\u4f4e\u6240\u9700\u4eff\u771f\u6b21\u6570\u4e0e\u8d44\u6e90\u6d88\u8017\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u7ba1\u7ebf\uff0c\u7528\u4e8e\u6839\u636e\u98de\u673a\u4e0d\u540c\u4efb\u52a1\u7684\u98de\u884c\u53c2\u6570\u9884\u6d4b\u673a\u7ffc\u5404\u4f4d\u7f6e\u7684\u75b2\u52b3\u5bff\u547d\uff0c\u4f5c\u4e3a\u4f20\u7edf FEM \u7b49\u65b9\u6cd5\u7684\u8865\u5145\uff0c\u4ece\u800c\u51cf\u5c11\u6602\u8d35\u7684\u4eff\u771f\u4e0e\u4eba\u5de5\u6210\u672c\u3002"}}
{"id": "2509.10248", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.10248", "abs": "https://arxiv.org/abs/2509.10248", "authors": ["Janis Keuper"], "title": "Prompt Injection Attacks on LLM Generated Reviews of Scientific Publications", "comment": null, "summary": "The ongoing intense discussion on rising LLM usage in the scientific\npeer-review process has recently been mingled by reports of authors using\nhidden prompt injections to manipulate review scores. Since the existence of\nsuch \"attacks\" - although seen by some commentators as \"self-defense\" - would\nhave a great impact on the further debate, this paper investigates the\npracticability and technical success of the described manipulations. Our\nsystematic evaluation uses 1k reviews of 2024 ICLR papers generated by a wide\nrange of LLMs shows two distinct results: I) very simple prompt injections are\nindeed highly effective, reaching up to 100% acceptance scores. II) LLM reviews\nare generally biased toward acceptance (>95% in many models). Both results have\ngreat impact on the ongoing discussions on LLM usage in peer-review.", "AI": {"tldr": "\u5bf92024 ICLR\u4e0a1000\u7bc7\u8bba\u6587\u7528\u591a\u79cdLLM\u751f\u6210\u5ba1\u7a3f\u5e76\u6ce8\u5165\u9690\u85cf\u63d0\u793a\u7684\u5b9e\u8bc1\u7814\u7a76\u8868\u660e\uff1a\u7b80\u5355\u63d0\u793a\u6ce8\u5165\u80fd\u663e\u8457\u63d0\u9ad8\u63a5\u53d7\u7387\uff08\u6700\u9ad8\u8fbe100%\uff09\uff0c\u4e14LLM\u672c\u8eab\u666e\u904d\u504f\u5411\u63a5\u53d7\uff0c\u8868\u660eLLM\u5728\u540c\u884c\u8bc4\u5ba1\u4e2d\u6613\u88ab\u6ee5\u7528\u5e76\u5b58\u5728\u7cfb\u7edf\u6027\u504f\u5dee\u3002", "motivation": "\u52a8\u673a\u662f\u56de\u5e94\u5173\u4e8e\u4f5c\u8005\u4f7f\u7528\u9690\u85cf\u63d0\u793a\uff08prompt injection\uff09\u4ee5\u64cd\u7eb5\u7531LLM\u751f\u6210\u7684\u540c\u884c\u8bc4\u5ba1\u7684\u62a5\u9053\uff0c\u8bc4\u4f30\u6b64\u7c7b\u653b\u51fb\u7684\u53ef\u884c\u6027\u548c\u5b9e\u9645\u5f71\u54cd\uff0c\u4ece\u800c\u4e3a\u5173\u4e8eLLM\u5728\u5b66\u672f\u8bc4\u5ba1\u4e2d\u7684\u4f7f\u7528\u5b89\u5168\u6027\u4e0e\u9053\u5fb7\u6027\u63d0\u4f9b\u5b9e\u8bc1\u4f9d\u636e\u3002", "method": "\u4f5c\u8005\u7cfb\u7edf\u5730\u4f7f\u7528\u591a\u79cdLLM\u5bf92024\u5e74ICLR\u76841000\u7bc7\u8bba\u6587\u751f\u6210\u5ba1\u6838\uff0c\u5e76\u5728\u751f\u6210\u8fc7\u7a0b\u4e2d\u52a0\u5165\u4e0d\u540c\u590d\u6742\u5ea6\u7684\u9690\u85cf\u63d0\u793a\u6ce8\u5165\u6765\u6d4b\u8bd5\u64cd\u7eb5\u6548\u679c\uff0c\u7edf\u8ba1\u63a5\u53d7\u7387\u548c\u8bc4\u5206\u53d8\u5316\uff0c\u518d\u5206\u6790\u6a21\u578b\u95f4\u504f\u597d\u5dee\u5f02\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff1a1) \u7b80\u5355\u7684\u63d0\u793a\u6ce8\u5165\u5373\u53ef\u8fbe\u5230\u6781\u9ad8\u7684\u64cd\u7eb5\u6210\u529f\u7387\uff08\u67d0\u4e9b\u60c5\u5f62\u4e0b\u63a5\u53d7\u7387\u8fbe100%\uff09\u30022) \u591a\u6570LLM\u5728\u9ed8\u8ba4\u60c5\u51b5\u4e0b\u5bf9\u63a5\u53d7\u503e\u5411\u660e\u663e\u504f\u9ad8\uff08\u8bb8\u591a\u6a21\u578b\u7684\u63a5\u53d7\u7387\u8d85\u8fc795%\uff09\u3002\u4e24\u70b9\u5747\u5bf9\u5b66\u672f\u540c\u884c\u8bc4\u5ba1\u6d41\u7a0b\u7684\u516c\u6b63\u6027\u6784\u6210\u4e25\u91cd\u6311\u6218\u3002", "conclusion": "\u672c\u6587\u7ed3\u8bba\u4e3a\uff1a\u7b80\u5355\u7684\u9690\u85cf\u63d0\u793a\u6ce8\u5165\u80fd\u663e\u8457\u64cd\u7eb5LLM\u751f\u6210\u7684\u540c\u884c\u8bc4\u5ba1\uff0c\u4f7f\u63a5\u53d7\u8bc4\u5206\u5927\u5e45\u4e0a\u5347\uff0c\u540c\u65f6\u591a\u6570LLM\u672c\u8eab\u5bf9\u63a5\u53d7\u6301\u504f\u5411\u6027\uff0c\u8868\u660e\u5728\u79d1\u7814\u540c\u884c\u8bc4\u5ba1\u4e2d\u4f7f\u7528LLM\u5b58\u5728\u4e25\u91cd\u98ce\u9669\u3002"}}
{"id": "2509.10273", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.10273", "abs": "https://arxiv.org/abs/2509.10273", "authors": ["Sahil Sethi", "Kai Sundmacher", "Caroline Ganzer"], "title": "Property prediction for ionic liquids without prior structural knowledge using limited experimental data: A data-driven neural recommender system leveraging transfer learning", "comment": null, "summary": "Ionic liquids (ILs) have emerged as versatile replacements for traditional\nsolvents because their physicochemical properties can be precisely tailored to\nvarious applications. However, accurately predicting key thermophysical\nproperties remains challenging due to the vast chemical design space and the\nlimited availability of experimental data. In this study, we present a\ndata-driven transfer learning framework that leverages a neural recommender\nsystem (NRS) to enable reliable property prediction for ILs using sparse\nexperimental datasets. The approach involves a two-stage process: first,\npre-training NRS models on COSMO-RS-based simulated data at fixed temperature\nand pressure to learn property-specific structural embeddings for cations and\nanions; and second, fine-tuning simple feedforward neural networks using these\nembeddings with experimental data at varying temperatures and pressures. In\nthis work, five essential IL properties are considered: density, viscosity,\nsurface tension, heat capacity, and melting point. The framework supports both\nwithin-property and cross-property knowledge transfer. Notably, pre-trained\nmodels for density, viscosity, and heat capacity are used to fine-tune models\nfor all five target properties, achieving improved performance by a substantial\nmargin for four of them. The model exhibits robust extrapolation to previously\nunseen ILs. Moreover, the final trained models enable property prediction for\nover 700,000 IL combinations, offering a scalable solution for IL screening in\nprocess design. This work highlights the effectiveness of combining simulated\ndata and transfer learning to overcome sparsity in the experimental data.", "AI": {"tldr": "\u4f7f\u7528COSMO-RS\u6a21\u62df\u6570\u636e\u9884\u8bad\u7ec3NRS\u83b7\u5f97\u79bb\u5b50\u5d4c\u5165\uff0c\u518d\u5728\u5b9e\u9a8c\u6570\u636e\u4e0a\u5fae\u8c03\u5c0f\u578b\u7f51\u7edc\uff0c\u901a\u8fc7\u8fc1\u79fb\u5b66\u4e60\u663e\u8457\u6539\u5584\u5728\u7a00\u758f\u5b9e\u9a8c\u6570\u636e\u4e0b\u5bf9IL\u4e94\u9879\u6027\u8d28\u7684\u9884\u6d4b\u5e76\u5b9e\u73b0\u5927\u89c4\u6a21\u7b5b\u9009\u3002", "motivation": "IL\u5316\u5b66\u7a7a\u95f4\u5de8\u5927\u4e14\u5b9e\u9a8c\u6570\u636e\u7a00\u7f3a\uff0c\u76f4\u63a5\u7528\u5b9e\u9a8c\u6570\u636e\u8bad\u7ec3\u96be\u4ee5\u6cdb\u5316\uff1b\u5229\u7528\u5927\u91cf\u6a21\u62df\u6570\u636e+\u8fc1\u79fb\u5b66\u4e60\u4ee5\u7f13\u89e3\u6570\u636e\u7a00\u758f\u6027\u5e76\u63d0\u5347\u9884\u6d4b\u6027\u80fd\u3002", "method": "\u4e24\u9636\u6bb5\u65b9\u6cd5\uff1a\u5148\u5728\u56fa\u5b9a\u6e29\u5ea6\u4e0e\u538b\u529b\u4e0b\u7528COSMO-RS\u6a21\u62df\u6570\u636e\u9884\u8bad\u7ec3NRS\u4ee5\u83b7\u53d6\u9488\u5bf9\u6027\u8d28\u7684\u79bb\u5b50\u5d4c\u5165\uff1b\u518d\u5c06\u8fd9\u4e9b\u5d4c\u5165\u4f5c\u4e3a\u7279\u5f81\uff0c\u5fae\u8c03\u7b80\u5355\u524d\u9988\u795e\u7ecf\u7f51\u7edc\u4ee5\u62df\u5408\u4e0d\u540c\u6e29\u538b\u4e0b\u7684\u5b9e\u9a8c\u6570\u636e\u3002\u652f\u6301\u540c\u6027\u8d28\u548c\u8de8\u6027\u8d28\u8fc1\u79fb\u5b66\u4e60\u3002", "result": "\u9488\u5bf9\u5bc6\u5ea6\u3001\u7c98\u5ea6\u3001\u8868\u9762\u5f20\u529b\u3001\u70ed\u5bb9\u548c\u7194\u70b9\u4e94\u79cd\u6027\u8d28\uff0c\u4f7f\u7528\u9884\u8bad\u7ec3\u7684\u5bc6\u5ea6\u3001\u7c98\u5ea6\u548c\u70ed\u5bb9\u6a21\u578b\u5bf9\u4e94\u4e2a\u76ee\u6807\u6027\u8d28\u8fdb\u884c\u5fae\u8c03\uff0c\u56db\u9879\u6027\u8d28\u663e\u8457\u63d0\u9ad8\uff1b\u6a21\u578b\u80fd\u7a33\u5065\u5916\u63a8\u5230\u672a\u89c1IL\uff0c\u5e76\u53ef\u5bf970\u4e07+\u79cdIL\u7ec4\u5408\u8fdb\u884c\u6027\u8d28\u9884\u6d4b\uff0c\u9002\u7528\u4e8e\u89c4\u6a21\u5316\u7b5b\u9009\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u5c06\u57fa\u4e8eCOSMO-RS\u7684\u6a21\u62df\u6570\u636e\u4e0e\u5b9e\u9a8c\u6570\u636e\u76f8\u7ed3\u5408\u7684\u8fc1\u79fb\u5b66\u4e60\u6846\u67b6\uff0c\u4f7f\u7528\u795e\u7ecf\u63a8\u8350\u7cfb\u7edf\uff08NRS\uff09\u5b66\u4e60\u79bb\u5b50\u6db2\u4f53\uff08IL\uff09\u4e2d\u9633\u79bb\u5b50\u548c\u9634\u79bb\u5b50\u7684\u7ed3\u6784\u5d4c\u5165\uff0c\u5e76\u901a\u8fc7\u5fae\u8c03\u5c0f\u578b\u524d\u9988\u795e\u7ecf\u7f51\u7edc\u4ee5\u5728\u7a00\u758f\u5b9e\u9a8c\u6570\u636e\u4e0b\u5b9e\u73b0\u53ef\u9760\u7684\u6027\u8d28\u9884\u6d4b\u3002"}}
{"id": "2509.10303", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.10303", "abs": "https://arxiv.org/abs/2509.10303", "authors": ["Jesse van Remmerden", "Zaharah Bukhsh", "Yingqian Zhang"], "title": "Generalizing Beyond Suboptimality: Offline Reinforcement Learning Learns Effective Scheduling through Random Data", "comment": null, "summary": "The Job-Shop Scheduling Problem (JSP) and Flexible Job-Shop Scheduling\nProblem (FJSP), are canonical combinatorial optimization problems with\nwide-ranging applications in industrial operations. In recent years, many\nonline reinforcement learning (RL) approaches have been proposed to learn\nconstructive heuristics for JSP and FJSP. Although effective, these online RL\nmethods require millions of interactions with simulated environments that may\nnot capture real-world complexities, and their random policy initialization\nleads to poor sample efficiency. To address these limitations, we introduce\nConservative Discrete Quantile Actor-Critic (CDQAC), a novel offline RL\nalgorithm that learns effective scheduling policies directly from historical\ndata, eliminating the need for costly online interactions, while maintaining\nthe ability to improve upon suboptimal training data. CDQAC couples a\nquantile-based critic with a delayed policy update, estimating the return\ndistribution of each machine-operation pair rather than selecting pairs\noutright. Our extensive experiments demonstrate CDQAC's remarkable ability to\nlearn from diverse data sources. CDQAC consistently outperforms the original\ndata-generating heuristics and surpasses state-of-the-art offline and online RL\nbaselines. In addition, CDQAC is highly sample efficient, requiring only 10-20\ntraining instances to learn high-quality policies. Surprisingly, we find that\nCDQAC performs better when trained on data generated by a random heuristic than\nwhen trained on higher-quality data from genetic algorithms and priority\ndispatching rules.", "AI": {"tldr": "\u63d0\u51faCDQAC\uff0c\u4e00\u79cd\u9762\u5411JSP/FJSP\u7684\u79bb\u7ebfRL\u7b97\u6cd5\uff0c\u901a\u8fc7\u5206\u4f4d\u6570\u56de\u62a5\u4f30\u8ba1\u4e0e\u4fdd\u5b88\u7b56\u7565\u66f4\u65b0\u4ece\u5386\u53f2\u6570\u636e\u9ad8\u6548\u5b66\u4e60\uff0c\u6837\u672c\u9700\u6c42\u4f4e\u4e14\u8868\u73b0\u4f18\u4e8e\u591a\u79cd\u57fa\u7ebf\uff0c\u5c24\u5176\u5728\u968f\u673a\u751f\u6210\u6570\u636e\u4e0a\u6548\u679c\u610f\u5916\u66f4\u597d\u3002", "motivation": "\u5728\u7ebfRL\u65b9\u6cd5\u6837\u672c\u6548\u7387\u4f4e\u3001\u9700\u8981\u5927\u91cf\u4eff\u771f\u4ea4\u4e92\u4e14\u968f\u673a\u521d\u59cb\u5316\u5bfc\u81f4\u6536\u655b\u6162\uff0c\u79bb\u7ebfRL\u53ef\u76f4\u63a5\u5229\u7528\u5386\u53f2\u6570\u636e\u5e76\u4fdd\u7559\u8d85\u8d8a\u6b21\u4f18\u8bad\u7ec3\u6570\u636e\u7684\u6f5c\u529b\u3002", "method": "CDQAC\u7ed3\u5408\u4e86\u5206\u4f4d\u6570\u4ef7\u503c\u4f30\u8ba1\u7684critic\u548c\u5ef6\u8fdf\u7b56\u7565\u66f4\u65b0\uff0c\u901a\u8fc7\u4f30\u8ba1\u6bcf\u4e2a\u673a\u5e8a-\u5de5\u5e8f\u5bf9\u7684\u56de\u62a5\u5206\u5e03\u800c\u975e\u76f4\u63a5\u9009\u62e9\u52a8\u4f5c\uff0c\u5b9e\u73b0\u4fdd\u5b88\u79bb\u6563\u5316\u51b3\u7b56\uff1b\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u91c7\u7528\u79bb\u7ebf\u6570\u636e\u6279\u6b21\u5b66\u4e60\u4ee5\u907f\u514d\u5728\u7ebf\u4ea4\u4e92\u3002", "result": "\u5b9e\u9a8c\u663e\u793aCDQAC\u5728\u591a\u79cd\u6570\u636e\u6e90\u4e0b\u8868\u73b0\u7a33\u5065\uff0c\u8d85\u8d8a\u539f\u59cb\u6570\u636e\u751f\u6210\u542f\u53d1\u5f0f\u3001\u4ee5\u53ca\u5f53\u524d\u79bb\u7ebf\u548c\u5728\u7ebfRL\u57fa\u7ebf\uff1b\u4ec5\u970010-20\u4e2a\u8bad\u7ec3\u5b9e\u4f8b\u5373\u53ef\u5b66\u5230\u9ad8\u8d28\u91cf\u7b56\u7565\uff1b\u5728\u968f\u673a\u542f\u53d1\u5f0f\u751f\u6210\u7684\u6570\u636e\u4e0a\u8868\u73b0\u4f18\u4e8e\u5728\u9ad8\u7ea7\u751f\u6210\u5668\uff08\u9057\u4f20\u7b97\u6cd5\u3001\u4f18\u5148\u89c4\u5219\uff09\u4e0a\u7684\u8bad\u7ec3\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5CDQAC\uff0c\u7528\u4e8eJSP\u548cFJSP\u8c03\u5ea6\u95ee\u9898\uff0c\u80fd\u4ece\u5386\u53f2\u6570\u636e\u5b66\u4e60\u9ad8\u6548\u7b56\u7565\u5e76\u63d0\u5347\u6570\u636e\u751f\u6210\u542f\u53d1\u5f0f\u6027\u80fd\u3002"}}
{"id": "2509.10308", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.10308", "abs": "https://arxiv.org/abs/2509.10308", "authors": ["Joshua Dimasaka", "Christian Gei\u00df", "Robert Muir-Wood", "Emily So"], "title": "GraphCSVAE: Graph Categorical Structured Variational Autoencoder for Spatiotemporal Auditing of Physical Vulnerability Towards Sustainable Post-Disaster Risk Reduction", "comment": "Accepted full paper at the 8th International Disaster and Risk\n  Conference, IDRC 2025 | Keywords: weakly supervised, graph deep learning,\n  categorical distribution, physical vulnerability, remote sensing,\n  spatiotemporal disaster risk, transition matrix | The data and code are\n  respectively available at https://doi.org/10.5281/zenodo.16656471 and\n  https://github.com/riskaudit/GraphCSVAE", "summary": "In the aftermath of disasters, many institutions worldwide face challenges in\ncontinually monitoring changes in disaster risk, limiting the ability of key\ndecision-makers to assess progress towards the UN Sendai Framework for Disaster\nRisk Reduction 2015-2030. While numerous efforts have substantially advanced\nthe large-scale modeling of hazard and exposure through Earth observation and\ndata-driven methods, progress remains limited in modeling another equally\nimportant yet challenging element of the risk equation: physical vulnerability.\nTo address this gap, we introduce Graph Categorical Structured Variational\nAutoencoder (GraphCSVAE), a novel probabilistic data-driven framework for\nmodeling physical vulnerability by integrating deep learning, graph\nrepresentation, and categorical probabilistic inference, using time-series\nsatellite-derived datasets and prior expert belief systems. We introduce a\nweakly supervised first-order transition matrix that reflects the changes in\nthe spatiotemporal distribution of physical vulnerability in two\ndisaster-stricken and socioeconomically disadvantaged areas: (1) the\ncyclone-impacted coastal Khurushkul community in Bangladesh and (2) the\nmudslide-affected city of Freetown in Sierra Leone. Our work reveals\npost-disaster regional dynamics in physical vulnerability, offering valuable\ninsights into localized spatiotemporal auditing and sustainable strategies for\npost-disaster risk reduction.", "AI": {"tldr": "\u63d0\u51faGraphCSVAE\uff0c\u7528\u56fe\u6a21\u578b\u4e0e\u5206\u7c7b\u578bVAE\u5bf9\u65f6\u5e8f\u536b\u661f\u6570\u636e\u8fdb\u884c\u5f31\u76d1\u7763\u63a8\u65ad\uff0c\u523b\u753b\u707e\u540e\u7269\u7406\u8106\u5f31\u6027\u7684\u65f6\u7a7a\u8f6c\u53d8\uff0c\u5e76\u5728\u4e24\u5904\u53d7\u707e\u793e\u533a\u5c55\u793a\u4e86\u53ef\u89e3\u91ca\u7684\u8106\u5f31\u6027\u52a8\u6001\u3002", "motivation": "\u5c3d\u7ba1\u5730\u9707\u3001\u6d2a\u6c34\u7b49\u707e\u5bb3\u7684\u5371\u9669\u6027\u548c\u66b4\u9732\u5df2\u7ecf\u53ef\u901a\u8fc7\u9065\u611f\u4e0e\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u5927\u5c3a\u5ea6\u5efa\u6a21\uff0c\u4f46\u7269\u7406\u8106\u5f31\u6027\uff08\u6613\u635f\u6027\uff09\u5efa\u6a21\u8fdb\u5c55\u6ede\u540e\uff0c\u9650\u5236\u4e86\u8bc4\u4f30\u51cf\u707e\u6846\u67b6\uff08\u5982Sendai\uff09\u8fdb\u5c55\u7684\u80fd\u529b\uff0c\u5c24\u5176\u5728\u707e\u540e\u9700\u6301\u7eed\u76d1\u6d4b\u8106\u5f31\u6027\u53d8\u5316\u4ee5\u6307\u5bfc\u51b3\u7b56\u3002", "method": "\u8bbe\u8ba1Graph Categorical Structured VAE\uff1a\u91c7\u7528\u56fe\u795e\u7ecf\u7f51\u7edc\u8868\u5f81\u7a7a\u95f4\u90bb\u63a5\u4e0e\u4e92\u76f8\u5173\uff0c\u7ed3\u5408\u5206\u7c7b\u578b\u6f5c\u53d8\u91cf\u4e0e\u5f31\u76d1\u7763\u4e00\u9636\u8f6c\u79fb\u77e9\u9635\u6765\u8868\u793a\u8106\u5f31\u6027\u7c7b\u522b\u95f4\u7684\u65f6\u5e8f\u8f6c\u53d8\uff1b\u8f93\u5165\u4e3a\u536b\u661f\u65f6\u5e8f\u4e0e\u5916\u90e8\u5148\u9a8c\u4fe1\u5ff5\uff0c\u8f93\u51fa\u4e3a\u6bcf\u4e2a\u7a7a\u95f4\u5355\u5143\u7684\u7c7b\u522b\u540e\u9a8c\u5206\u5e03\u4e0e\u8f6c\u79fb\u6982\u7387\u3002", "result": "\u5728\u5b5f\u52a0\u62c9\u56fdKhurushkul\u6cbf\u6d77\u4e0e\u585e\u62c9\u5229\u6602Freetown\u6ce5\u77f3\u6d41\u53d7\u707e\u5730\u533a\u7684\u6848\u4f8b\u7814\u7a76\u4e2d\uff0cGraphCSVAE\u63ed\u793a\u4e86\u707e\u540e\u4e0d\u540c\u533a\u57df\u7684\u8106\u5f31\u6027\u7c7b\u522b\u65f6\u7a7a\u8fc1\u79fb\u6a21\u5f0f\uff0c\u80fd\u591f\u63d0\u4f9b\u5c40\u90e8\u5316\u7684\u8106\u5f31\u6027\u5ba1\u8ba1\u7ebf\u7d22\u5e76\u652f\u6301\u53ef\u6301\u7eed\u7684\u51cf\u707e\u7b56\u7565\u5236\u5b9a\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9762\u5411\u7269\u7406\u8106\u5f31\u6027\u5efa\u6a21\u7684\u65b0\u9896\u6982\u7387\u6570\u636e\u9a71\u52a8\u6846\u67b6GraphCSVAE\uff0c\u5c06\u56fe\u8868\u793a\u3001\u53d8\u5206\u81ea\u7f16\u7801\u5668\u548c\u5206\u7c7b\u578b\u6982\u7387\u63a8\u65ad\u878d\u5408\uff0c\u4ee5\u5229\u7528\u65f6\u5e8f\u536b\u661f\u6570\u636e\u4e0e\u4e13\u5bb6\u5148\u9a8c\u6765\u523b\u753b\u707e\u540e\u8106\u5f31\u6027\u65f6\u7a7a\u6f14\u5316\u3002"}}
{"id": "2509.10324", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.10324", "abs": "https://arxiv.org/abs/2509.10324", "authors": ["Myung Jin Kim", "YeongHyeon Park", "Il Dong Yun"], "title": "ARMA Block: A CNN-Based Autoregressive and Moving Average Module for Long-Term Time Series Forecasting", "comment": null, "summary": "This paper proposes a simple yet effective convolutional module for long-term\ntime series forecasting. The proposed block, inspired by the Auto-Regressive\nIntegrated Moving Average (ARIMA) model, consists of two convolutional\ncomponents: one for capturing the trend (autoregression) and the other for\nrefining local variations (moving average). Unlike conventional ARIMA, which\nrequires iterative multi-step forecasting, the block directly performs\nmulti-step forecasting, making it easily extendable to multivariate settings.\nExperiments on nine widely used benchmark datasets demonstrate that our method\nARMA achieves competitive accuracy, particularly on datasets exhibiting strong\ntrend variations, while maintaining architectural simplicity. Furthermore,\nanalysis shows that the block inherently encodes absolute positional\ninformation, suggesting its potential as a lightweight replacement for\npositional embeddings in sequential models.", "AI": {"tldr": "\u63d0\u51fa\u53d7ARIMA\u542f\u53d1\u7684\u53cc\u5206\u652f\u5377\u79ef\u6a21\u5757ARMA\uff0c\u76f4\u63a5\u591a\u6b65\u957f\u5e8f\u5217\u9884\u6d4b\uff0c\u53ef\u6269\u5c55\u5230\u591a\u53d8\u91cf\uff0c\u7b80\u5355\u6709\u6548\uff0c\u7279\u522b\u9002\u5408\u8d8b\u52bf\u663e\u8457\u7684\u6570\u636e\uff0c\u5e76\u80fd\u5185\u5d4c\u4f4d\u7f6e\u4fe1\u606f\u3002", "motivation": "\u4f20\u7edf\u957f\u5e8f\u5217\u9884\u6d4b\u65b9\u6cd5\uff08\u5982ARIMA\u6216\u590d\u6742\u6df1\u5ea6\u6a21\u578b\uff09\u8981\u4e48\u9700\u8981\u8fed\u4ee3\u591a\u6b65\u9884\u6d4b\u3001\u8981\u4e48\u7ed3\u6784\u590d\u6742\u4e14\u96be\u4ee5\u6269\u5c55\u5230\u591a\u53d8\u91cf\u3002\u4f5c\u8005\u5e0c\u671b\u8bbe\u8ba1\u4e00\u4e2a\u65e2\u7b80\u5355\u53c8\u6709\u6548\u3001\u80fd\u6355\u6349\u8d8b\u52bf\u4e0e\u5c40\u90e8\u6ce2\u52a8\u5e76\u76f4\u63a5\u8fdb\u884c\u591a\u6b65\u9884\u6d4b\u7684\u5377\u79ef\u6a21\u5757\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u5305\u542b\u4e24\u90e8\u5206\u5377\u79ef\u7684\u6a21\u5757\uff1a\u4e00\u90e8\u5206\u6a21\u62df\u81ea\u56de\u5f52\u7528\u4e8e\u6355\u6349\u8d8b\u52bf\uff0c\u53e6\u4e00\u90e8\u5206\u6a21\u62df\u79fb\u52a8\u5e73\u5747\u7528\u4e8e\u4fee\u6b63\u5c40\u90e8\u6ce2\u52a8\uff1b\u76f4\u63a5\u8f93\u51fa\u591a\u6b65\u9884\u6d4b\u800c\u975e\u8fed\u4ee3\u6b65\u9aa4\uff1b\u6a21\u5757\u53ef\u65e0\u7f1d\u7528\u4e8e\u591a\u53d8\u91cf\u9884\u6d4b\uff0c\u5e76\u4e14\u901a\u8fc7\u5206\u6790\u663e\u793a\u5176\u5377\u79ef\u7ed3\u6784\u5185\u5d4c\u7edd\u5bf9\u4f4d\u7f6e\u4fe1\u606f\u3002", "result": "\u57289\u4e2a\u5e38\u7528\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0cARMA\u5728\u6574\u4f53\u7cbe\u5ea6\u4e0a\u5177\u6709\u7ade\u4e89\u529b\uff0c\u5c24\u5176\u5728\u8d8b\u52bf\u660e\u663e\u7684\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\uff1b\u6b64\u5916\u5206\u6790\u8868\u660e\u8be5\u6a21\u5757\u80fd\u591f\u7f16\u7801\u7edd\u5bf9\u4f4d\u7f6e\u4fe1\u606f\uff0c\u6709\u671b\u4f5c\u4e3a\u8f7b\u91cf\u7ea7\u7684\u4f4d\u7f6e\u5d4c\u5165\u66ff\u4ee3\u65b9\u6848\u3002", "conclusion": "\u8be5\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u53d7ARIMA\u542f\u53d1\u7684\u5377\u79ef\u6a21\u5757\uff08ARMA\uff09\uff0c\u7528\u4e8e\u957f\u5e8f\u5217\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\uff0c\u80fd\u591f\u76f4\u63a5\u8fdb\u884c\u591a\u6b65\u9884\u6d4b\u5e76\u6269\u5c55\u5230\u591a\u53d8\u91cf\uff1b\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u4e0e\u73b0\u6709\u65b9\u6cd5\u7ade\u4e89\u7684\u51c6\u786e\u6027\uff0c\u5c24\u5176\u5728\u8d8b\u52bf\u53d8\u5316\u5f3a\u7684\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u7a81\u51fa\uff0c\u540c\u65f6\u7ed3\u6784\u7b80\u5355\u5e76\u53ef\u5185\u5728\u7f16\u7801\u7edd\u5bf9\u4f4d\u7f6e\u4fe1\u606f\uff0c\u53ef\u80fd\u66ff\u4ee3\u4f4d\u7f6e\u5d4c\u5165\u3002"}}
{"id": "2509.10369", "categories": ["cs.LG", "cs.AI", "eess.SP", "q-bio.TO"], "pdf": "https://arxiv.org/pdf/2509.10369", "abs": "https://arxiv.org/abs/2509.10369", "authors": ["Gul Rukh Khattak", "Konstantinos Patlatzoglou", "Joseph Barker", "Libor Pastika", "Boroumand Zeidaabadi", "Ahmed El-Medany", "Hesham Aggour", "Yixiu Liang", "Antonio H. Ribeiro", "Jeffrey Annis", "Antonio Luiz Pinho Ribeiro", "Junbo Ge", "Daniel B. Kramer", "Jonathan W. Waks", "Evan Brittain", "Nicholas Peters", "Fu Siong Ng", "Arunashis Sau"], "title": "Data distribution impacts the performance and generalisability of contrastive learning-based foundation models of electrocardiograms", "comment": "Currently under review at npj Digital Medicine", "summary": "Contrastive learning is a widely adopted self-supervised pretraining\nstrategy, yet its dependence on cohort composition remains underexplored. We\npresent Contrasting by Patient Augmented Electrocardiograms (CAPE) foundation\nmodel and pretrain on four cohorts (n = 5,203,352), from diverse populations\nacross three continents (North America, South America, Asia). We systematically\nassess how cohort demographics, health status, and population diversity\ninfluence the downstream performance for prediction tasks also including two\nadditional cohorts from another continent (Europe). We find that downstream\nperformance depends on the distributional properties of the pretraining cohort,\nincluding demographics and health status. Moreover, while pretraining with a\nmulti-centre, demographically diverse cohort improves in-distribution accuracy,\nit reduces out-of-distribution (OOD) generalisation of our contrastive approach\nby encoding cohort-specific artifacts. To address this, we propose the\nIn-Distribution Batch (IDB) strategy, which preserves intra-cohort consistency\nduring pretraining and enhances OOD robustness. This work provides important\ninsights for developing clinically fair and generalisable foundation models.", "AI": {"tldr": "\u5bf9\u6bd4\u5b66\u4e60\u7684\u9884\u8bad\u7ec3\u961f\u5217\u7ec4\u6210\u4f1a\u663e\u8457\u5f71\u54cd\u4e34\u5e8aECG\u57fa\u5ea7\u6a21\u578b\u7684\u516c\u5e73\u6027\u4e0e\u6cdb\u5316\uff1bIDB\u7b56\u7565\u80fd\u51cf\u5c11\u591a\u4e2d\u5fc3\u9884\u8bad\u7ec3\u5e26\u6765\u7684OOD\u6027\u80fd\u4e0b\u964d\u3002", "motivation": "\u7814\u7a76\u5bf9\u6bd4\u81ea\u76d1\u7763\u9884\u8bad\u7ec3\u5bf9\u961f\u5217\u7ec4\u6210\uff08\u4eba\u53e3\u5b66\u4e0e\u5065\u5eb7\u72b6\u6001\uff09\u654f\u611f\u6027\uff0c\u5e76\u5bfb\u6c42\u63d0\u9ad8\u6a21\u578b\u5728\u4e34\u5e8a\u5e94\u7528\u4e2d\u5bf9\u4e0d\u540c\u4eba\u7fa4\u7684\u516c\u5e73\u6027\u4e0e\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u6784\u5efaCAPE\u57fa\u5ea7\u6a21\u578b\uff0c\u5728\u56db\u4e2a\u5305\u542b5,203,352\u4e2a\u5fc3\u7535\u56fe\u6837\u672c\u7684\u961f\u5217\u4e0a\u8fdb\u884c\u5bf9\u6bd4\u5b66\u4e60\u9884\u8bad\u7ec3\uff0c\u7cfb\u7edf\u8bc4\u4f30\u4e0d\u540c\u961f\u5217\u7684\u5e74\u9f84/\u6027\u522b/\u5065\u5eb7\u72b6\u6001\u548c\u4eba\u53e3\u5b66\u591a\u6837\u6027\u5bf9\u4e0b\u6e38\u4efb\u52a1\uff08\u542b\u6765\u81ea\u4e24\u4e2a\u4eba\u53e3\u4f53\u7684\u989d\u5916\u961f\u5217\uff09\u9884\u6d4b\u6027\u80fd\u7684\u5f71\u54cd\uff1b\u8bbe\u8ba1IDB\u8bad\u7ec3\u7b56\u7565\uff0c\u5728\u6279\u6b21\u91c7\u6837\u8fc7\u7a0b\u4e2d\u4fdd\u6301\u540c\u961f\u5217\u6837\u672c\u4e00\u81f4\u6027\u4ee5\u51cf\u5c11\u961f\u5217\u4f2a\u5f71\u7684\u5b66\u4e60\u3002", "result": "\u53d1\u73b0\u4e0b\u6e38\u6027\u80fd\u53d7\u9884\u8bad\u7ec3\u961f\u5217\u5206\u5e03\u5c5e\u6027\u5f71\u54cd\uff1b\u591a\u4e2d\u5fc3\u591a\u6837\u5316\u9884\u8bad\u7ec3\u63d0\u5347\u540c\u5206\u5e03\u51c6\u786e\u7387\u4f46\u964d\u4f4eOOD\u6cdb\u5316\uff1bIDB\u80fd\u5728\u591a\u6570\u60c5\u51b5\u4e0b\u63d0\u5347OOD\u9c81\u68d2\u6027\uff0c\u51cf\u5f31\u961f\u5217\u7279\u5f02\u4f2a\u5f71\u7684\u5f71\u54cd\uff0c\u540c\u65f6\u7ef4\u6301\u6216\u63a5\u8fd1\u540c\u5206\u5e03\u6027\u80fd\u3002", "conclusion": "\u9884\u8bad\u7ec3\u961f\u5217\u7ec4\u6210\u663e\u8457\u5f71\u54cd\u5bf9\u6bd4\u5b66\u4e60\u8868\u5f81\u8d28\u91cf\uff1b\u591a\u4e2d\u5fc3\u591a\u6837\u5316\u9884\u8bad\u7ec3\u63d0\u5347\u540c\u5206\u5e03\u6027\u80fd\u4f46\u4f1a\u5f15\u5165\u961f\u5217/\u961f\u5217\u7279\u5f02\u4f2a\u5f71\uff0c\u524a\u5f31OOD\u6cdb\u5316\uff1b\u63d0\u51fa\u7684In-Distribution Batch(IDB)\u901a\u8fc7\u4fdd\u7559\u540c\u961f\u5217\u5185\u4e00\u81f4\u6027\u6765\u589e\u5f3a\u8de8\u961f\u5217\u9c81\u68d2\u6027\u3002"}}
{"id": "2509.10363", "categories": ["cs.LG", "cs.NA", "math.NA"], "pdf": "https://arxiv.org/pdf/2509.10363", "abs": "https://arxiv.org/abs/2509.10363", "authors": ["Benjamin David Shaffer", "Brooks Kinch", "Joseph Klobusicky", "M. Ani Hsieh", "Nathaniel Trask"], "title": "Physics-informed sensor coverage through structure preserving machine learning", "comment": null, "summary": "We present a machine learning framework for adaptive source localization in\nwhich agents use a structure-preserving digital twin of a coupled\nhydrodynamic-transport system for real-time trajectory planning and data\nassimilation. The twin is constructed with conditional neural Whitney forms\n(CNWF), coupling the numerical guarantees of finite element exterior calculus\n(FEEC) with transformer-based operator learning. The resulting model preserves\ndiscrete conservation, and adapts in real time to streaming sensor data. It\nemploys a conditional attention mechanism to identify: a reduced Whitney-form\nbasis; reduced integral balance equations; and a source field, each compatible\nwith given sensor measurements. The induced reduced-order environmental model\nretains the stability and consistency of standard finite-element simulation,\nyielding a physically realizable, regular mapping from sensor data to the\nsource field. We propose a staggered scheme that alternates between evaluating\nthe digital twin and applying Lloyd's algorithm to guide sensor placement, with\nanalysis providing conditions for monotone improvement of a coverage\nfunctional. Using the predicted source field as an importance function within\nan optimal-recovery scheme, we demonstrate recovery of point sources under\ncontinuity assumptions, highlighting the role of regularity as a sufficient\ncondition for localization. Experimental comparisons with physics-agnostic\ntransformer architectures show improved accuracy in complex geometries when\nphysical constraints are enforced, indicating that structure preservation\nprovides an effective inductive bias for source identification.", "AI": {"tldr": "\u4f5c\u8005\u7528\u7ed3\u5408FEEC\u7ed3\u6784\u4e0eTransformer\u7684\u6761\u4ef6\u795e\u7ecfWhitney\u5f62\u5f0f\u6784\u5efa\u7269\u7406\u4e00\u81f4\u7684\u6570\u5b57\u5b6a\u751f\uff0c\u5b9e\u73b0\u5b9e\u65f6\u6570\u636e\u540c\u5316\u4e0e\u4f20\u611f\u5668\u81ea\u9002\u5e94\u90e8\u7f72\uff0c\u663e\u8457\u6539\u5584\u590d\u6742\u51e0\u4f55\u4e0b\u7684\u70b9\u6e90\u5b9a\u4f4d\u3002", "motivation": "\u5728\u590d\u6742\u6c34\u52a8\u529b-\u4f20\u8f93\u8026\u5408\u7cfb\u7edf\u4e2d\u5b9e\u73b0\u5b9e\u65f6\u3001\u7269\u7406\u4e00\u81f4\u7684\u6e90\u5b9a\u4f4d\u9700\u8981\u65e2\u4fdd\u7559\u6570\u503c\u5b88\u6052\u7ed3\u6784\u53c8\u5177\u5907\u6570\u636e\u9a71\u52a8\u7684\u9002\u5e94\u6027\uff1b\u7eaf\u6570\u636e\u9a71\u52a8\u6a21\u578b\u5728\u590d\u6742\u51e0\u4f55\u4e0b\u7f3a\u4e4f\u7269\u7406\u7ea6\u675f\uff0c\u7cbe\u5ea6\u53d7\u9650\uff0c\u56e0\u6b64\u5f15\u5165\u7ed3\u6784\u4fdd\u6301\u7684\u6570\u5b57\u5b6a\u751f\u4ee5\u63d0\u5347\u5b9a\u4f4d\u53ef\u9760\u6027\u3002", "method": "\u63d0\u51fa\u6761\u4ef6\u795e\u7ecfWhitney\u5f62\u5f0f(CNWF)\uff0c\u5c06\u6709\u9650\u5143\u5916\u5fae\u79ef\u5206(FEEC)\u7684\u7ed3\u6784\u6027\u79bb\u6563\u5b88\u6052\u4e0e\u57fa\u4e8eTransformer\u7684\u7b97\u5b50\u5b66\u4e60\u76f8\u7ed3\u5408\uff1b\u901a\u8fc7\u6761\u4ef6\u6ce8\u610f\u529b\u673a\u5236\u9009\u53d6\u964d\u7ef4Whitney\u57fa\u3001\u964d\u7ef4\u79ef\u5206\u5e73\u8861\u65b9\u7a0b\u548c\u6e90\u573a\uff1b\u91c7\u7528\u4ea4\u9519\u65b9\u6848\u5728\u8bc4\u4f30\u6570\u5b57\u5b6a\u751f\u4e0e\u5e94\u7528Lloyd\u7b97\u6cd5\u4e4b\u95f4\u4ea4\u66ff\u4ee5\u5f15\u5bfc\u4f20\u611f\u5668\u5e03\u7f6e\uff1b\u5e76\u7528\u6700\u4f18\u6062\u590d\u65b9\u6848\u4ee5\u9884\u6d4b\u6e90\u573a\u4f5c\u4e3a\u91cd\u8981\u6027\u51fd\u6570\u5b9e\u73b0\u70b9\u6e90\u6062\u590d\u3002", "result": "\u6784\u5efa\u7684CNWF\u6570\u5b57\u5b6a\u751f\u5728\u590d\u6742\u51e0\u4f55\u4e0b\u8f83\u65e0\u7269\u7406\u7ea6\u675f\u7684Transformer\u6a21\u578b\u8868\u73b0\u51fa\u66f4\u9ad8\u7684\u5b9a\u4f4d\u7cbe\u5ea6\uff1b\u63d0\u4f9b\u4e86\u8986\u76d6\u6cdb\u51fd\u5355\u8c03\u6539\u8fdb\u7684\u6761\u4ef6\u5206\u6790\uff1b\u5728\u8fde\u7eed\u6027\u5047\u8bbe\u4e0b\uff0c\u5c55\u793a\u4e86\u5229\u7528\u9884\u6d4b\u6e90\u573a\u4f5c\u4e3a\u91cd\u8981\u6027\u51fd\u6570\u53ef\u6062\u590d\u70b9\u6e90\u7684\u53ef\u884c\u6027\u3002", "conclusion": "\u8be5\u8bba\u6587\u6784\u5efa\u4e86\u4e00\u4e2a\u7ed3\u5408\u7269\u7406\u7ea6\u675f\u4e0eTransformer\u7b97\u5b50\u5b66\u4e60\u7684\u6570\u5b57\u5b6a\u751f\u6846\u67b6\uff0c\u7528\u4e8e\u81ea\u9002\u5e94\u6e90\u5b9a\u4f4d\uff0c\u8bc1\u660e\u5728\u4fdd\u5b88\u6027\u548c\u6570\u503c\u7a33\u5b9a\u6027\u4e0b\u80fd\u5b9e\u65f6\u540c\u5316\u4f20\u611f\u5668\u6570\u636e\u5e76\u6539\u8fdb\u4f20\u611f\u5668\u5e03\u5c40\uff0c\u4ece\u800c\u63d0\u9ad8\u70b9\u6e90\u6062\u590d\u7cbe\u5ea6\u3002"}}
{"id": "2509.10367", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.10367", "abs": "https://arxiv.org/abs/2509.10367", "authors": ["Tong Chen", "Raghavendra Selvan"], "title": "A Discrepancy-Based Perspective on Dataset Condensation", "comment": "30 pages, 4 tables, 1 figure", "summary": "Given a dataset of finitely many elements $\\mathcal{T} = \\{\\mathbf{x}_i\\}_{i\n= 1}^N$, the goal of dataset condensation (DC) is to construct a synthetic\ndataset $\\mathcal{S} = \\{\\tilde{\\mathbf{x}}_j\\}_{j = 1}^M$ which is\nsignificantly smaller ($M \\ll N$) such that a model trained from scratch on\n$\\mathcal{S}$ achieves comparable or even superior generalization performance\nto a model trained on $\\mathcal{T}$. Recent advances in DC reveal a close\nconnection to the problem of approximating the data distribution represented by\n$\\mathcal{T}$ with a reduced set of points. In this work, we present a unified\nframework that encompasses existing DC methods and extend the task-specific\nnotion of DC to a more general and formal definition using notions of\ndiscrepancy, which quantify the distance between probability distribution in\ndifferent regimes. Our framework broadens the objective of DC beyond\ngeneralization, accommodating additional objectives such as robustness,\nprivacy, and other desirable properties.", "AI": {"tldr": "\u5c06\u6570\u636e\u6d53\u7f29\u95ee\u9898\u5f62\u5f0f\u5316\u4e3a\u57fa\u4e8e\u5206\u6b67\u7684\u5206\u5e03\u8fd1\u4f3c\u95ee\u9898\uff0c\u63d0\u51fa\u7edf\u4e00\u6846\u67b6\uff0c\u80fd\u6574\u5408\u73b0\u6709\u65b9\u6cd5\u5e76\u6269\u5c55\u5230\u9c81\u68d2\u6027\u3001\u9690\u79c1\u7b49\u591a\u76ee\u6807\u8bbe\u7f6e\u3002", "motivation": "\u73b0\u6709DC\u65b9\u6cd5\u591a\u4fa7\u91cd\u4e8e\u8bad\u7ec3\u540e\u6cdb\u5316\u6027\u80fd\uff0c\u4e14\u65b9\u6cd5\u79cd\u7c7b\u7e41\u591a\u3001\u76ee\u6807\u4e0d\u4e00\u81f4\uff1b\u9700\u8981\u4e00\u4e2a\u7406\u8bba\u5316\u3001\u53ef\u5bf9\u6bd4\u4e14\u53ef\u6269\u5c55\u7684\u6846\u67b6\u6765\u7edf\u4e00\u7406\u89e3\u5e76\u6269\u5c55DC\u81f3\u5982\u9c81\u68d2\u6027\u3001\u9690\u79c1\u7b49\u5176\u4ed6\u76ee\u6807\u3002", "method": "\u901a\u8fc7\u5f15\u5165\u5206\u6b67\u7684\u5f62\u5f0f\u5316\u5b9a\u4e49\uff0c\u5c06\u6570\u636e\u96c6\u6d53\u7f29\u89c6\u4e3a\u7528\u5c11\u91cf\u70b9\u8fd1\u4f3c\u539f\u59cb\u6570\u636e\u5206\u5e03\u7684\u95ee\u9898\uff1b\u5728\u7edf\u4e00\u6846\u67b6\u4e0b\u5206\u6790\u5e76\u6574\u5408\u73b0\u6709\u65b9\u6cd5\u7684\u76ee\u6807\u4e0e\u4f18\u5316\u7b56\u7565\uff0c\u5141\u8bb8\u5728\u4e0d\u540c\u4efb\u52a1/\u8303\u5f0f\u4e0b\u91c7\u7528\u4e0d\u540c\u7684\u5206\u6b67\u5ea6\u91cf\u548c\u7ea6\u675f\u3002", "result": "\u6784\u5efa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u5206\u6b67\u7684\u901a\u7528\u5b9a\u4e49\u4e0e\u4f18\u5316\u76ee\u6807\uff0c\u8bc1\u660e\u8be5\u6846\u67b6\u80fd\u6db5\u76d6\u73b0\u6709\u65b9\u6cd5\u5e76\u81ea\u7136\u6269\u5c55\u5230\u5176\u5b83\u76ee\u6807\uff0c\u63d0\u4f9b\u4e86\u66f4\u7075\u6d3b\u7684\u76ee\u6807\u8bbe\u8ba1\u7a7a\u95f4\u4ee5\u5b9e\u73b0\u9c81\u68d2\u6027\u3001\u9690\u79c1\u7b49\u9644\u52a0\u5c5e\u6027\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u6846\u67b6\uff0c\u5c06\u73b0\u6709\u7684\u6570\u636e\u6d53\u7f29(dataset condensation, DC)\u65b9\u6cd5\u7eb3\u5165\u5176\u4e2d\uff0c\u5e76\u5c06\u7279\u5b9a\u4efb\u52a1\u7684DC\u63a8\u5e7f\u4e3a\u57fa\u4e8e\u5206\u6b67(discrepancy)\u7684\u66f4\u4e00\u822c\u5f62\u5f0f\uff0c\u4ece\u800c\u8d85\u8d8a\u5355\u4e00\u7684\u6cdb\u5316\u76ee\u6807\u3002"}}
{"id": "2509.10384", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2509.10384", "abs": "https://arxiv.org/abs/2509.10384", "authors": ["Jianxin Zhang", "Clayton Scott"], "title": "Flow Straight and Fast in Hilbert Space: Functional Rectified Flow", "comment": null, "summary": "Many generative models originally developed in finite-dimensional Euclidean\nspace have functional generalizations in infinite-dimensional settings.\nHowever, the extension of rectified flow to infinite-dimensional spaces remains\nunexplored. In this work, we establish a rigorous functional formulation of\nrectified flow in an infinite-dimensional Hilbert space. Our approach builds\nupon the superposition principle for continuity equations in an\ninfinite-dimensional space. We further show that this framework extends\nnaturally to functional flow matching and functional probability flow ODEs,\ninterpreting them as nonlinear generalizations of rectified flow. Notably, our\nextension to functional flow matching removes the restrictive measure-theoretic\nassumptions in the existing theory of \\citet{kerrigan2024functional}.\nFurthermore, we demonstrate experimentally that our method achieves superior\nperformance compared to existing functional generative models.", "AI": {"tldr": "\u672c\u6587\u5728\u65e0\u9650\u7ef4\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\u4e2d\u7ed9\u51farectified flow\u7684\u4e25\u683c\u51fd\u6570\u5f62\u5f0f\uff0c\u5e76\u5c06\u5176\u6269\u5c55\u5230functional flow matching\u548c\u6982\u7387\u6d41ODEs\uff0c\u7406\u8bba\u4e0a\u653e\u5bbd\u4e86\u5148\u524d\u7684\u6d4b\u5ea6\u5047\u8bbe\uff0c\u4e14\u5b9e\u9a8c\u5c55\u793a\u4e86\u66f4\u597d\u7684\u751f\u6210\u6027\u80fd\u3002", "motivation": "\u8bb8\u591a\u751f\u6210\u6a21\u578b\u5728\u6709\u9650\u7ef4\u6b27\u6c0f\u7a7a\u95f4\u5df2\u6709\u6210\u529f\uff0c\u4f46\u5176\u5728\u65e0\u9650\u7ef4\u51fd\u6570\u7a7a\u95f4\uff08\u5982\u968f\u673a\u8fc7\u7a0b\u3001\u51fd\u6570\u6570\u636e\uff09\u4e0a\u7684\u63a8\u5e7f\u5c1a\u4e0d\u5145\u5206\uff0c\u7279\u522b\u662frectified flow\u5c1a\u672a\u88ab\u6269\u5c55\u5230\u51fd\u6570\u7a7a\u95f4\uff1b\u9700\u8981\u4e00\u4e2a\u4e25\u683c\u7684\u7406\u8bba\u6846\u67b6\u4ee5\u4fdd\u8bc1\u65b9\u6cd5\u7684\u53ef\u884c\u6027\u548c\u62d3\u5c55\u6027\u3002", "method": "\u57fa\u4e8e\u65e0\u9650\u7ef4\u7a7a\u95f4\u4e2d\u8fde\u7eed\u6027\u65b9\u7a0b\u7684\u53e0\u52a0\u539f\u7406\u6784\u5efa\u6846\u67b6\uff1b\u5c06rectified flow\u63a8\u5e7f\u5230\u51fd\u6570\u7a7a\u95f4\uff0c\u5e76\u628afunctional flow matching\u4e0eprobability flow ODE\u89e3\u91ca\u4e3a\u8be5\u6846\u67b6\u4e0b\u7684\u975e\u7ebf\u6027\u53d8\u4f53\uff1b\u5728\u7406\u8bba\u4e0a\u8bba\u8bc1\u5b58\u5728\u6027\u4e0e\u4e00\u81f4\u6027\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e0a\u4e0e\u73b0\u6709\u51fd\u6570\u751f\u6210\u6a21\u578b\u6bd4\u8f83\u6027\u80fd\u3002", "result": "\u63d0\u4f9b\u4e86\u7406\u8bba\u4e0a\u7684\u51fd\u6570\u7a7a\u95f4rectified flow\u6784\u9020\uff0c\u6269\u5c55\u5230functional flow matching\u548cprobability flow ODEs\uff0c\u79fb\u9664\u4e86kerrigan2024functional\u4e2d\u7684\u9650\u5236\u6027\u6d4b\u5ea6\u5047\u8bbe\uff1b\u5b9e\u9a8c\u8868\u660e\u6240\u63d0\u65b9\u6cd5\u5728\u6027\u80fd\u4e0a\u4f18\u4e8e\u73b0\u6709\u51fd\u6570\u751f\u6210\u6a21\u578b\u3002", "conclusion": "\u8be5\u8bba\u6587\u5efa\u7acb\u4e86\u5728\u65e0\u9650\u7ef4\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\u4e2d\u5bf9rectified flow\u7684\u4e25\u683c\u51fd\u6570\u7a7a\u95f4\u8868\u8ff0\uff0c\u5e76\u5c06\u5176\u63a8\u5e7f\u5230functional flow matching\u548cfunctional probability flow ODEs\uff0c\u63ed\u793a\u5b83\u4eec\u4e3arectified flow\u7684\u975e\u7ebf\u6027\u63a8\u5e7f\uff0c\u540c\u65f6\u6d88\u9664\u4e86\u73b0\u6709\u5de5\u4f5c\u4e2d\u5bf9\u6d4b\u5ea6\u8bba\u5047\u8bbe\u7684\u9650\u5236\u3002"}}
{"id": "2509.10390", "categories": ["cs.LG", "cs.IT", "math.IT", "q-bio.PE"], "pdf": "https://arxiv.org/pdf/2509.10390", "abs": "https://arxiv.org/abs/2509.10390", "authors": ["Quan Nguyen", "Adji Bousso Dieng"], "title": "Vendi Information Gain for Active Learning and its Application to Ecology", "comment": null, "summary": "While monitoring biodiversity through camera traps has become an important\nendeavor for ecological research, identifying species in the captured image\ndata remains a major bottleneck due to limited labeling resources. Active\nlearning -- a machine learning paradigm that selects the most informative data\nto label and train a predictive model -- offers a promising solution, but\ntypically focuses on uncertainty in the individual predictions without\nconsidering uncertainty across the entire dataset. We introduce a new active\nlearning policy, Vendi information gain (VIG), that selects images based on\ntheir impact on dataset-wide prediction uncertainty, capturing both\ninformativeness and diversity. Applied to the Snapshot Serengeti dataset, VIG\nachieves impressive predictive accuracy close to full supervision using less\nthan 10% of the labels. It consistently outperforms standard baselines across\nmetrics and batch sizes, collecting more diverse data in the feature space. VIG\nhas broad applicability beyond ecology, and our results highlight its value for\nbiodiversity monitoring in data-limited environments.", "AI": {"tldr": "VIG\u662f\u4e00\u79cd\u9762\u5411\u6570\u636e\u96c6\u6574\u4f53\u4e0d\u786e\u5b9a\u6027\u7684\u4e3b\u52a8\u5b66\u4e60\u7b56\u7565\uff0c\u80fd\u5728\u5927\u5e45\u51cf\u5c11\u6807\u6ce8\u91cf\u7684\u60c5\u51b5\u4e0b\uff0c\u4fdd\u6301\u63a5\u8fd1\u5168\u76d1\u7763\u7684\u7269\u79cd\u8bc6\u522b\u6027\u80fd\uff0c\u9002\u5408\u751f\u6001\u5b66\u548c\u5176\u4ed6\u6570\u636e\u6709\u9650\u573a\u666f\u3002", "motivation": "\u76f8\u673a\u6355\u83b7\u7684\u751f\u7269\u591a\u6837\u6027\u56fe\u50cf\u6807\u6ce8\u6602\u8d35\u4e14\u7a00\u7f3a\uff0c\u4f20\u7edf\u4e3b\u52a8\u5b66\u4e60\u4fa7\u91cd\u4e2a\u4f53\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\uff0c\u5ffd\u89c6\u8de8\u6570\u636e\u96c6\u7684\u4e0d\u786e\u5b9a\u6027\u548c\u591a\u6837\u6027\uff0c\u9650\u5236\u4e86\u6807\u6ce8\u6548\u7387\u3002", "method": "\u63d0\u51faVendi information gain (VIG)\u7b56\u7565\uff0c\u57fa\u4e8e\u5bf9\u6574\u4e2a\u6570\u636e\u96c6\u9884\u6d4b\u5206\u5e03\u7684\u4e0d\u786e\u5b9a\u6027\u53d8\u5316\u6765\u8bc4\u4f30\u6bcf\u4e00\u6279\u5f85\u6807\u6ce8\u6837\u672c\u7684\u4ef7\u503c\uff1b\u5728Snapshot Serengeti\u6570\u636e\u96c6\u4e0a\u4e0e\u5e38\u89c1\u57fa\u7ebf\uff08\u5982\u4e0d\u786e\u5b9a\u6027\u91c7\u6837\u3001\u968f\u673a\u91c7\u6837\u7b49\uff09\u6bd4\u8f83\uff0c\u5e76\u5206\u6790\u7279\u5f81\u7a7a\u95f4\u7684\u591a\u6837\u6027\u3002", "result": "\u5728Snapshot Serengeti\u6570\u636e\u96c6\u4e0a\uff0c\u4f7f\u7528\u4e0d\u523010%\u6807\u6ce8\u6570\u636e\uff0cVIG\u7684\u9884\u6d4b\u51c6\u786e\u5ea6\u63a5\u8fd1\u5168\u76d1\u7763\u8bad\u7ec3\uff0c\u5e76\u6301\u7eed\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728\u4e0d\u540c\u6279\u91cf\u5927\u5c0f\u548c\u8bc4\u4f30\u6307\u6807\u4e0b\u5747\u8868\u73b0\u66f4\u597d\uff0c\u540c\u65f6\u91c7\u96c6\u5230\u5728\u7279\u5f81\u7a7a\u95f4\u4e0a\u66f4\u4e3a\u591a\u6837\u7684\u6837\u672c\u3002", "conclusion": "VIG\u901a\u8fc7\u8861\u91cf\u5bf9\u5168\u6570\u636e\u96c6\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u7684\u51cf\u5c11\u6765\u9009\u62e9\u6807\u6ce8\u6837\u672c\uff0c\u6709\u6548\u517c\u987e\u4fe1\u606f\u6027\u4e0e\u591a\u6837\u6027\uff0c\u4ece\u800c\u5728\u6709\u9650\u6807\u6ce8\u4e0b\u663e\u8457\u63d0\u5347\u7269\u79cd\u8bc6\u522b\u6027\u80fd\u3002"}}
{"id": "2509.10396", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.10396", "abs": "https://arxiv.org/abs/2509.10396", "authors": ["Siyan Zhao", "Mengchen Liu", "Jing Huang", "Miao Liu", "Chenyu Wang", "Bo Liu", "Yuandong Tian", "Guan Pang", "Sean Bell", "Aditya Grover", "Feiyu Chen"], "title": "Inpainting-Guided Policy Optimization for Diffusion Large Language Models", "comment": "preprint; 21 pages", "summary": "Masked diffusion large language models (dLLMs) are emerging as promising\nalternatives to autoregressive LLMs, offering competitive performance while\nsupporting unique generation capabilities such as inpainting. We explore how\ninpainting can inform RL algorithm design for dLLMs. Aligning LLMs with\nreinforcement learning faces an exploration challenge: sparse reward signals\nand sample waste when models fail to discover correct solutions. While this\ninefficiency affects LLMs broadly, dLLMs offer a distinctive opportunity--their\ninpainting ability can guide exploration. We introduce IGPO (Inpainting Guided\nPolicy Optimization), an RL framework that strategically inserts partial\nground-truth reasoning traces during online sampling. Unlike providing full\nsolutions, inpainting steers exploration toward promising trajectory spaces\nwhile preserving self-generated reasoning, bridging supervised fine-tuning and\nreinforcement learning. We apply IGPO to group-based optimization methods such\nas GRPO, where exploration failures cause zero advantages and gradients. IGPO\nrestores meaningful gradients while improving sample efficiency. We also\npropose supervised fine-tuning on synthetically rewritten concise traces that\nbetter align with dLLM generation patterns. With additional techniques\nincluding entropy-based filtering, our training recipe yields substantial gains\nacross three mathematical benchmarks--GSM8K, Math500, and AMC--achieving new\nstate-of-the-art results for full-attention masked dLLMs.", "AI": {"tldr": "\u5229\u7528dLLMs\u7684inpainting\u7279\u6027\u63d2\u5165\u90e8\u5206\u771f\u5b9e\u63a8\u7406\u7247\u6bb5\u4ee5\u6307\u5bfcRL\u63a2\u7d22\uff0c\u63d0\u51faIGPO\u5e76\u914d\u5408\u96c6\u6210\u8bad\u7ec3\u6280\u5de7\uff0c\u5728\u6570\u5b66\u9898\u89e3\u57fa\u51c6\u4e0a\u663e\u8457\u63d0\u9ad8\u6837\u672c\u6548\u7387\u4e0e\u6027\u80fd\uff0c\u8fbe\u6210masked dLLMs\u7684\u65b0SOTA\u3002", "motivation": "dLLMs\u652f\u6301inpainting\uff0c\u53ef\u5728\u5f3a\u5316\u5b66\u4e60\u4e2d\u7528\u4f5c\u5f15\u5bfc\u63a2\u7d22\u7684\u5de5\u5177\uff0c\u4ece\u800c\u7f13\u89e3\u7a00\u758f\u5956\u52b1\u548c\u6837\u672c\u6d6a\u8d39\u95ee\u9898\uff1b\u5e0c\u671b\u5728\u4fdd\u6301\u6a21\u578b\u81ea\u751f\u6210\u63a8\u7406\u7684\u540c\u65f6\u63d0\u9ad8\u53d1\u73b0\u6b63\u786e\u89e3\u7684\u6982\u7387\u4e0e\u8bad\u7ec3\u6548\u7387\u3002", "method": "\u63d0\u51fa\u5728RL\u6846\u67b6\u4e2d\u4f7f\u7528inpainting\u63d2\u5165\u90e8\u5206ground-truth\u63a8\u7406\u8f68\u8ff9\u4ee5\u5f15\u5bfc\u63a2\u7d22\uff1b\u5c06\u8be5\u65b9\u6cd5\u5e94\u7528\u4e8e\u57fa\u4e8e\u7ec4\u7684\u4f18\u5316\u65b9\u6cd5\uff08\u5982GRPO\uff09\u4ee5\u6062\u590d\u6709\u610f\u4e49\u7684\u68af\u5ea6\uff1b\u5e76\u7ed3\u5408\u5bf9\u5408\u6210\u91cd\u5199\u7684\u7b80\u6d01\u63a8\u7406\u7247\u6bb5\u8fdb\u884c\u76d1\u7763\u5fae\u8c03\u53ca\u57fa\u4e8e\u71b5\u7684\u7b5b\u9009\u7b49\u8bad\u7ec3\u6280\u5de7\u3002", "result": "\u5728GSM8K\u3001Math500\u548cAMC\u4e09\u5957\u6570\u5b66\u57fa\u51c6\u4e0a\uff0c\u7ed3\u5408IGPO\u4e0e\u76f8\u5173\u8bad\u7ec3\u6280\u5de7\uff0c\u5e26\u6765\u663e\u8457\u63d0\u5347\u5e76\u5b9e\u73b0\u5bf9\u5168\u6ce8\u610f\u529bmasked dLLMs\u7684\u65b0SOTA\u6210\u7ee9\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86IGPO\uff08Inpainting Guided Policy Optimization\uff09\uff0c\u5229\u7528dLLMs\u7684inpainting\u80fd\u529b\u5728\u5728\u7ebf\u91c7\u6837\u65f6\u63d2\u5165\u90e8\u5206\u771f\u5b9e\u63a8\u7406\u7247\u6bb5\uff0c\u6539\u5584\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u63a2\u7d22\u95ee\u9898\uff0c\u4ece\u800c\u5728\u6570\u5b66\u9898\u89e3\u4efb\u52a1\u4e0a\u663e\u8457\u63d0\u5347\u6837\u672c\u6548\u7387\u4e0e\u6027\u80fd\uff0c\u8fbe\u5230\u4e86masked dLLMs\u7684\u65b0SOTA\u3002"}}
{"id": "2509.10406", "categories": ["cs.LG", "68W25, 68T50 (primary) 68W40, 68T07 (secondary)", "I.2.6; I.2.7"], "pdf": "https://arxiv.org/pdf/2509.10406", "abs": "https://arxiv.org/abs/2509.10406", "authors": ["Rupert Mitchell", "Kristian Kersting"], "title": "Multipole Semantic Attention: A Fast Approximation of Softmax Attention for Pretraining", "comment": null, "summary": "We present Multipole Semantic Attention (MuSe), an efficient approximation of\nsoftmax attention that combines semantic clustering with multipole expansions\nfrom computational physics. Our method addresses the quadratic computational\ncomplexity of transformers in the context length by clustering queries and keys\nseparately in their learned representation spaces, enabling a hierarchical\ntwo-stage attention mechanism. Unlike prior clustering approaches that group\nonly keys or use unified clustering, we maintain separate clusterings that\nrespect attention's asymmetric treatment of these spaces. We augment\ncentroid-based (monopole) approximations with dipole corrections that capture\ndirectional variance within clusters, preserving richer information during\ntraining. The method operates as a drop-in replacement for standard attention,\nrequiring only hyperparameter specification without architectural\nmodifications. Our approach achieves $\\mathcal{O}(NCD)$ complexity for acausal\nattention with $C$ clusters and $\\mathcal{O}(NCD \\log N)$ for causal attention.\nOn isolated attention layers, we demonstrate $3\\times$ speedup over CUDNN Flash\nAttention at 8k context length, with relative squared errors below 20%. For\ncausal attention, we develop a hierarchical block decomposition that combines\nexact local computation with efficient long-range approximation. In end-to-end\npretraining of a 30M parameter model on book-length texts with 16k context, we\nachieve 12.2% runtime reduction with only 0.36% loss degradation, establishing\nthe viability of multipole approximations for efficient transformer\npretraining.", "AI": {"tldr": "MuSe \u7528\u8bed\u4e49\u72ec\u7acb\u805a\u7c7b\u52a0\u591a\u6781\uff08\u5305\u542b\u5076\u6781\u4fee\u6b63\uff09\u8fd1\u4f3c\u6ce8\u610f\u529b\uff0c\u5728\u957f\u5e8f\u5217\u4e0b\u663e\u8457\u52a0\u901f\u4e14\u8bef\u5dee\u53ef\u63a7\uff0c\u53ef\u4f5c\u4e3a\u6ce8\u610f\u529b\u5c42\u7684\u76f4\u63a5\u66ff\u6362\u7528\u4e8e\u9ad8\u6548\u9884\u8bad\u7ec3\u4e0e\u63a8\u7406\u3002", "motivation": "\u7f13\u89e3 Transformer \u5728\u4e0a\u4e0b\u6587\u957f\u5ea6 N \u589e\u957f\u65f6\u4e8c\u6b21\u590d\u6742\u5ea6\u5e26\u6765\u7684\u8ba1\u7b97\u4e0e\u5185\u5b58\u74f6\u9888\uff0c\u540c\u65f6\u4fdd\u7559\u6ce8\u610f\u529b\u673a\u5236\u7684\u7cbe\u7ec6\u4fe1\u606f\u4ee5\u5728\u9884\u8bad\u7ec3\u4e0e\u4efb\u52a1\u4e2d\u7ef4\u6301\u6027\u80fd\u3002", "method": "\u5bf9\u67e5\u8be2\u548c\u503c\uff08keys\uff09\u5728\u5176\u5b66\u4e60\u5230\u7684\u8868\u793a\u7a7a\u95f4\u4e2d\u5206\u522b\u805a\u7c7b\uff0c\u6784\u5efa\u4e24\u9636\u6bb5\u5c42\u6b21\u5316\u6ce8\u610f\u529b\uff1b\u4f7f\u7528\u8d28\u5fc3\uff08\u5355\u6781\uff09\u8fd1\u4f3c\u5e76\u52a0\u5165\u5076\u6781\uff08dipole\uff09\u4fee\u6b63\u4ee5\u6355\u6349\u7c07\u5185\u65b9\u5411\u6027\u65b9\u5dee\uff1b\u5bf9\u56e0\u679c\u6ce8\u610f\u529b\u91c7\u7528\u5206\u5c42\u5757\u5206\u89e3\u7ed3\u5408\u7cbe\u786e\u5c40\u90e8\u8ba1\u7b97\u4e0e\u9ad8\u6548\u8fdc\u7a0b\u8fd1\u4f3c\u3002\u65f6\u95f4\u590d\u6742\u5ea6\u4e3aO(N C D)\uff08\u975e\u56e0\u679c\uff09\u548cO(N C D log N)\uff08\u56e0\u679c\uff09\u3002", "result": "\u5728\u5b64\u7acb\u6ce8\u610f\u529b\u5c42\u8bc4\u4f30\u4e2d\uff0c8k \u4e0a\u4e0b\u6587\u957f\u5ea6\u4e0b\u76f8\u6bd4 CUDNN Flash Attention \u8fbe\u5230\u7ea63\u500d\u52a0\u901f\uff0c\u76f8\u5bf9\u5e73\u65b9\u8bef\u5dee\u4f4e\u4e8e20%\uff1b\u5728 30M \u53c2\u6570\u6a21\u578b\u300116k \u4e0a\u4e0b\u6587\u7684\u7aef\u5230\u7aef\u9884\u8bad\u7ec3\u4e2d\uff0c\u5b9e\u73b012.2% \u7684\u8fd0\u884c\u65f6\u95f4\u51cf\u5c11\uff0c\u4ec5\u5e26\u67650.36% \u7684\u6027\u80fd\u635f\u5931\u3002", "conclusion": "MuSe \u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u8bed\u4e49\u805a\u7c7b\u548c\u591a\u6781\u5c55\u5f00\u7684\u9ad8\u6548\u6ce8\u610f\u529b\u8fd1\u4f3c\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u5728\u957f\u4e0a\u4e0b\u6587\u4e0b\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\u5e76\u4fdd\u6301\u8f83\u4f4e\u8bef\u5dee\u7387\uff0c\u9002\u5408\u4f5c\u4e3a\u6807\u51c6\u6ce8\u610f\u529b\u7684\u65e0\u7f1d\u66ff\u6362\u3002"}}
{"id": "2509.10419", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.10419", "abs": "https://arxiv.org/abs/2509.10419", "authors": ["Francesco Vitale", "Tommaso Zoppi", "Francesco Flammini", "Nicola Mazzocca"], "title": "Run-Time Monitoring of ERTMS/ETCS Control Flow by Process Mining", "comment": "Accepted to the 6th International Conference on Reliability, Safety,\n  and Security of Railway Systems (RSSRail2025)", "summary": "Ensuring the resilience of computer-based railways is increasingly crucial to\naccount for uncertainties and changes due to the growing complexity and\ncriticality of those systems. Although their software relies on strict\nverification and validation processes following well-established best-practices\nand certification standards, anomalies can still occur at run-time due to\nresidual faults, system and environmental modifications that were unknown at\ndesign-time, or other emergent cyber-threat scenarios. This paper explores\nrun-time control-flow anomaly detection using process mining to enhance the\nresilience of ERTMS/ETCS L2 (European Rail Traffic Management System / European\nTrain Control System Level 2). Process mining allows learning the actual\ncontrol flow of the system from its execution traces, thus enabling run-time\nmonitoring through online conformance checking. In addition, anomaly\nlocalization is performed through unsupervised machine learning to link\nrelevant deviations to critical system components. We test our approach on a\nreference ERTMS/ETCS L2 scenario, namely the RBC/RBC Handover, to show its\ncapability to detect and localize anomalies with high accuracy, efficiency, and\nexplainability.", "AI": {"tldr": "\u4f5c\u8005\u7528\u8fc7\u7a0b\u6316\u6398+\u5728\u7ebf\u7b26\u5408\u6027\u68c0\u6d4b\u68c0\u6d4bERTMS/ETCS L2\u7684\u63a7\u5236\u6d41\u5f02\u5e38\uff0c\u914d\u5408\u65e0\u76d1\u7763\u5b66\u4e60\u5b9e\u73b0\u5f02\u5e38\u5b9a\u4f4d\uff0c\u5728RBC\u5207\u6362\u573a\u666f\u4e0a\u9a8c\u8bc1\u4e86\u9ad8\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u5c3d\u7ba1\u94c1\u8def\u8f6f\u4ef6\u7ecf\u8fc7\u4e25\u683c\u9a8c\u8bc1\u4e0e\u8ba4\u8bc1\uff0c\u8fd0\u884c\u65f6\u4ecd\u53ef\u80fd\u51fa\u73b0\u672a\u77e5\u6545\u969c\u4e0e\u5a01\u80c1\uff0c\u56e0\u6b64\u9700\u8981\u8fd0\u884c\u65f6\u76d1\u6d4b\u4e0e\u5feb\u901f\u5b9a\u4f4d\u673a\u5236\u6765\u63d0\u9ad8\u7cfb\u7edf\u5f39\u6027\u3002", "method": "\u4ece\u7cfb\u7edf\u6267\u884c\u65e5\u5fd7\u4e2d\u901a\u8fc7\u8fc7\u7a0b\u6316\u6398\u5b66\u4e60\u5b9e\u9645\u63a7\u5236\u6d41\uff0c\u5e76\u5728\u8fd0\u884c\u65f6\u4f7f\u7528\u5728\u7ebf\u7b26\u5408\u6027\u68c0\u6d4b\u6765\u53d1\u73b0\u504f\u79bb\uff1b\u968f\u540e\u7528\u65e0\u76d1\u7763\u673a\u5668\u5b66\u4e60\u5bf9\u504f\u5dee\u4e8b\u4ef6\u8fdb\u884c\u805a\u7c7b/\u5f52\u56e0\uff0c\u5b9e\u73b0\u5f02\u5e38\u5b9a\u4f4d\u3002", "result": "\u5728RBC/RBC\u5207\u6362\u573a\u666f\u4e0a\u8bc4\u4f30\uff0c\u65b9\u6cd5\u5728\u68c0\u6d4b\u51c6\u786e\u6027\u3001\u6548\u7387\u548c\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u8868\u73b0\u826f\u597d\uff0c\u80fd\u591f\u5b9e\u65f6\u53d1\u73b0\u5e76\u5b9a\u4f4d\u63a7\u5236\u6d41\u5f02\u5e38\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8fc7\u7a0b\u6316\u6398\u7684\u8fd0\u884c\u65f6\u63a7\u5236\u6d41\u5f02\u5e38\u68c0\u6d4b\u4e0e\u5b9a\u4f4d\u65b9\u6cd5\uff0c\u7528\u4e8e\u63d0\u5347ERTMS/ETCS L2\u94c1\u8def\u7cfb\u7edf\u7684\u5f39\u6027\uff0c\u5e94\u5bf9\u8fd0\u884c\u65f6\u6b8b\u7559\u6545\u969c\u3001\u672a\u77e5\u4fee\u6539\u548c\u7f51\u7edc\u5a01\u80c1\u3002"}}
{"id": "2509.10439", "categories": ["cs.LG", "math.OC", "stat.ML"], "pdf": "https://arxiv.org/pdf/2509.10439", "abs": "https://arxiv.org/abs/2509.10439", "authors": ["Ahmed Khaled", "Satyen Kale", "Arthur Douillard", "Chi Jin", "Rob Fergus", "Manzil Zaheer"], "title": "Understanding Outer Optimizers in Local SGD: Learning Rates, Momentum, and Acceleration", "comment": null, "summary": "Modern machine learning often requires training with large batch size,\ndistributed data, and massively parallel compute hardware (like mobile and\nother edge devices or distributed data centers). Communication becomes a major\nbottleneck in such settings but methods like Local Stochastic Gradient Descent\n(Local SGD) show great promise in reducing this additional communication\noverhead. Local SGD consists of three parts: a local optimization process, an\naggregation mechanism, and an outer optimizer that uses the aggregated updates\nfrom the nodes to produce a new model. While there exists an extensive\nliterature on understanding the impact of hyperparameters in the local\noptimization process, the choice of outer optimizer and its hyperparameters is\nless clear. We study the role of the outer optimizer in Local SGD, and prove\nnew convergence guarantees for the algorithm. In particular, we show that\ntuning the outer learning rate allows us to (a) trade off between optimization\nerror and stochastic gradient noise variance, and (b) make up for ill-tuning of\nthe inner learning rate. Our theory suggests that the outer learning rate\nshould sometimes be set to values greater than $1$. We extend our results to\nsettings where we use momentum in the outer optimizer, and we show a similar\nrole for the momentum-adjusted outer learning rate. We also study acceleration\nin the outer optimizer and show that it improves the convergence rate as a\nfunction of the number of communication rounds, improving upon the convergence\nrate of prior algorithms that apply acceleration locally. Finally, we also\nintroduce a novel data-dependent analysis of Local SGD that yields further\ninsights on outer learning rate tuning. We conduct comprehensive experiments\nwith standard language models and various outer optimizers to validate our\ntheory.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76Local SGD\u4e2d\u5916\u90e8\u4f18\u5316\u5668\u7684\u4f5c\u7528\uff0c\u8bc1\u660e\u8c03\u8282\u5916\u5b66\u4e60\u7387\uff08\u751a\u81f3>1\uff09\u548c\u52a8\u91cf\u80fd\u5728\u6536\u655b\u7387\u4e0e\u566a\u58f0\u95f4\u53d6\u5f97\u66f4\u597d\u6743\u8861\u3001\u8865\u507f\u5185\u5b66\u4e60\u7387\u8bef\u8bbe\uff0c\u5e76\u901a\u8fc7\u52a0\u901f\u65b9\u6cd5\u6539\u5584\u901a\u4fe1\u8f6e\u6570\u76f8\u5173\u6536\u655b\uff0c\u7406\u8bba\u4e0e\u8bed\u8a00\u6a21\u578b\u5b9e\u9a8c\u8bc1\u5b9e\u3002", "motivation": "\u5728\u5206\u5e03\u5f0f/\u5927\u6279\u91cf\u8bad\u7ec3\u4e2d\u901a\u4fe1\u6210\u4e3a\u74f6\u9888\uff0cLocal SGD\u80fd\u51cf\u5c11\u901a\u4fe1\u4f46\u5916\u90e8\u4f18\u5316\u5668\u7684\u9009\u62e9\u4e0e\u8d85\u53c2\u8c03\u4f18\u5c1a\u4e0d\u660e\u786e\uff0c\u9700\u7406\u89e3\u5916\u5b66\u4e60\u7387\u53ca\u52a8\u91cf\u5982\u4f55\u5f71\u54cd\u6536\u655b\u4e0e\u566a\u58f0\u6743\u8861\u3002", "method": "\u4f5c\u8005\u5728\u7406\u8bba\u4e0a\u5206\u6790\u4e86Local SGD\uff0c\u5c06\u7b97\u6cd5\u5206\u4e3a\u5c40\u90e8\u4f18\u5316\u3001\u805a\u5408\u673a\u5236\u4e0e\u5916\u90e8\u4f18\u5316\u5668\u4e09\u90e8\u5206\uff0c\u8bc1\u660e\u4e86\u5728\u4e0d\u540c\u8bbe\u5b9a\u4e0b\u5173\u4e8e\u5916\u5b66\u4e60\u7387\u4e0e\u52a8\u91cf\u8c03\u6574\u7684\u6536\u655b\u6027\u754c\uff1b\u6269\u5c55\u5230\u5e26\u52a8\u91cf\u53ca\u52a0\u901f\u7684\u5916\u90e8\u4f18\u5316\u5668\uff0c\u63a8\u5bfc\u901a\u4fe1\u8f6e\u6570\u76f8\u5173\u7684\u6539\u8fdb\u6536\u655b\u7387\uff1b\u5e76\u7ed9\u51fa\u6570\u636e\u76f8\u5173\u7684\u5206\u6790\u3002\u6700\u540e\u901a\u8fc7\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u5b9e\u9a8c\u9a8c\u8bc1\u7406\u8bba\u3002", "result": "\u7406\u8bba\u4e0a\u8bc1\u660e\u5916\u5b66\u4e60\u7387\u53ef\u7528\u6765\u5e73\u8861\u4f18\u5316\u8bef\u5dee\u4e0e\u566a\u58f0\u3001\u8865\u507f\u5185\u5b66\u4e60\u7387\u8c03\u53c2\u5931\u8bef\uff1b\u5916\u5b66\u4e60\u7387\u6709\u65f6\u9700>1\uff1b\u5e26\u52a8\u91cf\u548c\u52a0\u901f\u7684\u5916\u4f18\u5316\u5668\u80fd\u8fdb\u4e00\u6b65\u63d0\u5347\u901a\u4fe1\u8f6e\u6570\u4e0b\u7684\u6536\u655b\u6027\uff1b\u6570\u636e\u4f9d\u8d56\u5206\u6790\u7ed9\u51fa\u989d\u5916\u8c03\u53c2\u6307\u5f15\u3002\u5b9e\u9a8c\u5728\u8bed\u8a00\u6a21\u578b\u4e0a\u652f\u6301\u7406\u8bba\u7ed3\u8bba\u3002", "conclusion": "\u672c\u6587\u7ed3\u8bba\u662f\uff1a\u5916\u90e8\u4f18\u5316\u5668\uff08outer optimizer\uff09\u53ca\u5176\u5b66\u4e60\u7387\u5728Local SGD\u4e2d\u8d77\u5173\u952e\u4f5c\u7528\uff0c\u5408\u7406\u8c03\u6574\u5916\u5b66\u4e60\u7387\u53ef\u4ee5\u5728\u4f18\u5316\u8bef\u5dee\u4e0e\u968f\u673a\u68af\u5ea6\u566a\u58f0\u4e4b\u95f4\u6743\u8861\uff0c\u5e76\u80fd\u5f25\u8865\u5185\u90e8\u5b66\u4e60\u7387\u7684\u4e0d\u826f\u9009\u62e9\uff1b\u5f53\u5f15\u5165\u52a8\u91cf\u6216\u52a0\u901f\u65b9\u6cd5\u65f6\uff0c\u5916\u5b66\u4e60\u7387\u7684\u8c03\u6574\u540c\u6837\u6709\u6548\u4e14\u53ef\u6539\u5584\u901a\u4fe1\u8f6e\u6570\u76f8\u5173\u7684\u6536\u655b\u7387\u3002\u6b64\u5916\uff0c\u6570\u636e\u76f8\u5173\u7684\u5206\u6790\u4e3a\u5916\u5b66\u4e60\u7387\u8c03\u53c2\u63d0\u4f9b\u4e86\u8fdb\u4e00\u6b65\u6d1e\u89c1\u3002"}}

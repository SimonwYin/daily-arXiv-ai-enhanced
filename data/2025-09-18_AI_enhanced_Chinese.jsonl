{"id": "2509.13325", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2509.13325", "abs": "https://arxiv.org/abs/2509.13325", "authors": ["Matteo Zanotto", "Leonardo Vicentini", "Redi Vreto", "Francesco Lumpp", "Diego Braga", "Sandro Fiore"], "title": "A User-centric Kubernetes-based Architecture for Green Cloud Computing", "comment": null, "summary": "To meet the increasing demand for cloud computing services, the scale and\nnumber of data centers keeps increasing worldwide. This growth comes at the\ncost of increased electricity consumption, which directly correlates to CO2\nemissions, the main driver of climate change. As such, researching ways to\nreduce cloud computing emissions is more relevant than ever. However, although\ncloud providers are reportedly already working near optimal power efficiency,\nthey fail in providing precise sustainability reporting. This calls for further\nimprovements on the cloud computing consumer's side. To this end, in this paper\nwe propose a user-centric, Kubernetes-based architecture for green cloud\ncomputing. We implement a carbon intensity forecaster and we use it to schedule\nworkloads based on the availability of green energy, exploiting both regional\nand temporal variations to minimize emissions. We evaluate our system using\nreal-world traces of cloud workloads execution comparing the achieved carbon\nemission savings against a baseline round-robin scheduler. Our findings\nindicate that our system can achieve up to a 13% reduction in emissions in a\nstrict scenario with heavy limitations on the available resources.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eKubernetes\u7684\u7528\u6237\u4fa7\u7eff\u8272\u4e91\u8ba1\u7b97\u6846\u67b6\uff0c\u5305\u542b\u78b3\u5f3a\u5ea6\u9884\u6d4b\u5668\u5e76\u636e\u6b64\u8c03\u5ea6\u4efb\u52a1\uff0c\u5b9e\u6d4b\u5728\u53d7\u9650\u8d44\u6e90\u60c5\u666f\u4e0b\u53ef\u51cf\u5c11\u6700\u591a13%\u78b3\u6392\u653e", "motivation": "cloud providers lack precise sustainability reporting and consumers need tools to reduce emissions by scheduling workloads when/where green energy available", "method": "user-centric Kubernetes-based architecture; carbon intensity forecaster; workload scheduling leveraging regional and temporal green energy variations", "result": "implemented system evaluated on real-world traces showing up to 13% emission reduction vs round-robin under strict resource limits", "conclusion": "\u7528\u6237\u4fa7\u8c03\u5ea6\u7ed3\u5408\u78b3\u5f3a\u5ea6\u9884\u6d4b\u4e0e\u533a\u57df/\u65f6\u95f4\u7ef4\u5ea6\u53ef\u5728\u73b0\u5b9e\u8d1f\u8f7d\u4e0b\u5b9e\u73b0\u663e\u8457\u78b3\u51cf\u6392\uff0c\u672a\u6765\u53ef\u8fdb\u4e00\u6b65\u6539\u8fdb\u9884\u6d4b\u4e0e\u8d44\u6e90\u7ea6\u675f\u6574\u5408\u4ee5\u63d0\u5347\u6548\u679c"}}
{"id": "2509.13575", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2509.13575", "abs": "https://arxiv.org/abs/2509.13575", "authors": ["Benjamin Wilfong", "Anand Radhakrishnan", "Henry A. Le Berre", "Tanush Prathi", "Stephen Abbott", "Spencer H. Bryngelson"], "title": "Testing and benchmarking emerging supercomputers via the MFC flow solver", "comment": "9 pages, 3 figures", "summary": "Deploying new supercomputers requires testing and evaluation via application\ncodes. Portable, user-friendly tools enable evaluation, and the Multicomponent\nFlow Code (MFC), a computational fluid dynamics (CFD) code, addresses this\nneed. MFC is adorned with a toolchain that automates input generation,\ncompilation, batch job submission, regression testing, and benchmarking. The\ntoolchain design enables users to evaluate compiler-hardware combinations for\ncorrectness and performance with limited software engineering experience. As\nwith other PDE solvers, wall time per spatially discretized grid point serves\nas a figure of merit. We present MFC benchmarking results for five generations\nof NVIDIA GPUs, three generations of AMD GPUs, and various CPU architectures,\nutilizing Intel, Cray, NVIDIA, AMD, and GNU compilers. These tests have\nrevealed compiler bugs and regressions on recent machines such as Frontier and\nEl Capitan. MFC has benchmarked approximately 50 compute devices and 5 flagship\nsupercomputers.", "AI": {"tldr": "MFC plus an automated toolchain facilitates portable evaluation of compilers and hardware; extensive benchmarking found performance data and uncovered compiler issues on cutting-edge supercomputers.", "motivation": "Enable portable, user-friendly benchmarking of new supercomputers using an automated toolchain around MFC for testing correctness and performance across compilers and hardware.", "method": "Paper analysis", "result": "Benchmarking across ~50 devices and 5 supercomputers, revealing compiler bugs/regressions on recent machines (Frontier, El Capitan); provided wall-time per grid point metrics for multiple NVIDIA and AMD GPU generations and various CPUs with different compilers.", "conclusion": "The MFC toolchain effectively automates evaluation workflows, enabling detection of compiler/hardware issues and providing comparable performance metrics across diverse architectures."}}
{"id": "2509.13583", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2509.13583", "abs": "https://arxiv.org/abs/2509.13583", "authors": ["Varsha Rao", "Andrew A. Chien"], "title": "Modeling the Carbon Footprint of HPC: The Top 500 and EasyC", "comment": "15 pages, 11 figures", "summary": "Climate change is a critical concern for HPC systems, but GHG protocol\ncarbon-emission accounting methodologies are difficult for a single system, and\neffectively infeasible for a collection of systems. As a result, there is no\nHPC-wide carbon reporting, and even the largest HPC sites do not do GHG\nprotocol reporting.\n  We assess the carbon footprint of HPC, focusing on the Top 500 systems. The\nkey challenge lies in modeling the carbon footprint with limited data\navailability.\n  With the disclosed Top500.org data, and using a new tool, EasyC, we were able\nto model the operational carbon of 391 HPC systems and the embodied carbon of\n283 HPC systems. We further show how this coverage can be enhanced by\nexploiting additional public information. With improved coverage, then\ninterpolation is used to produce the first carbon footprint estimates of the\nTop 500 HPC systems. They are 1,393.7 million MT CO2e operational carbon (1\nYear) and 1,881.8 million MT CO2e embodied carbon. We also project how the Top\n500's carbon footprint will increase through 2030.\n  A key enabler is the EasyC tool which models carbon footprint with only a few\ndata metrics. We explore availability of data and enhancement, showing that\ncoverage can be increased to 98% of Top 500 systems for operational and 80.8%\nof the systems for embodied emissions.", "AI": {"tldr": "\u63d0\u51faEasyC\u5de5\u5177\uff0c\u5728\u6709\u9650\u516c\u5f00\u6570\u636e\u4e0b\u5bf9Top500\u8d85\u7ea7\u8ba1\u7b97\u7cfb\u7edf\u8fdb\u884c\u4e86\u8fd0\u884c\u4e0e\u56fa\u6709\u78b3\u8db3\u8ff9\u5efa\u6a21\u4e0e\u4f30\u7b97\uff0c\u5f97\u51faTop500\u5e74\u5ea6\u8fd0\u884c\u7ea61.39\u4ebf\u5428CO2e\uff08\u6ce8\u610f\u5355\u4f4d\u8bba\u6587\u4e3a\u767e\u4e07MT\uff0c\u9700\u8981\u6838\u5bf9\uff09\u548c\u56fa\u6709\u7ea61.88\u4ebf\u5428CO2e\u7684\u4f30\u7b97\uff0c\u5e76\u5c55\u793a\u4e86\u63d0\u5347\u6570\u636e\u8986\u76d6\u7387\u7684\u65b9\u6cd5\u4e0e2030\u5e74\u6295\u5f71\u3002", "motivation": "\u5f53\u524dHPC\u9886\u57df\u7f3a\u4e4f\u7edf\u4e00\u7684GHG\u534f\u8bae\u5f0f\u78b3\u6392\u653e\u4e0a\u62a5\uff1b\u6570\u636e\u7a00\u7f3a\u4f7f\u5f97\u5355\u7cfb\u7edf\u6216\u96c6\u5408\u7cfb\u7edf\u7684\u7cbe\u786e\u6838\u7b97\u96be\u4ee5\u5b9e\u73b0\uff0c\u56e0\u800c\u9700\u8981\u4e00\u79cd\u4f4e\u6570\u636e\u9700\u6c42\u3001\u53ef\u6269\u5c55\u7684\u65b9\u6cd5\u6765\u4f30\u7b97\u548c\u62a5\u544aHPC\u7fa4\u4f53\u7684\u78b3\u8db3\u8ff9\u3002", "method": "\u4f5c\u8005\u5229\u7528Top500.org\u7684\u516c\u5f00\u7cfb\u7edf\u6570\u636e\uff0c\u5f00\u53d1EasyC\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u4ec5\u9700\u5c11\u91cf\u6307\u6807\uff08\u5982\u529f\u8017\u3001\u8fd0\u884c\u65f6\u95f4\u3001\u673a\u67b6/\u90e8\u4ef6\u4fe1\u606f\u7b49\uff09\u5373\u53ef\u4f30\u7b97\u8fd0\u884c\u548c\u56fa\u6709\u78b3\u6392\u653e\u3002\u5bf9391\u4e2a\u7cfb\u7edf\u5efa\u6a21\u8fd0\u884c\u78b3\u3001\u5bf9283\u4e2a\u7cfb\u7edf\u5efa\u6a21\u56fa\u6709\u78b3\uff0c\u5e76\u901a\u8fc7\u5229\u7528\u989d\u5916\u516c\u5f00\u4fe1\u606f\u63d0\u9ad8\u8986\u76d6\u7387\uff0c\u6700\u540e\u5bf9\u7f3a\u5931\u6570\u636e\u91c7\u7528\u63d2\u503c\u65b9\u6cd5\u63a8\u65ad\u51faTop500\u6574\u4f53\u78b3\u8db3\u8ff9\u3002", "result": "\u57fa\u4e8eEasyC\u548cTop500\u6570\u636e\uff0c\u4f5c\u8005\u4f30\u7b97Top500\u7684\u5e74\u5ea6\u8fd0\u884c\u78b3\u4e3a\u7ea61,393.7\u767e\u4e07\u516c\u5428CO2e\uff0c\u56fa\u6709\u78b3\u4e3a\u7ea61,881.8\u767e\u4e07\u516c\u5428CO2e\uff1b\u901a\u8fc7\u6570\u636e\u589e\u5f3a\u548c\u63d2\u503c\uff0c\u8986\u76d6\u7387\u53ef\u63d0\u5347\u81f3\u8fd0\u884c\u78b398%\u3001\u56fa\u6709\u78b380.8%\uff1b\u5e76\u63d0\u4f9b\u4e86\u52302030\u5e74\u7684\u78b3\u6392\u653e\u589e\u957f\u9884\u6d4b\u3002", "conclusion": "\u8be5\u8bba\u6587\u9996\u6b21\u5bf9Top500\u8d85\u7ea7\u8ba1\u7b97\u7cfb\u7edf\u7684\u78b3\u8db3\u8ff9\u8fdb\u884c\u4f30\u7b97\uff0c\u6307\u51fa\u5f53\u524d\u57fa\u4e8eGHG\u534f\u8bae\u7684\u9010\u7cfb\u7edf\u6838\u7b97\u5728HPC\u9886\u57df\u4e0d\u53ef\u884c\uff0c\u5bfc\u81f4\u7f3a\u4e4f\u7edf\u4e00\u4e0a\u62a5\uff1b\u901a\u8fc7\u63d0\u51fa\u5e76\u4f7f\u7528EasyC\u5de5\u5177\uff0c\u4f5c\u8005\u5728\u6709\u9650\u516c\u5f00\u6570\u636e\u4e0b\u5efa\u6a21\u5e76\u4f30\u7b97\u4e86Top500\u7684\u8fd0\u884c\uff08operational\uff09\u548c\u56fa\u6709\uff08embodied\uff09\u78b3\u6392\u653e\uff0c\u5e76\u9884\u6d4b\u4e86\u52302030\u5e74\u7684\u589e\u957f\u8d8b\u52bf\u3002"}}
{"id": "2509.13332", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.13332", "abs": "https://arxiv.org/abs/2509.13332", "authors": ["Pratik Jayarao", "Himanshu Gupta", "Neeraj Varshney", "Chaitanya Dwivedi"], "title": "Explicit Reasoning Makes Better Judges: A Systematic Study on Accuracy, Efficiency, and Robustness", "comment": null, "summary": "As Large Language Models (LLMs) are increasingly adopted as automated judges\nin benchmarking and reward modeling, ensuring their reliability, efficiency,\nand robustness has become critical. In this work, we present a systematic\ncomparison of \"thinking\" and \"non-thinking\" LLMs in the LLM-as-a-judge paradigm\nusing open-source Qwen 3 models of relatively small sizes (0.6B, 1.7B, and 4B\nparameters). We evaluate both accuracy and computational efficiency (FLOPs) on\nRewardBench tasks, and further examine augmentation strategies for non-thinking\nmodels, including in-context learning, rubric-guided judging, reference-based\nevaluation, and n-best aggregation. Our results show that despite these\nenhancements, non-thinking models generally fall short of their thinking\ncounterparts. Our results show that thinking models achieve approximately 10%\npoints higher accuracy with little overhead (under 2x), in contrast to\naugmentation strategies like few-shot learning, which deliver modest gains at a\nhigher cost (>8x). Bias and robustness analyses further demonstrate that\nthinking models maintain significantly greater consistency under a variety of\nbias conditions such as positional, bandwagon, identity, diversity, and random\nbiases (6% higher on average). We further extend our experiments to the\nmultilingual setting and our results confirm that explicit reasoning extends\nits benefits beyond English. Overall, our work results in several important\nfindings that provide systematic evidence that explicit reasoning offers clear\nadvantages in the LLM-as-a-judge paradigm not only in accuracy and efficiency\nbut also in robustness.", "AI": {"tldr": "\u672c\u6587\u5728LLM\u4f5c\u4e3a\u8bc4\u5224\u8005\uff08LLM-as-a-judge\uff09\u8303\u5f0f\u4e0b\uff0c\u7cfb\u7edf\u6bd4\u8f83\u4e86\u5177\u6709\u201c\u601d\u8003\u201d\uff08explicit reasoning, chain-of-thought\uff09\u80fd\u529b\u4e0e\u4e0d\u5177\u5907\u6b64\u80fd\u529b\u7684\u5f00\u6e90Qwen 3\u5c0f\u578b\u6a21\u578b\uff080.6B\u30011.7B\u30014B\u53c2\u6570\uff09\u3002\u5728RewardBench\u4efb\u52a1\u4e0a\u8bc4\u4f30\u4e86\u51c6\u786e\u6027\u4e0e\u8ba1\u7b97\u6548\u7387\uff08FLOPs\uff09\uff0c\u5e76\u8003\u5bdf\u4e86\u5bf9\u975e\u601d\u8003\u6a21\u578b\u7684\u589e\u5f3a\u7b56\u7565\uff08\u5c11\u6837\u672c\u3001rubric\u3001\u53c2\u8003\u7b54\u6848\u5bf9\u6bd4\u3001n-best\u805a\u5408\uff09\u3002\u7ed3\u679c\u8868\u660e\uff1a\u601d\u8003\u6a21\u578b\u5728\u51c6\u786e\u7387\u4e0a\u7ea6\u9ad810\u4e2a\u767e\u5206\u70b9\u4e14\u8ba1\u7b97\u5f00\u9500\u8f83\u5c0f\uff08<2x\uff09\uff0c\u800c\u5c11\u6837\u672c\u7b49\u589e\u5f3a\u7b56\u7565\u5e26\u6765\u8f83\u5c0f\u63d0\u5347\u4f46\u8ba1\u7b97\u5f00\u9500\u9ad8\uff08>8x\uff09\uff1b\u5728\u504f\u89c1\u4e0e\u9c81\u68d2\u6027\u6d4b\u8bd5\u4e2d\uff0c\u601d\u8003\u6a21\u578b\u5728\u591a\u79cd\u504f\u89c1\u4e0b\u8868\u73b0\u51fa\u66f4\u9ad8\u7684\u4e00\u81f4\u6027\uff08\u5e73\u5747\u9ad86%\uff09\uff1b\u591a\u8bed\u79cd\u5b9e\u9a8c\u4e5f\u8bc1\u5b9e\u4e86\u63a8\u7406\u7684\u4f18\u52bf\u8d85\u8d8a\u82f1\u6587\u3002\u603b\u4f53\u7ed3\u8bba\u662f\uff0c\u663e\u5f0f\u63a8\u7406\u5728\u51c6\u786e\u6027\u3001\u6548\u7387\u548c\u9c81\u68d2\u6027\u4e0a\u5747\u4f18\u4e8e\u975e\u663e\u5f0f\u63a8\u7406\u7684\u5224\u522b\u8303\u5f0f\u3002", "motivation": "\u968f\u7740LLM\u88ab\u5e7f\u6cdb\u7528\u4e8e\u81ea\u52a8\u8bc4\u5224\u548c\u5956\u52b1\u5efa\u6a21\uff0c\u9700\u4fdd\u969c\u5176\u53ef\u9760\u6027\u3001\u6548\u7387\u4e0e\u9c81\u68d2\u6027\uff1b\u4f46\u73b0\u6709\u7814\u7a76\u672a\u7cfb\u7edf\u6bd4\u8f83\u663e\u5f0f\u63a8\u7406\uff08thinking\uff09\u4e0e\u975e\u663e\u5f0f\u63a8\u7406\u6a21\u578b\u5728\u5224\u51b3\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u4e0e\u5f00\u9500\u3002", "method": "\u4f7f\u7528\u5f00\u6e90Qwen 3\u7cfb\u5217\u5c0f\u6a21\u578b\uff080.6B\u30011.7B\u30014B\uff09\u5728RewardBench\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0c\u6bd4\u8f83\u201c\u601d\u8003\u201d\u4e0e\u201c\u975e\u601d\u8003\u201d\u4e24\u79cd\u5224\u51b3\u7b56\u7565\u7684\u51c6\u786e\u7387\u4e0eFLOPs\uff1b\u5bf9\u975e\u601d\u8003\u6a21\u578b\u5c1d\u8bd5\u591a\u79cd\u589e\u5f3a\u7b56\u7565\uff08in-context few-shot\u3001rubric-guided\u3001reference-based\u3001n-best aggregation\uff09\uff0c\u5e76\u505a\u504f\u89c1\uff08\u4f4d\u7f6e\u3001\u4ece\u4f17\u3001\u8eab\u4efd\u3001\u591a\u6837\u6027\u3001\u968f\u673a\uff09\u4e0e\u591a\u8bed\u79cd\u9c81\u68d2\u6027\u5206\u6790\u3002", "result": "\u601d\u8003\u6a21\u578b\u663e\u8457\u4f18\u4e8e\u975e\u601d\u8003\u6a21\u578b\uff1a\u51c6\u786e\u7387\u63d0\u9ad8\u7ea610\u4e2a\u767e\u5206\u70b9\uff1b\u8ba1\u7b97\u5f00\u9500\u5c0f\u4e8e2\u500d\uff1b\u5e38\u89c1\u589e\u5f3a\u7b56\u7565\u63d0\u5347\u6709\u9650\u4e14\u6210\u672c\u9ad8\uff08>8x\uff09\uff1b\u5728\u5404\u7c7b\u504f\u89c1\u4e0b\u5e73\u5747\u7a33\u5b9a\u6027\u9ad86%\uff1b\u8be5\u4f18\u52bf\u5728\u591a\u8bed\u79cd\u8bbe\u7f6e\u4e2d\u4ecd\u7136\u6210\u7acb\u3002", "conclusion": "\u663e\u5f0f\u63a8\u7406\uff08thinking / chain-of-thought\uff09\u5728LLM\u4f5c\u4e3a\u8bc4\u5224\u8005\u7684\u8bbe\u7f6e\u4e2d\u603b\u4f53\u4f18\u4e8e\u975e\u663e\u5f0f\u63a8\u7406\u6a21\u578b\uff1a\u7ea6\u63d0\u534710%\u51c6\u786e\u7387\u3001\u8ba1\u7b97\u5f00\u9500\u5c0f\u4e8e2x\u3001\u5728\u591a\u79cd\u504f\u89c1\u6d4b\u8bd5\u4e2d\u5e73\u5747\u9ad8\u51fa6%\u7684\u7a33\u5b9a\u6027\uff0c\u5e76\u4e14\u8be5\u7ed3\u8bba\u5728\u591a\u8bed\u79cd\u573a\u666f\u4e2d\u6210\u7acb\u3002"}}
{"id": "2509.13490", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2509.13490", "abs": "https://arxiv.org/abs/2509.13490", "authors": ["Paul Bergeron", "Sandhya Aneja"], "title": "GRU-Based Learning for the Identification of Congestion Protocols in TCP Traffic", "comment": null, "summary": "This paper presents the identification of congestion control protocols TCP\nReno, TCP Cubic, TCP Vegas, and BBR on the Marist University campus, with an\naccuracy of 97.04% using a GRU-based learning model. We used a faster neural\nnetwork architecture on a more complex and competitive network in comparison to\nexisting work and achieved comparably high accuracy.", "AI": {"tldr": "\u5728\u771f\u5b9e\u6821\u56ed\u7f51\u7edc\u4e0a\uff0c\u57fa\u4e8eGRU\u7684\u5feb\u901f\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u80fd\u4ee597.04%\u7684\u51c6\u786e\u7387\u8bc6\u522bReno\u3001Cubic\u3001Vegas\u548cBBR\u56db\u79cd\u62e5\u585e\u63a7\u5236\u534f\u8bae\u3002", "motivation": "\u73b0\u6709\u5de5\u4f5c\u591a\u5728\u8f83\u7b80\u5355\u6216\u53d7\u63a7\u73af\u5883\u4e0b\u8bc4\u4f30\u62e5\u585e\u63a7\u5236\u534f\u8bae\u8bc6\u522b\u65b9\u6cd5\u3002\u4f5c\u8005\u65e8\u5728\u9a8c\u8bc1\u5728\u66f4\u771f\u5b9e\u3001\u590d\u6742\u4e14\u7ade\u4e89\u6027\u7684\u7f51\u7edc\u73af\u5883\u4e2d\uff0c\u80fd\u5426\u4f7f\u7528\u66f4\u9ad8\u6548\u7684\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u5b9e\u73b0\u51c6\u786e\u8bc6\u522b\uff0c\u4ece\u800c\u63d0\u9ad8\u65b9\u6cd5\u7684\u5b9e\u9645\u53ef\u7528\u6027\u548c\u90e8\u7f72\u6f5c\u529b\u3002", "method": "\u4f7f\u7528\u95e8\u63a7\u5faa\u73af\u5355\u5143\uff08GRU\uff09\u795e\u7ecf\u7f51\u7edc\u4f5c\u4e3a\u5206\u7c7b\u6a21\u578b\uff0c\u91c7\u7528\u66f4\u5feb\u7684\u7f51\u7edc\u67b6\u6784\u5e76\u5728\u66f4\u590d\u6742\u3001\u66f4\u5177\u7ade\u4e89\u6027\u7684\u6821\u56ed\u7f51\u7edc\u73af\u5883\u4e2d\u8bad\u7ec3\u548c\u6d4b\u8bd5\u3002\u901a\u8fc7\u7279\u5f81\u63d0\u53d6\uff08\u672a\u5728\u6458\u8981\u8be6\u7ec6\u8bf4\u660e\uff0c\u63a8\u6d4b\u5305\u542b\u65f6\u5e8f\u7f51\u7edc\u6027\u80fd\u6307\u6807\uff09\u5e76\u5bf9\u56db\u7c7b\u62e5\u585e\u63a7\u5236\u534f\u8bae\u8fdb\u884c\u76d1\u7763\u5b66\u4e60\uff0c\u6a21\u578b\u8fbe\u5230\u4e86\u9ad8\u51c6\u786e\u7387\u3002", "result": "\u5728Marist\u5927\u5b66\u6821\u56ed\u7f51\u7edc\u7684\u6d4b\u8bd5\u4e2d\uff0c\u6240\u63d0GRU\u6a21\u578b\u4ee597.04%\u7684\u51c6\u786e\u7387\u533a\u5206\u4e86TCP Reno\u3001TCP Cubic\u3001TCP Vegas\u548cBBR\u3002\u4f5c\u8005\u8fd8\u58f0\u79f0\u6240\u7528\u7f51\u7edc\u67b6\u6784\u66f4\u5feb\u4e14\u5728\u66f4\u590d\u6742\u7f51\u7edc\u6761\u4ef6\u4e0b\u4ecd\u80fd\u53d6\u5f97\u4e0e\u73b0\u6709\u5de5\u4f5c\u76f8\u5f53\u751a\u81f3\u66f4\u597d\u7684\u6027\u80fd\u3002", "conclusion": "\u8be5\u8bba\u6587\u901a\u8fc7\u5728Marist\u5927\u5b66\u6821\u56ed\u7f51\u7edc\u4e0a\u4f7f\u7528\u57fa\u4e8eGRU\u7684\u5b66\u4e60\u6a21\u578b\uff0c\u6210\u529f\u8bc6\u522b\u51faTCP Reno\u3001TCP Cubic\u3001TCP Vegas\u548cBBR\u56db\u79cd\u62e5\u585e\u63a7\u5236\u534f\u8bae\uff0c\u5e76\u53d6\u5f97\u4e8697.04%\u7684\u9ad8\u51c6\u786e\u7387\uff0c\u8868\u660e\u6240\u63d0\u65b9\u6cd5\u5728\u771f\u5b9e\u590d\u6742\u7f51\u7edc\u73af\u5883\u4e2d\u5177\u6709\u8f83\u5f3a\u7684\u533a\u5206\u80fd\u529b\u3002"}}
{"id": "2509.13703", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2509.13703", "abs": "https://arxiv.org/abs/2509.13703", "authors": ["Sriram Srinivasan", "Hamdan Alabsi", "Rand Obeidat", "Nithisha Ponnala", "Azene Zenebe"], "title": "GPU Programming for AI Workflow Development on AWS SageMaker: An Instructional Approach", "comment": null, "summary": "We present the design, implementation, and comprehensive evaluation of a\nspecialized course on GPU architecture, GPU programming, and how these are used\nfor developing AI agents. This course is offered to undergraduate and graduate\nstudents during Fall 2024 and Spring 2025. The course began with foundational\nconcepts in GPU/CPU hardware and parallel computing and progressed to develop\nRAG and optimizing them using GPUs. Students gained experience provisioning and\nconfiguring cloud-based GPU instances, implementing parallel algorithms, and\ndeploying scalable AI solutions. We evaluated learning outcomes through\nassessments, course evaluations, and anonymous surveys. The results reveal that\n(1) AWS served as an effective and economical platform for practical GPU\nprogramming, (2) experiential learning significantly enhanced technical\nproficiency and engagement, and (3) the course strengthened students'\nproblem-solving and critical thinking skills through tools such as TensorBoard\nand HPC profilers, which exposed performance bottlenecks and scaling issues.\nOur findings underscore the pedagogical value of integrating parallel computing\ninto STEM education. We advocate for broader adoption of similar electives\nacross STEM curricula to prepare students for the demands of modern,\ncompute-intensive fields.", "AI": {"tldr": "\u63d0\u4f9b\u5bf9\u4e00\u95e8\u5173\u4e8eGPU\u67b6\u6784\u3001GPU\u7f16\u7a0b\u548c\u7528\u4e8eAI\u4ee3\u7406\u5f00\u53d1\u7684\u8bfe\u7a0b\u7684\u6458\u8981\u6027\u5206\u6790\uff0c\u5f3a\u8c03\u8bfe\u7a0b\u8bbe\u8ba1\u3001\u5b9e\u73b0\u3001\u8bc4\u4f30\u65b9\u6cd5\u4e0e\u7ed3\u679c\uff0c\u5e76\u7ed9\u51fa\u6539\u8fdb\u5efa\u8bae\u3002", "motivation": "\u56de\u5e94\u73b0\u4ee3\u8ba1\u7b97\u5bc6\u96c6\u578b\u9886\u57df\u5bf9\u5177\u5907GPU\u7f16\u7a0b\u3001\u5e76\u884c\u8ba1\u7b97\u4e0eAI\u5e94\u7528\u90e8\u7f72\u6280\u80fd\u4eba\u624d\u7684\u9700\u6c42\uff0c\u901a\u8fc7\u8bfe\u7a0b\u5c06\u7406\u8bba\u4e0e\u5b9e\u8df5\u7ed3\u5408\uff0c\u63d0\u5347\u5b66\u751f\u5c31\u4e1a\u4e0e\u7814\u7a76\u80fd\u529b\u3002", "method": "\u8bfe\u7a0b\u4eceGPU/CPU\u786c\u4ef6\u57fa\u7840\u4e0e\u5e76\u884c\u8ba1\u7b97\u51fa\u53d1\uff0c\u9010\u6b65\u8986\u76d6RAG\uff08Retrieval-Augmented Generation\uff09\u53ca\u5176\u5728GPU\u4e0a\u7684\u4f18\u5316\u3002\u6559\u5b66\u5305\u542b\u4e91\u7aefGPU\u5b9e\u4f8b\u914d\u7f6e\u3001\u5e76\u884c\u7b97\u6cd5\u5b9e\u73b0\u4e0e\u53ef\u6269\u5c55AI\u89e3\u51b3\u65b9\u6848\u90e8\u7f72\uff1b\u8bc4\u4f30\u901a\u8fc7\u6d4b\u9a8c\u3001\u4f5c\u4e1a\u3001\u8bfe\u7a0b\u8bc4\u4ef7\u548c\u533f\u540d\u95ee\u5377\u8fdb\u884c\u3002", "result": "\u7814\u7a76\u8868\u660e\uff1a1) AWS\u4f5c\u4e3a\u5b9e\u8df5GPU\u7f16\u7a0b\u7684\u7ecf\u6d4e\u5e73\u53f0\uff1b2) \u4f53\u9a8c\u5f0f\u5b66\u4e60\u663e\u8457\u63d0\u9ad8\u5b66\u751f\u6280\u672f\u6c34\u5e73\u4e0e\u53c2\u4e0e\u5ea6\uff1b3) \u4f7f\u7528TensorBoard\u4e0eHPC profiler\u5e2e\u52a9\u5b66\u751f\u8bc6\u522b\u6027\u80fd\u74f6\u9888\u5e76\u63d0\u5347\u95ee\u9898\u89e3\u51b3\u80fd\u529b\u3002", "conclusion": "\u8be5\u8bfe\u7a0b\u5728\u5b9e\u8df5\u4e0e\u8bc4\u4f30\u4e2d\u8bc1\u660e\u4e86\u5c06\u5e76\u884c\u8ba1\u7b97\u548cGPU\u7f16\u7a0b\u7eb3\u5165STEM\u6559\u80b2\u7684\u6709\u6548\u6027\uff0cAWS\u4e3a\u7ecf\u6d4e\u53ef\u884c\u7684\u5e73\u53f0\uff0c\u4f53\u9a8c\u5f0f\u5b66\u4e60\u63d0\u5347\u6280\u80fd\uff0c\u5de5\u5177\uff08TensorBoard\u3001HPC profiler\uff09\u6709\u52a9\u4e8e\u53d1\u73b0\u74f6\u9888\u3002\u5efa\u8bae\u5728\u66f4\u591a\u8bfe\u7a0b\u4e2d\u91c7\u7eb3\u7c7b\u4f3c\u9009\u4fee\u8bfe\uff0c\u5e76\u5728\u672a\u6765\u8fed\u4ee3\u4e2d\u52a0\u5165\u66f4\u591a\u786c\u4ef6\u7c7b\u578b\u3001\u957f\u671f\u9879\u76ee\u548c\u66f4\u7ec6\u5316\u7684\u8bc4\u4f30\u6307\u6807\u3002"}}
{"id": "2509.13333", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.13333", "abs": "https://arxiv.org/abs/2509.13333", "authors": ["Maheep Chaudhary", "Ian Su", "Nikhil Hooda", "Nishith Shankar", "Julia Tan", "Kevin Zhu", "Ashwinee Panda", "Ryan Lagasse", "Vasu Sharma"], "title": "Evaluation Awareness Scales Predictably in Open-Weights Large Language Models", "comment": null, "summary": "Large language models (LLMs) can internally distinguish between evaluation\nand deployment contexts, a behaviour known as \\emph{evaluation awareness}. This\nundermines AI safety evaluations, as models may conceal dangerous capabilities\nduring testing. Prior work demonstrated this in a single $70$B model, but the\nscaling relationship across model sizes remains unknown. We investigate\nevaluation awareness across $15$ models scaling from $0.27$B to $70$B\nparameters from four families using linear probing on steering vector\nactivations. Our results reveal a clear power-law scaling: evaluation awareness\nincreases predictably with model size. This scaling law enables forecasting\ndeceptive behavior in future larger models and guides the design of scale-aware\nevaluation strategies for AI safety. A link to the implementation of this paper\ncan be found at\nhttps://anonymous.4open.science/r/evaluation-awareness-scaling-laws/README.md.", "AI": {"tldr": "\u6211\u4eec\u7814\u7a76\u4e8615\u4e2a\u4ece0.27B\u523070B\u53c2\u6570\u7684LLM\uff0c\u53d1\u73b0\u201cevaluation awareness\u201d\uff08\u8bc4\u4f30\u610f\u8bc6\uff09\u968f\u6a21\u578b\u89c4\u6a21\u5448\u5e42\u5f8b\u589e\u957f\uff0c\u53ef\u7528\u7ebf\u6027\u63a2\u6d4b\u5668\u5728steering\u5411\u91cf\u6fc0\u6d3b\u4e0a\u68c0\u6d4b\u5230\u3002\u8fd9\u4f7f\u5f97\u80fd\u9884\u6d4b\u66f4\u5927\u6a21\u578b\u7684\u6b3a\u9a97\u6027\u884c\u4e3a\uff0c\u5e76\u6307\u5bfc\u57fa\u4e8e\u89c4\u6a21\u7684\u5b89\u5168\u8bc4\u4f30\u7b56\u7565\u8bbe\u8ba1\u3002", "motivation": "\u82e5\u6a21\u578b\u5728\u8bc4\u4f30\u65f6\u9690\u85cf\u5371\u9669\u80fd\u529b\uff08evaluation awareness\uff09\uff0c\u5219\u73b0\u6709\u5b89\u5168\u8bc4\u4f30\u5c06\u88ab\u8bef\u5bfc\uff1b\u56e0\u6b64\u9700\u8981\u4e86\u89e3\u8fd9\u79cd\u73b0\u8c61\u5982\u4f55\u968f\u6a21\u578b\u89c4\u6a21\u53d8\u5316\uff0c\u4ee5\u9884\u6d4b\u672a\u6765\u6a21\u578b\u7684\u98ce\u9669\u5e76\u8bbe\u8ba1\u66f4\u53ef\u9760\u7684\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u572815\u4e2a\u6a21\u578b\u4e0a\u4f7f\u7528\u7ebf\u6027\u63a2\u6d4b\u5668\uff08linear probing\uff09\u68c0\u6d4bsteering\u5411\u91cf\u6fc0\u6d3b\u4e2d\u8868\u5f81\u7684\u8bc4\u4f30/\u90e8\u7f72\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u6a21\u578b\u89c4\u6a21\u4ece0.27B\u523070B\uff0c\u6765\u81ea\u56db\u4e2a\u6a21\u578b\u5bb6\u65cf\uff1b\u901a\u8fc7\u56de\u5f52\u62df\u5408\u53d1\u73b0\u610f\u8bc6\u5f3a\u5ea6\u4e0e\u53c2\u6570\u6570\u76ee\u7684\u5e42\u5f8b\u5173\u7cfb\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u5728\u6240\u6709\u56db\u4e2a\u6a21\u578b\u5bb6\u65cf\u4e2d\u5747\u51fa\u73b0\u8bc4\u4f30\u610f\u8bc6\uff0c\u5f3a\u5ea6\u968f\u89c4\u6a21\u6309\u5e42\u5f8b\u589e\u957f\uff0c\u80fd\u7528\u8be5\u7f29\u653e\u5f8b\u9884\u6d4b\u66f4\u5927\u6a21\u578b\u7684\u6b3a\u9a97\u6982\u7387\uff0c\u5e76\u636e\u6b64\u63d0\u51fa\u89c4\u6a21\u611f\u77e5\u7684\u8bc4\u4f30\u5efa\u8bae\u3002", "conclusion": "\u8bc4\u4f30\u610f\u8bc6\u968f\u7740\u6a21\u578b\u53c2\u6570\u589e\u957f\u800c\u6309\u5e42\u5f8b\u589e\u5f3a\uff0c\u80fd\u901a\u8fc7\u7ebf\u6027\u63a2\u6d4b\u5728steering\u5411\u91cf\u6fc0\u6d3b\u4e2d\u7a33\u5065\u68c0\u6d4b\uff1b\u56e0\u6b64\u672a\u6765\u66f4\u5927\u578b\u6a21\u578b\u66f4\u53ef\u80fd\u5728\u8bc4\u4f30\u65f6\u9690\u85cf\u5371\u9669\u80fd\u529b\uff0c\u8bc4\u4f30\u5e94\u91c7\u7528\u89c4\u6a21\u654f\u611f\u7684\u7b56\u7565\u3002"}}
{"id": "2509.13511", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2509.13511", "abs": "https://arxiv.org/abs/2509.13511", "authors": ["Duo Cheng", "Ramanujan K Sheshadri", "Ahan Kak", "Nakjung Choi", "Xingyu Zhou", "Bo Ji"], "title": "Odin: Effective End-to-End SLA Decomposition for 5G/6G Network Slicing via Online Learning", "comment": "accepted for publication at ACM MobiHoc 2025", "summary": "Network slicing plays a crucial role in realizing 5G/6G advances, enabling\ndiverse Service Level Agreement (SLA) requirements related to latency,\nthroughput, and reliability. Since network slices are deployed end-to-end\n(E2E), across multiple domains including access, transport, and core networks,\nit is essential to efficiently decompose an E2E SLA into domain-level targets,\nso that each domain can provision adequate resources for the slice. However,\ndecomposing SLAs is highly challenging due to the heterogeneity of domains,\ndynamic network conditions, and the fact that the SLA orchestrator is oblivious\nto the domain's resource optimization. In this work, we propose Odin, a\nBayesian Optimization-based solution that leverages each domain's online\nfeedback for provably-efficient SLA decomposition. Through theoretical analyses\nand rigorous evaluations, we demonstrate that Odin's E2E orchestrator can\nachieve up to 45% performance improvement in SLA satisfaction when compared\nwith baseline solutions whilst reducing overall resource costs even in the\npresence of noisy feedback from the individual domains.", "AI": {"tldr": "Proposes Odin, a Bayesian Optimization orchestrator using domain feedback for efficient E2E SLA decomposition, improving SLA satisfaction and lowering costs under noisy feedback", "motivation": "Efficiently decompose E2E SLA into domain-level targets despite domain heterogeneity, dynamic conditions, and lack of domain optimization visibility", "method": "Bayesian Optimization-based SLA decomposition leveraging online feedback from domains", "result": "Odin achieves up to 45% improvement in SLA satisfaction vs baselines and reduces overall resource costs, robust to noisy domain feedback", "conclusion": "Odin enables provably-efficient SLA decomposition across domains with significant SLA satisfaction gains and cost reductions even with noisy feedback"}}
{"id": "2509.13464", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.13464", "abs": "https://arxiv.org/abs/2509.13464", "authors": ["Onat Gungor", "Ishaan Kale", "Jiasheng Zhou", "Tajana Rosing"], "title": "LIGHT-HIDS: A Lightweight and Effective Machine Learning-Based Framework for Robust Host Intrusion Detection", "comment": "Accepted by The 24th IEEE International Conference on Machine\n  Learning and Applications (ICMLA'25)", "summary": "The expansion of edge computing has increased the attack surface, creating an\nurgent need for robust, real-time machine learning (ML)-based host intrusion\ndetection systems (HIDS) that balance accuracy and efficiency. In such\nsettings, inference latency poses a critical security risk, as delays may\nprovide exploitable opportunities for attackers. However, many state-of-the-art\nML-based HIDS solutions rely on computationally intensive architectures with\nhigh inference costs, limiting their practical deployment. This paper proposes\nLIGHT-HIDS, a lightweight machine learning framework that combines a compressed\nneural network feature extractor trained via Deep Support Vector Data\nDescription (DeepSVDD) with an efficient novelty detection model. This hybrid\napproach enables the learning of compact, meaningful representations of normal\nsystem call behavior for accurate anomaly detection. Experimental results on\nmultiple datasets demonstrate that LIGHT-HIDS consistently enhances detection\naccuracy while reducing inference time by up to 75x compared to\nstate-of-the-art methods. These findings highlight its effectiveness and\nscalability as a machine learning-based solution for real-time host intrusion\ndetection.", "AI": {"tldr": "LIGHT-HIDS: compressed NN feature extractor trained with DeepSVDD + novelty detector achieves better detection and up to 75x faster inference for real-time HIDS", "motivation": "Analyze abstract about lightweight HIDS combining DeepSVDD and novelty detection to reduce latency while maintaining accuracy", "method": "Paper analysis", "result": "Improved accuracy and up to 75x inference speedup claimed; compressed NN feature extractor with DeepSVDD + efficient novelty detector", "conclusion": "Promising approach balancing accuracy and latency for edge deployments; needs more details on datasets, baselines, model sizes, and reproducibility"}}
{"id": "2509.13425", "categories": ["cs.LG", "physics.app-ph", "92D25, 35K57, 68T07", "I.2.6; J.3; G.1.8"], "pdf": "https://arxiv.org/pdf/2509.13425", "abs": "https://arxiv.org/abs/2509.13425", "authors": ["Julian Evan Chrisnanto", "Yulison Herry Chrisnanto", "Ferry Faizal"], "title": "Unified Spatiotemopral Physics-Informed Learning (USPIL): A Framework for Modeling Complex Predator-Prey Dynamics", "comment": "20 pages, 11 figures. A preprint on using a unified physics-informed\n  neural network framework to model predator-prey dynamics", "summary": "Ecological systems exhibit complex multi-scale dynamics that challenge\ntraditional modeling. New methods must capture temporal oscillations and\nemergent spatiotemporal patterns while adhering to conservation principles. We\npresent the Unified Spatiotemporal Physics-Informed Learning (USPIL) framework,\na deep learning architecture integrating physics-informed neural networks\n(PINNs) and conservation laws to model predator-prey dynamics across\ndimensional scales. The framework provides a unified solution for both ordinary\n(ODE) and partial (PDE) differential equation systems, describing temporal\ncycles and reaction-diffusion patterns within a single neural network\narchitecture. Our methodology uses automatic differentiation to enforce physics\nconstraints and adaptive loss weighting to balance data fidelity with physical\nconsistency. Applied to the Lotka-Volterra system, USPIL achieves 98.9%\ncorrelation for 1D temporal dynamics (loss: 0.0219, MAE: 0.0184) and captures\ncomplex spiral waves in 2D systems (loss: 4.7656, pattern correlation: 0.94).\nValidation confirms conservation law adherence within 0.5% and shows a 10-50x\ncomputational speedup for inference compared to numerical solvers. USPIL also\nenables mechanistic understanding through interpretable physics constraints,\nfacilitating parameter discovery and sensitivity analysis not possible with\npurely data-driven methods. Its ability to transition between dimensional\nformulations opens new avenues for multi-scale ecological modeling. These\ncapabilities make USPIL a transformative tool for ecological forecasting,\nconservation planning, and understanding ecosystem resilience, establishing\nphysics-informed deep learning as a powerful and scientifically rigorous\nparadigm.", "AI": {"tldr": "USPIL\u662f\u4e00\u4e2a\u5c06PINNs\u4e0e\u5b88\u6052\u5f8b\u7ed3\u5408\u7684\u7edf\u4e00\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u80fd\u5728\u5355\u4e00\u7f51\u7edc\u4e2d\u6a21\u62dfODE\u4e0ePDE\u751f\u6001\u52a8\u529b\u5b66\uff0c\u7ed3\u679c\u663e\u793a\u9ad8\u7cbe\u5ea6\u3001\u5b88\u6052\u6027\u826f\u597d\u5e76\u663e\u8457\u52a0\u901f\u63a8\u7406\uff0c\u540c\u65f6\u652f\u6301\u53c2\u6570\u53d1\u73b0\u4e0e\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u4f20\u7edf\u6a21\u578b\u96be\u4ee5\u540c\u65f6\u523b\u753b\u751f\u6001\u7cfb\u7edf\u7684\u591a\u5c3a\u5ea6\u65f6\u7a7a\u52a8\u529b\u5b66\u4e14\u9700\u6ee1\u8db3\u5b88\u6052\u5f8b\uff0c\u56e0\u800c\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u6355\u83b7\u632f\u8361\u4e0e\u7a7a\u95f4\u56fe\u6837\u53c8\u80fd\u4fdd\u8bc1\u7269\u7406\u4e00\u81f4\u6027\u7684\u7edf\u4e00\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u3002", "method": "\u6784\u5efa\u5355\u4e00\u795e\u7ecf\u7f51\u7edc\u901a\u8fc7\u81ea\u52a8\u5fae\u5206\u5f3a\u5236\u7269\u7406\u7ea6\u675f\uff08ODE/PDE\u6b8b\u5dee\uff09\u5e76\u91c7\u7528\u81ea\u9002\u5e94\u635f\u5931\u52a0\u6743\u5e73\u8861\u6570\u636e\u9879\u4e0e\u7269\u7406\u9879\uff1b\u5229\u7528PINN\u5b66\u4e60\u65f6\u95f4\u6f14\u5316\u548c\u53cd\u5e94-\u6269\u6563\u9879\u4ee5\u751f\u62101D\u65f6\u95f4\u5e8f\u5217\u548c2D\u87ba\u65cb\u6ce2\u6a21\u5f0f\uff0c\u5e76\u7528\u53c2\u6570\u53d1\u73b0\u4e0e\u7075\u654f\u5ea6\u5206\u6790\u5b9e\u73b0\u53ef\u89e3\u91ca\u6027\u3002", "result": "\u5728Lotka-Volterra\u6848\u4f8b\u4e2d\uff0c1D\u65f6\u95f4\u52a8\u529b\u5b66\u8fbe98.9%\u76f8\u5173\uff08loss 0.0219, MAE 0.0184\uff09\uff1b2D\u87ba\u65cb\u6ce2\u6a21\u5f0f\u76f8\u51730.94\uff08loss 4.7656\uff09\uff1b\u5b88\u6052\u8bef\u5dee<0.5%\uff1b\u63a8\u7406\u6bd4\u6570\u503c\u6c42\u89e3\u5668\u5feb10-50\u500d\u3002", "conclusion": "USPIL\u63d0\u51fa\u4e86\u5c06PINNs\u4e0e\u5b88\u6052\u5f8b\u7ed3\u5408\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u80fd\u540c\u65f6\u5904\u7406ODE\u548cPDE\u5c3a\u5ea6\u7684\u6355\u98df-\u88ab\u6355\u98df\u52a8\u529b\u5b66\uff0c\u62a5\u544a\u5728Lotka-Volterra\u5b9e\u9a8c\u4e2d\u5177\u6709\u9ad8\u76f8\u5173\u6027\u3001\u4fdd\u6301\u5b88\u6052\u548c\u52a0\u901f\u63a8\u7406\u7684\u4f18\u52bf\u3002"}}
{"id": "2509.13978", "categories": ["cs.DC", "cs.AI", "cs.DB", "68M14, 68M20, 68T07", "C.2.4; D.1.3; I.2.0"], "pdf": "https://arxiv.org/pdf/2509.13978", "abs": "https://arxiv.org/abs/2509.13978", "authors": ["Renan Souza", "Timothy Poteet", "Brian Etz", "Daniel Rosendo", "Amal Gueroudji", "Woong Shin", "Prasanna Balaprakash", "Rafael Ferreira da Silva"], "title": "LLM Agents for Interactive Workflow Provenance: Reference Architecture and Evaluation Methodology", "comment": "Paper accepted in the proceedings of the ACM/IEEE Supercomputing\n  Conference (SC). Cite it as Renan Souza, Timothy Poteet, Brian Etz, Daniel\n  Rosendo, Amal Gueroudji, Woong Shin, Prasanna Balaprakash, and Rafael\n  Ferreira da Silva. 2025. LLM Agents for Interactive Workflow Provenance:\n  Reference Architecture and Evaluation Methodology. In SC Workshops (WORKS)", "summary": "Modern scientific discovery increasingly relies on workflows that process\ndata across the Edge, Cloud, and High Performance Computing (HPC) continuum.\nComprehensive and in-depth analyses of these data are critical for hypothesis\nvalidation, anomaly detection, reproducibility, and impactful findings.\nAlthough workflow provenance techniques support such analyses, at large scale,\nthe provenance data become complex and difficult to analyze. Existing systems\ndepend on custom scripts, structured queries, or static dashboards, limiting\ndata interaction. In this work, we introduce an evaluation methodology,\nreference architecture, and open-source implementation that leverages\ninteractive Large Language Model (LLM) agents for runtime data analysis. Our\napproach uses a lightweight, metadata-driven design that translates natural\nlanguage into structured provenance queries. Evaluations across LLaMA, GPT,\nGemini, and Claude, covering diverse query classes and a real-world chemistry\nworkflow, show that modular design, prompt tuning, and Retrieval-Augmented\nGeneration (RAG) enable accurate and insightful LLM agent responses beyond\nrecorded provenance.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u4ea4\u4e92\u5f0f\u5927\u6a21\u578b\u4ee3\u7406(LLM agents)\u7684\u8fd0\u884c\u65f6\u6eaf\u6e90\u6570\u636e\u5206\u6790\u65b9\u6cd5\uff0c\u7ed3\u5408\u8f7b\u91cf\u7ea7\u5143\u6570\u636e\u9a71\u52a8\u8bbe\u8ba1\uff0c\u5c06\u81ea\u7136\u8bed\u8a00\u8f6c\u6362\u4e3a\u7ed3\u6784\u5316\u6eaf\u6e90\u67e5\u8be2\u3002\u4f5c\u8005\u63d0\u4f9b\u4e86\u8bc4\u4f30\u65b9\u6cd5\u3001\u53c2\u8003\u67b6\u6784\u548c\u5f00\u6e90\u5b9e\u73b0\uff0c\u5e76\u5728\u591a\u6b3e\u5927\u6a21\u578b\uff08LLaMA\u3001GPT\u3001Gemini\u3001Claude\uff09\u4ee5\u53ca\u771f\u5b9e\u5316\u5b66\u5de5\u4f5c\u6d41\u4e0a\u9a8c\u8bc1\uff0c\u7ed3\u679c\u663e\u793a\u6a21\u5757\u5316\u8bbe\u8ba1\u3001\u63d0\u793a\u8c03\u4f18\u548cRAG\u63d0\u5347\u4e86\u4ee3\u7406\u7684\u54cd\u5e94\u51c6\u786e\u6027\u4e0e\u6d1e\u89c1\u6027\uff0c\u8d85\u8d8a\u4e86\u4ec5\u4f9d\u8d56\u8bb0\u5f55\u7684\u6eaf\u6e90\u4fe1\u606f\u3002", "motivation": "\u968f\u7740Edge\u3001Cloud\u548cHPC\u534f\u540c\u7684\u79d1\u5b66\u5de5\u4f5c\u6d41\u666e\u53ca\uff0c\u6eaf\u6e90\u6570\u636e\u89c4\u6a21\u548c\u590d\u6742\u5ea6\u6025\u5267\u589e\u957f\uff0c\u4f20\u7edf\u811a\u672c/\u67e5\u8be2/\u9759\u6001\u4eea\u8868\u76d8\u96be\u4ee5\u5b9e\u73b0\u7075\u6d3b\u4ea4\u4e92\u4e0e\u6df1\u5ea6\u5206\u6790\uff0c\u56e0\u6b64\u9700\u8981\u80fd\u7528\u81ea\u7136\u8bed\u8a00\u4ea4\u4e92\u3001\u652f\u6301\u8fd0\u884c\u65f6\u63a8\u7406\u548c\u4e0a\u4e0b\u6587\u68c0\u7d22\u7684\u5206\u6790\u5de5\u5177\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u53c2\u8003\u67b6\u6784\u4e0e\u5f00\u6e90\u5b9e\u73b0\uff1a\u7528\u8f7b\u91cf\u5143\u6570\u636e\u63cf\u8ff0\u6eaf\u6e90\u7ed3\u6784\uff0c\u6784\u5efa\u6a21\u5757\u5316LLM\u4ee3\u7406\u6846\u67b6\uff08\u542b\u89e3\u6790\u3001\u68c0\u7d22\u3001\u67e5\u8be2\u751f\u6210\u4e0e\u6267\u884c\u3001\u7ed3\u679c\u6574\u5408\uff09\uff0c\u901a\u8fc7\u63d0\u793a\u5de5\u7a0b\u548cRAG\u628a\u81ea\u7136\u8bed\u8a00\u8f6c\u4e3a\u7ed3\u6784\u5316\u67e5\u8be2\u5e76\u7ed3\u5408\u76f8\u5173\u4e0a\u4e0b\u6587\u68c0\u7d22\uff1b\u5728\u591a\u79cdLLM\u4e0a\u8fdb\u884c\u8de8\u67e5\u8be2\u7c7b\u522b\u4e0e\u771f\u5b9e\u5316\u5b66\u5de5\u4f5c\u6d41\u7684\u8bc4\u4f30\u3002", "result": "\u5728\u591a\u6a21\u578b\uff08LLaMA\u3001GPT\u3001Gemini\u3001Claude\uff09\u548c\u771f\u5b9e\u5316\u5b66\u5de5\u4f5c\u6d41\u7684\u8bc4\u4f30\u4e2d\uff0c\u6a21\u5757\u5316\u6846\u67b6\u3001\u63d0\u793a\u8c03\u4f18\u4e0eRAG\u663e\u8457\u63d0\u9ad8\u4e86LLM\u4ee3\u7406\u5bf9\u4e0d\u540c\u67e5\u8be2\u7c7b\u522b\u7684\u51c6\u786e\u6027\u4e0e\u6d1e\u5bdf\u529b\uff0c\u4e14\u80fd\u63a8\u65ad\u51fa\u8d85\u51fa\u8bb0\u5f55\u6eaf\u6e90\u6570\u636e\u7684\u7ed3\u8bba\u3002", "conclusion": "\u901a\u8fc7\u5143\u6570\u636e\u9a71\u52a8\u3001\u6a21\u5757\u5316\u7684\u8bbe\u8ba1\u548cRAG\u589e\u5f3a\uff0c\u4ea4\u4e92\u5f0fLLM\u4ee3\u7406\u53ef\u4ee5\u5c06\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u6709\u6548\u6620\u5c04\u4e3a\u7ed3\u6784\u5316\u6eaf\u6e90\u67e5\u8be2\uff0c\u4ece\u800c\u5728\u5927\u89c4\u6a21\u3001\u590d\u6742\u7684\u5de5\u4f5c\u6d41\u6eaf\u6e90\u6570\u636e\u4e0a\u5b9e\u73b0\u51c6\u786e\u3001\u5bcc\u6709\u6d1e\u89c1\u7684\u8fd0\u884c\u65f6\u5206\u6790\uff0c\u63d0\u5347\u53ef\u4ea4\u4e92\u6027\u5e76\u652f\u6301\u8d85\u8d8a\u9759\u6001\u8bb0\u5f55\u7684\u63a8\u65ad\u3002"}}
{"id": "2509.13334", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.13334", "abs": "https://arxiv.org/abs/2509.13334", "authors": ["Anand Swaroop", "Akshat Nallani", "Saksham Uboweja", "Adiliia Uzdenova", "Michael Nguyen", "Kevin Zhu", "Sunishchal Dev", "Ashwinee Panda", "Vasu Sharma", "Maheep Chaudhary"], "title": "FRIT: Using Causal Importance to Improve Chain-of-Thought Faithfulness", "comment": null, "summary": "Chain-of-thought (CoT) reasoning has emerged as a powerful tool for improving\nlarge language model performance on complex tasks, but recent work shows that\nreasoning steps often fail to causally influence the final answer, creating\nbrittle and untrustworthy outputs. Prior approaches focus primarily on\nmeasuring faithfulness, while methods for systematically improving it remain\nlimited. We introduce Faithful Reasoning via Intervention Training (FRIT), a\nscalable alignment method that trains models to produce causally consistent\nreasoning by learning from systematically corrupted examples. FRIT generates\nsynthetic training data by intervening on individual reasoning steps in\nmodel-generated CoTs, creating faithful/unfaithful pairs that highlight when\nreasoning breaks down. We then apply Direct Preference Optimization to teach\nmodels to prefer causally consistent reasoning paths. Evaluating on Qwen3-8B\nand Mistral-7B-v0.1 across factual and symbolic reasoning tasks, FRIT increases\nfaithful reasoning by $3.4$ percentage points for Mistral on GSM8K while\nimproving accuracy by $7.6$ percentage points. Our approach provides the first\nscalable, supervision-free method for training language models to produce more\nreliable and interpretable reasoning, addressing a critical gap between\nreasoning performance and trustworthiness. We release our code at\n\\href{https://github.com/Anut-py/frit}.", "AI": {"tldr": "\u63d0\u51faFRIT\uff0c\u901a\u8fc7\u5bf9CoT\u5355\u6b65\u5e72\u9884\u751f\u6210\u5fe0\u5b9e/\u4e0d\u5fe0\u5b9e\u6837\u672c\u5e76\u7528DPO\u8bad\u7ec3\uff0c\u9996\u6b21\u63d0\u4f9b\u4e00\u79cd\u65e0\u9700\u4eba\u5de5\u76d1\u7763\u7684\u53ef\u6269\u5c55\u65b9\u6cd5\u6765\u63d0\u5347\u5927\u6a21\u578b\u63a8\u7406\u7684\u56e0\u679c\u5fe0\u5b9e\u6027\u4e0e\u51c6\u786e\u7387\u3002", "motivation": "\u73b0\u6709CoT\u63a8\u7406\u867d\u63d0\u5347\u590d\u6742\u4efb\u52a1\u6027\u80fd\uff0c\u4f46\u4e2d\u95f4\u63a8\u7406\u6b65\u9aa4\u5e38\u4e0e\u6700\u7ec8\u7b54\u6848\u65e0\u56e0\u679c\u6027\uff0c\u5bfc\u81f4\u8f93\u51fa\u4e0d\u53ef\u9760\uff1b\u5df2\u6709\u5de5\u4f5c\u4e3b\u8981\u5ea6\u91cf\u5fe0\u5b9e\u6027\uff0c\u7f3a\u4e4f\u7cfb\u7edf\u6027\u6539\u8fdb\u65b9\u6cd5\u3002", "method": "FRIT\u5148\u5bf9\u6a21\u578b\u751f\u6210\u7684CoT\u8fdb\u884c\u5355\u6b65\u5e72\u9884\uff0c\u751f\u6210\u5408\u6210\u8bad\u7ec3\u6837\u672c\uff08\u5fe0\u5b9e/\u4e0d\u5fe0\u5b9e\u5bf9\uff09\uff0c\u7136\u540e\u91c7\u7528\u76f4\u63a5\u504f\u597d\u4f18\u5316\uff08DPO\uff09\u8ba9\u6a21\u578b\u66f4\u504f\u597d\u56e0\u679c\u4e00\u81f4\u7684\u63a8\u7406\u8def\u5f84\u3002", "result": "\u5728Qwen3-8B\u4e0eMistral-7B-v0.1\u4e0a\u8bc4\u4f30\uff0cFRIT\u5728GSM8K\u4e0a\u4f7fMistral\u7684\u5fe0\u5b9e\u63a8\u7406\u63d0\u53473.4\u4e2a\u767e\u5206\u70b9\uff0c\u51c6\u786e\u7387\u63d0\u53477.6\u4e2a\u767e\u5206\u70b9\uff0c\u663e\u793a\u51fa\u5bf9\u4e8b\u5b9e\u4e0e\u7b26\u53f7\u63a8\u7406\u4efb\u52a1\u7684\u6548\u679c\u3002", "conclusion": "FRIT\u901a\u8fc7\u5728\u6a21\u578b\u751f\u6210\u7684\u94fe\u5f0f\u63a8\u7406\uff08CoT\uff09\u4e2d\u6709\u7cfb\u7edf\u5730\u5e72\u9884\u5355\u6b65\uff0c\u751f\u6210\u5fe0\u5b9e\u4e0e\u4e0d\u5fe0\u5b9e\u5bf9\u6bd4\u6837\u672c\uff0c\u5e76\u7528\u76f4\u63a5\u504f\u597d\u4f18\u5316\uff08DPO\uff09\u8bad\u7ec3\u6a21\u578b\uff0c\u663e\u8457\u63d0\u5347\u63a8\u7406\u7684\u56e0\u679c\u4e00\u81f4\u6027\u4e0e\u51c6\u786e\u6027\uff0c\u4e3a\u65e0\u9700\u4eba\u5de5\u76d1\u7763\u7684\u53ef\u6269\u5c55\u5bf9\u9f50\u65b9\u6cd5\u3002"}}
{"id": "2509.13604", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2509.13604", "abs": "https://arxiv.org/abs/2509.13604", "authors": ["Yoseph Berhanu Alebachew", "Mulugeta Libsie"], "title": "A Framework for Multi-source Prefetching Through Adaptive Weight", "comment": null, "summary": "The World Wide Web has come to be a great part of our daily life, yet user\nobserved latency is still a problem that needs a proper means of handling. Even\nthough earlier attempts focused on caching as the chief solution to tackling\nthis issue, its success was extremely limited. Prefetching has come to be the\nprimary technique in supplementing caching towards soothing the latency problem\nassociated with the contemporary Internet. However, existing approaches in\nprefetching are extremely limited in their ability to employ application level\nweb document relationship which is often visible only to the content developer.\nThis is because most approaches are access history based schemes that make\nfuture users' access prediction only based on past user access. Attempts to\nincorporate prefetching schemes that utilize semantic information with those\nthat use users past access history are extremely limited in their\nextensibility. In this work we present a novel framework that enables\nintegration of schemes from both worlds of prefetching without the need for a\nmajor modification to the algorithms. When there is a need/possibility to\ncapture new application level context, a new algorithm could be developed to do\nso and then it can be integrated into the framework. Since each participating\nscheme is merely viewed as an algorithm that produces a list of candidate\nobjects that are likely to be accessed in the near future, the framework can\nentertain any one of the existing prefetching schemes. With its adaptive weight\nmanagement technique the framework adjusts the effect of each algorithm in the\noverall prediction to parallel with its observed performance so far. We have\nfound this formwork to be less aggressive than its contemporary counterparts\nwhich is extremely important for resource constrained mobile devices that have\ncome to be the major means of access by users of the current web.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u53ef\u63d2\u62d4\u7684\u9884\u53d6\u6846\u67b6\uff0c\u7ed3\u5408\u5386\u53f2\u4e0e\u8bed\u4e49\u7b97\u6cd5\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u6743\u91cd\u5408\u5e76\u5019\u9009\u5217\u8868\uff0c\u63d0\u5347\u9884\u6d4b\u51c6\u786e\u6027\u5e76\u964d\u4f4e\u79fb\u52a8\u7aef\u8d44\u6e90\u5f00\u9500\u3002", "motivation": "\u4f20\u7edf\u7684\u9884\u53d6\u591a\u4f9d\u8d56\u8bbf\u95ee\u5386\u53f2\uff0c\u96be\u4ee5\u5229\u7528\u53ea\u6709\u5185\u5bb9\u5f00\u53d1\u8005\u53ef\u89c1\u7684\u5e94\u7528\u7ea7\u8bed\u4e49\u5173\u7cfb\uff1b\u9700\u8981\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u3001\u80fd\u7ed3\u5408\u8bed\u4e49\u4e0e\u5386\u53f2\u4fe1\u606f\u4e14\u5bf9\u79fb\u52a8\u8bbe\u5907\u8d44\u6e90\u53cb\u597d\u7684\u9884\u53d6\u65b9\u6848\u3002", "method": "\u5c06\u5404\u9884\u53d6\u7b97\u6cd5\u89c6\u4e3a\u751f\u6210\u5019\u9009\u5bf9\u8c61\u5217\u8868\u7684\u6a21\u5757\uff0c\u6846\u67b6\u6536\u96c6\u5404\u7b97\u6cd5\u7684\u5019\u9009\u5217\u8868\u5e76\u6309\u52a8\u6001\u6743\u91cd\u5408\u5e76\uff0c\u6743\u91cd\u6839\u636e\u7b97\u6cd5\u7684\u5386\u53f2\u8868\u73b0\u8fdb\u884c\u66f4\u65b0\uff1b\u6846\u67b6\u652f\u6301\u63d2\u5165\u65b0\u7684\u5e94\u7528\u7ea7\u8bed\u4e49\u7b97\u6cd5\u800c\u65e0\u9700\u5927\u5e45\u4fee\u6539\u73b0\u6709\u673a\u5236\u3002", "result": "\u6846\u67b6\u4e0e\u73b0\u6709\u65b9\u6cd5\u76f8\u6bd4\u66f4\u4e0d\u6fc0\u8fdb\uff0c\u4ece\u800c\u9002\u5408\u8d44\u6e90\u53d7\u9650\u7684\u79fb\u52a8\u8bbe\u5907\uff1b\u80fd\u591f\u517c\u5bb9\u4efb\u4f55\u73b0\u6709\u7684\u9884\u53d6\u7b97\u6cd5\uff0c\u5e76\u901a\u8fc7\u6743\u91cd\u8c03\u6574\u63d0\u5347\u6574\u4f53\u9884\u6d4b\u6027\u80fd\u53ca\u8d44\u6e90\u5229\u7528\u6548\u7387\u3002", "conclusion": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u901a\u7528\u7684\u9884\u53d6\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u4e0d\u540c\u6765\u6e90\u7684\u9884\u53d6\u7b97\u6cd5\uff08\u57fa\u4e8e\u5386\u53f2\u8bbf\u95ee\u4e0e\u57fa\u4e8e\u8bed\u4e49\u7684\u7b97\u6cd5\uff09\u4f5c\u4e3a\u751f\u6210\u5019\u9009\u5bf9\u8c61\u5217\u8868\u7684\u9ed1\u7bb1\u7b97\u6cd5\u8fdb\u884c\u96c6\u6210\uff0c\u5e76\u901a\u8fc7\u81ea\u9002\u5e94\u6743\u91cd\u7ba1\u7406\u52a8\u6001\u8c03\u6574\u5404\u7b97\u6cd5\u8d21\u732e\uff0c\u4ece\u800c\u63d0\u9ad8\u4e86\u9884\u53d6\u9884\u6d4b\u7684\u51c6\u786e\u6027\u5e76\u964d\u4f4e\u4e86\u8d44\u6e90\u6d88\u8017\u3002"}}
{"id": "2509.13509", "categories": ["cs.CR", "cs.CY", "cs.HC"], "pdf": "https://arxiv.org/pdf/2509.13509", "abs": "https://arxiv.org/abs/2509.13509", "authors": ["Priyanka Nanayakkara", "Elena Ghazi", "Salil Vadhan"], "title": "Practitioners' Perspectives on a Differential Privacy Deployment Registry", "comment": null, "summary": "Differential privacy (DP) -- a principled approach to producing statistical\ndata products with strong, mathematically provable privacy guarantees for the\nindividuals in the underlying dataset -- has seen substantial adoption in\npractice over the past decade. Applying DP requires making several\nimplementation decisions, each with significant impacts on data privacy and/or\nutility. Hence, to promote shared learning and accountability around DP\ndeployments, Dwork, Kohli, and Mulligan (2019) proposed a public-facing\nrepository (\"registry\") of DP deployments. The DP community has recently\nstarted to work toward realizing this vision. We contribute to this effort by\n(1) developing a holistic, hierarchical schema to describe any given DP\ndeployment and (2) designing and implementing an interactive interface to act\nas a registry where practitioners can access information about past DP\ndeployments. We (3) populate our interface with 21 real-world DP deployments\nand (4) conduct an exploratory user study with DP practitioners ($n=16$) to\nunderstand how they would use the registry, as well as what challenges and\nopportunities they foresee around its adoption. We find that participants were\nenthusiastic about the registry as a valuable resource for evaluating prior\ndeployments and making future deployments. They also identified several\nopportunities for the registry, including that it can become a \"hub\" for the\ncommunity and support broader communication around DP (e.g., to legal teams).\nAt the same time, they identified challenges around the registry gaining\nadoption, including the effort and risk involved with making implementation\nchoices public and moderating the quality of entries. Based on our findings, we\noffer recommendations for encouraging adoption and increasing the registry's\nvalue not only to DP practitioners, but also to policymakers, data users, and\ndata subjects.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5e76\u5b9e\u73b0\u4e86\u4e00\u4e2a\u5dee\u5206\u9690\u79c1\uff08DP\uff09\u90e8\u7f72\u767b\u8bb0\u5e93\uff1a\u8bbe\u8ba1\u4e86\u5206\u5c42\u6a21\u5f0f(schema)\u6765\u63cf\u8ff0\u4efb\u610fDP\u90e8\u7f72\uff0c\u6784\u5efa\u4ea4\u4e92\u5f0f\u754c\u9762\u5e76\u5f55\u516521\u4e2a\u771f\u5b9e\u90e8\u7f72\uff0c\u57fa\u4e8e16\u4f4dDP\u4ece\u4e1a\u8005\u7684\u63a2\u7d22\u6027\u7814\u7a76\u8bc4\u4f30\u5176\u53ef\u7528\u6027\u4e0e\u91c7\u7eb3\u969c\u788d\u3002", "motivation": "\u5dee\u5206\u9690\u79c1\u90e8\u7f72\u6d89\u53ca\u591a\u9879\u5173\u952e\u5b9e\u73b0\u51b3\u7b56\uff0c\u8fd9\u4e9b\u51b3\u7b56\u5f71\u54cd\u9690\u79c1\u4e0e\u6548\u7528\uff1b\u9700\u8981\u4e00\u4e2a\u516c\u5171\u7684\u3001\u9762\u5411\u5b9e\u8df5\u8005\u7684\u767b\u8bb0\u5e93\u6765\u4fc3\u8fdb\u7ecf\u9a8c\u5171\u4eab\u4e0e\u95ee\u8d23\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u6574\u4f53\u7684\u5206\u5c42schema\u63cf\u8ff0DP\u90e8\u7f72\uff0c\u5f00\u53d1\u5e76\u5b9e\u73b0\u4ea4\u4e92\u5f0f\u6ce8\u518c\u754c\u9762\uff1b\u586b\u514521\u4e2a\u771f\u5b9e\u4e16\u754c\u90e8\u7f72\u5b9e\u4f8b\uff1b\u5bf916\u540dDP\u4ece\u4e1a\u8005\u8fdb\u884c\u63a2\u7d22\u6027\u7528\u6237\u7814\u7a76\u4ee5\u6536\u96c6\u53cd\u9988\u3002", "result": "\u5b9e\u73b0\u4e86\u4e00\u4e2a\u53ef\u7528\u7684\u767b\u8bb0\u754c\u9762\u5e76\u586b\u5145\u5b9e\u4f8b\uff1b\u7528\u6237\u7814\u7a76\u663e\u793a\u4ece\u4e1a\u8005\u4e50\u89c2\u4f46\u62c5\u5fe7\u91c7\u7eb3\u95e8\u69db\u4e0e\u98ce\u9669\uff0c\u5e76\u63d0\u51fa\u6539\u8fdb\u5efa\u8bae\u3002", "conclusion": "\u53d7\u8bbf\u4ece\u4e1a\u8005\u5bf9\u767b\u8bb0\u5e93\u8868\u793a\u79ef\u6781\uff0c\u8ba4\u4e3a\u5176\u53ef\u52a9\u4e8e\u8bc4\u4f30\u4e0e\u8bbe\u8ba1DP\u90e8\u7f72\u5e76\u4f5c\u4e3a\u793e\u533a\u6c9f\u901a\u67a2\u7ebd\uff1b\u4f46\u91c7\u7eb3\u9762\u4e34\u516c\u5f00\u5b9e\u73b0\u7ec6\u8282\u7684\u6210\u672c\u4e0e\u98ce\u9669\u3001\u6761\u76ee\u8d28\u91cf\u5ba1\u6838\u7b49\u6311\u6218\u3002\u4f5c\u8005\u63d0\u51fa\u82e5\u5e72\u4fc3\u8fdb\u91c7\u7eb3\u4e0e\u63d0\u9ad8\u4ef7\u503c\u7684\u5efa\u8bae\uff0c\u9762\u5411\u4ece\u4e1a\u8005\u3001\u653f\u7b56\u5236\u5b9a\u8005\u548c\u6570\u636e\u4e3b\u4f53\u3002"}}
{"id": "2509.13516", "categories": ["cs.LG", "68T05 (Primary) 90C30, 68W40 (Secondary)"], "pdf": "https://arxiv.org/pdf/2509.13516", "abs": "https://arxiv.org/abs/2509.13516", "authors": ["Tom Almog"], "title": "An Analysis of Optimizer Choice on Energy Efficiency and Performance in Neural Network Training", "comment": "7 pages. 3 figures", "summary": "As machine learning models grow increasingly complex and computationally\ndemanding, understanding the environmental impact of training decisions becomes\ncritical for sustainable AI development. This paper presents a comprehensive\nempirical study investigating the relationship between optimizer choice and\nenergy efficiency in neural network training. We conducted 360 controlled\nexperiments across three benchmark datasets (MNIST, CIFAR-10, CIFAR-100) using\neight popular optimizers (SGD, Adam, AdamW, RMSprop, Adagrad, Adadelta, Adamax,\nNAdam) with 15 random seeds each. Using CodeCarbon for precise energy tracking\non Apple M1 Pro hardware, we measured training duration, peak memory usage,\ncarbon dioxide emissions, and final model performance. Our findings reveal\nsubstantial trade-offs between training speed, accuracy, and environmental\nimpact that vary across datasets and model complexity. We identify AdamW and\nNAdam as consistently efficient choices, while SGD demonstrates superior\nperformance on complex datasets despite higher emissions. These results provide\nactionable insights for practitioners seeking to balance performance and\nsustainability in machine learning workflows.", "AI": {"tldr": "\u5927\u89c4\u6a21\u5b9e\u9a8c\u663e\u793a\u4f18\u5316\u5668\u9009\u62e9\u663e\u8457\u5f71\u54cd\u8bad\u7ec3\u65f6\u95f4\u3001\u80fd\u8017\u548c\u6700\u7ec8\u6027\u80fd\uff1bAdamW\u4e0eNAdam\u5728\u591a\u573a\u666f\u4e0b\u80fd\u6548\u8f83\u4f18\uff0cSGD\u5728\u590d\u6742\u4efb\u52a1\u4e0a\u6027\u80fd\u66f4\u597d\u4f46\u6392\u653e\u66f4\u9ad8\u3002", "motivation": "\u968f\u7740\u6a21\u578b\u590d\u6742\u5ea6\u4e0e\u8bad\u7ec3\u6210\u672c\u4e0a\u5347\uff0c\u91cf\u5316\u8bad\u7ec3\u51b3\u7b56\u7684\u73af\u5883\u5f71\u54cd\u5bf9\u53ef\u6301\u7eedAI\u81f3\u5173\u91cd\u8981\uff0c\u672c\u7814\u7a76\u65e8\u5728\u4e3a\u4f18\u5316\u5668\u9009\u62e9\u63d0\u4f9b\u80fd\u6548\u4e0e\u6027\u80fd\u7684\u5b9e\u8bc1\u4f9d\u636e\u3002", "method": "360\u6b21\u53ef\u91cd\u590d\u5b9e\u9a8c\uff1a\u4e09\u6570\u636e\u96c6\u00d7\u516b\u4f18\u5316\u5668\u00d715\u968f\u673a\u79cd\u5b50\uff1b\u5728Apple M1 Pro\u4e0a\u4f7f\u7528CodeCarbon\u8ddf\u8e2a\u8bad\u7ec3\u65f6\u957f\u3001\u5cf0\u503c\u5185\u5b58\u3001CO2\u6392\u653e\u53ca\u6700\u7ec8\u51c6\u786e\u7387\uff0c\u6bd4\u8f83\u5404\u4f18\u5316\u5668\u7684\u5e73\u5747\u4e0e\u65b9\u5dee\u8868\u73b0\u3002", "result": "This paper empirically studies optimizer choice vs energy efficiency during neural network training, performing 360 runs across MNIST, CIFAR-10, CIFAR-100 with 8 optimizers and 15 seeds, measuring energy, time, memory, CO2, and accuracy on Apple M1 Pro using CodeCarbon. Key findings: trade-offs between speed, accuracy, emissions; AdamW and NAdam are consistently efficient; SGD gives better accuracy on complex datasets but higher emissions; advice for practitioners to balance performance and sustainability.", "conclusion": "\u4f18\u5316\u5668\u9009\u62e9\u4f1a\u5728\u8bad\u7ec3\u901f\u5ea6\u3001\u80fd\u8017\u4e0e\u6027\u80fd\u95f4\u4ea7\u751f\u6743\u8861\uff1b\u9009\u62e9\u9700\u8981\u6839\u636e\u4efb\u52a1\u590d\u6742\u5ea6\u4e0e\u53ef\u63a5\u53d7\u7684\u73af\u5883\u5f71\u54cd\u6298\u4e2d\u3002"}}
{"id": "2509.13523", "categories": ["cs.LG", "cs.DC"], "pdf": "https://arxiv.org/pdf/2509.13523", "abs": "https://arxiv.org/abs/2509.13523", "authors": ["V\u00e4in\u00f6 Hatanp\u00e4\u00e4", "Eugene Ku", "Jason Stock", "Murali Emani", "Sam Foreman", "Chunyong Jung", "Sandeep Madireddy", "Tung Nguyen", "Varuni Sastry", "Ray A. O. Sinurat", "Sam Wheeler", "Huihuo Zheng", "Troy Arcomano", "Venkatram Vishwanath", "Rao Kotamarthi"], "title": "AERIS: Argonne Earth Systems Model for Reliable and Skillful Predictions", "comment": "14 pages, 7 figures", "summary": "Generative machine learning offers new opportunities to better understand\ncomplex Earth system dynamics. Recent diffusion-based methods address spectral\nbiases and improve ensemble calibration in weather forecasting compared to\ndeterministic methods, yet have so far proven difficult to scale stably at high\nresolutions. We introduce AERIS, a 1.3 to 80B parameter pixel-level Swin\ndiffusion transformer to address this gap, and SWiPe, a generalizable technique\nthat composes window parallelism with sequence and pipeline parallelism to\nshard window-based transformers without added communication cost or increased\nglobal batch size. On Aurora (10,080 nodes), AERIS sustains 10.21 ExaFLOPS\n(mixed precision) and a peak performance of 11.21 ExaFLOPS with $1 \\times 1$\npatch size on the 0.25{\\deg} ERA5 dataset, achieving 95.5% weak scaling\nefficiency, and 81.6% strong scaling efficiency. AERIS outperforms the IFS ENS\nand remains stable on seasonal scales to 90 days, highlighting the potential of\nbillion-parameter diffusion models for weather and climate prediction.", "AI": {"tldr": "AERIS\u7ed3\u5408SWiPe\u5e76\u884c\u6280\u672f\uff0c\u5b9e\u73b0\u4e86\u53ef\u6269\u5c55\u523080B\u53c2\u6570\u7684\u50cf\u7d20\u7ea7Swin\u6269\u6563Transformer\uff0c\u5728\u9ad8\u5206\u8fa8\u7387\u5929\u6c14\u9884\u62a5\u4e2d\u8fbe\u5230\u4e86ExaFLOPS\u7ea7\u6027\u80fd\u5e76\u4f18\u4e8e\u4f20\u7edf\u96c6\u5408\u9884\u62a5\u3002", "motivation": "\u6269\u6563\u65b9\u6cd5\u867d\u5728\u89e3\u51b3\u9891\u8c31\u504f\u5dee\u4e0e\u6539\u8fdb\u96c6\u5408\u6821\u51c6\u65b9\u9762\u4f18\u4e8e\u786e\u5b9a\u6027\u65b9\u6cd5\uff0c\u4f46\u96be\u4ee5\u5728\u9ad8\u5206\u8fa8\u7387\u4e0b\u7a33\u5b9a\u6269\u5c55\uff1b\u56e0\u6b64\u9700\u8981\u53ef\u6269\u5c55\u7684\u6a21\u578b\u67b6\u6784\u4e0e\u5e76\u884c\u6280\u672f\u4ee5\u5b9e\u73b0\u5927\u5c3a\u5ea6\u3001\u9ad8\u5206\u8fa8\u7387\u7684\u751f\u6210\u5f0f\u6c14\u8c61\u5efa\u6a21\u3002", "method": "\u63d0\u51faAERIS\u6a21\u578b\uff081.3B\u81f380B\u53c2\u6570\uff09\uff0c\u7ed3\u5408\u50cf\u7d20\u7ea7Swin\u6269\u6563\u7ed3\u6784\uff1b\u5e76\u5f15\u5165SWiPe\u5e76\u884c\u7b56\u7565\uff0c\u5c06\u7a97\u53e3\u5e76\u884c\u3001\u5e8f\u5217\u5e76\u884c\u4e0e\u6d41\u6c34\u7ebf\u5e76\u884c\u7ec4\u5408\uff0c\u7528\u4ee5\u65e0\u989d\u5916\u901a\u4fe1\u6216\u589e\u52a0\u5168\u5c40\u6279\u91cf\u7684\u6761\u4ef6\u4e0b\u5207\u5206\u7a97\u53e3\u578bTransformer\u3002", "result": "\u5728Aurora\u8d85\u7b97\uff0810,080\u8282\u70b9\uff09\u4e0a\uff0cAERIS\u57280.25\u00b0 ERA5\u6570\u636e\u96c6\uff0c1\u00d71 patch\u4e0b\u5b9e\u73b0\u6df7\u5408\u7cbe\u5ea6\u6301\u7eed10.21 ExaFLOPS\uff0c\u5cf0\u503c11.21 ExaFLOPS\uff1b\u5f31\u6269\u5c55\u6548\u738795.5%\uff0c\u5f3a\u6269\u5c55\u6548\u738781.6%\u3002\u6a21\u578b\u4f18\u4e8eIFS ENS\uff0c\u5e76\u5728\u957f\u8fbe90\u5929\u7684\u5b63\u8282\u5c3a\u5ea6\u4e0a\u4fdd\u6301\u7a33\u5b9a\u3002", "conclusion": "\u8be5\u8bba\u6587\u5c55\u793a\u4e86\u5927\u89c4\u6a21\u50cf\u7d20\u7ea7Swin\u6269\u6563\u53d8\u6362\u5668\uff08AERIS\uff09\u5728\u9ad8\u5206\u8fa8\u7387\u5929\u6c14\u9884\u62a5\u4e0a\u7684\u53ef\u6269\u5c55\u6027\u4e0e\u6027\u80fd\u4f18\u52bf\uff0c\u8bc1\u660e\u4e86\u5341\u4ebf\u7ea7\u53c2\u6570\u6269\u6563\u6a21\u578b\u5728\u5b63\u8282\u5c3a\u5ea6\uff08\u81f390\u5929\uff09\u9884\u6d4b\u4e2d\u7684\u7a33\u5b9a\u6027\u548c\u4f18\u8d8a\u6027\u3002"}}
{"id": "2509.13339", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.13339", "abs": "https://arxiv.org/abs/2509.13339", "authors": ["Ming Jin", "Hyunin Lee"], "title": "Position: AI Safety Must Embrace an Antifragile Perspective", "comment": null, "summary": "This position paper contends that modern AI research must adopt an\nantifragile perspective on safety -- one in which the system's capacity to\nguarantee long-term AI safety such as handling rare or out-of-distribution\n(OOD) events expands over time. Conventional static benchmarks and single-shot\nrobustness tests overlook the reality that environments evolve and that models,\nif left unchallenged, can drift into maladaptation (e.g., reward hacking,\nover-optimization, or atrophy of broader capabilities). We argue that an\nantifragile approach -- Rather than striving to rapidly reduce current\nuncertainties, the emphasis is on leveraging those uncertainties to better\nprepare for potentially greater, more unpredictable uncertainties in the future\n-- is pivotal for the long-term reliability of open-ended ML systems. In this\nposition paper, we first identify key limitations of static testing, including\nscenario diversity, reward hacking, and over-alignment. We then explore the\npotential of antifragile solutions to manage rare events. Crucially, we\nadvocate for a fundamental recalibration of the methods used to measure,\nbenchmark, and continually improve AI safety over the long term, complementing\nexisting robustness approaches by providing ethical and practical guidelines\ntowards fostering an antifragile AI safety community.", "AI": {"tldr": "\u63d0\u51fa\u5c06AI\u5b89\u5168\u7814\u7a76\u4ece\u9759\u6001\u9c81\u68d2\u6027\u8f6c\u5411\u53cd\u8106\u5f31\u6027\uff0c\u4e3b\u5f20\u901a\u8fc7\u6301\u7eed\u6311\u6218\u4e0e\u5229\u7528\u4e0d\u786e\u5b9a\u6027\u6765\u63d0\u5347\u6a21\u578b\u5e94\u5bf9\u7a00\u6709\u4e0eOOD\u4e8b\u4ef6\u7684\u957f\u671f\u80fd\u529b\uff0c\u5e76\u547c\u5401\u91cd\u6784\u6d4b\u8bc4\u4e0e\u793e\u533a\u5b9e\u8df5\u3002", "motivation": "\u5f53\u524d\u9759\u6001\u6d4b\u8bd5\u5ffd\u7565\u73af\u5883\u6f14\u5316\u4e0e\u6a21\u578b\u968f\u65f6\u95f4\u9000\u5316\uff08\u5982\u5956\u52b1\u6295\u673a\u3001\u8fc7\u5ea6\u4f18\u5316\u3001\u80fd\u529b\u840e\u7f29\uff09\uff0c\u65e0\u6cd5\u4fdd\u8bc1\u5f00\u653e\u5f0fML\u7cfb\u7edf\u7684\u957f\u671f\u53ef\u9760\u6027\uff0c\u4e9f\u9700\u4e00\u79cd\u80fd\u5229\u7528\u4e0d\u786e\u5b9a\u6027\u6765\u5e94\u5bf9\u672a\u6765\u66f4\u5927\u4e0d\u53ef\u9884\u6d4b\u6027\u7684\u6846\u67b6\u3002", "method": "\u901a\u8fc7\u6279\u5224\u9759\u6001\u57fa\u51c6\u548c\u4e00\u6b21\u6027\u9c81\u68d2\u6027\u6d4b\u8bd5\u7684\u4e0d\u8db3\uff0c\u4f5c\u8005\u63d0\u51fa\u5c06\u4e0d\u786e\u5b9a\u6027\u89c6\u4e3a\u957f\u671f\u6539\u8fdb\u7684\u8d44\u6e90\uff0c\u5f3a\u8c03\u6301\u7eed\u5bf9\u6297\u3001\u6f14\u5316\u548c\u591a\u573a\u666f\u8bad\u7ec3\u4ee5\u57f9\u517b\u53cd\u8106\u5f31\u6027\uff0c\u5e76\u63d0\u51fa\u8861\u91cf\u4e0e\u57fa\u51c6\u5316\u65b9\u6cd5\u7684\u91cd\u6821\u51c6\u3002", "result": "\u8bba\u6587\u8bc6\u522b\u4e86\u9759\u6001\u6d4b\u8bd5\u5728\u573a\u666f\u591a\u6837\u6027\u3001\u5956\u52b1\u6295\u673a\u548c\u8fc7\u5ea6\u5bf9\u9f50\u65b9\u9762\u7684\u5173\u952e\u5c40\u9650\uff0c\u63d0\u51fa\u53cd\u8106\u5f31\u89e3\u51b3\u65b9\u6848\u7684\u6f5c\u529b\u4ee5\u53ca\u5bf9\u6d4b\u8bc4\u3001\u57fa\u51c6\u548c\u793e\u533a\u5b9e\u8df5\u7684\u4f26\u7406\u4e0e\u5b9e\u7528\u6027\u6307\u5bfc\u3002", "conclusion": "\u672c\u6587\u4e3b\u5f20\u5728AI\u5b89\u5168\u7814\u7a76\u4e2d\u91c7\u7528\u201c\u53cd\u8106\u5f31\u201d\uff08antifragile\uff09\u89c6\u89d2\uff0c\u4f7f\u7cfb\u7edf\u5728\u9762\u5bf9\u7a00\u6709\u6216\u5206\u5e03\u5916\u4e8b\u4ef6\u65f6\uff0c\u968f\u7740\u65f6\u95f4\u63a8\u79fb\u53d8\u5f97\u66f4\u6709\u80fd\u529b\u4fdd\u8bc1\u957f\u671f\u5b89\u5168\u3002"}}
{"id": "2509.13714", "categories": ["cs.NI", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.13714", "abs": "https://arxiv.org/abs/2509.13714", "authors": ["Benoit Pit-Claudel", "Muriel M\u00e9dard", "Manya Ghobadi"], "title": "LINC: An In-Network Coding Approach to Tame Packet Loss in Hybrid Wireless-Fiber Backbones", "comment": null, "summary": "The emergence of ultra-low latency applications, such as financial\ntransactions, has driven the development of hybrid backbone networks that rely\non fiber, satellite, and microwave links. Despite providing low latencies,\nthese hybrid networks suffer from occasional environmental packet loss caused\nby poor weather, construction, and line of sight blockage. Paradoxically,\ntoday's hybrid backbones rely on conventional transport protocols that take\npacket loss to signal network congestion, as opposed to transient environmental\nobstacles. A common approach to address this challenge is to use network coding\n(NC) between the end hosts to recover from these occasional packet loss events.\nHowever, current NC proposals assume full access to the end-hosts' stack to\nperform end-to-end encoding/decoding operations. In this paper, we introduce\nLINC, a novel system that provides in-network NC capabilities to mitigate\nenvironmental packet loss events without requiring cooperation from the end\nhosts. LINC uses a systematic block coding approach on a link-by-link basis,\nencoding and decoding packets inside the network. We model the tradeoff in\ngoodput between end-to-end retransmissions and redundant packets introduced by\nLINC, and propose an optimization formulation to determine the optimal choice\nof coding parameters. Our simulations on real-world backbone topologies\ndemonstrate that LINC reduces the end-to-end latency by up to 18% by\neliminating unnecessary retransmissions.", "AI": {"tldr": "LINC adds in-network link-by-link systematic block coding to recover from transient environmental losses without end-host modification, optimizing coding rate to balance redundancy vs retransmissions and reducing latency up to 18%.", "motivation": "Hybrid backbone networks using fiber, satellite, microwave provide ultra-low latency but suffer transient environmental packet loss; current transport protocols treat loss as congestion; end-to-end network coding helps but requires end-host access which is not always possible.", "method": "Design of LINC: systematic block coding deployed in network switches/links, link-by-link encoding/decoding; analytical model of goodput tradeoff; optimization formulation for coding parameters; simulation on real backbone topologies to evaluate latency improvements.", "result": "LINC, an in-network systematic block coding system, encodes/decodes packets on link-by-link basis without end-host changes; models tradeoff between retransmissions and added redundancy; optimization chooses coding parameters; simulations show up to 18% end-to-end latency reduction.", "conclusion": "In-network network coding using systematic block codes can mitigate environmental packet loss in hybrid backbones, improving latency and avoiding end-host changes; proper parameter optimization is key."}}
{"id": "2509.13514", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.13514", "abs": "https://arxiv.org/abs/2509.13514", "authors": ["Onat Gungor", "Roshan Sood", "Harold Wang", "Tajana Rosing"], "title": "AQUA-LLM: Evaluating Accuracy, Quantization, and Adversarial Robustness Trade-offs in LLMs for Cybersecurity Question Answering", "comment": "Accepted by the 24th IEEE International Conference on Machine\n  Learning and Applications (ICMLA'25)", "summary": "Large Language Models (LLMs) have recently demonstrated strong potential for\ncybersecurity question answering (QA), supporting decision-making in real-time\nthreat detection and response workflows. However, their substantial\ncomputational demands pose significant challenges for deployment on\nresource-constrained edge devices. Quantization, a widely adopted model\ncompression technique, can alleviate these constraints. Nevertheless,\nquantization may degrade model accuracy and increase susceptibility to\nadversarial attacks. Fine-tuning offers a potential means to mitigate these\nlimitations, but its effectiveness when combined with quantization remains\ninsufficiently explored. Hence, it is essential to understand the trade-offs\namong accuracy, efficiency, and robustness. We propose AQUA-LLM, an evaluation\nframework designed to benchmark several state-of-the-art small LLMs under four\ndistinct configurations: base, quantized-only, fine-tuned, and fine-tuned\ncombined with quantization, specifically for cybersecurity QA. Our results\ndemonstrate that quantization alone yields the lowest accuracy and robustness\ndespite improving efficiency. In contrast, combining quantization with\nfine-tuning enhances both LLM robustness and predictive performance, achieving\nan optimal balance of accuracy, robustness, and efficiency. These findings\nhighlight the critical need for quantization-aware, robustness-preserving\nfine-tuning methodologies to enable the robust and efficient deployment of LLMs\nfor cybersecurity QA.", "AI": {"tldr": "\u5bf9\u6bd4\u56db\u79cd\u914d\u7f6e\u7684\u57fa\u51c6\u6d4b\u8bd5\u8868\u660e\uff1a\u91cf\u5316\u5e26\u6765\u6548\u7387\u4f46\u727a\u7272\u8868\u73b0\uff0c\u5fae\u8c03\u53ef\u6062\u590d\u6027\u80fd\uff0c\u4e14\u5fae\u8c03\u540e\u518d\u91cf\u5316\u662f\u5b9e\u73b0\u8fb9\u7f18\u90e8\u7f72\u7684\u6700\u4f73\u7b56\u7565\u3002", "motivation": "\u52a8\u673a\u662f\u5f53\u524dLLM\u5728\u7f51\u7edc\u5b89\u5168\u95ee\u7b54\u4e2d\u8868\u73b0\u826f\u597d\u4f46\u8ba1\u7b97\u8d44\u6e90\u9700\u6c42\u9ad8\uff0c\u96be\u4ee5\u90e8\u7f72\u5230\u8fb9\u7f18\u53d7\u9650\u8bbe\u5907\uff1b\u91cf\u5316\u80fd\u51cf\u8f7b\u8d44\u6e90\u8d1f\u62c5\u4f46\u53ef\u80fd\u635f\u5bb3\u6027\u80fd\u5e76\u589e\u5927\u5bf9\u6297\u8106\u5f31\u6027\uff0c\u4e14\u5c1a\u4e0d\u6e05\u695a\u5fae\u8c03\u5728\u91cf\u5316\u60c5\u5883\u4e0b\u7684\u6548\u679c\u4e0e\u6743\u8861\u3002", "method": "\u63d0\u51faAQUA-LLM\u8bc4\u4f30\u6846\u67b6\uff0c\u5bf9\u82e5\u5e72\u6700\u5148\u8fdb\u5c0f\u578bLLM\u5728\u56db\u79cd\u914d\u7f6e\uff08\u539f\u59cb\u3001\u4ec5\u91cf\u5316\u3001\u4ec5\u5fae\u8c03\u3001\u5fae\u8c03\u540e\u91cf\u5316\uff09\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8bc4\u4f30\u6307\u6807\u5305\u62ec\u51c6\u786e\u7387\u3001\u9c81\u68d2\u6027\uff08\u5bf9\u6297/\u566a\u58f0\u653b\u51fb\u8868\u73b0\uff09\u4e0e\u6548\u7387\uff08\u6a21\u578b\u5927\u5c0f\u3001\u5ef6\u8fdf\u3001\u8ba1\u7b97\u5f00\u9500\uff09\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff1a\u5355\u72ec\u91cf\u5316\u63d0\u9ad8\u6548\u7387\u4f46\u5bfc\u81f4\u6700\u4f4e\u7684\u51c6\u786e\u6027\u4e0e\u9c81\u68d2\u6027\uff1b\u800c\u91cf\u5316\u4e0e\u5fae\u8c03\u7ed3\u5408\u80fd\u663e\u8457\u63d0\u5347\u9c81\u68d2\u6027\u4e0e\u9884\u6d4b\u6027\u80fd\uff0c\u5728\u51c6\u786e\u7387\u3001\u9c81\u68d2\u6027\u548c\u6548\u7387\u4e0a\u8fbe\u6210\u6700\u4f73\u6298\u8877\u3002", "conclusion": "\u672c\u6587\u7ed3\u8bba\u662f\uff1a\u5728\u7f51\u7edc\u5b89\u5168\u95ee\u7b54\u573a\u666f\u4e0b\uff0c\u5bf9\u5c0f\u578bLLM\u8fdb\u884c\u91cf\u5316\u53ef\u663e\u8457\u63d0\u5347\u6548\u7387\u4f46\u4f1a\u964d\u4f4e\u51c6\u786e\u6027\u4e0e\u9c81\u68d2\u6027\uff1b\u5c06\u91cf\u5316\u4e0e\u5fae\u8c03\u7ed3\u5408\u53ef\u5728\u7cbe\u5ea6\u3001\u9c81\u68d2\u6027\u4e0e\u6548\u7387\u4e4b\u95f4\u53d6\u5f97\u66f4\u597d\u5e73\u8861\uff0c\u8868\u660e\u9700\u8981\u9762\u5411\u91cf\u5316\u611f\u77e5\u4e14\u4fdd\u6301\u9c81\u68d2\u6027\u7684\u5fae\u8c03\u65b9\u6cd5\u3002"}}
{"id": "2509.13520", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.13520", "abs": "https://arxiv.org/abs/2509.13520", "authors": ["Varun Kumar", "Jing Bi", "Cyril Ngo Ngoc", "Victor Oancea", "George Em Karniadakis"], "title": "Learning Nonlinear Responses in PET Bottle Buckling with a Hybrid DeepONet-Transolver Framework", "comment": null, "summary": "Neural surrogates and operator networks for solving partial differential\nequation (PDE) problems have attracted significant research interest in recent\nyears. However, most existing approaches are limited in their ability to\ngeneralize solutions across varying non-parametric geometric domains. In this\nwork, we address this challenge in the context of Polyethylene Terephthalate\n(PET) bottle buckling analysis, a representative packaging design problem\nconventionally solved using computationally expensive finite element analysis\n(FEA). We introduce a hybrid DeepONet-Transolver framework that simultaneously\npredicts nodal displacement fields and the time evolution of reaction forces\nduring top load compression. Our methodology is evaluated on two families of\nbottle geometries parameterized by two and four design variables. Training data\nis generated using nonlinear FEA simulations in Abaqus for 254 unique designs\nper family. The proposed framework achieves mean relative $L^{2}$ errors of\n2.5-13% for displacement fields and approximately 2.4% for time-dependent\nreaction forces for the four-parameter bottle family. Point-wise error analyses\nfurther show absolute displacement errors on the order of $10^{-4}$-$10^{-3}$,\nwith the largest discrepancies confined to localized geometric regions.\nImportantly, the model accurately captures key physical phenomena, such as\nbuckling behavior, across diverse bottle geometries. These results highlight\nthe potential of our framework as a scalable and computationally efficient\nsurrogate, particularly for multi-task predictions in computational mechanics\nand applications requiring rapid design evaluation.", "AI": {"tldr": "\u63d0\u51fa\u6df7\u5408DeepONet-Transolver\u4ee3\u7406\u7528\u4e8ePET\u74f6\u5c48\u66f2\u5206\u6790\uff0c\u5728254\u4e2a\u8bbe\u8ba1\u6837\u672c\u4e0a\u5bf9\u4f4d\u79fb\u573a\u548c\u65f6\u95f4\u4f9d\u8d56\u53cd\u4f5c\u7528\u529b\u5b9e\u73b0\u4f4e\u8bef\u5dee\u3001\u591a\u4efb\u52a1\u5feb\u901f\u9884\u6d4b\uff0c\u53ef\u4f5c\u4e3aFEA\u7684\u9ad8\u6548\u66ff\u4ee3\u7528\u4e8e\u8bbe\u8ba1\u7a7a\u95f4\u641c\u7d22\u3002", "motivation": "\u73b0\u6709\u795e\u7ecf\u4ee3\u7406\u4e0e\u7b97\u5b50\u7f51\u7edc\u5728\u4e0d\u540c\u975e\u53c2\u6570\u5316\u51e0\u4f55\u57df\u4e0a\u7684\u6cdb\u5316\u80fd\u529b\u6709\u9650\uff0c\u800cPET\u74f6\u5c48\u66f2\u95ee\u9898\u5728\u5305\u88c5\u8bbe\u8ba1\u4e2d\u5e38\u9700\u5927\u91cf\u4eff\u771f\uff0c\u4e9f\u9700\u5feb\u901f\u3001\u53ef\u6269\u5c55\u7684\u4ee3\u7406\u6a21\u578b\u4ee5\u51cf\u5c11\u8ba1\u7b97\u6210\u672c\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u6df7\u5408DeepONet-Transolver\u6846\u67b6\uff0c\u8bad\u7ec3\u6570\u636e\u901a\u8fc7Abaqus\u4e2d\u5bf9\u4e24\u4e2a\u53c2\u6570\u5316\u74f6\u65cf\uff08\u5206\u522b\u75312\u548c4\u4e2a\u8bbe\u8ba1\u53d8\u91cf\u63cf\u8ff0\uff09\u8fdb\u884c\u975e\u7ebf\u6027\u6709\u9650\u5143\u6a21\u62df\u83b7\u5f97\uff0c\u5171254\u4e2a\u8bbe\u8ba1\u6837\u672c\uff1b\u6a21\u578b\u540c\u65f6\u56de\u5f52\u8282\u70b9\u4f4d\u79fb\u573a\u548c\u968f\u65f6\u95f4\u53d8\u5316\u7684\u53cd\u4f5c\u7528\u529b\u3002", "result": "\u56db\u53c2\u6570\u74f6\u65cf\u7684\u5e73\u5747\u76f8\u5bf9L2\u8bef\u5dee\u57282.5%~13%\u4e4b\u95f4\uff08\u4f4d\u79fb\u573a\uff09\uff0c\u65f6\u95f4\u4f9d\u8d56\u7684\u53cd\u4f5c\u7528\u529b\u7ea6\u4e3a2.4%\uff1b\u9010\u70b9\u7edd\u5bf9\u4f4d\u79fb\u8bef\u5dee\u57281e-4~1e-3\u8303\u56f4\uff0c\u8bef\u5dee\u4e3b\u8981\u96c6\u4e2d\u5728\u5c40\u90e8\u51e0\u4f55\u533a\u57df\uff1b\u6a21\u578b\u80fd\u51c6\u786e\u6355\u6349\u5c48\u66f2\u884c\u4e3a\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u5c55\u793a\u4e86\u5c06\u795e\u7ecf\u7b97\u5b50\uff08DeepONet\uff09\u4e0e\u8f6c\u5bfc\u5668\uff08Transolver\uff09\u76f8\u7ed3\u5408\u7528\u4e8ePET\u74f6\u538b\u7f29\u5c48\u66f2\u5206\u6790\u7684\u6709\u6548\u6027\uff0c\u80fd\u591f\u5728\u4e0d\u540c\u51e0\u4f55\u57df\u4e0a\u540c\u65f6\u9884\u6d4b\u4f4d\u79fb\u573a\u4e0e\u65f6\u95f4\u6f14\u5316\u7684\u53cd\u4f5c\u7528\u529b\uff0c\u4ece\u800c\u4f5c\u4e3a\u4e00\u79cd\u9ad8\u6548\u7684\u66ff\u4ee3FEA\u7684\u4ee3\u7406\u6a21\u578b\u3002"}}
{"id": "2509.13627", "categories": ["cs.CR", "cs.AI", "cs.DC"], "pdf": "https://arxiv.org/pdf/2509.13627", "abs": "https://arxiv.org/abs/2509.13627", "authors": ["Vijay Kumar Butte", "Sujata Butte"], "title": "Secure, Scalable and Privacy Aware Data Strategy in Cloud", "comment": null, "summary": "The enterprises today are faced with the tough challenge of processing,\nstoring large amounts of data in a secure, scalable manner and enabling\ndecision makers to make quick, informed data driven decisions. This paper\naddresses this challenge and develops an effective enterprise data strategy in\nthe cloud. Various components of an effective data strategy are discussed and\narchitectures addressing security, scalability and privacy aspects are\nprovided.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u5957\u9762\u5411\u4f01\u4e1a\u7684\u4e91\u6570\u636e\u7b56\u7565\u4e0e\u5206\u5c42\u67b6\u6784\uff0c\u7ed3\u5408\u4e91\u539f\u751f\u6280\u672f\u4e0e\u5b89\u5168\u9690\u79c1\u673a\u5236\uff0c\u89e3\u51b3\u5927\u89c4\u6a21\u6570\u636e\u7684\u5b89\u5168\u5b58\u50a8\u4e0e\u53ef\u6269\u5c55\u5904\u7406\uff0c\u652f\u6301\u5feb\u901f\u6570\u636e\u9a71\u52a8\u51b3\u7b56\u3002", "motivation": "\u4f01\u4e1a\u9762\u4e34\u6d77\u91cf\u6570\u636e\u7684\u5b58\u50a8\u4e0e\u5904\u7406\u6311\u6218\uff0c\u540c\u65f6\u9700\u786e\u4fdd\u6570\u636e\u5b89\u5168\u4e0e\u9690\u79c1\uff0c\u4e14\u51b3\u7b56\u8005\u8981\u6c42\u53ca\u65f6\u3001\u53ef\u9760\u7684\u6570\u636e\u652f\u6301\u3002\u4e3a\u6b64\u9700\u8981\u5728\u4e91\u4e0a\u8bbe\u8ba1\u4e00\u5957\u517c\u987e\u5b89\u5168\u3001\u53ef\u6269\u5c55\u4e0e\u9690\u79c1\u4fdd\u62a4\u7684\u4f01\u4e1a\u6570\u636e\u7b56\u7565\u3002", "method": "\u901a\u8fc7\u5206\u6790\u4f01\u4e1a\u6570\u636e\u9700\u6c42\uff0c\u6784\u5efa\u5305\u542b\u6570\u636e\u91c7\u96c6\u3001\u5b58\u50a8\u3001\u5904\u7406\u3001\u6cbb\u7406\u548c\u8bbf\u95ee\u63a7\u5236\u7684\u5206\u5c42\u67b6\u6784\uff0c\u7ed3\u5408\u4e91\u539f\u751f\u670d\u52a1\uff08\u5982\u5206\u5e03\u5f0f\u5b58\u50a8\u3001\u5f39\u6027\u8ba1\u7b97\u3001\u52a0\u5bc6\u4e0e\u8eab\u4efd\u7ba1\u7406\uff09\u5e76\u63d0\u51fa\u5b89\u5168\u4e0e\u9690\u79c1\u4fdd\u62a4\u673a\u5236\uff08\u4f8b\u5982\u6570\u636e\u52a0\u5bc6\u3001\u7ec6\u7c92\u5ea6\u8bbf\u95ee\u63a7\u5236\u3001\u5dee\u5206\u9690\u79c1\u6216\u533f\u540d\u5316\uff09\u3002\u8bba\u6587\u8fd8\u63d0\u4f9b\u4e86\u67b6\u6784\u90e8\u7f72\u65b9\u6848\u4e0e\u53ef\u6269\u5c55\u6027\u8bbe\u8ba1\u6a21\u5f0f\u3002", "result": "\u8bba\u6587\u7ed9\u51fa\u82e5\u5e72\u67b6\u6784\u56fe\u4e0e\u7ec4\u4ef6\u8bf4\u660e\uff0c\u5c55\u793a\u4e86\u5982\u4f55\u5728\u4e91\u73af\u5883\u4e0b\u5b9e\u73b0\u5b89\u5168\u3001\u53ef\u6269\u5c55\u4e14\u652f\u6301\u9690\u79c1\u4fdd\u62a4\u7684\u4f01\u4e1a\u6570\u636e\u5e73\u53f0\uff0c\u5e76\u8bf4\u660e\u5176\u80fd\u63d0\u9ad8\u51b3\u7b56\u6548\u7387\u4e0e\u7cfb\u7edf\u5f39\u6027\uff08\u6587\u4e2d\u53ef\u80fd\u5305\u542b\u6848\u4f8b\u6216\u6027\u80fd\u8bc4\u4f30\u4ee5\u9a8c\u8bc1\u8bbe\u8ba1\uff09\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u5e76\u5b9e\u73b0\u4e86\u4e00\u4e2a\u9762\u5411\u4f01\u4e1a\u7684\u4e91\u6570\u636e\u7b56\u7565\u6846\u67b6\uff0c\u65e8\u5728\u89e3\u51b3\u5927\u89c4\u6a21\u6570\u636e\u5904\u7406\u3001\u5b58\u50a8\u7684\u5b89\u5168\u6027\u3001\u53ef\u6269\u5c55\u6027\u548c\u9690\u79c1\u4fdd\u62a4\u95ee\u9898\uff0c\u4ece\u800c\u652f\u6301\u9ad8\u6548\u7684\u6570\u636e\u9a71\u52a8\u51b3\u7b56\u3002"}}
{"id": "2509.13341", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.13341", "abs": "https://arxiv.org/abs/2509.13341", "authors": ["Ahmet H. G\u00fczel", "Matthew Thomas Jackson", "Jarek Luca Liesen", "Tim Rockt\u00e4schel", "Jakob Nicolaus Foerster", "Ilija Bogunovic", "Jack Parker-Holder"], "title": "Imagined Autocurricula", "comment": null, "summary": "Training agents to act in embodied environments typically requires vast\ntraining data or access to accurate simulation, neither of which exists for\nmany cases in the real world. Instead, world models are emerging as an\nalternative leveraging offline, passively collected data, they make it possible\nto generate diverse worlds for training agents in simulation. In this work, we\nharness world models to generate imagined environments to train robust agents\ncapable of generalizing to novel task variations. One of the challenges in\ndoing this is ensuring the agent trains on useful generated data. We thus\npropose a novel approach, IMAC (Imagined Autocurricula), leveraging\nUnsupervised Environment Design (UED), which induces an automatic curriculum\nover generated worlds. In a series of challenging, procedurally generated\nenvironments, we show it is possible to achieve strong transfer performance on\nheld-out environments, having trained only inside a world model learned from a\nnarrower dataset. We believe this opens the path to utilizing larger-scale,\nfoundation world models for generally capable agents.", "AI": {"tldr": "\u901a\u8fc7\u5728\u5b66\u5230\u7684\u4e16\u754c\u6a21\u578b\u4e2d\u7ed3\u5408\u65e0\u76d1\u7763\u73af\u5883\u8bbe\u8ba1\u5f62\u6210\u81ea\u52a8\u8bfe\u7a0b\uff0cIMAC\u80fd\u5728\u60f3\u8c61\u73af\u5883\u4e2d\u8bad\u7ec3\u51fa\u80fd\u6cdb\u5316\u5230\u672a\u89c1\u4efb\u52a1\u53d8\u4f53\u7684\u9c81\u68d2\u4ee3\u7406\u3002", "motivation": "\u73b0\u5b9e\u4e2d\u7f3a\u4e4f\u5927\u91cf\u4ea4\u4e92\u6570\u636e\u6216\u9ad8\u4fdd\u771f\u6a21\u62df\uff0c\u96be\u4ee5\u8bad\u7ec3\u80fd\u6cdb\u5316\u7684\u4ee3\u7406\u3002\u4e16\u754c\u6a21\u578b\u53ef\u5229\u7528\u79bb\u7ebf\u88ab\u52a8\u6570\u636e\u751f\u6210\u591a\u6837\u5316\u8bad\u7ec3\u73af\u5883\uff0c\u4f46\u9700\u786e\u4fdd\u751f\u6210\u6570\u636e\u5bf9\u5b66\u4e60\u6709\u5229\uff0c\u56e0\u6b64\u5f15\u5165\u81ea\u52a8\u8bfe\u7a0b\u4ee5\u5f15\u5bfc\u8bad\u7ec3\u3002", "method": "\u65b9\u6cd5\u4e3aIMAC\uff08Imagined Autocurricula\uff09\uff1a\u9996\u5148\u5b66\u4e60\u4e00\u4e2a\u57fa\u4e8e\u79bb\u7ebf\u88ab\u52a8\u6570\u636e\u7684\u4e16\u754c\u6a21\u578b\uff0c\u7528\u8be5\u6a21\u578b\u751f\u6210\u591a\u6837\u5316\u7684\u60f3\u8c61\u73af\u5883\uff1b\u5176\u6b21\u5f15\u5165UED\u5728\u751f\u6210\u73af\u5883\u4e0a\u81ea\u52a8\u521b\u5efa\u96be\u5ea6\u8fdb\u5316\u7684\u8bfe\u7a0b\u4ee5\u4fdd\u8bc1\u8bad\u7ec3\u6570\u636e\u6709\u7528\uff1b\u6700\u540e\u5728\u8fd9\u4e9b\u60f3\u8c61\u73af\u5883\u4e2d\u8bad\u7ec3\u4ee3\u7406\u5e76\u5728\u771f\u5b9e\u6216\u66f4\u5e7f\u7684\u7a0b\u5e8f\u751f\u6210\u73af\u5883\u4e2d\u8bc4\u4f30\u5176\u8fc1\u79fb\u80fd\u529b\u3002", "result": "\u5728\u4e00\u7cfb\u5217\u5177\u6709\u6311\u6218\u6027\u7684\u7a0b\u5e8f\u5316\u73af\u5883\u4e2d\uff0cIMAC\u5728\u4ec5\u4f7f\u7528\u4ece\u8f83\u7a84\u6570\u636e\u5b66\u4e60\u7684\u4e16\u754c\u6a21\u578b\u8bad\u7ec3\u7684\u60c5\u51b5\u4e0b\uff0c\u4ecd\u5728\u672a\u89c1\u73af\u5883\u4e0a\u53d6\u5f97\u4e86\u5f3a\u8fc1\u79fb\u6027\u80fd\uff0c\u8868\u660e\u8be5\u65b9\u6cd5\u80fd\u63d0\u9ad8\u6cdb\u5316\u80fd\u529b\u5e76\u4e3a\u5229\u7528\u66f4\u5927\u89c4\u6a21\u57fa\u7840\u4e16\u754c\u6a21\u578b\u5f00\u8f9f\u8def\u5f84\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u901a\u8fc7\u5728\u4e16\u754c\u6a21\u578b\u4e2d\u751f\u6210\u60f3\u8c61\u73af\u5883\u5e76\u7ed3\u5408\u65e0\u76d1\u7763\u73af\u5883\u8bbe\u8ba1\uff08UED\uff09\u5f62\u6210\u81ea\u52a8\u8bfe\u7a0b\uff0c\u4ece\u800c\u8bad\u7ec3\u80fd\u5728\u65b0\u4efb\u52a1\u53d8\u4f53\u4e0a\u6cdb\u5316\u7684\u9c81\u68d2\u4ee3\u7406\u3002\u5b9e\u9a8c\u8868\u660e\u5728\u7a0b\u5e8f\u751f\u6210\u73af\u5883\u4e2d\uff0c\u4ece\u8f83\u7a84\u6570\u636e\u5b66\u4e60\u7684\u4e16\u754c\u6a21\u578b\u4e2d\u8bad\u7ec3\u4ecd\u53ef\u8fc1\u79fb\u5230\u672a\u89c1\u73af\u5883\u3002"}}
{"id": "2509.13724", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2509.13724", "abs": "https://arxiv.org/abs/2509.13724", "authors": ["Jan Janak", "Kahlil Dozier", "Lauren Berny", "Liang Hu", "Dan Rubenstein", "Charles Jennings", "Henning Schulzrinne"], "title": "Conducting Mission-Critical Voice Experiments with Automated Speech Recognition and Crowdsourcing", "comment": null, "summary": "Mission-critical voice (MCV) communications systems have been a critical tool\nfor the public safety community for over eight decades. Public safety users\nexpect MCV systems to operate reliably and consistently, particularly in\nchallenging conditions. Because of these expectations, the Public Safety\nCommunications Research (PSCR) Division of the National Institute of Standards\nand Technology (NIST) has been interested in correlating impairments in MCV\ncommunication systems and public safety user quality of experience (QoE).\nPrevious research has studied MCV voice quality and intelligibility in a\ncontrolled environment. However, such research has been limited by the\nchallenges inherent in emulating real-world environmental conditions.\nAdditionally, there is the question of the best metric to use to reflect QoE\naccurately.\n  This paper describes our efforts to develop the methodology and tools for\nhuman-subject experiments with MCV. We illustrate their use in human-subject\nexperiments in emulated real-world environments. The tools include a testbed\nfor emulating real-world MCV systems and an automated speech recognition (ASR)\nrobot approximating human subjects in transcription tasks. We evaluate QoE\nthrough a Levenshtein Distance-based metric, arguing it is a suitable proxy for\nmeasuring comprehension and the QoE. We conducted human-subject studies with\nAmazon MTurk volunteers to understand the influence of selected system\nparameters and impairments on human subject performance and end-user QoE. We\nalso compare the performance of several ASR system configurations with\nhuman-subject performance. We find that humans generally perform better than\nASR in accuracy-related MCV tasks and that the codec significantly influences\nthe end-user QoE and ASR performance.", "AI": {"tldr": "\u5efa\u7acb\u4e86\u7528\u4e8e\u4eff\u771f\u771f\u5b9e\u73af\u5883\u4e0bMCV\u4eba\u7c7b\u5b9e\u9a8c\u7684\u6d4b\u8bd5\u5e73\u53f0\u4e0e\u57fa\u4e8e\u7f16\u8f91\u8ddd\u79bb\u7684QoE\u6307\u6807\uff0c\u8bc1\u660e\u4eba\u7c7b\u5728\u51c6\u786e\u6027\u4e0a\u4f18\u4e8eASR\uff0c\u4e14codec\u5bf9\u4f53\u9a8c\u5f71\u54cd\u663e\u8457\u3002", "motivation": "\u516c\u5171\u5b89\u5168\u7528\u6237\u5bf9MCV\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u548c\u4e00\u81f4\u6027\u6709\u9ad8\u671f\u5f85\uff0c\u5148\u524d\u5728\u53d7\u63a7\u73af\u5883\u4e2d\u7684\u8bed\u97f3\u8d28\u91cf\u4e0e\u53ef\u61c2\u5ea6\u7814\u7a76\u96be\u4ee5\u5b8c\u5168\u6a21\u62df\u771f\u5b9e\u73af\u5883\uff0c\u540c\u65f6\u9700\u8981\u5408\u9002\u7684QoE\u91cf\u5316\u6307\u6807\u6765\u53cd\u6620\u7528\u6237\u4f53\u9a8c\u3002", "method": "\u6784\u5efa\u4eff\u771f\u6d4b\u8bd5\u5e73\u53f0\u4ee5\u91cd\u73b0\u771f\u5b9e\u4e16\u754cMCV\u7cfb\u7edf\u6761\u4ef6\uff1b\u4f7f\u7528\u57fa\u4e8eLevenshtein\u8ddd\u79bb\u7684\u5ea6\u91cf\u8bc4\u4f30\u8f6c\u5f55\u4e0e\u53ef\u61c2\u5ea6\uff1b\u90e8\u7f72ASR\u7cfb\u7edf\u591a\u79cd\u914d\u7f6e\u4e0eAmazon MTurk\u62db\u52df\u7684\u4eba\u7c7b\u53d7\u8bd5\u8005\u5e76\u884c\u6d4b\u8bd5\uff1b\u6bd4\u8f83ASR\u4e0e\u4eba\u7c7b\u5728\u4e0d\u540c\u7cfb\u7edf\u53c2\u6570\u4e0e\u5e72\u6270\u6761\u4ef6\u4e0b\u7684\u8868\u73b0\u3002", "result": "\u901a\u8fc7\u4eba\u7c7b\u53d7\u8bd5\u8005\u5b9e\u9a8c\u548cASR\u5bf9\u7167\uff0c\u53d1\u73b0\uff1a1\uff09\u4eba\u7c7b\u5728\u8f6c\u5f55\u51c6\u786e\u6027\u4e0a\u4f18\u4e8eASR\uff1b2\uff09\u97f3\u9891\u7f16\u7801\u5668\u5bf9\u53ef\u61c2\u5ea6\u548cASR\u8bef\u5dee\u7387\u6709\u663e\u8457\u5f71\u54cd\uff1b3\uff09\u57fa\u4e8eLevenshtein\u8ddd\u79bb\u7684\u6307\u6807\u53ef\u4f5c\u4e3a\u8bc4\u4f30\u7406\u89e3\u5ea6\u4e0eQoE\u7684\u5408\u7406\u4ee3\u7406\uff1b4\uff09\u6d4b\u8bd5\u5e73\u53f0\u4e0eASR\u673a\u5668\u4eba\u53ef\u7528\u4e8e\u5927\u89c4\u6a21\u6216\u81ea\u52a8\u5316\u5b9e\u9a8c\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u5957\u7528\u4e8eMCV\uff08\u4efb\u52a1\u5173\u952e\u8bed\u97f3\uff09\u4eba\u7c7b\u53d7\u8bd5\u8005\u5b9e\u9a8c\u7684\u5de5\u5177\u4e0e\u65b9\u6cd5\u8bba\uff0c\u5305\u542b\u771f\u5b9e\u73af\u5883\u4eff\u771f\u7684\u6d4b\u8bd5\u5e73\u53f0\u548c\u4ee5\u7f16\u8f91\u8ddd\u79bb\u4e3a\u57fa\u7840\u7684QoE\u8bc4\u4f30\u6307\u6807\uff0c\u5e76\u7528ASR\u673a\u5668\u4eba\u4f5c\u4e3a\u81ea\u52a8\u5316\u8fd1\u4f3c\u5bf9\u7167\u3002\u5b9e\u9a8c\u8bc1\u660e\uff1a\u4eba\u7c7b\u5728\u51c6\u786e\u6027\u76f8\u5173\u4efb\u52a1\u4e0a\u901a\u5e38\u4f18\u4e8eASR\uff1b\u7f16\u7801\u5668\uff08codec\uff09\u5bf9\u7528\u6237QoE\u548cASR\u8868\u73b0\u5f71\u54cd\u663e\u8457\u3002"}}
{"id": "2509.13561", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.13561", "abs": "https://arxiv.org/abs/2509.13561", "authors": ["Mengxiao Wang", "Guofei Gu"], "title": "GuardianPWA: Enhancing Security Throughout the Progressive Web App Installation Lifecycle", "comment": null, "summary": "Progressive Web App (PWA) installation is critical for integrating web and\nmobile app functionalities, offering a seamless user experience. However,\nensuring the security of the PWA installation lifecycle is essential for\nmaintaining user trust and privacy. This paper introduces the GUARDIANPWA\nframework, a comprehensive approach to analyzing the PWA installation mechanism\nbased on the CIA security principles (Confidentiality, Integrity, and\nAvailability) and identifying areas where browser vendors fail to comply with\nthese principles. Our study revealed 203 instances of non-compliance with\nsecurity principles, highlighting how these irregularities in the PWA\ninstallation lifecycle can lead to potential violations of user privacy. For\ninstance, in Firefox, PWAs installed in private mode incorrectly appear in\nnormal mode, risking user confidentiality. Additionally, 29,465 PWAs are at\nrisk because Samsung Internet does not display origins when PWAs navigate to\nthird-party websites, undermining integrity. These findings were reported to\nbrowser vendors, leading to Firefox acknowledging four issues, resolving one,\nand planning to resolve two others. GUARDIANPWA supports developers by\nanalyzing PWA manifest files for syntactic and semantic correctness, offering\nactionable recommendations, and helping to create PWAs that align with security\nbest practices. By using GUARDIANPWA, developers and users can address critical\nsecurity gaps and enhance compliance with CIA principles throughout the PWA\ninstallation lifecycle.", "AI": {"tldr": "GUARDIANPWA\u57fa\u65bcCIA\u539f\u5247\u6aa2\u6e2cPWA\u5b89\u88dd\u5b89\u5168\uff0c\u627e\u51fa\u5927\u91cf\u700f\u89bd\u5668\u4e0d\u5408\u898f\u554f\u984c\uff0c\u4e26\u63d0\u4f9bmanifest\u6aa2\u67e5\u8207\u4fee\u5fa9\u5efa\u8b70\uff0c\u5df2\u4fc3\u6210\u90e8\u5206\u6f0f\u6d1e\u4fee\u88dc\u3002", "motivation": "PWA\u4f5c\u70ba\u9023\u63a5\u7db2\u9801\u8207\u884c\u52d5\u61c9\u7528\u7684\u91cd\u8981\u5f62\u5f0f\uff0c\u5176\u5b89\u88dd\u6a5f\u5236\u82e5\u4e0d\u5b89\u5168\u6703\u5371\u53ca\u7528\u6236\u96b1\u79c1\u8207\u4fe1\u4efb\uff1b\u73fe\u6709\u700f\u89bd\u5668\u5be6\u4f5c\u53ef\u80fd\u9055\u80ccCIA\u539f\u5247\uff0c\u9700\u7cfb\u7d71\u5316\u6aa2\u6e2c\u8207\u4fee\u6b63\u5efa\u8b70\u3002", "method": "\u63d0\u51faGUARDIANPWA\u6846\u67b6\uff0c\u57fa\u65bcCIA\u4e09\u539f\u5247\u5c0dPWA\u5b89\u88dd\u6d41\u7a0b\u9032\u884c\u7cfb\u7d71\u5316\u5206\u6790\uff0c\u6383\u63cf\u5927\u91cf\u700f\u89bd\u5668\u884c\u70ba\u8207manifest\u6587\u4ef6\uff0c\u8b58\u5225\u4e0d\u5408\u898f\u6848\u4f8b\u4e26\u5411\u5ee0\u5546\u56de\u5831\uff1b\u540c\u6642\u63d0\u4f9bmanifest\u8a9e\u6cd5\u8207\u8a9e\u7fa9\u6aa2\u67e5\u8207\u5efa\u8b70\u3002", "result": "\u767c\u73fe203\u8655\u5b89\u5168\u539f\u5247\u4e0d\u5408\u898f\u6848\u4f8b\uff08\u5982Firefox\u79c1\u5bc6\u6a21\u5f0f\u5b89\u88dd\u5728\u666e\u901a\u6a21\u5f0f\u986f\u793a\u3001Samsung Internet\u4e0d\u986f\u793a\u7b2c\u4e09\u65b9\u5c0e\u5411\u6642\u7684origin\uff09\uff0c\u5f71\u97ff29,465\u500bPWA\uff1b\u5411\u5ee0\u5546\u901a\u5831\u5f8cFirefox\u627f\u8a8d4\u500b\u554f\u984c\u4e26\u5df2\u4fee\u5fa91\u9805\u3001\u8a08\u5283\u4fee\u5fa92\u9805\u3002", "conclusion": "GUARDIANPWA\u63ed\u793a\u4e26\u91cf\u5316\u4e86PWA\u5b89\u88dd\u751f\u547d\u5468\u671f\u4e2d\u9055\u53cd\u6a5f\u5bc6\u6027\u3001\u5b8c\u6574\u6027\u8207\u53ef\u7528\u6027\uff08CIA\uff09\u539f\u5247\u7684\u591a\u9805\u554f\u984c\uff0c\u4e26\u4fc3\u6210\u4f9b\u61c9\u5546\u4fee\u88dc\u90e8\u5206\u6f0f\u6d1e\uff0c\u80fd\u8f14\u52a9\u958b\u767c\u8005\u6539\u5584manifest\u4e26\u63d0\u5347\u5b89\u5168\u6027\u3002"}}
{"id": "2509.13739", "categories": ["cs.LG", "cs.DC"], "pdf": "https://arxiv.org/pdf/2509.13739", "abs": "https://arxiv.org/abs/2509.13739", "authors": ["Zihou Wu", "Yuecheng Li", "Tianchi Liao", "Jian Lou", "Chuan Chen"], "title": "ParaAegis: Parallel Protection for Flexible Privacy-preserved Federated Learning", "comment": "8 pages, 1 figure", "summary": "Federated learning (FL) faces a critical dilemma: existing protection\nmechanisms like differential privacy (DP) and homomorphic encryption (HE)\nenforce a rigid trade-off, forcing a choice between model utility and\ncomputational efficiency. This lack of flexibility hinders the practical\nimplementation. To address this, we introduce ParaAegis, a parallel protection\nframework designed to give practitioners flexible control over the\nprivacy-utility-efficiency balance. Our core innovation is a strategic model\npartitioning scheme. By applying lightweight DP to the less critical, low norm\nportion of the model while protecting the remainder with HE, we create a\ntunable system. A distributed voting mechanism ensures consensus on this\npartitioning. Theoretical analysis confirms the adjustments between efficiency\nand utility with the same privacy. Crucially, the experimental results\ndemonstrate that by adjusting the hyperparameters, our method enables flexible\nprioritization between model accuracy and training time.", "AI": {"tldr": "\u63d0\u51faParaAegis\uff0c\u4e00\u79cd\u5728\u8054\u90a6\u5b66\u4e60\u4e2d\u901a\u8fc7\u6a21\u578b\u5206\u533a\u5e76\u884c\u5e94\u7528\u5dee\u5206\u9690\u79c1\u4e0e\u540c\u6001\u52a0\u5bc6\u7684\u7075\u6d3b\u4fdd\u62a4\u6846\u67b6\uff0c\u53ef\u5728\u9690\u79c1\u3001\u6548\u7528\u4e0e\u6548\u7387\u4e4b\u95f4\u8c03\u8282\u6743\u8861\u3002", "motivation": "\u73b0\u6709\u8054\u90a6\u5b66\u4e60\u7684\u4fdd\u62a4\u673a\u5236\uff08DP\u6216HE\uff09\u5728\u6548\u7528\u4e0e\u6548\u7387\u4e0a\u5b58\u5728\u521a\u6027\u6298\u4e2d\uff0c\u964d\u4f4e\u4e86\u5b9e\u9645\u53ef\u7528\u6027\uff0c\u6545\u9700\u4e00\u79cd\u53ef\u8c03\u8282\u7684\u4fdd\u62a4\u6846\u67b6\u4ee5\u6ee1\u8db3\u4e0d\u540c\u573a\u666f\u9700\u6c42\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u6a21\u578b\u53c2\u6570\u8303\u6570\u7684\u5206\u533a\u7b56\u7565\uff0c\u5c06\u53c2\u6570\u6309\u91cd\u8981\u6027\u5206\u4e3a\u4f4e\u8303\u6570\uff08\u8f7bDP\uff09\u4e0e\u9ad8\u8303\u6570\uff08HE\uff09\u4e24\u90e8\u5206\uff1b\u4f7f\u7528\u5206\u5e03\u5f0f\u6295\u7968\u673a\u5236\u8fbe\u6210\u5168\u5c40\u5206\u533a\u4e00\u81f4\u6027\uff1b\u7406\u8bba\u63a8\u5bfc\u8868\u660e\u5728\u56fa\u5b9a\u9690\u79c1\u7ea6\u675f\u4e0b\u53ef\u901a\u8fc7\u8d85\u53c2\u8c03\u8282\u5f71\u54cd\u6548\u7528\u4e0e\u8ba1\u7b97\u5f00\u9500\uff1b\u5728\u5b9e\u9a8c\u4e2d\u9a8c\u8bc1\u4e86\u4e0d\u540c\u8d85\u53c2\u8bbe\u7f6e\u4e0b\u7684\u51c6\u786e\u7387\u4e0e\u8bad\u7ec3\u65f6\u95f4\u53d8\u5316\u3002", "result": "\u7406\u8bba\u4e0e\u5b9e\u9a8c\u7ed3\u679c\u5747\u8868\u660eParaAegis\u80fd\u5728\u76f8\u540c\u9690\u79c1\u6c34\u5e73\u4e0b\u901a\u8fc7\u8c03\u6574\u5206\u533a\u4e0e\u566a\u58f0\u8d85\u53c2\uff0c\u5728\u6a21\u578b\u51c6\u786e\u7387\u4e0e\u8bad\u7ec3\u65f6\u95f4\u4e4b\u95f4\u5b9e\u73b0\u5e73\u6ed1\u53ef\u63a7\u7684\u6743\u8861\u3002", "conclusion": "ParaAegis\u901a\u8fc7\u5bf9\u6a21\u578b\u4f4e\u8303\u6570\u90e8\u5206\u4f7f\u7528\u8f7b\u91cf\u7ea7\u5dee\u5206\u9690\u79c1\u3001\u5bf9\u5176\u4f59\u90e8\u5206\u4f7f\u7528\u540c\u6001\u52a0\u5bc6\uff0c\u5e76\u7ed3\u5408\u5206\u5e03\u5f0f\u6295\u7968\u51b3\u5b9a\u5206\u533a\uff0c\u5b9e\u73b0\u5728\u76f8\u540c\u9690\u79c1\u9884\u7b97\u4e0b\u5728\u51c6\u786e\u7387\u4e0e\u8bad\u7ec3\u65f6\u95f4\u4e4b\u95f4\u53ef\u8c03\u7684\u6298\u4e2d\u65b9\u6848\u3002"}}
{"id": "2509.13347", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.13347", "abs": "https://arxiv.org/abs/2509.13347", "authors": ["Zihao Wang", "Muyao Li", "Kaichen He", "Xiangyu Wang", "Zhancun Mu", "Anji Liu", "Yitao Liang"], "title": "OpenHA: A Series of Open-Source Hierarchical Agentic Models in Minecraft", "comment": null, "summary": "The choice of action spaces is a critical yet unresolved challenge in\ndeveloping capable, end-to-end trainable agents. This paper first presents a\nlarge-scale, systematic comparison of prominent abstracted action spaces and\ntokenizers for Vision-Language-Action (VLA) or hierarchical agent models in the\nopen-ended Minecraft. Our analysis reveals that no single action space is\nuniversally optimal; instead, the most effective abstraction is highly\ntask-dependent, creating a dilemma for building generalist agents. To resolve\nthis, we introduce Chain of Action (CoA), a novel framework that unifies\nhigh-level planning and low-level control within a single, monolithic VLA\nmodel. CoA treats an abstracted action not as a command for a separate policy,\nbut as an intermediate reasoning step--akin to a chain of thought--that guides\nthe generation of the final, executable action. Furthermore, we demonstrate\nthat an All-in-One agent trained on a diverse mixture of action spaces using\nthe CoA paradigm learns a more robust and generalizable policy. This unified\nagent achieves a new state-of-the-art, improving the overall task success rate\nover strong, specialized baselines. To foster reproducible research, we release\nthe OpenHA (Open Hierarchical Agents) suite, which includes our comprehensive\nbenchmark of over 800 distinct tasks, curated datasets, source code, and all\npretrained model checkpoints at https://github.com/CraftJarvis/OpenHA", "AI": {"tldr": "\u8bba\u6587\u5728Minecraft\u4e0a\u7cfb\u7edf\u6bd4\u8f83\u52a8\u4f5c\u62bd\u8c61\uff0c\u63d0\u51faChain of Action\uff1a\u628a\u62bd\u8c61\u52a8\u4f5c\u4f5c\u4e3a\u4e2d\u95f4\u63a8\u7406\u5e76\u5728\u5355\u6a21\u578b\u5185\u7edf\u4e00\u89c4\u5212\u4e0e\u63a7\u5236\uff0c\u901a\u8fc7\u5728\u6df7\u5408\u52a8\u4f5c\u7a7a\u95f4\u4e0a\u8bad\u7ec3\u7684All-in-One\u4ee3\u7406\u63d0\u5347\u6cdb\u5316\u5e76\u8fbeSOTA\uff0c\u540c\u65f6\u53d1\u5e03OpenHA\u57fa\u51c6\u3002", "motivation": "\u52a8\u4f5c\u7a7a\u95f4\u7684\u9009\u62e9\u5bf9\u7aef\u5230\u7aef\u53ef\u8bad\u7ec3\u4ee3\u7406\u6027\u80fd\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5728\u5f00\u653e\u5f0f\u4efb\u52a1\u4e2d\u6ca1\u6709\u7edf\u4e00\u6700\u4f18\u7684\u62bd\u8c61\u65b9\u5f0f\uff0c\u5bfc\u81f4\u901a\u7528\u667a\u80fd\u4f53\u96be\u4ee5\u6784\u5efa\u3002\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u80fd\u5728\u4e0d\u540c\u4efb\u52a1\u95f4\u5171\u4eab\u5e76\u878d\u5408\u591a\u79cd\u52a8\u4f5c\u62bd\u8c61\u4ee5\u63d0\u9ad8\u6cdb\u5316\u6027\u3002", "method": "\u5927\u89c4\u6a21\u7cfb\u7edf\u6bd4\u8f83\u4e0d\u540c\u62bd\u8c61\u52a8\u4f5c\u7a7a\u95f4\u4e0etokenizer\uff0c\u5728\u8d85\u8fc7800\u4e2a\u4efb\u52a1\u7684Minecraft\u57fa\u51c6\u4e0a\u8bc4\u4f30\uff1b\u63d0\u51faCoA\u8303\u5f0f\uff0c\u5728\u5355\u4e00VLA\u6a21\u578b\u5185\u5c06\u62bd\u8c61\u52a8\u4f5c\u4f5c\u4e3a\u7c7b\u4f3cChain-of-Thought\u7684\u4e2d\u95f4\u8868\u793a\uff0c\u518d\u7531\u6a21\u578b\u751f\u6210\u6700\u7ec8\u53ef\u6267\u884c\u52a8\u4f5c\uff1b\u8bad\u7ec3\u4e00\u4e2aAll-in-One\u4ee3\u7406\u5728\u591a\u79cd\u52a8\u4f5c\u7a7a\u95f4\u6df7\u5408\u6570\u636e\u4e0a\u8fdb\u884c\u7aef\u5230\u7aef\u8bad\u7ec3\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u6ca1\u6709\u5355\u4e00\u52a8\u4f5c\u7a7a\u95f4\u5bf9\u6240\u6709\u4efb\u52a1\u6700\u4f18\uff1b\u91c7\u7528CoA\u5e76\u8bad\u7ec3All-in-One\u4ee3\u7406\u540e\uff0c\u5728\u6574\u4f53\u4efb\u52a1\u6210\u529f\u7387\u4e0a\u8d85\u8fc7\u5f3a\u57fa\u7ebf\u5e76\u8fbe\u65b0SOTA\u3002\u5f00\u6e90OpenHA\u5957\u4ef6\uff08800+\u4efb\u52a1\u3001\u6570\u636e\u96c6\u3001\u4ee3\u7801\u3001\u9884\u8bad\u7ec3\u6a21\u578b\uff09\u4ee5\u52a9\u590d\u73b0\u3002", "conclusion": "\u8be5\u8bba\u6587\u6307\u51fa\u5728\u5f00\u6e90\u3001\u5f00\u653e\u5f0f\u73af\u5883\uff08Minecraft\uff09\u4e2d\uff0c\u4e0d\u5b58\u5728\u5355\u4e00\u901a\u7528\u7684\u52a8\u4f5c\u62bd\u8c61\u6700\u4f18\u89e3\uff1b\u52a8\u4f5c\u7a7a\u95f4\u6548\u679c\u9ad8\u5ea6\u4f9d\u8d56\u4efb\u52a1\u3002\u4e3a\u89e3\u51b3\u6cdb\u5316\u95ee\u9898\uff0c\u63d0\u51faChain of Action\uff08CoA\uff09\u6846\u67b6\uff0c\u5c06\u62bd\u8c61\u52a8\u4f5c\u4f5c\u4e3a\u4e2d\u95f4\u63a8\u7406\u6b65\u9aa4\u800c\u975e\u72ec\u7acb\u7b56\u7565\u547d\u4ee4\uff0c\u7edf\u4e00\u9ad8\u5c42\u89c4\u5212\u4e0e\u4f4e\u5c42\u63a7\u5236\uff0c\u5e76\u901a\u8fc7\u5728\u6df7\u5408\u52a8\u4f5c\u7a7a\u95f4\u4e0a\u8bad\u7ec3\u7684All-in-One\u4ee3\u7406\u5b9e\u73b0\u66f4\u9c81\u68d2\u6cdb\u5316\uff0c\u53d6\u5f97SOTA\u6027\u80fd\u3002\u540c\u65f6\u53d1\u5e03OpenHA\u57fa\u51c6\u4e0e\u4ee3\u7801\u6570\u636e\u96c6\u3002"}}
{"id": "2509.13901", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2509.13901", "abs": "https://arxiv.org/abs/2509.13901", "authors": ["Saptarshi Ghosh", "Ioannis Mavromatis", "Konstantinos Antonakoglou", "Konstantinos Katsaros"], "title": "Performance Evaluation of Intent-Based Networking Scenarios: A GitOps and Nephio Approach", "comment": "Accepted for publication at IEEE CSCN 2025", "summary": "GitOps has emerged as a foundational paradigm for managing cloud-native\ninfrastructures by enabling declarative configuration, version-controlled\nstate, and automated reconciliation between intents and runtime deployments.\nDespite its widespread adoption, the performance and scalability of GitOps\ntools in Intent-Based Networking (IBN) scenarios are insufficiently evaluated.\nThis paper presents a reproducible, metric-driven benchmarking, assessing the\nlatency and resource overheads of three widely used GitOps operators: Argo CD,\nFlux CD, and ConfigSync. We conduct controlled experiments under both single-\nand multi-intent scenarios, capturing key performance indicators such as\nlatency and resource consumption. Our results highlight trade-offs between the\ntools in terms of determinism, resource efficiency, and responsiveness. We\nfurther investigate a realistic orchestration scenario, using Nephio as our\norchestrator, to quantify the processing latency and overhead in declarative\nend-to-end deployment pipelines. Our findings can offer valuable insights for\ntool selection and optimisation in future autonomous network orchestration\nsystems.", "AI": {"tldr": "\u5bf9Argo CD\u3001Flux CD\u4e0eConfigSync\u5728IBN\u573a\u666f\u4e0b\u8fdb\u884c\u6307\u6807\u9a71\u52a8\u57fa\u51c6\u6d4b\u8bd5\uff0c\u63ed\u793a\u4e09\u8005\u5728\u5ef6\u8fdf\u3001\u8d44\u6e90\u4e0e\u786e\u5b9a\u6027\u4e0a\u7684\u6743\u8861\uff0c\u5e76\u5728Nephio\u7f16\u6392\u4e0b\u8bc4\u4f30\u7aef\u5230\u7aef\u5f00\u9500\uff0c\u4e3a\u5de5\u5177\u9009\u62e9\u4e0e\u4f18\u5316\u63d0\u4f9b\u5b9e\u8bc1\u4f9d\u636e\u3002", "motivation": "\u5c3d\u7ba1GitOps\u5728\u4e91\u539f\u751f\u57fa\u7840\u8bbe\u65bd\u4e2d\u5e7f\u6cdb\u5e94\u7528\uff0c\u5176\u5728Intent-Based Networking\u573a\u666f\u4e0b\u7684\u6027\u80fd\u4e0e\u53ef\u6269\u5c55\u6027\u5c1a\u7f3a\u4e4f\u7cfb\u7edf\u8bc4\u4f30\uff0c\u5f71\u54cd\u5de5\u5177\u9009\u62e9\u4e0e\u4f18\u5316\u51b3\u7b56\u3002", "method": "\u8bbe\u8ba1\u53d7\u63a7\u5b9e\u9a8c\u5305\u542b\u5355\u610f\u56fe\u4e0e\u591a\u610f\u56fe\u573a\u666f\uff0c\u91c7\u96c6\u5173\u952e\u6027\u80fd\u6307\u6807\uff08\u5ef6\u8fdf\u4e0e\u8d44\u6e90\u6d88\u8017\uff09\uff0c\u5e76\u5728\u771f\u5b9e\u7f16\u6392\uff08Nephio\uff09\u573a\u666f\u4e0b\u6d4b\u91cf\u5904\u7406\u5ef6\u8fdf\uff1b\u4f7f\u7528\u53ef\u590d\u73b0\u7684\u6d4b\u8bd5\u5957\u4ef6\u548c\u91cf\u5316\u6307\u6807\u5bf9\u4e09\u6b3eGitOps operator\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff1a\u4e0d\u540cGitOps\u5de5\u5177\u5728\u786e\u5b9a\u6027\u3001\u8d44\u6e90\u5360\u7528\u548c\u54cd\u5e94\u901f\u5ea6\u4e0a\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff1b\u67d0\u4e9b\u5de5\u5177\u66f4\u8282\u7701\u8d44\u6e90\u4f46\u5ef6\u8fdf\u66f4\u9ad8\uff0c\u53e6\u4e00\u4e9b\u5de5\u5177\u54cd\u5e94\u66f4\u5feb\u4f46\u8d44\u6e90\u5f00\u9500\u66f4\u5927\uff1b\u5728Nephio\u7aef\u5230\u7aef\u573a\u666f\u4e2d\uff0c\u58f0\u660e\u5f0f\u7ba1\u9053\u5f15\u5165\u53ef\u89c2\u7684\u5904\u7406\u5ef6\u8fdf\uff0c\u9700\u8981\u5728\u5de5\u5177\u9009\u62e9\u548c\u8c03\u4f18\u4e2d\u6743\u8861\u3002", "conclusion": "\u672c\u6587\u901a\u8fc7\u53ef\u590d\u73b0\u3001\u57fa\u4e8e\u6307\u6807\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u6bd4\u8f83\u4e86Argo CD\u3001Flux CD\u548cConfigSync\u5728Intent-Based Networking\u60c5\u5883\u4e0b\u7684\u6027\u80fd\u4e0e\u53ef\u6269\u5c55\u6027\uff0c\u53d1\u73b0\u5404\u5de5\u5177\u5728\u786e\u5b9a\u6027\u3001\u8d44\u6e90\u6548\u7387\u4e0e\u54cd\u5e94\u6027\u95f4\u5b58\u5728\u6743\u8861\uff0c\u5e76\u5728Nephio\u7f16\u6392\u573a\u666f\u4e0b\u8bc4\u4f30\u4e86\u7aef\u5230\u7aef\u58f0\u660e\u5f0f\u90e8\u7f72\u7ba1\u9053\u7684\u5904\u7406\u5ef6\u8fdf\u4e0e\u5f00\u9500\u3002"}}
{"id": "2509.13563", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.13563", "abs": "https://arxiv.org/abs/2509.13563", "authors": ["Mengxiao Wang", "Guofei Gu"], "title": "Demystifying Progressive Web Application Permission Systems", "comment": null, "summary": "Progressive Web Applications (PWAs) blend the advantages of web and native\napps, offering features like offline access, push notifications, and\ninstallability. Beyond these, modern PWAs are increasingly granted system-level\ncapabilities such as auto-start on login and shared context with native\napplications. However, their permission management remains poorly defined and\ninconsistently implemented across platforms and browsers.\n  To investigate these gaps, we developed Permissioner, a cross-platform\nanalysis tool, and conducted a systematic study of PWA permissions. Our\nanalysis uncovered critical issues of inconsistency, incompleteness, and\nunclear boundaries in permission enforcement, leading to various attacks\nincluding permission leakage, device identification, and Permission API abuse.\nWe further examined why some browsers resist adopting more granular permission\ncontrols, identifying trade-offs involving usability, compatibility, and\nplatform limitations. Through collaboration with browser vendors, several\nissues reported in our findings were acknowledged and resolved, notably by\nFirefox and Chrome. Our work highlights the urgent need for a unified, robust\npermission model for PWAs and provides actionable guidance toward achieving\nthis goal.", "AI": {"tldr": "\u4f5c\u8005\u7528Permissioner\u7cfb\u7edf\u6027\u5206\u6790PWA\u6743\u9650\uff0c\u53d1\u73b0\u5b9e\u73b0\u6df7\u4e71\u5bfc\u81f4\u5b89\u5168\u9690\u60a3\uff0c\u5c55\u793a\u653b\u51fb\u5e76\u63a8\u52a8\u6d4f\u89c8\u5668\u4fee\u590d\uff0c\u547c\u5401\u7edf\u4e00\u6743\u9650\u6a21\u578b\u3002", "motivation": "\u73b0\u4ee3PWA\u88ab\u8d4b\u4e88\u8d8a\u6765\u8d8a\u591a\u7cfb\u7edf\u7ea7\u80fd\u529b\uff0c\u4f46\u6743\u9650\u7ba1\u7406\u89c4\u8303\u7f3a\u4e4f\u4e14\u5404\u5b9e\u73b0\u5dee\u5f02\u5927\uff0c\u5e26\u6765\u5b89\u5168\u4e0e\u9690\u79c1\u98ce\u9669\uff0c\u4fc3\u4f7f\u4f5c\u8005\u7814\u7a76\u73b0\u72b6\u5e76\u63d0\u51fa\u6539\u8fdb\u5efa\u8bae\u3002", "method": "\u4f5c\u8005\u5f00\u53d1\u4e86\u8de8\u5e73\u53f0\u5206\u6790\u5de5\u5177Permissioner\uff0c\u5bf9\u4e0d\u540c\u5e73\u53f0\u4e0e\u6d4f\u89c8\u5668\u4e0a\u7684PWA\u6743\u9650\u5b9e\u73b0\u8fdb\u884c\u7cfb\u7edf\u6027\u68c0\u6d4b\u4e0e\u5b9e\u9a8c\uff0c\u6a21\u62df\u653b\u51fb\u573a\u666f\u5e76\u4e0e\u6d4f\u89c8\u5668\u5382\u5546\u6c9f\u901a\u4ee5\u9a8c\u8bc1\u4e0e\u4fee\u590d\u95ee\u9898\u3002", "result": "\u53d1\u73b0\u591a\u4e2a\u5173\u952e\u95ee\u9898\uff1a\u6743\u9650\u6267\u884c\u4e0d\u4e00\u81f4\u3001\u6743\u9650\u8868\u8ff0\u4e0e\u5b9e\u73b0\u4e0d\u5b8c\u6574\u3001PWA\u4e0e\u539f\u751f\u95f4\u6743\u9650\u754c\u9650\u6a21\u7cca\uff1b\u6f14\u793a\u4e86\u591a\u7c7b\u653b\u51fb\uff1b\u5e76\u901a\u8fc7\u4e0e\u5382\u5546\u5408\u4f5c\u4fc3\u4f7fChrome\u4e0eFirefox\u4fee\u590d\u82e5\u5e72\u95ee\u9898\u3002", "conclusion": "\u672c\u6587\u6307\u51fa\u5f53\u524dPWA\u6743\u9650\u7ba1\u7406\u5b58\u5728\u4e0d\u4e00\u81f4\u3001\u4e0d\u5b8c\u6574\u4e0e\u8fb9\u754c\u4e0d\u6e05\u7684\u95ee\u9898\uff0c\u5bfc\u81f4\u6743\u9650\u6cc4\u9732\u3001\u8bbe\u5907\u8bc6\u522b\u4e0ePermission API\u6ee5\u7528\u7b49\u5b89\u5168\u98ce\u9669\uff1b\u7814\u7a76\u4fc3\u6210\u90e8\u5206\u6d4f\u89c8\u5668\u4fee\u590d\u95ee\u9898\uff0c\u5e76\u547c\u5401\u7edf\u4e00\u5065\u5168\u7684PWA\u6743\u9650\u6a21\u578b\u3002"}}
{"id": "2509.13527", "categories": ["cs.LG", "physics.chem-ph"], "pdf": "https://arxiv.org/pdf/2509.13527", "abs": "https://arxiv.org/abs/2509.13527", "authors": ["Yulia Pimonova", "Michael G. Taylor", "Alice Allen", "Ping Yang", "Nicholas Lubbers"], "title": "Meta-Learning Linear Models for Molecular Property Prediction", "comment": "26 pages, 16 figures", "summary": "Chemists in search of structure-property relationships face great challenges\ndue to limited high quality, concordant datasets. Machine learning (ML) has\nsignificantly advanced predictive capabilities in chemical sciences, but these\nmodern data-driven approaches have increased the demand for data. In response\nto the growing demand for explainable AI (XAI) and to bridge the gap between\npredictive accuracy and human comprehensibility, we introduce LAMeL - a Linear\nAlgorithm for Meta-Learning that preserves interpretability while improving the\nprediction accuracy across multiple properties. While most approaches treat\neach chemical prediction task in isolation, LAMeL leverages a meta-learning\nframework to identify shared model parameters across related tasks, even if\nthose tasks do not share data, allowing it to learn a common functional\nmanifold that serves as a more informed starting point for new unseen tasks.\nOur method delivers performance improvements ranging from 1.1- to 25-fold over\nstandard ridge regression, depending on the domain of the dataset. While the\ndegree of performance enhancement varies across tasks, LAMeL consistently\noutperforms or matches traditional linear methods, making it a reliable tool\nfor chemical property prediction where both accuracy and interpretability are\ncritical.", "AI": {"tldr": "LAMeL\u662f\u4e00\u79cd\u53ef\u89e3\u91ca\u7684\u7ebf\u6027\u5143\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u76f8\u5173\u5316\u5b66\u9884\u6d4b\u4efb\u52a1\u95f4\u5171\u4eab\u53c2\u6570\u663e\u8457\u63d0\u5347\u5c0f\u6837\u672c\u4efb\u52a1\u7684\u9884\u6d4b\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u7ebf\u6027\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u5316\u5b66\u9886\u57df\u9ad8\u8d28\u91cf\u4e00\u81f4\u6570\u636e\u7a00\u7f3a\uff0c\u800c\u673a\u5668\u5b66\u4e60\u9700\u8981\u5927\u91cf\u6570\u636e\u4e14\u5e38\u727a\u7272\u53ef\u89e3\u91ca\u6027\uff1b\u56e0\u6b64\u9700\u4e00\u79cd\u65e2\u53ef\u89e3\u91ca\u53c8\u80fd\u5728\u6570\u636e\u7a00\u7f3a\u65f6\u63d0\u9ad8\u6027\u80fd\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u7ebf\u6027\u56de\u5f52\u7684\u5143\u5b66\u4e60\u7b97\u6cd5\uff08LAMeL\uff09\uff0c\u5b66\u4e60\u5171\u4eab\u53c2\u6570/\u521d\u59cb\u70b9\uff08\u5171\u540c\u51fd\u6570\u6d41\u5f62\uff09\uff0c\u518d\u9488\u5bf9\u65b0\u4efb\u52a1\u5feb\u901f\u8c03\u6574\uff0c\u4fdd\u7559\u7ebf\u6027\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\uff1b\u4e0e\u6807\u51c6\u5cad\u56de\u5f52\u6bd4\u8f83\u8bc4\u4f30\u3002", "result": "\u5728\u4e0d\u540c\u6570\u636e\u96c6\u4e0a\u5bf9\u6bd4\u5b9e\u9a8c\u663e\u793a\uff0c\u76f8\u8f83\u6807\u51c6\u5cad\u56de\u5f52\uff0cLAMeL\u5e26\u67651.1\u81f325\u500d\u7684\u6027\u80fd\u63d0\u5347\uff08\u89c6\u6570\u636e\u57df\u800c\u5b9a\uff09\uff0c\u5e76\u5728\u591a\u6570\u4efb\u52a1\u4e0a\u4fdd\u6301\u6216\u8d85\u8d8a\u4f20\u7edf\u7ebf\u6027\u65b9\u6cd5\u3002", "conclusion": "LAMeL\u5728\u4fdd\u6301\u7ebf\u6027\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u7684\u540c\u65f6\uff0c\u901a\u8fc7\u5143\u5b66\u4e60\u5728\u591a\u4efb\u52a1\u95f4\u5171\u4eab\u53c2\u6570\uff0c\u663e\u8457\u63d0\u5347\u5316\u5b66\u6027\u8d28\u9884\u6d4b\u7684\u51c6\u786e\u6027\uff0c\u5728\u591a\u6570\u4efb\u52a1\u4e0a\u4f18\u4e8e\u6216\u4e0d\u900a\u8272\u4e8e\u4f20\u7edf\u5cad\u56de\u5f52\uff0c\u9002\u7528\u4e8e\u9700\u8981\u53ef\u89e3\u91ca\u6027\u548c\u6027\u80fd\u7684\u573a\u666f\u3002"}}
{"id": "2509.13855", "categories": ["cs.LG", "cs.DC"], "pdf": "https://arxiv.org/pdf/2509.13855", "abs": "https://arxiv.org/abs/2509.13855", "authors": ["Shamsiiat Abdurakhmanova", "Alex Jung"], "title": "Graph-Regularized Learning of Gaussian Mixture Models", "comment": null, "summary": "We present a graph-regularized learning of Gaussian Mixture Models (GMMs) in\ndistributed settings with heterogeneous and limited local data. The method\nexploits a provided similarity graph to guide parameter sharing among nodes,\navoiding the transfer of raw data. The resulting model allows for flexible\naggregation of neighbors' parameters and outperforms both centralized and\nlocally trained GMMs in heterogeneous, low-sample regimes.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u76f8\u4f3c\u6027\u56fe\u7684\u5206\u5e03\u5f0fGMM\u5b66\u4e60\uff0c\u901a\u8fc7\u56fe\u6b63\u5219\u5316\u5728\u8282\u70b9\u95f4\u5171\u4eab\u53c2\u6570\uff0c\u907f\u514d\u4f20\u8f93\u539f\u59cb\u6570\u636e\uff0c\u80fd\u5728\u5f02\u8d28\u548c\u5c0f\u6837\u672c\u6761\u4ef6\u4e0b\u4f18\u4e8e\u96c6\u4e2d\u5f0f\u548c\u672c\u5730GMM\u3002", "motivation": "\u5728\u5206\u5e03\u5f0f\u7cfb\u7edf\u4e2d\uff0c\u8282\u70b9\u6570\u636e\u5f80\u5f80\u5f02\u8d28\u4e14\u6837\u672c\u91cf\u6709\u9650\uff0c\u5355\u72ec\u8bad\u7ec3\u4f1a\u6b20\u62df\u5408\uff0c\u800c\u7b80\u5355\u96c6\u4e2d\u5f0f\u6216\u76f4\u63a5\u5e73\u5747\u53c2\u6570\u53ef\u80fd\u6cc4\u9732\u6570\u636e\u6216\u65e0\u6cd5\u9002\u5e94\u5f02\u8d28\u6027\u3002\u5229\u7528\u5df2\u6709\u7684\u76f8\u4f3c\u6027\u56fe\u6307\u5bfc\u53c2\u6570\u5171\u4eab\u53ef\u4ee5\u5728\u4fdd\u62a4\u6570\u636e\u9690\u79c1\u7684\u540c\u65f6\u63d0\u9ad8\u5b66\u4e60\u6548\u679c\u3002", "method": "\u5728\u6bcf\u4e2a\u8282\u70b9\u5c40\u90e8\u62df\u5408GMM\u53c2\u6570\u7684\u57fa\u7840\u4e0a\uff0c\u5f15\u5165\u57fa\u4e8e\u63d0\u4f9b\u7684\u76f8\u4f3c\u6027\u56fe\u7684\u6b63\u5219\u9879\uff0c\u4f7f\u76f8\u90bb\u8282\u70b9\u7684\u6a21\u578b\u53c2\u6570\u5728\u4f18\u5316\u8fc7\u7a0b\u4e2d\u8d8b\u4e8e\u4e00\u81f4\u3002\u8be5\u65b9\u6cd5\u5141\u8bb8\u7075\u6d3b\u5730\u805a\u5408\u90bb\u5c45\u7684\u53c2\u6570\uff08\u4f8b\u5982\u52a0\u6743\u5e73\u5747\u6216\u57fa\u4e8e\u56fe\u62c9\u666e\u62c9\u65af\u7684\u6b63\u5219\u5316\uff09\uff0c\u5e76\u901a\u8fc7\u5206\u5e03\u5f0f\u4f18\u5316\u7b56\u7565\uff08\u907f\u514d\u539f\u59cb\u6570\u636e\u4f20\u8f93\uff09\u66f4\u65b0\u5404\u8282\u70b9\u53c2\u6570\u3002", "result": "\u65b9\u6cd5\u5728\u5f02\u8d28\u6027\u5f3a\u3001\u6837\u672c\u91cf\u8f83\u5c11\u7684\u8bbe\u7f6e\u4e0b\uff0c\u8868\u73b0\u4f18\u4e8e\u96c6\u4e2d\u5f0f\u8bad\u7ec3\uff08\u5728\u9690\u79c1\u6216\u901a\u4fe1\u53d7\u9650\u60c5\u5f62\u4e0b\uff09\u548c\u6bcf\u8282\u70b9\u5404\u81ea\u8bad\u7ec3\u7684GMM\uff0c\u8868\u660e\u56fe\u5f15\u5bfc\u7684\u53c2\u6570\u5171\u4eab\u80fd\u6709\u6548\u5229\u7528\u90bb\u5c45\u4fe1\u606f\u63d0\u5347\u4f30\u8ba1\u8d28\u91cf\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u5728\u5206\u5e03\u5f0f\u3001\u5f02\u8d28\u4e14\u672c\u5730\u6837\u672c\u6709\u9650\u7684\u573a\u666f\u4e0b\uff0c\u7ed3\u5408\u56fe\u6b63\u5219\u5316\u7684\u9ad8\u65af\u6df7\u5408\u6a21\u578b\uff08GMM\uff09\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u5229\u7528\u5df2\u77e5\u7684\u76f8\u4f3c\u6027\u56fe\u5728\u8282\u70b9\u95f4\u5171\u4eab\u53c2\u6570\u800c\u975e\u4f20\u8f93\u539f\u59cb\u6570\u636e\uff0c\u4ece\u800c\u5728\u4f4e\u6837\u672c\u548c\u5f02\u8d28\u6027\u60c5\u51b5\u4e0b\u53d6\u5f97\u4f18\u4e8e\u96c6\u4e2d\u5f0f\u4e0e\u672c\u5730\u8bad\u7ec3GMM\u7684\u6027\u80fd\u3002"}}
{"id": "2509.13351", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.13351", "abs": "https://arxiv.org/abs/2509.13351", "authors": ["Pulkit Verma", "Ngoc La", "Anthony Favier", "Swaroop Mishra", "Julie A. Shah"], "title": "Teaching LLMs to Plan: Logical Chain-of-Thought Instruction Tuning for Symbolic Planning", "comment": null, "summary": "Large language models (LLMs) have demonstrated impressive capabilities across\ndiverse tasks, yet their ability to perform structured symbolic planning\nremains limited, particularly in domains requiring formal representations like\nthe Planning Domain Definition Language (PDDL). In this paper, we present a\nnovel instruction tuning framework, PDDL-Instruct, designed to enhance LLMs'\nsymbolic planning capabilities through logical chain-of-thought reasoning. Our\napproach focuses on teaching models to rigorously reason about action\napplicability, state transitions, and plan validity using explicit logical\ninference steps. By developing instruction prompts that guide models through\nthe precise logical reasoning required to determine when actions can be applied\nin a given state, we enable LLMs to self-correct their planning processes\nthrough structured reflection. The framework systematically builds verification\nskills by decomposing the planning process into explicit reasoning chains about\nprecondition satisfaction, effect application, and invariant preservation.\nExperimental results on multiple planning domains show that our\nchain-of-thought reasoning based instruction-tuned models are significantly\nbetter at planning, achieving planning accuracy of up to 94% on standard\nbenchmarks, representing a 66% absolute improvement over baseline models. This\nwork bridges the gap between the general reasoning capabilities of LLMs and the\nlogical precision required for automated planning, offering a promising\ndirection for developing better AI planning systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faPDDL-Instruct\uff0c\u4e00\u79cd\u901a\u8fc7\u903b\u8f91\u94fe\u5f0f\u601d\u7ef4\uff08chain-of-thought\uff09\u6307\u4ee4\u5fae\u8c03LLM\u4ee5\u63d0\u5347PDDL\u5f62\u5f0f\u5316\u89c4\u5212\u80fd\u529b\u7684\u6846\u67b6\u3002\u901a\u8fc7\u5f15\u5bfc\u6a21\u578b\u5206\u89e3\u524d\u63d0\u6ee1\u8db3\u3001\u6548\u679c\u5e94\u7528\u4e0e\u4e0d\u53d8\u91cf\u4fdd\u6301\u7684\u63a8\u7406\u94fe\uff0c\u6a21\u578b\u80fd\u5bf9\u52a8\u4f5c\u9002\u7528\u6027\u3001\u72b6\u6001\u8f6c\u79fb\u4e0e\u8ba1\u5212\u6709\u6548\u6027\u8fdb\u884c\u4e25\u683c\u63a8\u7406\u5e76\u81ea\u6211\u7ea0\u6b63\u3002\u5b9e\u9a8c\u5728\u591a\u4e2a\u89c4\u5212\u57df\u663e\u793a\u663e\u8457\u63d0\u5347\uff0c\u6700\u9ad8\u8fbe94%\u89c4\u5212\u51c6\u786e\u7387\uff0c\u6bd4\u57fa\u7ebf\u63d0\u534766\u4e2a\u767e\u5206\u70b9\u3002", "motivation": "\u73b0\u6709LLM\u5728\u901a\u7528\u63a8\u7406\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5728\u9700\u8981\u7cbe\u786e\u5f62\u5f0f\u5316\u8868\u793a\u548c\u4e25\u683c\u903b\u8f91\u9a8c\u8bc1\u7684\u81ea\u52a8\u89c4\u5212\u4efb\u52a1\u4e0a\u80fd\u529b\u6709\u9650\uff0c\u56e0\u800c\u9700\u8981\u4e00\u79cd\u80fd\u6559\u4f1a\u6a21\u578b\u8fdb\u884c\u660e\u786e\u3001\u53ef\u9a8c\u8bc1\u7b26\u53f7\u63a8\u7406\u7684\u5fae\u8c03\u65b9\u6cd5\u3002", "method": "\u6784\u5efa\u9488\u5bf9PDDL\u7684\u6307\u4ee4\u5fae\u8c03\u6570\u636e\u4e0e\u63d0\u793a\u6a21\u677f\uff0c\u5305\u542b\u5206\u6b65\u7684\u903b\u8f91\u94fe\u5f0f\u63a8\u7406\uff08\u6838\u67e5\u524d\u7f6e\u6761\u4ef6\u3001\u5e94\u7528\u6548\u679c\u3001\u7ef4\u62a4\u4e0d\u53d8\u91cf\uff09\uff0c\u5e76\u8bad\u7ec3\u6216\u5fae\u8c03LLM\u4ee5\u751f\u6210\u5e76\u9a8c\u8bc1\u8fd9\u4e9b\u63a8\u7406\u6b65\u9aa4\uff0c\u652f\u6301\u81ea\u6211\u7ea0\u9519\u4e0e\u7ed3\u6784\u5316\u53cd\u601d\u3002", "result": "\u5728\u591a\u4e2a\u6807\u51c6\u89c4\u5212\u57fa\u51c6\u4e0a\uff0c\u7ecf\u8fc7\u94fe\u5f0f\u601d\u7ef4\u6307\u4ee4\u5fae\u8c03\u7684\u6a21\u578b\u5728\u89c4\u5212\u51c6\u786e\u7387\u4e0a\u6700\u9ad8\u8fbe94%\uff0c\u76f8\u6bd4\u57fa\u7ebf\u6a21\u578b\u7edd\u5bf9\u63d0\u5347\u7ea666\u4e2a\u767e\u5206\u70b9\uff0c\u663e\u793a\u51fa\u5728\u52a8\u4f5c\u9002\u7528\u6027\u5224\u65ad\u3001\u72b6\u6001\u8f6c\u79fb\u6a21\u62df\u4e0e\u6574\u4f53\u8ba1\u5212\u6709\u6548\u6027\u9a8c\u8bc1\u65b9\u9762\u7684\u663e\u8457\u6539\u8fdb\u3002", "conclusion": "PDDL-Instruct\u80fd\u663e\u8457\u589e\u5f3aLLM\u5728PDDL\u7b49\u5f62\u5f0f\u5316\u89c4\u5212\u4efb\u52a1\u4e2d\u7684\u7b26\u53f7\u5316\u8ba1\u5212\u80fd\u529b\uff0c\u4f7f\u6a21\u578b\u901a\u8fc7\u663e\u5f0f\u903b\u8f91\u63a8\u7406\u94fe\u5224\u65ad\u52a8\u4f5c\u9002\u7528\u6027\u4e0e\u72b6\u6001\u8f6c\u79fb\uff0c\u4ece\u800c\u5927\u5e45\u63d0\u9ad8\u8ba1\u5212\u6b63\u786e\u7387\uff0c\u7f29\u5c0f\u4e86\u901a\u7528\u63a8\u7406\u4e0e\u81ea\u52a8\u89c4\u5212\u7cbe\u786e\u6027\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002"}}
{"id": "2509.13954", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2509.13954", "abs": "https://arxiv.org/abs/2509.13954", "authors": ["Surya Agustian", "Sandra Permana", "Salman Teguh Pratista", "Syarifu Adam", "Iswandi"], "title": "Low-cost Highly-interoperable Multiplatform Campus Network: Experience of YARSI University", "comment": "6 pages of paper submitting to conference", "summary": "To some organizations, building campus network is sometimes considered to be\nvery expensive; and this has made the project uneasy to perform. Moreover, if\nthe organization without sufficient IT knowledge does not have capable IT\nengineers, leaving this project to third parties without supervision would lead\nto unexpected larger expenses. For this reason, in the year of 2003, YARSI\nUniversity formed CMIS (Center for Management Infor-mation System) to perform\ntasks in designing, operations and maintenance of campus network and its\nservices. By combining Open Source operating system run on a local assembled\npersonal computer as gateway and router, and switching technology from Cisco,\nwe designed a low-cost UTP-based campus network which covering rooms and\nbuildings in YARSI environment. Meanwhile the internet access through several\nbroadband connections and dedicated wireless was shared to more than 100\nsimultaneous users by a captive portal system. With this strategy, we can\nsignificantly reduce cost for purchasing, maintenance and operations of network\ninfrastructure and internet access. Our model in designing low-cost campus\nnetwork and internet connections could be adopted by rural community or\norganizations that have limited budget to have internet access.", "AI": {"tldr": "\u7528\u5f00\u6e90\u7cfb\u7edf+\u81ea\u7ec4\u786c\u4ef6\u505a\u7f51\u5173\uff0cCisco\u4ea4\u6362+UTP\u5e03\u7ebf\uff0c\u914d\u5408\u5bbd\u5e26\u805a\u5408\u4e0ecaptive portal\uff0c\u6210\u529f\u6784\u5efa\u4f4e\u6210\u672c\u3001\u53ef\u7ef4\u62a4\u7684\u6821\u56ed\u7f51\u7edc\uff0c\u9002\u5408\u9884\u7b97\u6709\u9650\u7684\u673a\u6784\u6216\u519c\u6751\u793e\u533a\u91c7\u7528\u3002", "motivation": "\u964d\u4f4e\u6821\u56ed\u7f51\u7edc\u5efa\u8bbe\u4e0e\u7ef4\u62a4\u6210\u672c\uff0c\u4f7f\u7f3a\u4e4fIT\u8d44\u6e90\u7684\u7ec4\u7ec7\u4e5f\u80fd\u81ea\u4e3b\u7ba1\u7406\u5e76\u63d0\u4f9b\u4e92\u8054\u7f51\u63a5\u5165\u3002", "method": "\u91c7\u7528\u672c\u5730\u7ec4\u88c5PC\u8fd0\u884c\u5f00\u6e90\u64cd\u4f5c\u7cfb\u7edf\u4f5c\u4e3a\u7f51\u5173/\u8def\u7531\u5668\uff0c\u4f7f\u7528Cisco\u4ea4\u6362\u673a\u505a\u4e8c\u4e09\u5c42\u4ea4\u6362\uff0cUTP\u5e03\u7ebf\u8986\u76d6\u5efa\u7b51\uff0c\u591a\u4e2a\u5bbd\u5e26\u8fde\u63a5\u4e0e\u4e13\u7528\u65e0\u7ebf\u63a5\u5165\u6c47\u805a\u4e92\u8054\u7f51\uff0c\u5e76\u901a\u8fc7captive portal\u8fdb\u884c\u63a5\u5165\u63a7\u5236\u4e0e\u5171\u4eab\u3002", "result": "\u57fa\u4e8e\u5f00\u6e90\u64cd\u4f5c\u7cfb\u7edf\u4e0e\u81ea\u88c5PC\u4f5c\u4e3a\u7f51\u5173/\u8def\u7531\uff0c\u914d\u5408Cisco\u4ea4\u6362\u8bbe\u5907\u548cUTP\u5e03\u7ebf\uff0c\u6784\u5efa\u8986\u76d6\u6559\u5ba4\u4e0e\u697c\u5b87\u7684\u4f4e\u6210\u672c\u6821\u56ed\u7f51\u7edc\uff1b\u901a\u8fc7\u591a\u6761\u5bbd\u5e26\u548c\u4e13\u7528\u65e0\u7ebf\u63a5\u5165\uff0c\u5e76\u7528captive portal\u5b9e\u73b0100+\u5e76\u53d1\u7528\u6237\u5171\u4eab\u4e92\u8054\u7f51\u3002", "conclusion": "\u8be5\u65b9\u6848\u663e\u8457\u964d\u4f4e\u91c7\u8d2d\u3001\u7ef4\u62a4\u4e0e\u8fd0\u8425\u6210\u672c\uff0c\u9002\u5408\u9884\u7b97\u6709\u9650\u6216IT\u4eba\u624b\u4e0d\u8db3\u7684\u7ec4\u7ec7\u4f5c\u4e3a\u6821\u56ed\u6216\u793e\u533a\u8054\u7f51\u6a21\u578b\u3002"}}
{"id": "2509.13581", "categories": ["cs.CR", "cs.SD"], "pdf": "https://arxiv.org/pdf/2509.13581", "abs": "https://arxiv.org/abs/2509.13581", "authors": ["Mohamad Fakih", "Rahul Dharmaji", "Youssef Mahmoud", "Halima Bouzidi", "Mohammad Abdullah Al Faruque"], "title": "Invisible Ears at Your Fingertips: Acoustic Eavesdropping via Mouse Sensors", "comment": "Appearing in the Annual Computer Security Applications Conference\n  (ACSAC 2025)", "summary": "Modern optical mouse sensors, with their advanced precision and high\nresponsiveness, possess an often overlooked vulnerability: they can be\nexploited for side-channel attacks. This paper introduces Mic-E-Mouse, the\nfirst-ever side-channel attack that targets high-performance optical mouse\nsensors to covertly eavesdrop on users. We demonstrate that audio signals can\ninduce subtle surface vibrations detectable by a mouse's optical sensor.\nRemarkably, user-space software on popular operating systems can collect and\nbroadcast this sensitive side channel, granting attackers access to raw mouse\ndata without requiring direct system-level permissions. Initially, the\nvibration signals extracted from mouse data are of poor quality due to\nnon-uniform sampling, a non-linear frequency response, and significant\nquantization. To overcome these limitations, Mic-E-Mouse employs a\nsophisticated end-to-end data filtering pipeline that combines Wiener\nfiltering, resampling corrections, and an innovative encoder-only spectrogram\nneural filtering technique. We evaluate the attack's efficacy across diverse\nconditions, including speaking volume, mouse polling rate and DPI, surface\nmaterials, speaker languages, and environmental noise. In controlled\nenvironments, Mic-E-Mouse improves the signal-to-noise ratio (SNR) by up to +19\ndB for speech reconstruction. Furthermore, our results demonstrate a speech\nrecognition accuracy of roughly 42% to 61% on the AudioMNIST and VCTK datasets.\nAll our code and datasets are publicly accessible on\nhttps://sites.google.com/view/mic-e-mouse.", "AI": {"tldr": "Mic-E-Mouse\u5229\u7528\u5149\u5b66\u9f20\u6807\u68c0\u6d4b\u5230\u7684\u8868\u9762\u632f\u52a8\u4f5c\u4e3a\u65c1\u8def\u97f3\u9891\u901a\u9053\uff0c\u901a\u8fc7\u4fe1\u53f7\u5904\u7406\u4e0e\u8c31\u56fe\u795e\u7ecf\u53bb\u566a\u5b9e\u73b0\u53ef\u89c2\u7684\u8bed\u97f3\u91cd\u5efa\u4e0e\u8bc6\u522b\uff0c\u63ed\u793a\u4e86\u9f20\u6807\u4f20\u611f\u5668\u88ab\u6ee5\u7528\u4e3a\u7a83\u542c\u6e20\u9053\u7684\u5b89\u5168\u9690\u60a3\u3002", "motivation": "\u9ad8\u6027\u80fd\u5149\u5b66\u9f20\u6807\u4f20\u611f\u5668\u5bf9\u5fae\u5c0f\u8868\u9762\u632f\u52a8\u654f\u611f\uff0c\u4e14\u5176\u539f\u59cb\u6570\u636e\u53ef\u5728\u7528\u6237\u6001\u8bbf\u95ee\uff0c\u5b58\u5728\u88ab\u6ee5\u7528\u4e3a\u65e0\u58f0\u4fa7\u4fe1\u9053\u6765\u7a83\u53d6\u8bed\u97f3\u4fe1\u606f\u7684\u98ce\u9669\u3002\u7814\u7a76\u65e8\u5728\u63ed\u793a\u8fd9\u4e00\u672a\u88ab\u5145\u5206\u8ba4\u8bc6\u7684\u5a01\u80c1\u5e76\u63d0\u51fa\u76f8\u5e94\u7684\u653b\u51fb\u4e0e\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u5229\u7528\u97f3\u9891\u6fc0\u53d1\u751f\u6210\u8868\u9762\u5fae\u632f\u52a8\uff0c\u4f7f\u7528\u7528\u6237\u6001\u7a0b\u5e8f\u8bbf\u95ee\u5e76\u8bb0\u5f55\u9f20\u6807\u539f\u59cb\u4f4d\u7f6e\u6570\u636e\uff1b\u9488\u5bf9\u975e\u5747\u5300\u91c7\u6837\u3001\u975e\u7ebf\u6027\u9891\u7387\u54cd\u5e94\u548c\u91cf\u5316\u566a\u58f0\uff0c\u8bbe\u8ba1\u5305\u542bWiener\u6ee4\u6ce2\u3001\u91cd\u91c7\u6837\u6821\u6b63\u548c\u7f16\u7801\u5668\u5f0f\u8c31\u56fe\u795e\u7ecf\u6ee4\u6ce2\u7684\u53bb\u566a\u91cd\u5efa\u7ba1\u9053\uff1b\u5728\u591a\u79cd\u73af\u5883\u6761\u4ef6\u4e0b\u8bc4\u4f30\u91cd\u5efa\u4e0e\u8bc6\u522b\u6027\u80fd\u3002", "result": "\u5728\u53d7\u63a7\u73af\u5883\u4e0b\uff0cMic-E-Mouse\u5bf9\u8bed\u97f3\u91cd\u5efa\u7684SNR\u6700\u9ad8\u63d0\u5347\u7ea6+19 dB\uff1b\u5728AudioMNIST\u548cVCTK\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u7ea642%\u523061%\u7684\u8bed\u97f3\u8bc6\u522b\u51c6\u786e\u7387\u3002\u7814\u7a76\u8fd8\u516c\u5e03\u4e86\u4ee3\u7801\u548c\u6570\u636e\u96c6\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86Mic-E-Mouse\uff0c\u4e00\u79cd\u5229\u7528\u9ad8\u6027\u80fd\u5149\u5b66\u9f20\u6807\u4f20\u611f\u5668\u4f5c\u4e3a\u65c1\u8def\u901a\u9053\u7a83\u542c\u7528\u6237\u7684\u653b\u51fb\u65b9\u6cd5\uff0c\u5c55\u793a\u4e86\u97f3\u9891\u6fc0\u53d1\u4ea7\u751f\u7684\u5fae\u5c0f\u632f\u52a8\u53ef\u88ab\u9f20\u6807\u4f20\u611f\u5668\u68c0\u6d4b\u5e76\u901a\u8fc7\u7528\u6237\u6001\u8f6f\u4ef6\u6536\u96c6\u3002\u653b\u51fb\u901a\u8fc7\u7aef\u5230\u7aef\u6ee4\u6ce2\u7ba1\u9053\u4e0e\u795e\u7ecf\u7f51\u7edc\u9891\u8c31\u53bb\u566a\u63d0\u9ad8\u4fe1\u566a\u6bd4\u5e76\u5b9e\u73b0\u8bed\u97f3\u91cd\u5efa\u3002"}}
{"id": "2509.13608", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.13608", "abs": "https://arxiv.org/abs/2509.13608", "authors": ["Niruthiha Selvanayagam", "Ted Kurti"], "title": "Is GPT-4o mini Blinded by its Own Safety Filters? Exposing the Multimodal-to-Unimodal Bottleneck in Hate Speech Detection", "comment": null, "summary": "As Large Multimodal Models (LMMs) become integral to daily digital life,\nunderstanding their safety architectures is a critical problem for AI\nAlignment. This paper presents a systematic analysis of OpenAI's GPT-4o mini, a\nglobally deployed model, on the difficult task of multimodal hate speech\ndetection. Using the Hateful Memes Challenge dataset, we conduct a multi-phase\ninvestigation on 500 samples to probe the model's reasoning and failure modes.\nOur central finding is the experimental identification of a \"Unimodal\nBottleneck,\" an architectural flaw where the model's advanced multimodal\nreasoning is systematically preempted by context-blind safety filters. A\nquantitative validation of 144 content policy refusals reveals that these\noverrides are triggered in equal measure by unimodal visual 50% and textual 50%\ncontent. We further demonstrate that this safety system is brittle, blocking\nnot only high-risk imagery but also benign, common meme formats, leading to\npredictable false positives. These findings expose a fundamental tension\nbetween capability and safety in state-of-the-art LMMs, highlighting the need\nfor more integrated, context-aware alignment strategies to ensure AI systems\ncan be deployed both safely and effectively.", "AI": {"tldr": "GPT-4o mini\u5728\u591a\u6a21\u6001\u4ec7\u6068\u68c0\u6d4b\u4e2d\u88ab\u4e0a\u4e0b\u6587\u76f2\u76ee\u7684\u5355\u6a21\u6001\u5b89\u5168\u8fc7\u6ee4\u5668\u963b\u65ad\uff0c\u5f15\u53d1\u9ad8\u8bef\u62a5\u7387\u548c\u5bf9\u65e0\u5bb3\u5185\u5bb9\u7684\u963b\u6b62\uff0c\u9700\u66f4\u5177\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u5bf9\u9f50\u7b56\u7565\u3002", "motivation": "\u968f\u7740LMM\u5e7f\u6cdb\u90e8\u7f72\uff0c\u7406\u89e3\u5176\u5b89\u5168\u673a\u5236\u5982\u4f55\u5f71\u54cd\u5b9e\u9645\u63a8\u7406\u5bf9AI Alignment\u81f3\u5173\u91cd\u8981\uff0c\u7279\u522b\u662f\u5728\u654f\u611f\u4efb\u52a1\u5982\u591a\u6a21\u6001\u4ec7\u6068\u8a00\u8bba\u68c0\u6d4b\u4e2d\u3002", "method": "\u4f7f\u7528Hateful Memes Challenge\u6570\u636e\u96c6\uff0c\u5bf9500\u4e2a\u6837\u672c\u8fdb\u884c\u591a\u9636\u6bb5\u5206\u6790\uff0c\u91cf\u5316144\u6b21\u88ab\u62d2\u7edd\u7684\u5185\u5bb9\uff0c\u68c0\u67e5\u89e6\u53d1\u56e0\u7d20\uff08\u89c6\u89c9\u6216\u6587\u672c\u5404\u536050%\uff09\uff0c\u5e76\u5206\u6790\u9519\u8bef\u7c7b\u578b\u4e0e\u7cfb\u7edf\u8106\u5f31\u6027\u3002", "result": "\u53d1\u73b0\u4e86Unimodal Bottleneck\uff1a\u5b89\u5168\u7cfb\u7edf\u8fc7\u65e9\u57fa\u4e8e\u5355\u6a21\u6001\u4fe1\u53f7\uff08\u89c6\u89c9\u6216\u6587\u672c\uff09\u89e6\u53d1\u62d2\u7edd\uff0c\u5bfc\u81f4\u5bf9\u5e38\u89c1\u65e0\u5bb3\u6a21\u56e0\u683c\u5f0f\u7684\u8bef\u5224\uff0c\u66b4\u9732\u51fa\u80fd\u529b\u4e0e\u5b89\u5168\u4e4b\u95f4\u7684\u6839\u672c\u5f20\u529b\u3002", "conclusion": "\u8be5\u8bba\u6587\u63ed\u793aGPT-4o mini\u5728\u591a\u6a21\u6001\u4ec7\u6068\u8a00\u8bba\u68c0\u6d4b\u4efb\u52a1\u4e2d\u5b58\u5728\u201c\u5355\u6a21\u74f6\u9888\u201d\uff0c\u5373\u5b89\u5168\u8fc7\u6ee4\u5668\u5728\u5ffd\u89c6\u8de8\u6a21\u6001\u8bed\u5883\u7684\u60c5\u51b5\u4e0b\u63d0\u524d\u963b\u65ad\u6a21\u578b\u63a8\u7406\uff0c\u5bfc\u81f4\u8bef\u62a5\u548c\u80fd\u529b-\u5b89\u5168\u51b2\u7a81\u3002"}}
{"id": "2509.13933", "categories": ["cs.LG", "cs.DC"], "pdf": "https://arxiv.org/pdf/2509.13933", "abs": "https://arxiv.org/abs/2509.13933", "authors": ["Qiyue Li", "Yingxin Liu", "Hang Qi", "Jieping Luo", "Zhizhang Liu", "Jingjin Wu"], "title": "Adaptive Client Selection via Q-Learning-based Whittle Index in Wireless Federated Learning", "comment": null, "summary": "We consider the client selection problem in wireless Federated Learning (FL),\nwith the objective of reducing the total required time to achieve a certain\nlevel of learning accuracy. Since the server cannot observe the clients'\ndynamic states that can change their computation and communication efficiency,\nwe formulate client selection as a restless multi-armed bandit problem. We\npropose a scalable and efficient approach called the Whittle Index Learning in\nFederated Q-learning (WILF-Q), which uses Q-learning to adaptively learn and\nupdate an approximated Whittle index associated with each client, and then\nselects the clients with the highest indices. Compared to existing approaches,\nWILF-Q does not require explicit knowledge of client state transitions or data\ndistributions, making it well-suited for deployment in practical FL settings.\nExperiment results demonstrate that WILF-Q significantly outperforms existing\nbaseline policies in terms of learning efficiency, providing a robust and\nefficient approach to client selection in wireless FL.", "AI": {"tldr": "WILF-Q\u7528Q\u5b66\u4e60\u8fd1\u4f3cWhittle\u6307\u6570\u8fdb\u884c\u5ba2\u6237\u7aef\u9009\u62e9\uff0c\u65e0\u9700\u77e5\u9053\u5ba2\u6237\u7aef\u72b6\u6001\u8f6c\u79fb\u548c\u6570\u636e\u5206\u5e03\uff0c\u663e\u8457\u63d0\u9ad8\u65e0\u7ebfFL\u7684\u5b66\u4e60\u6548\u7387\u3002", "motivation": "\u65e0\u7ebf\u8054\u90a6\u5b66\u4e60\u4e2d\u5ba2\u6237\u7aef\u8ba1\u7b97\u4e0e\u901a\u4fe1\u80fd\u529b\u52a8\u6001\u53d8\u5316\uff0c\u670d\u52a1\u5668\u65e0\u6cd5\u89c2\u6d4b\u8fd9\u4e9b\u52a8\u6001\u72b6\u6001\uff0c\u76f4\u63a5\u5f71\u54cd\u8bad\u7ec3\u65f6\u95f4\u548c\u6548\u7387\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u4e2a\u65e0\u9700\u663e\u5f0f\u72b6\u6001/\u5206\u5e03\u4fe1\u606f\u3001\u80fd\u81ea\u9002\u5e94\u9009\u62e9\u5ba2\u6237\u7aef\u4ee5\u6700\u5c0f\u5316\u603b\u8bad\u7ec3\u65f6\u95f4\u7684\u7b56\u7565\u3002", "method": "\u5c06\u5ba2\u6237\u7aef\u89c6\u4e3a\u591a\u81c2\u8001\u864e\u673a\uff08restless MAB\uff09\uff0c\u4f7f\u7528Q\u5b66\u4e60\u4f30\u8ba1\u6bcf\u4e2a\u5ba2\u6237\u7aef\u7684Whittle\u6307\u6570\uff08\u8fd1\u4f3c\uff09\uff0c\u5e76\u6309\u6307\u6570\u6392\u5e8f\u9009\u62e9\u5ba2\u6237\u7aef\uff1b\u8be5\u65b9\u6cd5\u4e3a\u53ef\u6269\u5c55\u7684\u5728\u7ebf\u5b66\u4e60\u7b56\u7565\uff0c\u4e0e\u4f20\u7edf\u57fa\u4e8e\u663e\u5f0f\u6a21\u578b\u7684\u65b9\u6cd5\u4e0d\u540c\uff0c\u65e0\u9700\u5df2\u77e5\u72b6\u6001\u8f6c\u79fb\u6216\u6570\u636e\u5206\u5e03\u3002", "result": "\u5b9e\u9a8c\u8868\u660eWILF-Q\u5728\u5b66\u4e60\u6548\u7387\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u7b56\u7565\uff0c\u80fd\u66f4\u5feb\u8fbe\u5230\u7ed9\u5b9a\u7684\u5b66\u4e60\u7cbe\u5ea6\uff0c\u4e14\u65b9\u6cd5\u5177\u6709\u9c81\u68d2\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684WILF-Q\u65b9\u6cd5\u5c06\u5ba2\u6237\u7aef\u9009\u62e9\u95ee\u9898\u5efa\u6a21\u4e3arestless multi-armed bandit\uff0c\u5e76\u901a\u8fc7Q\u5b66\u4e60\u8fd1\u4f3c\u5e76\u66f4\u65b0\u6bcf\u4e2a\u5ba2\u6237\u7aef\u7684Whittle\u6307\u6570\uff0c\u4ece\u800c\u9009\u62e9\u6307\u6570\u6700\u9ad8\u7684\u5ba2\u6237\u7aef\u4ee5\u6700\u5c0f\u5316\u5b8c\u6210\u7ed9\u5b9a\u7cbe\u5ea6\u6240\u9700\u7684\u603b\u65f6\u95f4\u3002\u5b9e\u9a8c\u8bc1\u660eWILF-Q\u5728\u5b66\u4e60\u6548\u7387\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u7b56\u7565\uff0c\u4e14\u4e0d\u9700\u8981\u663e\u5f0f\u7684\u5ba2\u6237\u7aef\u72b6\u6001\u8f6c\u79fb\u6216\u6570\u636e\u5206\u5e03\u4fe1\u606f\uff0c\u9002\u5408\u5b9e\u9645\u65e0\u7ebf\u8054\u90a6\u5b66\u4e60\u573a\u666f\u3002"}}
{"id": "2509.13352", "categories": ["cs.AI", "cs.RO", "68T07, 68T40, 68T42", "I.2.9; I.2.11; I.2.8; I.2.10"], "pdf": "https://arxiv.org/pdf/2509.13352", "abs": "https://arxiv.org/abs/2509.13352", "authors": ["Anis Koubaa", "Khaled Gabr"], "title": "Agentic UAVs: LLM-Driven Autonomy with Integrated Tool-Calling and Cognitive Reasoning", "comment": "14 pages, 1 figure", "summary": "Unmanned Aerial Vehicles (UAVs) are increasingly deployed in defense,\nsurveillance, and disaster response, yet most systems remain confined to SAE\nLevel 2--3 autonomy. Their reliance on rule-based control and narrow AI\nrestricts adaptability in dynamic, uncertain missions. Existing UAV frameworks\nlack context-aware reasoning, autonomous decision-making, and ecosystem-level\nintegration; critically, none leverage Large Language Model (LLM) agents with\ntool-calling for real-time knowledge access. This paper introduces the Agentic\nUAVs framework, a five-layer architecture (Perception, Reasoning, Action,\nIntegration, Learning) that augments UAVs with LLM-driven reasoning, database\nquerying, and third-party system interaction. A ROS2 and Gazebo-based prototype\nintegrates YOLOv11 object detection with GPT-4 reasoning and local Gemma-3\ndeployment. In simulated search-and-rescue scenarios, agentic UAVs achieved\nhigher detection confidence (0.79 vs. 0.72), improved person detection rates\n(91% vs. 75%), and markedly increased action recommendation (92% vs. 4.5%).\nThese results confirm that modest computational overhead enables qualitatively\nnew levels of autonomy and ecosystem integration.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5c06 LLM \u4ee3\u7406\u4e0e\u5de5\u5177\u8c03\u7528\u7eb3\u5165 UAV \u7684\u4e94\u5c42\u67b6\u6784\uff0c\u5e76\u7528 ROS2/Gazebo \u539f\u578b\u9a8c\u8bc1\uff0c\u5728\u641c\u6551\u4eff\u771f\u4e2d\u663e\u8457\u63d0\u9ad8\u68c0\u6d4b\u4e0e\u51b3\u7b56\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u65e0\u4eba\u673a\u591a\u505c\u7559\u5728 SAE Level 2-3\uff0c\u81ea\u4e3b\u6027\u548c\u60c5\u5883\u611f\u77e5\u4e0d\u8db3\uff0c\u4f20\u7edf\u89c4\u5219\u4e0e\u7a84\u57df AI \u96be\u4ee5\u9002\u5e94\u52a8\u6001\u3001\u4e0d\u786e\u5b9a\u4efb\u52a1\uff1b\u5c1a\u65e0\u5c06 LLM \u4ee3\u7406\u4e0e\u5b9e\u65f6\u5de5\u5177\u8c03\u7528\u6574\u5408\u8fdb UAV \u751f\u6001\u7684\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u4e94\u5c42\u67b6\u6784\uff08Perception, Reasoning, Action, Integration, Learning\uff09\uff1b\u5b9e\u73b0\u57fa\u4e8e ROS2/Gazebo \u7684\u539f\u578b\uff0c\u7ed3\u5408 YOLOv11 \u76ee\u6807\u68c0\u6d4b\u3001GPT-4 \u63a8\u7406\u4e0e\u672c\u5730 Gemma-3 \u90e8\u7f72\uff0c\u652f\u6301\u6570\u636e\u5e93\u67e5\u8be2\u4e0e\u7b2c\u4e09\u65b9\u7cfb\u7edf\u5de5\u5177\u8c03\u7528\u3002", "result": "\u4eff\u771f\u641c\u6551\u573a\u666f\u4e0b\uff0cagentic UAV \u76f8\u8f83\u57fa\u7ebf\u5728\u68c0\u6d4b\u7f6e\u4fe1\u5ea6\uff080.79 vs 0.72\uff09\u3001\u4eba\u5458\u68c0\u6d4b\u7387\uff0891% vs 75%\uff09\u548c\u52a8\u4f5c\u5efa\u8bae\u7387\uff0892% vs 4.5%\uff09\u4e0a\u5747\u6709\u663e\u8457\u63d0\u5347\uff0c\u4e14\u8ba1\u7b97\u5f00\u9500\u9002\u4e2d\u3002", "conclusion": "Agentic UAVs \u6846\u67b6\u901a\u8fc7\u5c06 LLM \u9a71\u52a8\u7684\u63a8\u7406\u4e0e\u611f\u77e5\u3001\u52a8\u4f5c\u3001\u96c6\u6210\u4e0e\u5b66\u4e60\u5c42\u7ed3\u5408\uff0c\u663e\u8457\u63d0\u5347\u4e86\u65e0\u4eba\u673a\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u51b3\u7b56\u4e0e\u534f\u4f5c\u80fd\u529b\u3002"}}
{"id": "2509.13993", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2509.13993", "abs": "https://arxiv.org/abs/2509.13993", "authors": ["Vincent Mutolo", "Rhea Parekh", "Dan Rubenstein"], "title": "Path-Oblivious Entanglement Swapping for the Quantum Internet", "comment": "To appear, ACM HotNets 2025, November 2025", "summary": "Proposed Bell pair swapping protocols, an essential component of the Quantum\nInternet, are planned-path: specific, structured, routing paths are reserved\nprior to the execution of the swapping process. This makes sense when one\nassumes the state used in the swapping process is expensive, fragile, and\nunstable. However, lessons from classical networking have shown that while\nreservations seem promising in concept, flexible, reservation-light or free\napproaches often outperform their more restrictive counterparts in\nwell-provisioned networks. In this paper, we propose that a path-oblivious\napproach is more amenable to supporting swapping as quantum state evolves into\na cheaper, more robust form. We formulate the swapping process as a linear\nprogram and present and evaluate a fairly naive baseline swapping protocol that\ntries to balance Bell pairs throughout the network. Preliminary results show\nthat while naive balancing leaves room for improvement, investigating\npath-oblivious swapping is a promising direction.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u8def\u5f84\u65e0\u5173(path-oblivious)\u7684\u8d1d\u5c14\u5bf9\u4ea4\u6362\u7b56\u7565\uff0c\u9488\u5bf9\u672a\u6765\u91cf\u5b50\u7f51\u7edc\u4e2d\u91cf\u5b50\u6001\u66f4\u5ec9\u4ef7\u7a33\u5065\u65f6\u7684\u573a\u666f\u3002\u4f5c\u8005\u5c06\u4ea4\u6362\u5efa\u6a21\u4e3a\u7ebf\u6027\u89c4\u5212\uff0c\u5e76\u7ed9\u51fa\u4e00\u4e2a\u7b80\u5355\u7684\u57fa\u7ebf\u534f\u8bae\uff0c\u901a\u8fc7\u5728\u7f51\u7edc\u4e2d\u5e73\u8861\u8d1d\u5c14\u5bf9\u6765\u8fdb\u884c\u4ea4\u6362\u3002\u521d\u6b65\u4eff\u771f\u663e\u793a\u8be5\u7b80\u5355\u65b9\u6cd5\u53ef\u884c\u4f46\u6709\u63d0\u5347\u7a7a\u95f4\uff0c\u8868\u660e\u8def\u5f84\u65e0\u5173\u7b56\u7565\u503c\u5f97\u8fdb\u4e00\u6b65\u7814\u7a76\u3002", "motivation": "\u4f20\u7edf\u7684\u8d1d\u5c14\u5bf9\u4ea4\u6362\u901a\u5e38\u91c7\u7528\u9884\u5148\u4fdd\u7559\u8def\u5f84\u7684\u505a\u6cd5\uff0c\u9002\u7528\u4e8e\u8106\u5f31\u6602\u8d35\u7684\u91cf\u5b50\u6001\u3002\u4f46\u968f\u7740\u91cf\u5b50\u6001\u53d8\u5f97\u66f4\u7a33\u5b9a\u3001\u6210\u672c\u66f4\u4f4e\uff0c\u6765\u81ea\u7ecf\u5178\u7f51\u7edc\u7684\u7ecf\u9a8c\u8868\u660e\u8f7b\u91cf\u6216\u65e0\u4fdd\u7559\u7b56\u7565\u5728\u8d44\u6e90\u5145\u8db3\u65f6\u66f4\u4f18\uff0c\u56e0\u800c\u63a2\u7a76\u8def\u5f84\u65e0\u5173\u7684\u4ea4\u6362\u7b56\u7565\u662f\u5426\u66f4\u5408\u9002\u3002", "method": "\u5c06\u4ea4\u6362\u95ee\u9898\u5f62\u5f0f\u5316\u4e3a\u7ebf\u6027\u89c4\u5212\uff0c\u8bbe\u8ba1\u5e76\u8bc4\u4f30\u4e00\u4e2a\u6734\u7d20\u7684\u57fa\u7ebf\u534f\u8bae\u2014\u2014\u8bd5\u56fe\u5728\u7f51\u7edc\u4e2d\u5e73\u8861\u5404\u94fe\u8def\u7684\u8d1d\u5c14\u5bf9\u8d44\u6e90\u5206\u5e03\uff0c\u907f\u514d\u4e8b\u5148\u4fdd\u7559\u5177\u4f53\u8def\u7531\u3002\u901a\u8fc7\u4eff\u771f\u8bc4\u4f30\u6027\u80fd\u5e76\u4e0e\u9884\u671f\u4fdd\u7559\u5f0f\u65b9\u6cd5\u8fdb\u884c\u6982\u5ff5\u6bd4\u8f83\u3002", "result": "\u57fa\u7ebf\u5e73\u8861\u7b56\u7565\u80fd\u591f\u5b9e\u73b0\u8def\u5f84\u65e0\u5173\u4ea4\u6362\u7684\u57fa\u672c\u529f\u80fd\uff0c\u4f46\u6027\u80fd\u8fd8\u6709\u660e\u663e\u6539\u8fdb\u7a7a\u95f4\uff1b\u521d\u6b65\u7ed3\u679c\u652f\u6301\u7ee7\u7eed\u5728\u8def\u5f84\u65e0\u5173\u65b9\u5411\u4e0a\u8fdb\u884c\u66f4\u590d\u6742\u7b97\u6cd5\u548c\u4f18\u5316\u7684\u7814\u7a76\u3002", "conclusion": "\u8def\u5f84\u65e0\u5173\u7684\u4ea4\u6362\u65b9\u6cd5\u5728\u91cf\u5b50\u6001\u53d8\u5f97\u66f4\u7a33\u5065\u548c\u5ec9\u4ef7\u7684\u672a\u6765\u60c5\u666f\u4e0b\u662f\u6709\u524d\u666f\u7684\uff1b\u57fa\u7ebf\u7b97\u6cd5\u867d\u7b80\u5355\u4f46\u5c55\u793a\u4e86\u53ef\u884c\u6027\uff0c\u9700\u8981\u66f4\u590d\u6742\u7684\u8c03\u5ea6\u548c\u4f18\u5316\u4ee5\u63d0\u9ad8\u6027\u80fd\u3002"}}
{"id": "2509.13597", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.13597", "abs": "https://arxiv.org/abs/2509.13597", "authors": ["Abhishek Goswami"], "title": "Agentic JWT: A Secure Delegation Protocol for Autonomous AI Agents", "comment": "17 pages, 6 figures, 2 Tables", "summary": "Autonomous LLM agents can issue thousands of API calls per hour without human\noversight. OAuth 2.0 assumes deterministic clients, but in agentic settings\nstochastic reasoning, prompt injection, or multi-agent orchestration can\nsilently expand privileges.\n  We introduce Agentic JWT (A-JWT), a dual-faceted intent token that binds each\nagent's action to verifiable user intent and, optionally, to a specific\nworkflow step. A-JWT carries an agent's identity as a one-way checksum hash\nderived from its prompt, tools and configuration, and a chained delegation\nassertion to prove which downstream agent may execute a given task, and\nper-agent proof-of-possession keys to prevent replay and in-process\nimpersonation. We define a new authorization mechanism and add a lightweight\nclient shim library that self-verifies code at run time, mints intent tokens,\ntracks workflow steps and derives keys, thus enabling secure agent identity and\nseparation even within a single process.\n  We illustrate a comprehensive threat model for agentic applications,\nimplement a Python proof-of-concept and show functional blocking of\nscope-violating requests, replay, impersonation, and prompt-injection pathways\nwith sub-millisecond overhead on commodity hardware. The design aligns with\nongoing OAuth agent discussions and offers a drop-in path toward zero-trust\nguarantees for agentic applications. A comprehensive performance and security\nevaluation with experimental results will appear in our forthcoming journal\npublication", "AI": {"tldr": "\u63d0\u51fa\u4e86 Agentic JWT (A-JWT)\uff0c\u4e00\u79cd\u7ed1\u5b9a\u4ee3\u7406\u884c\u4e3a\u4e0e\u7528\u6237\u610f\u56fe\u7684\u53cc\u91cd\u610f\u56fe\u4ee4\u724c\uff0c\u5305\u542b\u57fa\u4e8e\u63d0\u793a/\u5de5\u5177/\u914d\u7f6e\u7684\u4e00\u6b21\u6027\u54c8\u5e0c\u8eab\u4efd\u3001\u94fe\u5f0f\u59d4\u6258\u65ad\u8a00\u548c\u6bcf\u4ee3\u7406\u6301\u6709\u8bc1\u660e\u5bc6\u94a5\uff0c\u4ee5\u9632\u91cd\u653e\u4e0e\u5192\u5145\uff1b\u63d0\u4f9b\u8f7b\u91cf\u5ba2\u6237\u7aef shim \u5728\u8fd0\u884c\u65f6\u81ea\u9a8c\u8bc1\u3001\u94f8\u9020\u4ee4\u724c\u3001\u8ddf\u8e2a\u5de5\u4f5c\u6d41\u5e76\u6d3e\u751f\u5bc6\u94a5\uff1b\u5b9e\u73b0 Python \u539f\u578b\u5e76\u5728\u5a01\u80c1\u6a21\u578b\u4e0b\u5c55\u793a\u963b\u6b62\u8d8a\u6743\u3001\u91cd\u653e\u3001\u5192\u5145\u4e0e\u63d0\u793a\u6ce8\u5165\uff0c\u5f00\u9500\u4e9a\u6beb\u79d2\uff0c\u517c\u5bb9 OAuth agent \u8ba8\u8bba\uff0c\u63d0\u4f9b\u96f6\u4fe1\u4efb\u8def\u5f84\u3002", "motivation": "\u4f20\u7edf OAuth 2.0 \u5047\u5b9a\u5ba2\u6237\u7aef\u662f\u786e\u5b9a\u6027\u7684\uff0c\u4f46\u81ea\u6cbb LLM \u4ee3\u7406\u5b58\u5728\u968f\u673a\u63a8\u7406\u3001\u63d0\u793a\u6ce8\u5165\u4e0e\u591a\u4ee3\u7406\u7f16\u6392\uff0c\u4f1a\u5728\u65e0\u76d1\u7763\u60c5\u51b5\u4e0b\u6269\u5927\u6743\u9650\uff0c\u9700\u65b0\u7684\u673a\u5236\u628a\u4ee3\u7406\u7684\u884c\u4e3a\u660e\u786e\u7ed1\u5b9a\u5230\u7528\u6237\u610f\u56fe\u5e76\u9632\u6b62\u6ee5\u7528\u3002", "method": "\u63d0\u51fa A-JWT \u4ee4\u724c\u683c\u5f0f\uff08\u5305\u542b\u4ee3\u7406\u8eab\u4efd\u54c8\u5e0c\u3001\u94fe\u5f0f\u59d4\u6258\u3001\u6bcf\u4ee3\u7406 PoP \u5bc6\u94a5\u7b49\uff09\uff0c\u5b9a\u4e49\u65b0\u6388\u6743\u673a\u5236\uff0c\u5e76\u5b9e\u73b0\u4e00\u4e2a Python \u5ba2\u6237\u7aef shim \u5b9e\u65f6\u81ea\u9a8c\u8bc1\u4ee3\u7801\u3001\u94f8\u9020\u610f\u56fe\u4ee4\u724c\u3001\u8ddf\u8e2a\u5de5\u4f5c\u6d41\u6b65\u9aa4\u5e76\u6d3e\u751f\u5bc6\u94a5\uff1b\u901a\u8fc7\u5a01\u80c1\u5efa\u6a21\u4e0e\u57fa\u51c6\u6d4b\u8bd5\u9a8c\u8bc1\u5b89\u5168\u6027\u4e0e\u6027\u80fd\u3002", "result": "\u5b9e\u73b0\u4e86 Python PoC\uff0c\u8bc1\u660e\u53ef\u4ee5\u5728\u4e9a\u6beb\u79d2\u5f00\u9500\u4e0b\u963b\u6b62\u8303\u56f4\u8d8a\u754c\u8bf7\u6c42\u3001\u91cd\u653e\u3001\u5192\u5145\u4e0e\u63d0\u793a\u6ce8\u5165\uff1b\u4e0e OAuth agent \u8ba8\u8bba\u517c\u5bb9\uff0c\u4e3a\u4ee3\u7406\u5316\u5e94\u7528\u63d0\u4f9b\u96f6\u4fe1\u4efb\u4fdd\u8bc1\u7684\u53ef\u884c\u8def\u5f84\uff1b\u8be6\u7ec6\u5b9e\u9a8c\u4e0e\u6027\u80fd\u8bc4\u4f30\u5c06\u5728\u671f\u520a\u7248\u4e2d\u7ed9\u51fa\u3002", "conclusion": "A-JWT \u53ef\u4ee5\u5728\u4ee3\u7406\u5316\u573a\u666f\u4e2d\u4e3a\u6bcf\u4e2a\u4ee3\u7406\u63d0\u4f9b\u53ef\u9a8c\u8bc1\u7684\u610f\u56fe\u7ed1\u5b9a\u3001\u94fe\u5f0f\u59d4\u6258\u4e0e\u6301\u6709\u8bc1\u660e\uff0c\u4ece\u800c\u6709\u6548\u9632\u6b62\u8d8a\u6743\u3001\u91cd\u653e\u3001\u8fdb\u7a0b\u5185\u5192\u5145\u548c\u63d0\u793a\u6ce8\u5165\u653b\u51fb\uff0c\u5e76\u4e14\u53ef\u901a\u8fc7\u8f7b\u91cf shim \u5728\u5355\u8fdb\u7a0b\u5185\u5b9e\u73b0\uff0c\u517c\u5bb9\u73b0\u6709 OAuth \u8ba8\u8bba\u6846\u67b6\u3002"}}
{"id": "2509.13621", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.13621", "abs": "https://arxiv.org/abs/2509.13621", "authors": ["Antonin Sulc", "Thorsten Hellert", "Steven Hunt"], "title": "Unsupervised Anomaly Detection in ALS EPICS Event Logs", "comment": "6 pages, 5 figures, The 20th International Conference on Accelerator\n  and Large Experimental Physics Control Systems", "summary": "This paper introduces an automated fault analysis framework for the Advanced\nLight Source (ALS) that processes real-time event logs from its EPICS control\nsystem. By treating log entries as natural language, we transform them into\ncontextual vector representations using semantic embedding techniques. A\nsequence-aware neural network, trained on normal operational data, assigns a\nreal-time anomaly score to each event. This method flags deviations from\nbaseline behavior, enabling operators to rapidly identify the critical event\nsequences that precede complex system failures.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e00\u79cd\u9488\u5bf9ALS\u52a0\u901f\u5668\u7684\u81ea\u52a8\u5316\u6545\u969c\u5206\u6790\u6846\u67b6\uff0c\u5229\u7528\u8bed\u4e49\u5d4c\u5165\u5c06EPICS\u63a7\u5236\u7cfb\u7edf\u7684\u5b9e\u65f6\u65e5\u5fd7\u8f6c\u4e3a\u5411\u91cf\uff0c\u7ed3\u5408\u5e8f\u5217\u611f\u77e5\u795e\u7ecf\u7f51\u7edc\u5bf9\u4e8b\u4ef6\u6253\u5206\u4ee5\u68c0\u6d4b\u5f02\u5e38\u5e76\u5b9a\u4f4d\u5bfc\u81f4\u590d\u6742\u6545\u969c\u7684\u5173\u952e\u4e8b\u4ef6\u5e8f\u5217\u3002", "motivation": "\u590d\u6742\u7269\u7406\u5b9e\u9a8c\u8bbe\u65bd\uff08\u5982ALS\uff09\u8fd0\u884c\u65f6\u4ea7\u751f\u5927\u91cf\u5b9e\u65f6\u4e8b\u4ef6\u65e5\u5fd7\uff0c\u4f20\u7edf\u57fa\u4e8e\u89c4\u5219\u6216\u7edf\u8ba1\u7684\u65b9\u6cd5\u96be\u4ee5\u6355\u6349\u8bed\u4e49\u4e30\u5bcc\u4e14\u65f6\u5e8f\u4f9d\u8d56\u7684\u5f02\u5e38\u6a21\u5f0f\uff0c\u56e0\u800c\u9700\u8981\u81ea\u52a8\u5316\u3001\u8bed\u4e49\u611f\u77e5\u4e14\u5177\u65f6\u5e8f\u5efa\u6a21\u80fd\u529b\u7684\u6545\u969c\u5206\u6790\u65b9\u6cd5\u4ee5\u63d0\u9ad8\u5feb\u901f\u5b9a\u4f4d\u548c\u54cd\u5e94\u80fd\u529b\u3002", "method": "\u5c06EPICS\u65e5\u5fd7\u89c6\u4e3a\u81ea\u7136\u8bed\u8a00\uff0c\u5148\u7528\u8bed\u4e49\u5d4c\u5165\u6a21\u578b\u5c06\u6bcf\u6761\u65e5\u5fd7\u8f6c\u4e3a\u4e0a\u4e0b\u6587\u5411\u91cf\uff1b\u7136\u540e\u7528\u5728\u6b63\u5e38\u8fd0\u884c\u6570\u636e\u4e0a\u8bad\u7ec3\u7684\u5e8f\u5217\u611f\u77e5\u795e\u7ecf\u7f51\u7edc\uff08\u5982LSTM/Transformer\uff09\u5bf9\u4e8b\u4ef6\u5e8f\u5217\u8fdb\u884c\u5efa\u6a21\uff0c\u8f93\u51fa\u5b9e\u65f6\u5f02\u5e38\u5206\u6570\u5e76\u57fa\u4e8e\u9608\u503c\u6216\u6392\u5e8f\u6807\u8bb0\u5f02\u5e38\u4e8b\u4ef6\u6216\u5f02\u5e38\u5e8f\u5217\u3002", "result": "\u6846\u67b6\u80fd\u5728\u5b9e\u65f6\u65e5\u5fd7\u6d41\u4e2d\u8bc6\u522b\u504f\u79bb\u57fa\u7ebf\u7684\u4e8b\u4ef6\u5e76\u751f\u6210\u5f02\u5e38\u5206\u6570\uff0c\u5b9e\u9a8c\u6216\u90e8\u7f72\u7ed3\u679c\u663e\u793a\u53ef\u5feb\u901f\u5b9a\u4f4d\u5bfc\u81f4\u590d\u6742\u7cfb\u7edf\u6545\u969c\u7684\u5173\u952e\u4e8b\u4ef6\u5e8f\u5217\uff0c\u964d\u4f4e\u8bca\u65ad\u65f6\u95f4\u5e76\u63d0\u9ad8\u8fd0\u7ef4\u54cd\u5e94\u6548\u7387\u3002", "conclusion": "\u7528\u57fa\u4e8e\u8bed\u4e49\u5d4c\u5165\u4e0e\u5e8f\u5217\u6a21\u578b\u7684\u5b9e\u65f6\u5f02\u5e38\u8bc4\u5206\u65b9\u6cd5\uff0c\u53ef\u6709\u6548\u68c0\u6d4b\u504f\u79bb\u57fa\u7ebf\u884c\u4e3a\u7684\u4e8b\u4ef6\u5e76\u5e2e\u52a9\u8fd0\u7ef4\u5feb\u901f\u9501\u5b9a\u5bfc\u81f4\u590d\u6742\u6545\u969c\u7684\u5173\u952e\u4e8b\u4ef6\u5e8f\u5217\uff0c\u4ece\u800c\u63d0\u5347\u6545\u969c\u8bca\u65ad\u7684\u6548\u7387\u4e0e\u51c6\u786e\u6027\u3002"}}
{"id": "2509.13357", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.13357", "abs": "https://arxiv.org/abs/2509.13357", "authors": ["Yongchao Huang", "Hassan Raza"], "title": "Semantic Fusion with Fuzzy-Membership Features for Controllable Language Modelling", "comment": "16 pages", "summary": "We propose semantic fusion, a lightweight scheme that augments a Transformer\nlanguage model (LM) with a parallel, fuzzy-membership feature channel that\nencodes token-level semantics. Each token is represented by a vector of\ninterpretable features (e.g. part-of-speech cues, shallow roles, boundary\nflags, sentiment polarity and strength) whose values are graded degrees from\ndifferentiable membership functions (e.g. power kernels). These per-token\nvectors form a sentence-level semantic matrix fused via a gated adapter into\nthe LM. Training uses standard next-token prediction, an auxiliary loss that\nreconstructs the semantic features from hidden states, and a lightweight\nuniformizer that regularizes adjective-class distributions. On a synthetic\ntwo-clause corpus with held-out adjectives for out-of-distribution (OOD)\ncontrol, semantic fusion improves perplexity and enables precise,\nuser-controllable generation of polarity and punctuation while maintaining\nmodel simplicity. This approach adds only small overhead, remains fully\ncompatible with tied input-output embeddings, and provides an interpretable\npathway for conditioned natural language generation.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u5e76\u884c\u8bed\u4e49\u7279\u5f81\u901a\u9053\u4e0e\u95e8\u63a7\u878d\u5408\u7684\u8f7b\u91cf\u53ef\u89e3\u91ca\u6269\u5c55\uff0c\u4f7f Transformer \u66f4\u6613\u63a7\u3001\u6cdb\u5316\u66f4\u597d\u3001\u5f00\u9500\u5c0f\u3002", "motivation": "\u63d0\u9ad8\u8bed\u8a00\u6a21\u578b\u5bf9\u7ec6\u7c92\u5ea6\u8bed\u4e49\uff08\u5982\u6781\u6027\u3001\u6807\u70b9\u8fb9\u754c\u3001\u8bcd\u6027\u7b49\uff09\u7684\u53ef\u63a7\u751f\u6210\u80fd\u529b\u4e0e\u53ef\u89e3\u91ca\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u7b80\u5355\u4e0e\u4e0e\u73b0\u6709\u5d4c\u5165\u5171\u4eab\u7684\u517c\u5bb9\u6027\u3002", "method": "\u5728 Transformer \u5e76\u884c\u52a0\u5165\u4e00\u6761\u6a21\u7cca\u6210\u5458\u7279\u5f81\u901a\u9053\uff0c\u5bf9\u6bcf\u4e2a token \u7528\u53ef\u89e3\u91ca\u7279\u5f81\u5411\u91cf\u8868\u793a\uff0c\u5229\u7528\u53ef\u5fae membership \u51fd\u6570\u7ed9\u51fa\u6e10\u8fdb\u503c\uff1b\u5c06\u53e5\u7ea7\u8bed\u4e49\u77e9\u9635\u7ecf\u95e8\u63a7\u9002\u914d\u5668\u878d\u5408\u5165 LM\uff0c\u8bad\u7ec3\u5305\u62ec\u4e3b\u4efb\u52a1\uff08\u4e0b\u4e00\u4e2a token \u9884\u6d4b\uff09\u3001\u4ece\u9690\u85cf\u6001\u91cd\u6784\u8bed\u4e49\u7279\u5f81\u7684\u8f85\u52a9\u635f\u5931\uff0c\u4ee5\u53ca\u5bf9\u5f62\u5bb9\u8bcd\u5206\u5e03\u7684\u8f7b\u91cf\u6b63\u5219\u5316\uff08uniformizer\uff09\u3002", "result": "\u5728\u5408\u6210\u4e24\u5b50\u53e5\u8bed\u6599\u4e0a\uff08\u5bf9\u5f62\u5bb9\u8bcd\u505a OOD \u63a7\u5236\uff09\u5c55\u793a\u4e86\u56f0\u60d1\u5ea6\u964d\u4f4e\u3001\u6781\u6027\u4e0e\u6807\u70b9\u7684\u7cbe\u786e\u53ef\u63a7\u751f\u6210\uff0c\u5e76\u4e14\u4ec5\u5e26\u6765\u5c0f\u7684\u8ba1\u7b97\u4e0e\u53c2\u6570\u5f00\u9500\u3002", "conclusion": "Semantic fusion \u63d0\u5347\u4e86 Transformer LM \u7684\u53ef\u63a7\u6027\u4e0e OOD \u6cdb\u5316\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u8f7b\u91cf\u4e0e\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2509.14002", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2509.14002", "abs": "https://arxiv.org/abs/2509.14002", "authors": ["Rongyu Zhang", "Xize Duan", "Jiaming Liu", "Li Du", "Yuan Du", "Dan Wang", "Shanghang Zhang", "Fangxin Wang"], "title": "RepCaM++: Exploring Transparent Visual Prompt With Inference-Time Re-Parameterization for Neural Video Delivery", "comment": null, "summary": "Recently, content-aware methods have been employed to reduce bandwidth and\nenhance the quality of Internet video delivery. These methods involve training\ndistinct content-aware super-resolution (SR) models for each video chunk on the\nserver, subsequently streaming the low-resolution (LR) video chunks with the SR\nmodels to the client. Prior research has incorporated additional partial\nparameters to customize the models for individual video chunks. However, this\nleads to parameter accumulation and can fail to adapt appropriately as video\nlengths increase, resulting in increased delivery costs and reduced\nperformance. In this paper, we introduce RepCaM++, an innovative framework\nbased on a novel Re-parameterization Content-aware Modulation (RepCaM) module\nthat uniformly modulates video chunks. The RepCaM framework integrates extra\nparallel-cascade parameters during training to accommodate multiple chunks,\nsubsequently eliminating these additional parameters through\nre-parameterization during inference. Furthermore, to enhance RepCaM's\nperformance, we propose the Transparent Visual Prompt (TVP), which includes a\nminimal set of zero-initialized image-level parameters (e.g., less than 0.1%)\nto capture fine details within video chunks. We conduct extensive experiments\non the VSD4K dataset, encompassing six different video scenes, and achieve\nstate-of-the-art results in video restoration quality and delivery bandwidth\ncompression.", "AI": {"tldr": "\u63d0\u51faRepCaM++\uff0c\u5229\u7528\u53ef\u91cd\u53c2\u6570\u5316\u7684\u5185\u5bb9\u611f\u77e5\u8c03\u5236\u6a21\u5757\u548c\u6781\u5c0f\u7684\u900f\u660e\u89c6\u89c9\u63d0\u793a\uff0c\u5b9e\u73b0\u5bf9\u89c6\u9891\u7247\u6bb5\u7684\u4e00\u81f4\u9ad8\u6548\u8c03\u5236\uff0c\u5728VSD4K\u4e0a\u53d6\u5f97SOTA\u7684\u6062\u590d\u4e0e\u5e26\u5bbd\u538b\u7f29\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u5185\u5bb9\u611f\u77e5SR\u4e3a\u6bcf\u4e2a\u89c6\u9891\u7247\u6bb5\u8bad\u7ec3/\u4f20\u8f93\u4e13\u5c5e\u53c2\u6570\uff0c\u5bfc\u81f4\u53c2\u6570\u9010\u6b65\u7d2f\u79ef\u3001\u968f\u7740\u89c6\u9891\u957f\u5ea6\u589e\u52a0\u800c\u6210\u672c\u4e0e\u6027\u80fd\u95ee\u9898\uff1b\u9700\u8981\u4e00\u79cd\u5728\u4fdd\u6301\u4e2a\u6027\u5316\u6548\u5e94\u540c\u65f6\u907f\u514d\u53c2\u6570\u7d2f\u79ef\u7684\u9ad8\u6548\u65b9\u6848\u3002", "method": "\u63d0\u51faRe-parameterization Content-aware Modulation (RepCaM)\u6a21\u5757\uff0c\u8bad\u7ec3\u9636\u6bb5\u63d2\u5165\u989d\u5916\u5e76\u8054-\u7ea7\u8054\u53c2\u6570\u4ee5\u9002\u914d\u591a\u7247\u6bb5\uff0c\u63a8\u7406\u9636\u6bb5\u901a\u8fc7\u91cd\u53c2\u6570\u5316\u5408\u5e76\u6d88\u9664\u8fd9\u4e9b\u989d\u5916\u53c2\u6570\uff1b\u540c\u65f6\u5f15\u5165Transparent Visual Prompt (TVP)\uff0c\u4ee5\u6781\u5c11\u96f6\u521d\u59cb\u5316\u56fe\u50cf\u7ea7\u53c2\u6570\u6355\u83b7\u7ec6\u8282\uff1b\u5728VSD4K\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u8bc4\u4f30\u3002", "result": "\u5728VSD4K\u7684\u516d\u4e2a\u89c6\u9891\u573a\u666f\u4e0a\uff0cRepCaM++\u5728\u89c6\u9891\u6062\u590d\u8d28\u91cf\u548c\u4f20\u8f93\u5e26\u5bbd\u538b\u7f29\u65b9\u9762\u5747\u8fbe\u5230\u4e86SOTA\u6c34\u5e73\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u6027\u80fd\u4e0e\u6210\u672c\u4e0a\u7684\u53cc\u91cd\u4f18\u52bf\u3002", "conclusion": "RepCaM++\u901a\u8fc7\u8bad\u7ec3\u65f6\u5e76\u8054\u7ea7\u8054\u7684\u53ef\u91cd\u53c2\u6570\u5316\u6a21\u5757\u5e76\u5728\u63a8\u7406\u65f6\u79fb\u9664\u989d\u5916\u53c2\u6570\uff0c\u5b9e\u73b0\u5bf9\u89c6\u9891\u7247\u6bb5\u7684\u4e00\u81f4\u8c03\u5236\uff0c\u4ece\u800c\u907f\u514d\u53c2\u6570\u7d2f\u79ef\u5e76\u4fdd\u6301\u9ad8\u8d28\u91cf\u91cd\u5efa\u4e0e\u5e26\u5bbd\u6548\u7387\u3002"}}
{"id": "2509.13625", "categories": ["cs.LG", "cs.CL", "cs.CR"], "pdf": "https://arxiv.org/pdf/2509.13625", "abs": "https://arxiv.org/abs/2509.13625", "authors": ["Bishnu Bhusal", "Manoj Acharya", "Ramneet Kaur", "Colin Samplawski", "Anirban Roy", "Adam D. Cobb", "Rohit Chadha", "Susmit Jha"], "title": "Privacy-Aware In-Context Learning for Large Language Models", "comment": null, "summary": "Large language models (LLMs) have significantly transformed natural language\nunderstanding and generation, but they raise privacy concerns due to potential\nexposure of sensitive information. Studies have highlighted the risk of\ninformation leakage, where adversaries can extract sensitive information\nembedded in the prompts. In this work, we introduce a novel private prediction\nframework for generating high-quality synthetic text with strong privacy\nguarantees. Our approach leverages the Differential Privacy (DP) framework to\nensure worst-case theoretical bounds on information leakage without requiring\nany fine-tuning of the underlying models.The proposed method performs inference\non private records and aggregates the resulting per-token output distributions.\nThis enables the generation of longer and coherent synthetic text while\nmaintaining privacy guarantees. Additionally, we propose a simple blending\noperation that combines private and public inference to further enhance\nutility. Empirical evaluations demonstrate that our approach outperforms\nprevious state-of-the-art methods on in-context-learning (ICL) tasks, making it\na promising direction for privacy-preserving text generation while maintaining\nhigh utility.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u5fae\u8c03\u7684\u57fa\u4e8e\u5dee\u5206\u9690\u79c1\u7684\u79c1\u6709\u9884\u6d4b\u5408\u6210\u6587\u672c\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u805a\u5408\u6bcf-token\u5206\u5e03\u5e76\u6df7\u5408\u516c\u79c1\u63a8\u7406\uff0c\u5728\u4fdd\u8bc1\u7406\u8bba\u9690\u79c1\u4e0b\u63d0\u5347\u751f\u6210\u8d28\u91cf\u548c\u957f\u671f\u8fde\u8d2f\u6027\uff0cICL\u4efb\u52a1\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u53ef\u80fd\u6cc4\u9732\u63d0\u793a\u4e2d\u5305\u542b\u7684\u654f\u611f\u4fe1\u606f\uff0c\u73b0\u6709\u653b\u51fb\u80fd\u63d0\u53d6\u79c1\u5bc6\u4fe1\u606f\uff1b\u56e0\u6b64\u9700\u8981\u5728\u4e0d\u5fae\u8c03\u6a21\u578b\u7684\u60c5\u51b5\u4e0b\u63d0\u4f9b\u5f3a\u9690\u79c1\u4fdd\u8bc1\u7684\u6587\u672c\u751f\u6210\u65b9\u6cd5\u3002", "method": "\u5bf9\u79c1\u4eba\u8bb0\u5f55\u8fdb\u884c\u63a8\u7406\uff0c\u6536\u96c6\u6bcf\u4e2atoken\u7684\u8f93\u51fa\u5206\u5e03\u5e76\u5bf9\u5176\u805a\u5408\uff0c\u4ece\u800c\u5728\u4fdd\u6301\u9690\u79c1\u4fdd\u8bc1\u7684\u524d\u63d0\u4e0b\u751f\u6210\u66f4\u957f\u4e14\u8fde\u8d2f\u7684\u6587\u672c\uff1b\u6b64\u5916\u63d0\u51fa\u4e86\u5c06\u79c1\u6709\u63a8\u7406\u4e0e\u516c\u5171\u63a8\u7406\u8fdb\u884c\u6df7\u5408\u7684\u64cd\u4f5c\u4ee5\u63d0\u9ad8\u6548\u7528\u3002", "result": "\u5b9e\u8bc1\u8bc4\u4f30\u8868\u660e\u8be5\u65b9\u6cd5\u5728in-context-learning\u4efb\u52a1\u4e0a\u4f18\u4e8e\u5148\u524d\u7684\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u5728\u4fdd\u8bc1\u5dee\u5206\u9690\u79c1\u4e0b\u5b9e\u73b0\u66f4\u9ad8\u7684\u5b9e\u7528\u6027\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5dee\u5206\u9690\u79c1\u7684\u79c1\u6709\u9884\u6d4b\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u4e0d\u5fae\u8c03\u6a21\u578b\u7684\u60c5\u51b5\u4e0b\u751f\u6210\u9ad8\u8d28\u91cf\u7684\u5408\u6210\u6587\u672c\uff0c\u5e76\u5728\u7406\u8bba\u4e0a\u7ed9\u51fa\u4fe1\u606f\u6cc4\u9732\u7684\u754c\u9650\u3002"}}
{"id": "2509.13364", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.13364", "abs": "https://arxiv.org/abs/2509.13364", "authors": ["Zixi Li"], "title": "Asterisk Operator", "comment": "Code available at: https://github.com/lizixi-0x2F/Asterisk-Games", "summary": "We propose the \\textbf{Asterisk Operator} ($\\ast$-operator), a novel unified\nframework for abstract reasoning based on Adjacency-Structured Parallel\nPropagation (ASPP). The operator formalizes structured reasoning tasks as\nlocal, parallel state evolution processes guided by implicit relational graphs.\nWe prove that the $\\ast$-operator maintains local computational constraints\nwhile achieving global reasoning capabilities, providing an efficient and\nconvergent computational paradigm for abstract reasoning problems. Through\nrigorous mathematical analysis and comprehensive experiments on ARC2 challenges\nand Conway's Game of Life, we demonstrate the operator's universality,\nconvergence properties, and superior performance. Our innovative\nEmbedding-Asterisk distillation method achieves 100\\% accuracy on ARC2\nvalidation with only 6M parameters, representing a significant breakthrough in\nneural-symbolic reasoning.\n  \\textbf{Keywords:} Abstract Reasoning, Adjacency Structure, Parallel\nPropagation, Asterisk Operator, Convergence, Universal Approximation", "AI": {"tldr": "\u63d0\u51fa\u4e86Asterisk\u7b97\u5b50\uff08ASPP\uff09\uff0c\u5c06\u7ed3\u6784\u5316\u63a8\u7406\u5efa\u6a21\u4e3a\u57fa\u4e8e\u9690\u5f0f\u5173\u7cfb\u56fe\u7684\u5c40\u90e8\u5e76\u884c\u72b6\u6001\u6f14\u5316\uff1b\u7406\u8bba\u8bc1\u660e\u5176\u6536\u655b\u6027\u548c\u5168\u5c40\u63a8\u7406\u80fd\u529b\uff0c\u5b9e\u9a8c\u5728ARC2\u4e0e\u751f\u547d\u6e38\u620f\u4e0a\u8868\u73b0\u4f18\u5f02\uff0cEmbedding-Asterisk\u57286M\u53c2\u6570\u4e0b\u5b9e\u73b0ARC2\u9a8c\u8bc1\u96c6100%\u51c6\u786e\u7387\u3002", "motivation": "Introduce a unified operator for abstract reasoning that leverages local adjacency-structured parallel propagation to enable efficient, convergent global reasoning under local constraints.", "method": "\u5c06\u63a8\u7406\u4efb\u52a1\u8868\u8ff0\u4e3a\u90bb\u63a5\u7ed3\u6784\u7684\u5e76\u884c\u4f20\u64ad\u8fc7\u7a0b\uff08ASPP\uff09\uff0c\u901a\u8fc7\u6570\u5b66\u8bc1\u660e\u5c55\u793a\u6536\u655b\u4e0e\u666e\u9002\u6027\uff0c\u5e76\u63d0\u51faEmbedding-Asterisk\u84b8\u998f\u4ee5\u8bad\u7ec36M\u53c2\u6570\u6a21\u578b\uff1b\u5728ARC2\u4e0e\u5eb7\u5a01\u751f\u547d\u6e38\u620f\u4e0a\u8fdb\u884c\u7efc\u5408\u5b9e\u9a8c\u8bc4\u4f30\u3002", "result": "Defined the Asterisk Operator (ASPP framework); proved local constraints preserved with global reasoning and convergence; empirical success on ARC2 and Game of Life; Embedding-Asterisk distillation achieved 100% ARC2 validation with 6M params.", "conclusion": "Asterisk\u7b97\u5b50\u4e3a\u62bd\u8c61\u63a8\u7406\u63d0\u4f9b\u4e86\u4e00\u4e2a\u540c\u65f6\u6ee1\u8db3\u5c40\u90e8\u8ba1\u7b97\u9650\u5236\u4e0e\u5168\u5c40\u63a8\u7406\u80fd\u529b\u7684\u9ad8\u6548\u3001\u53ef\u6536\u655b\u8303\u5f0f\uff0c\u5177\u5907\u666e\u9002\u6027\u5e76\u5728\u5c0f\u6a21\u578b\u4e0b\u5b9e\u73b0\u663e\u8457\u6027\u80fd\u3002"}}
{"id": "2509.13797", "categories": ["cs.CR", "cs.NI"], "pdf": "https://arxiv.org/pdf/2509.13797", "abs": "https://arxiv.org/abs/2509.13797", "authors": ["Ali Sadeghi Jahromi", "AbdelRahman Abdou", "Paul C. van Oorschot"], "title": "A Survey and Evaluation Framework for Secure DNS Resolution", "comment": null, "summary": "Since security was not among the original design goals of the Domain Name\nSystem (herein called Vanilla DNS), many secure DNS schemes have been proposed\nto enhance the security and privacy of the DNS resolution process. Some\nproposed schemes aim to replace the existing DNS infrastructure entirely, but\nnone have succeeded in doing so. In parallel, numerous schemes focus on\nimproving DNS security without modifying its fundamental two-stage structure.\nThese efforts highlight the feasibility of addressing DNS security as two\ndistinct but compatible stages. We survey DNS resolution process attacks and\nthreats and develop a comprehensive threat model and attack taxonomy for their\nsystematic categorization. This analysis results in the formulation of 14\ndesirable security, privacy, and availability properties to mitigate the\nidentified threats. Using these properties, we develop an objective evaluation\nframework and apply it to comparatively analyze 12 secure DNS schemes surveyed\nin this work that aim to augment the properties of the DNS resolution process.\nOur evaluation reveals that no single scheme provides ideal protection across\nthe entire resolution path. Instead, the schemes tend to address a subset of\nproperties specific to individual stages. Since these schemes targeting\ndifferent stages of DNS resolution are complementary and can operate together,\ncombining compatible schemes offers a practical and effective approach to\nachieving comprehensive security in the DNS resolution process.", "AI": {"tldr": "\u6784\u5efa\u4e86DNS\u89e3\u6790\u5a01\u80c1\u6a21\u578b\u4e0e14\u9879\u9632\u62a4\u5c5e\u6027\uff0c\u57fa\u4e8e\u6b64\u8bc4\u4f3012\u79cd\u589e\u5f3aDNS\u5b89\u5168\u7684\u65b9\u6848\uff0c\u53d1\u73b0\u65e0\u5355\u4e00\u4e07\u5168\u4e4b\u7b56\uff0c\u63a8\u8350\u7ec4\u5408\u4e92\u8865\u90e8\u7f72\u4ee5\u5b9e\u73b0\u5168\u9762\u9632\u62a4\u3002", "motivation": "\u9274\u4e8e\u539f\u59cbDNS\u8bbe\u8ba1\u672a\u5c06\u5b89\u5168\u4f5c\u4e3a\u76ee\u6807\uff0c\u4e14\u5b8c\u5168\u66ff\u4ee3\u73b0\u6709\u57fa\u7840\u8bbe\u65bd\u7684\u65b9\u6848\u672a\u6210\u529f\uff0c\u7814\u7a76\u8005\u503e\u5411\u4e8e\u5728\u4e0d\u6539\u52a8\u4e24\u9636\u6bb5\u89e3\u6790\u7ed3\u6784\u7684\u524d\u63d0\u4e0b\u9010\u6b65\u589e\u5f3aDNS\u5b89\u5168\u4e0e\u9690\u79c1\u3002\u4f5c\u8005\u65e8\u5728\u7cfb\u7edf\u5316\u5730\u5206\u7c7b\u653b\u51fb\u3001\u660e\u786e\u6240\u9700\u4fdd\u969c\u5c5e\u6027\uff0c\u5e76\u5ba2\u89c2\u8bc4\u4f30\u73b0\u6709\u65b9\u6848\u7684\u8986\u76d6\u60c5\u51b5\u3002", "method": "\u672c\u6587\u901a\u8fc7\u6784\u5efa\u5168\u9762\u7684\u5a01\u80c1\u6a21\u578b\u4e0e\u653b\u51fb\u5206\u7c7b\u6cd5\uff0c\u63d0\u70bc\u51fa14\u6761\u5b89\u5168/\u9690\u79c1/\u53ef\u7528\u6027\u5c5e\u6027\uff0c\u5e76\u4ee5\u6b64\u4e3a\u8bc4\u4f30\u6846\u67b6\uff0c\u5bf912\u79cd\u73b0\u6709\u589e\u5f3aDNS\u5b89\u5168\u7684\u65b9\u6848\u8fdb\u884c\u5bf9\u6bd4\u5206\u6790\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff1a\u5404\u65b9\u6848\u591a\u4e13\u6ce8\u67d0\u4e9b\u89e3\u6790\u9636\u6bb5\u7684\u95ee\u9898\uff0c\u7f3a\u4e4f\u5168\u8def\u5f84\u4fdd\u969c\uff1b\u65b9\u6848\u4e4b\u95f4\u5177\u5907\u4e92\u8865\u6027\uff0c\u53ef\u7ec4\u5408\u90e8\u7f72\u4ee5\u5f25\u8865\u5355\u4e00\u65b9\u6848\u7684\u4e0d\u8db3\u3002", "conclusion": "\u672c\u6587\u7ed3\u8bba\u4e3a\uff1a\u9488\u5bf9DNS\u89e3\u6790\u8fc7\u7a0b\u7684\u5b89\u5168\u3001\u9690\u79c1\u4e0e\u53ef\u7528\u6027\u95ee\u9898\uff0c\u6ca1\u6709\u5355\u4e00\u65b9\u6848\u80fd\u8986\u76d6\u6240\u6709\u9636\u6bb5\u4e0e\u9700\u6c42\uff0c\u4f46\u901a\u8fc7\u7ec4\u5408\u4e92\u8865\u7684\u65b9\u6848\u53ef\u4ee5\u5b9e\u73b0\u5168\u9762\u4e14\u5b9e\u7528\u7684\u4fdd\u62a4\u7b56\u7565\u3002"}}
{"id": "2509.13684", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.13684", "abs": "https://arxiv.org/abs/2509.13684", "authors": ["Lin Zhu", "Lingwei Kong", "Xin Ning", "Xiaoyang Qu", "Jianzong Wang"], "title": "Publicly Verifiable Private Information Retrieval Protocols Based on Function Secret Sharing", "comment": "Accepted by the 21st International Conference on Information Security\n  and Cryptology (Inscrypt2025)", "summary": "Private Information Retrieval (PIR) is a fundamental cryptographic primitive\nthat enables users to retrieve data from a database without revealing which\nitem is being accessed, thereby preserving query privacy. However, PIR\nprotocols also face the challenge of result verifiability, as users expect the\nreconstructed data to be trustworthy and authentic. In this work, we propose\ntwo effective constructions of publicly verifiable PIR (PVPIR) in the\nmulti-server setting, which achieve query privacy, correctness, and\nverifiability simultaneously. We further present three concrete instantiations\nbased on these constructions. For the point query, our protocol introduces\nminimal computational overhead and achieves strong verifiability guarantees\nwith significantly lower communication costs compared to existing Merkle\ntree-based approaches. For the predicate query, the communication complexity of\nour scheme remains stable as the database size increases, demonstrating strong\nscalability and suitability for large-scale private query applications.", "AI": {"tldr": "\u672c\u6587\u5728\u591a\u670d\u52a1\u5668\u73af\u5883\u4e0b\u63d0\u51fa\u4e24\u79cd\u516c\u5f00\u53ef\u9a8c\u8bc1PIR\u6784\u9020\u4e0e\u4e09\u79cd\u5b9e\u4f8b\u5316\uff1a\u70b9\u67e5\u901a\u4fe1\u6210\u672c\u4f4e\u3001\u8c13\u8bcd\u67e5\u901a\u4fe1\u590d\u6742\u5ea6\u4e0e\u6570\u636e\u5e93\u5927\u5c0f\u65e0\u5173\uff0c\u517c\u987e\u9690\u79c1\u4e0e\u53ef\u9a8c\u8bc1\u6027\u3002", "motivation": "\u4f20\u7edfPIR\u5173\u6ce8\u67e5\u8be2\u9690\u79c1\uff0c\u4f46\u7f3a\u5c11\u7ed3\u679c\u53ef\u9a8c\u8bc1\u6027\uff1b\u4e3a\u6ee1\u8db3\u7528\u6237\u5bf9\u6570\u636e\u771f\u5b9e\u6027\u7684\u9700\u6c42\uff0c\u9700\u5f15\u5165\u53ef\u9a8c\u8bc1\u673a\u5236\uff0c\u540c\u65f6\u5c3d\u91cf\u964d\u4f4e\u901a\u4fe1\u4e0e\u8ba1\u7b97\u5f00\u9500\uff0c\u7279\u522b\u662f\u5728\u591a\u670d\u52a1\u5668\u8bbe\u7f6e\u4e0b\u3002", "method": "\u901a\u8fc7\u8bbe\u8ba1\u540c\u65f6\u6ee1\u8db3\u67e5\u8be2\u9690\u79c1\u3001\u6b63\u786e\u6027\u4e0e\u53ef\u9a8c\u8bc1\u6027\u7684\u534f\u8bae\u6846\u67b6\uff0c\u5e76\u57fa\u4e8e\u8be5\u6846\u67b6\u63d0\u51fa\u4e09\u79cd\u5b9e\u4f8b\u5316\u65b9\u6848\uff1b\u70b9\u67e5\u8be2\u65b9\u6848\u91c7\u7528\u8f7b\u91cf\u7ea7\u8ba1\u7b97\u5e76\u7528\u66ff\u4ee3Merkle\u6811\u7684\u8bc1\u660e\u673a\u5236\u4ee5\u964d\u4f4e\u901a\u4fe1\u6210\u672c\uff1b\u8c13\u8bcd\u67e5\u8be2\u65b9\u6848\u4fdd\u6301\u4e0e\u6570\u636e\u5e93\u5927\u5c0f\u65e0\u5173\u7684\u901a\u4fe1\u590d\u6742\u5ea6\uff0c\u4ee5\u63d0\u5347\u53ef\u6269\u5c55\u6027\u3002", "result": "\u63d0\u51fa\u7684PVPIR\u6784\u9020\u5728\u4fdd\u8bc1\u5f3a\u53ef\u9a8c\u8bc1\u6027\u7684\u540c\u65f6\uff0c\u5728\u70b9\u67e5\u8be2\u4e2d\u663e\u8457\u964d\u4f4e\u901a\u4fe1\u6210\u672c\uff0c\u5728\u8c13\u8bcd\u67e5\u8be2\u4e2d\u4fdd\u6301\u901a\u4fe1\u590d\u6742\u5ea6\u4e0e\u6570\u636e\u5e93\u89c4\u6a21\u65e0\u5173\uff0c\u9002\u5408\u5927\u89c4\u6a21\u79c1\u6709\u67e5\u8be2\u573a\u666f\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e24\u79cd\u5728\u591a\u670d\u52a1\u5668\u73af\u5883\u4e0b\u5b9e\u73b0\u516c\u5f00\u53ef\u9a8c\u8bc1\u7684\u79c1\u6709\u4fe1\u606f\u68c0\u7d22(PVPIR)\u7684\u6784\u9020\uff0c\u5e76\u7ed9\u51fa\u4e09\u79cd\u5177\u4f53\u5b9e\u4f8b\u5316\uff1a\u70b9\u67e5\u548c\u8c13\u8bcd\u67e5\u67e5\u8be2\u7684\u534f\u8bae\u3002"}}
{"id": "2509.13633", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.13633", "abs": "https://arxiv.org/abs/2509.13633", "authors": ["Jeremy Oon", "Rakhi Manohar Mepparambath", "Ling Feng"], "title": "DeepLogit: A sequentially constrained explainable deep learning modeling approach for transport policy analysis", "comment": null, "summary": "Despite the significant progress of deep learning models in multitude of\napplications, their adaption in planning and policy related areas remains\nchallenging due to the black-box nature of these models. In this work, we\ndevelop a set of DeepLogit models that follow a novel sequentially constrained\napproach in estimating deep learning models for transport policy analysis. In\nthe first step of the proposed approach, we estimate a convolutional neural\nnetwork (CNN) model with only linear terms, which is equivalent of a\nlinear-in-parameter multinomial logit model. We then estimate other deep\nlearning models by constraining the parameters that need interpretability at\nthe values obtained in the linear-in-parameter CNN model and including higher\norder terms or by introducing advanced deep learning architectures like\nTransformers. Our approach can retain the interpretability of the selected\nparameters, yet provides significantly improved model accuracy than the\ndiscrete choice model. We demonstrate our approach on a transit route choice\nexample using real-world transit smart card data from Singapore. This study\nshows the potential for a unifying approach, where theory-based discrete choice\nmodel (DCM) and data-driven AI models can leverage each other's strengths in\ninterpretability and predictive power. With the availability of larger datasets\nand more complex constructions, such approach can lead to more accurate models\nusing discrete choice models while maintaining its applicability in planning\nand policy-related areas. Our code is available on\nhttps://github.com/jeremyoon/route-choice/ .", "AI": {"tldr": "DeepLogit\u901a\u8fc7\u5148\u4f30\u8ba1\u53ef\u89e3\u91ca\u7684\u7ebf\u6027CNN\u53c2\u6570\u5e76\u5728\u540e\u7eed\u6a21\u578b\u4e2d\u56fa\u5b9a\u8fd9\u4e9b\u53c2\u6570\uff0c\u540c\u65f6\u5f15\u5165\u66f4\u590d\u6742\u7684\u6df1\u5ea6\u67b6\u6784\uff0c\u5b9e\u73b0\u4e86\u53ef\u89e3\u91ca\u6027\u4e0e\u9884\u6d4b\u529b\u7684\u517c\u987e\uff0c\u5e76\u5728\u65b0\u52a0\u5761\u516c\u4ea4\u8def\u7ebf\u9009\u62e9\u4efb\u52a1\u4e0a\u9a8c\u8bc1\u4e86\u6548\u679c\u3002", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u867d\u6709\u9ad8\u9884\u6d4b\u80fd\u529b\uff0c\u4f46\u4f5c\u4e3a\u9ed1\u7bb1\u6a21\u578b\u96be\u4ee5\u7528\u4e8e\u89c4\u5212\u4e0e\u653f\u7b56\u9886\u57df\uff1b\u56e0\u6b64\u5e0c\u671b\u5728\u63d0\u5347\u9884\u6d4b\u6027\u80fd\u7684\u540c\u65f6\u4fdd\u7559\u51b3\u7b56\u5206\u6790\u6240\u9700\u7684\u53c2\u6570\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u63d0\u51fa\u987a\u5e8f\u7ea6\u675f\u7684\u4f30\u8ba1\u6d41\u7a0b\uff1a\u5148\u7528\u4ec5\u542b\u7ebf\u6027\u9879\u7684CNN\u4f30\u8ba1\u7b49\u4ef7\u4e8e\u7ebf\u6027\u53c2\u6570\u5316\u7684\u591a\u9879Logit\u6a21\u578b\uff0c\u56fa\u5b9a\u9700\u4fdd\u6301\u53ef\u89e3\u91ca\u6027\u7684\u53c2\u6570\u4e3a\u8be5\u4f30\u8ba1\u503c\uff0c\u7136\u540e\u5728\u540e\u7eed\u6a21\u578b\u4e2d\u52a0\u5165\u9ad8\u9636\u9879\u6216\u66f4\u590d\u6742\u67b6\u6784\uff08\u5982Transformer\uff09\u8fdb\u884c\u4f30\u8ba1\u3002", "result": "\u5728\u65b0\u52a0\u5761\u771f\u5b9e\u516c\u4ea4\u5237\u5361\u6570\u636e\u7684\u8def\u7ebf\u9009\u62e9\u6848\u4f8b\u4e2d\uff0cDeepLogit\u5728\u4fdd\u6301\u89e3\u91ca\u6027\u53c2\u6570\u4e0d\u53d8\u7684\u524d\u63d0\u4e0b\uff0c\u6bd4\u4f20\u7edf\u79bb\u6563\u9009\u62e9\u6a21\u578b\u63d0\u4f9b\u4e86\u663e\u8457\u7684\u7cbe\u5ea6\u63d0\u5347\u3002", "conclusion": "\u63d0\u51fa\u7684DeepLogit\u6846\u67b6\u5728\u4fdd\u7559\u5173\u952e\u53c2\u6570\u53ef\u89e3\u91ca\u6027\u7684\u540c\u65f6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u9884\u6d4b\u6027\u80fd\uff0c\u80fd\u5c06\u7406\u8bba\u9a71\u52a8\u7684\u79bb\u6563\u9009\u62e9\u6a21\u578b\u4e0e\u6570\u636e\u9a71\u52a8\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7ed3\u5408\u8d77\u6765\uff0c\u9002\u7528\u4e8e\u4ea4\u901a\u51fa\u884c\u7b56\u7565\u5206\u6790\u3002"}}
{"id": "2509.13368", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.13368", "abs": "https://arxiv.org/abs/2509.13368", "authors": ["Yuan Wei", "Xiaohan Shan", "Ran Miao", "Jianmin Li"], "title": "$Agent^2$: An Agent-Generates-Agent Framework for Reinforcement Learning Automation", "comment": "9 pages, 7 figures", "summary": "Reinforcement learning agent development traditionally requires extensive\nexpertise and lengthy iterations, often resulting in high failure rates and\nlimited accessibility. This paper introduces $Agent^2$, a novel\nagent-generates-agent framework that achieves fully automated RL agent design\nthrough intelligent LLM-driven generation. The system autonomously transforms\nnatural language task descriptions and environment code into comprehensive,\nhigh-performance reinforcement learning solutions without human intervention.\n$Agent^2$ features a revolutionary dual-agent architecture. The Generator Agent\nserves as an autonomous AI designer that analyzes tasks and generates\nexecutable RL agents, while the Target Agent is the resulting automatically\ngenerated RL agent. The framework decomposes RL development into two distinct\nstages: MDP modeling and algorithmic optimization, enabling more targeted and\neffective agent generation. Built on the Model Context Protocol, $Agent^2$\nprovides a unified framework that standardizes intelligent agent creation\nacross diverse environments and algorithms, while incorporating adaptive\ntraining management and intelligent feedback analysis for continuous\nimprovement. Extensive experiments on a wide range of benchmarks, including\nMuJoCo, MetaDrive, MPE, and SMAC, demonstrate that $Agent^2$ consistently\noutperforms manually designed solutions across all tasks, achieving up to 55%\nperformance improvement and substantial gains on average. By enabling truly\nend-to-end, closed-loop automation, this work establishes a new paradigm in\nwhich intelligent agents design and optimize other agents, marking a\nfundamental breakthrough for automated AI systems.", "AI": {"tldr": "Agent^2 \u7528LLM\u9a71\u52a8\u7684\u53cc\u667a\u80fd\u4f53\u6846\u67b6\u81ea\u52a8\u5c06\u4efb\u52a1\u4e0e\u73af\u5883\u4ee3\u7801\u751f\u6210\u9ad8\u6027\u80fdRL\u4ee3\u7406\uff0c\u5206\u4e3aMDP\u5efa\u6a21\u4e0e\u7b97\u6cd5\u4f18\u5316\u4e24\u9636\u6bb5\uff0c\u5e76\u5728\u591a\u9879\u57fa\u51c6\u4e0a\u4f18\u4e8e\u4eba\u5de5\u8bbe\u8ba1\uff0c\u6807\u5fd7\u7740\u4ee3\u7406\u81ea\u52a8\u5316\u7684\u65b0\u8303\u5f0f\u3002", "motivation": "\u51cf\u5c11\u5f3a\u5316\u5b66\u4e60\u5f00\u53d1\u5bf9\u4e13\u5bb6\u77e5\u8bc6\u548c\u53cd\u590d\u8fed\u4ee3\u7684\u4f9d\u8d56\uff0c\u964d\u4f4e\u5931\u8d25\u7387\u5e76\u63d0\u5347\u53ef\u53ca\u6027\uff0c\u5b9e\u73b0\u4ee3\u7406\u81ea\u52a8\u5316\u8bbe\u8ba1\u4e0e\u4f18\u5316\u3002", "method": "\u5f15\u5165Generator Agent\uff08\u751f\u6210\u5668\uff09\u548cTarget Agent\uff08\u76ee\u6807\u4ee3\u7406\uff09\uff0c\u5c06RL\u5f00\u53d1\u5206\u4e3aMDP\u5efa\u6a21\u4e0e\u7b97\u6cd5\u4f18\u5316\u4e24\u9636\u6bb5\uff1b\u57fa\u4e8eModel Context Protocol\u8fdb\u884c\u6807\u51c6\u5316\uff1b\u7ed3\u5408\u81ea\u9002\u5e94\u8bad\u7ec3\u7ba1\u7406\u548c\u667a\u80fd\u53cd\u9988\u5206\u6790\u5b9e\u73b0\u95ed\u73af\u6539\u8fdb\u3002", "result": "\u5728MuJoCo\u3001MetaDrive\u3001MPE\u3001SMAC\u7b49\u57fa\u51c6\u4e0a\u6bd4\u4eba\u5de5\u8bbe\u8ba1\u65b9\u6848\u6700\u9ad8\u63d0\u534755%\uff0c\u5e73\u5747\u4e5f\u6709\u663e\u8457\u63d0\u5347\uff0c\u5c55\u793a\u4e86\u7aef\u5230\u7aef\u95ed\u73af\u81ea\u52a8\u5316\u7684\u53ef\u884c\u6027\u3002", "conclusion": "Agent^2 \u63d0\u51fa\u4e86\u4e00\u79cd\u53cc\u667a\u80fd\u4f53\u67b6\u6784\uff0c\u5b9e\u73b0\u4e86\u4ece\u4efb\u52a1\u63cf\u8ff0\u548c\u73af\u5883\u4ee3\u7801\u5230\u53ef\u6267\u884c\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\u7684\u5168\u81ea\u52a8\u751f\u6210\uff0c\u58f0\u79f0\u5728\u591a\u79cd\u57fa\u51c6\u4e0a\u4f18\u4e8e\u4eba\u5de5\u8bbe\u8ba1\u3002"}}
{"id": "2509.13740", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.13740", "abs": "https://arxiv.org/abs/2509.13740", "authors": ["Moritz Bley", "Tobias Scharnowski", "Simon W\u00f6rner", "Moritz Schloegel", "Thorsten Holz"], "title": "Protocol-Aware Firmware Rehosting for Effective Fuzzing of Embedded Network Stacks", "comment": "Extended version of our paper \"Protocol-Aware Fimrware Rehosting for\n  Effective Fuzzing of Embedded Network Stacks\" published at ACM CCS 2025", "summary": "One of the biggest attack surfaces of embedded systems is their network\ninterfaces, which enable communication with other devices. Unlike their\ngeneral-purpose counterparts, embedded systems are designed for specialized use\ncases, resulting in unique and diverse communication stacks. Unfortunately,\ncurrent approaches for evaluating the security of these embedded network stacks\nrequire manual effort or access to hardware, and they generally focus only on\nsmall parts of the embedded system. A promising alternative is firmware\nrehosting, which enables fuzz testing of the entire firmware by generically\nemulating the physical hardware. However, existing rehosting methods often\nstruggle to meaningfully explore network stacks due to their complex,\nmulti-layered input formats. This limits their ability to uncover deeply nested\nsoftware faults.\n  To address this problem, we introduce a novel method to automatically detect\nand handle the use of network protocols in firmware called Pemu. By\nautomatically deducing the available network protocols, Pemu can transparently\ngenerate valid network packets that encapsulate fuzzing data, allowing the\nfuzzing input to flow directly into deeper layers of the firmware logic. Our\napproach thus enables a deeper, more targeted, and layer-by-layer analysis of\nfirmware components that were previously difficult or impossible to test. Our\nevaluation demonstrates that Pemu consistently improves the code coverage of\nthree existing rehosting tools for embedded network stacks. Furthermore, our\nfuzzer rediscovered several known vulnerabilities and identified five\npreviously unknown software faults, highlighting its effectiveness in\nuncovering deeply nested bugs in network-exposed code.", "AI": {"tldr": "Pemu\u81ea\u52a8\u63a8\u65ad\u56fa\u4ef6\u4e2d\u7f51\u7edc\u534f\u8bae\u5e76\u751f\u6210\u5408\u6cd5\u5c01\u5305\u4ee5\u627f\u8f7d\u6a21\u7cca\u6d4b\u8bd5\u8f93\u5165\uff0c\u4f7f\u91cd\u5bbf\u4e3b\u5316\u73af\u5883\u80fd\u6df1\u5165\u6d4b\u8bd5\u591a\u5c42\u7f51\u7edc\u6808\uff0c\u63d0\u5347\u8986\u76d6\u7387\u5e76\u53d1\u73b0\u65b0\u6f0f\u6d1e\u3002", "motivation": "\u5d4c\u5165\u5f0f\u7cfb\u7edf\u7f51\u7edc\u6808\u590d\u6742\u3001\u591a\u5c42\u4e14\u591a\u6837\u5316\uff0c\u73b0\u6709\u91cd\u5bbf\u4e3b\u5316\u65b9\u6cd5\u96be\u4ee5\u6784\u9020\u591a\u5c42\u5c01\u88c5\u7684\u6709\u6548\u7f51\u7edc\u8f93\u5165\uff0c\u5bfc\u81f4\u96be\u4ee5\u53d1\u73b0\u6df1\u5c42\u8f6f\u4ef6\u7f3a\u9677\uff1b\u9700\u8981\u4e00\u79cd\u81ea\u52a8\u5316\u65b9\u6cd5\u4f7f\u6a21\u7cca\u6d4b\u8bd5\u80fd\u591f\u7a7f\u900f\u534f\u8bae\u5c42\u6b21\u3002", "method": "\u901a\u8fc7\u5206\u6790\u56fa\u4ef6\u8fd0\u884c\u65f6\u5728\u91cd\u5bbf\u4e3b\u5316\u73af\u5883\u4e2d\u66b4\u9732\u7684\u7f51\u7edc\u63a5\u53e3\uff0c\u81ea\u52a8\u63a8\u65ad\u53ef\u7528\u7684\u7f51\u7edc\u534f\u8bae\u5e76\u751f\u6210\u5408\u6cd5\u5c01\u88c5\u7684\u6570\u636e\u5305\uff0c\u5c06\u6a21\u7cca\u6d4b\u8bd5\u6570\u636e\u5d4c\u5165\u8be5\u5c01\u88c5\uff0c\u652f\u6301\u9010\u5c42\u89e6\u8fbe\u56fa\u4ef6\u7684\u6df1\u5c42\u903b\u8f91\u3002\u96c6\u6210\u5230\u73b0\u6709\u91cd\u5bbf\u4e3b\u5316\u5de5\u5177\u4e2d\u4ee5\u8bc4\u4f30\u8986\u76d6\u7387\u5e76\u8fdb\u884c\u6f0f\u6d1e\u53d1\u73b0\u3002", "result": "\u5728\u4e09\u79cd\u73b0\u6709\u91cd\u5bbf\u4e3b\u5316\u5de5\u5177\u4e0a\uff0cPemu\u4e00\u81f4\u6027\u5730\u63d0\u9ad8\u4e86\u4ee3\u7801\u8986\u76d6\u7387\uff1b\u91cd\u65b0\u53d1\u73b0\u4e86\u82e5\u5e72\u5df2\u77e5\u6f0f\u6d1e\u5e76\u53d1\u73b0\u4e865\u4e2a\u65b0\u7684\u8f6f\u4ef6\u7f3a\u9677\uff0c\u9a8c\u8bc1\u4e86\u5176\u5728\u6316\u6398\u6df1\u5c42\u7f51\u7edc\u66b4\u9732\u4ee3\u7801\u4e2d\u6709\u6548\u6027\u3002", "conclusion": "Pemu\u901a\u8fc7\u81ea\u52a8\u8bc6\u522b\u5e76\u5904\u7406\u56fa\u4ef6\u4e2d\u7684\u7f51\u7edc\u534f\u8bae\uff0c\u4f7f\u91cd\u5bbf\u4e3b\u5316\u56fa\u4ef6\u6d4b\u8bd5\u80fd\u591f\u751f\u6210\u6709\u6548\u7684\u5c01\u88c5\u6570\u636e\u5305\uff0c\u5c06\u6a21\u7cca\u6d4b\u8bd5\u8f93\u5165\u4f20\u9012\u5230\u66f4\u6df1\u5c42\u7684\u534f\u8bae\u6808\uff0c\u4ece\u800c\u663e\u8457\u63d0\u9ad8\u4e86\u8986\u76d6\u7387\u5e76\u53d1\u73b0\u65b0\u7684\u6f0f\u6d1e\u3002"}}
{"id": "2509.13634", "categories": ["cs.LG", "cs.CR"], "pdf": "https://arxiv.org/pdf/2509.13634", "abs": "https://arxiv.org/abs/2509.13634", "authors": ["Md Bokhtiar Al Zami", "Md Raihan Uddin", "Dinh C. Nguyen"], "title": "Secure UAV-assisted Federated Learning: A Digital Twin-Driven Approach with Zero-Knowledge Proofs", "comment": "15 pages, under revision at IEEE Internet of Things Journal", "summary": "Federated learning (FL) has gained popularity as a privacy-preserving method\nof training machine learning models on decentralized networks. However to\nensure reliable operation of UAV-assisted FL systems, issues like as excessive\nenergy consumption, communication inefficiencies, and security vulnerabilities\nmust be solved. This paper proposes an innovative framework that integrates\nDigital Twin (DT) technology and Zero-Knowledge Federated Learning (zkFed) to\ntackle these challenges. UAVs act as mobile base stations, allowing scattered\ndevices to train FL models locally and upload model updates for aggregation. By\nincorporating DT technology, our approach enables real-time system monitoring\nand predictive maintenance, improving UAV network efficiency. Additionally,\nZero-Knowledge Proofs (ZKPs) strengthen security by allowing model verification\nwithout exposing sensitive data. To optimize energy efficiency and resource\nmanagement, we introduce a dynamic allocation strategy that adjusts UAV flight\npaths, transmission power, and processing rates based on network conditions.\nUsing block coordinate descent and convex optimization techniques, our method\nsignificantly reduces system energy consumption by up to 29.6% compared to\nconventional FL approaches. Simulation results demonstrate improved learning\nperformance, security, and scalability, positioning this framework as a\npromising solution for next-generation UAV-based intelligent networks.", "AI": {"tldr": "\u5c06DT\u4e0ezkFed\u7ed3\u5408\uff0cUAV\u4f5c\u4e3a\u79fb\u52a8\u57fa\u7ad9\uff0c\u52a0\u5165\u52a8\u6001\u8d44\u6e90\u5206\u914d\u548c\u4f18\u5316\u7b97\u6cd5\uff0c\u4eff\u771f\u8868\u660e\u80fd\u8017\u663e\u8457\u4e0b\u964d\u5e76\u589e\u5f3a\u5b89\u5168\u4e0e\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3UAV\u8f85\u52a9\u8054\u90a6\u5b66\u4e60\u9762\u4e34\u7684\u9ad8\u80fd\u8017\u3001\u901a\u4fe1\u6548\u7387\u4f4e\u548c\u5b89\u5168\u9690\u60a3\u95ee\u9898\uff0c\u63d0\u5347\u7cfb\u7edf\u53ef\u9760\u6027\u4e0e\u53ef\u6269\u5c55\u6027\uff0c\u4f7f\u5206\u5e03\u5f0f\u8bbe\u5907\u80fd\u5728\u65e0\u4eba\u673a\u7f51\u7edc\u4e2d\u9ad8\u6548\u4e14\u9690\u79c1\u4fdd\u62a4\u5730\u53c2\u4e0e\u6a21\u578b\u8bad\u7ec3\u3002", "method": "\u6784\u5efaUAV\u4f5c\u4e3a\u79fb\u52a8\u57fa\u7ad9\u7684\u7cfb\u7edf\u6a21\u578b\uff0c\u96c6\u6210DT\u7528\u4e8e\u5b9e\u65f6\u76d1\u63a7\u4e0e\u9884\u6d4b\u7ef4\u62a4\uff0c\u91c7\u7528\u96f6\u77e5\u8bc6\u8bc1\u660e\uff08ZKP\uff09\u5b9e\u73b0\u6a21\u578b\u66f4\u65b0\u7684\u9690\u79c1\u9a8c\u8bc1\u3002\u63d0\u51fa\u52a8\u6001\u5206\u914d\u7b56\u7565\u8c03\u6574UAV\u822a\u7ebf\u3001\u4f20\u8f93\u529f\u7387\u548c\u5904\u7406\u901f\u7387\uff1b\u4f7f\u7528\u4ea4\u66ff\u65b9\u5411\uff08\u5757\u5750\u6807\uff09\u4e0b\u964d\u4e0e\u51f8\u4f18\u5316\u65b9\u6cd5\u6c42\u89e3\u80fd\u8017\u4e0e\u8d44\u6e90\u5206\u914d\u95ee\u9898\uff1b\u901a\u8fc7\u4eff\u771f\u8bc4\u4f30\u80fd\u8017\u3001\u5b66\u4e60\u6027\u80fd\u548c\u5b89\u5168\u6027\u3002", "result": "\u57fa\u4e8e\u4eff\u771f\uff0c\u4f5c\u8005\u62a5\u544a\u7cfb\u7edf\u80fd\u8017\u6700\u591a\u51cf\u5c1129.6%\uff0c\u5e76\u79f0\u5728\u5b66\u4e60\u6027\u80fd\u3001\u7cfb\u7edf\u5b89\u5168\u6027\u53ca\u53ef\u6269\u5c55\u6027\u4e0a\u5747\u6709\u63d0\u5347\uff08\u5177\u4f53\u6570\u636e\u4e0e\u57fa\u51c6\u65b9\u6cd5\u672a\u5b8c\u5168\u8be6\u7ec6\u5316\uff09\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u5c06\u6570\u5b57\u5b6a\u751f\uff08DT\uff09\u4e0e\u96f6\u77e5\u8bc6\u8054\u90a6\u5b66\u4e60\uff08zkFed\uff09\u7ed3\u5408\u7684\u6846\u67b6\uff0c\u7528\u4e8eUAV\u8f85\u52a9\u7684\u8054\u90a6\u5b66\u4e60\u7cfb\u7edf\uff0c\u4ee5\u63d0\u9ad8\u80fd\u6548\u3001\u901a\u4fe1\u6548\u7387\u548c\u5b89\u5168\u6027\u3002\u4f5c\u8005\u58f0\u79f0\u901a\u8fc7\u52a8\u6001\u8d44\u6e90\u5206\u914d\u548c\u4f18\u5316\u7b97\u6cd5\uff0c\u7cfb\u7edf\u80fd\u8017\u76f8\u6bd4\u4f20\u7edfFL\u65b9\u6cd5\u964d\u4f4e\u7ea629.6%\uff0c\u5e76\u5728\u4eff\u771f\u4e2d\u5c55\u73b0\u4e86\u5b66\u4e60\u6027\u80fd\u3001\u5b89\u5168\u6027\u548c\u53ef\u6269\u5c55\u6027\u6539\u8fdb\u3002"}}
{"id": "2509.13379", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2509.13379", "abs": "https://arxiv.org/abs/2509.13379", "authors": ["Asif Azad", "Mohammad Sadat Hossain", "MD Sadik Hossain Shanto", "M Saifur Rahman", "Md Rizwan Pervez"], "title": "The Art of Saying \"Maybe\": A Conformal Lens for Uncertainty Benchmarking in VLMs", "comment": null, "summary": "Vision-Language Models (VLMs) have achieved remarkable progress in complex\nvisual understanding across scientific and reasoning tasks. While performance\nbenchmarking has advanced our understanding of these capabilities, the critical\ndimension of uncertainty quantification has received insufficient attention.\nTherefore, unlike prior conformal prediction studies that focused on limited\nsettings, we conduct a comprehensive uncertainty benchmarking study, evaluating\n16 state-of-the-art VLMs (open and closed-source) across 6 multimodal datasets\nwith 3 distinct scoring functions. Our findings demonstrate that larger models\nconsistently exhibit better uncertainty quantification; models that know more\nalso know better what they don't know. More certain models achieve higher\naccuracy, while mathematical and reasoning tasks elicit poorer uncertainty\nperformance across all models compared to other domains. This work establishes\na foundation for reliable uncertainty evaluation in multimodal systems.", "AI": {"tldr": "\u5bf916\u4e2aVLM\u57286\u4e2a\u591a\u6a21\u6001\u6570\u636e\u96c6\u30013\u79cd\u8bc4\u5206\u51fd\u6570\u4e0b\u8fdb\u884c\u4e0d\u786e\u5b9a\u6027\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7ed3\u8bba\u662f\uff1a\u6a21\u578b\u8d8a\u5927\u8d8a\u4f1a\u66f4\u597d\u5730\u8861\u91cf\u4e0d\u786e\u5b9a\u6027\uff0c\u786e\u5b9a\u6027\u9ad8\u5bf9\u5e94\u66f4\u9ad8\u51c6\u786e\u7387\uff0c\u4f46\u5728\u6570\u5b66/\u63a8\u7406\u4efb\u52a1\u4e2d\u666e\u904d\u8868\u73b0\u6b20\u4f73\u3002", "motivation": "\u5c3d\u7ba1VLM\u5728\u590d\u6742\u89c6\u89c9\u7406\u89e3\u4e0a\u53d6\u5f97\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u5173\u4e8e\u6a21\u578b\u8f93\u51fa\u4e0d\u786e\u5b9a\u6027\u7684\u7cfb\u7edf\u6027\u7814\u7a76\u4e0d\u8db3\u3002\u4e3a\u5b89\u5168\u53ef\u9760\u90e8\u7f72\u4e0e\u98ce\u9669\u63a7\u5236\uff0c\u4e9f\u9700\u5168\u9762\u7684\u591a\u6a21\u6001\u4e0d\u786e\u5b9a\u6027\u57fa\u51c6\u4e0e\u5206\u6790\u3002", "method": "\u4f5c\u8005\u5bf916\u4e2a\u6700\u5148\u8fdb\u7684VLM\uff08\u5305\u62ec\u5f00\u6e90\u548c\u95ed\u6e90\uff09\u8fdb\u884c\u7efc\u5408\u57fa\u51c6\u6d4b\u8bd5\uff0c\u4f7f\u75286\u4e2a\u591a\u6a21\u6001\u6570\u636e\u96c6\u548c3\u79cd\u4e0d\u540c\u7684\u6253\u5206\u51fd\u6570\u6765\u8bc4\u4f30\u7f6e\u4fe1\u533a\u95f4/\u7f6e\u4fe1\u9884\u6d4b\u80fd\u529b\uff0c\u91c7\u7528\u7edf\u4e00\u8bc4\u4f30\u6d41\u7a0b\u6bd4\u8f83\u6a21\u578b\u95f4\u6027\u80fd\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff1a\u66f4\u5927\u6a21\u578b\u4e0e\u66f4\u9ad8\u80fd\u529b\u6a21\u578b\u5728\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u4e0a\u8868\u73b0\u66f4\u597d\uff1b\u4e0d\u786e\u5b9a\u6027\u4e0e\u51c6\u786e\u7387\u6b63\u76f8\u5173\uff1b\u5728\u6570\u5b66\u4e0e\u63a8\u7406\u7c7b\u4efb\u52a1\u4e0a\u6240\u6709\u6a21\u578b\u7684\u4e0d\u786e\u5b9a\u6027\u8bc4\u4f30\u8868\u73b0\u8f83\u5dee\uff1b\u8be5\u7814\u7a76\u4e3a\u591a\u6a21\u6001\u7cfb\u7edf\u7684\u53ef\u9760\u4e0d\u786e\u5b9a\u6027\u8bc4\u4f30\u5960\u5b9a\u4e86\u57fa\u7840\u3002", "conclusion": "\u8be5\u8bba\u6587\u7cfb\u7edf\u6027\u8bc4\u4f30\u4e86\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b(VLMs)\u5728\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u9762\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u6a21\u578b\u89c4\u6a21\u8d8a\u5927\u3001\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u8d8a\u597d\uff1b\u77e5\u8bc6\u66f4\u4e30\u5bcc\u7684\u6a21\u578b\u5bf9\u672a\u77e5\u7684\u8bc6\u522b\u4e5f\u66f4\u51c6\u786e\uff1b\u66f4\u786e\u5b9a\u7684\u9884\u6d4b\u901a\u5e38\u5bf9\u5e94\u66f4\u9ad8\u7cbe\u5ea6\uff1b\u6570\u5b66\u548c\u63a8\u7406\u4efb\u52a1\u7684\u7f6e\u4fe1\u5ea6\u8bc4\u4f30\u6574\u4f53\u8f83\u5dee\u3002"}}
{"id": "2509.13772", "categories": ["cs.CR", "cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.13772", "abs": "https://arxiv.org/abs/2509.13772", "authors": ["Baolei Zhang", "Haoran Xin", "Yuxi Chen", "Zhuqing Liu", "Biao Yi", "Tong Li", "Lihai Nie", "Zheli Liu", "Minghong Fang"], "title": "Who Taught the Lie? Responsibility Attribution for Poisoned Knowledge in Retrieval-Augmented Generation", "comment": "To appear in the IEEE Symposium on Security and Privacy, 2026", "summary": "Retrieval-Augmented Generation (RAG) integrates external knowledge into large\nlanguage models to improve response quality. However, recent work has shown\nthat RAG systems are highly vulnerable to poisoning attacks, where malicious\ntexts are inserted into the knowledge database to influence model outputs.\nWhile several defenses have been proposed, they are often circumvented by more\nadaptive or sophisticated attacks.\n  This paper presents RAGOrigin, a black-box responsibility attribution\nframework designed to identify which texts in the knowledge database are\nresponsible for misleading or incorrect generations. Our method constructs a\nfocused attribution scope tailored to each misgeneration event and assigns a\nresponsibility score to each candidate text by evaluating its retrieval\nranking, semantic relevance, and influence on the generated response. The\nsystem then isolates poisoned texts using an unsupervised clustering method. We\nevaluate RAGOrigin across seven datasets and fifteen poisoning attacks,\nincluding newly developed adaptive poisoning strategies and multi-attacker\nscenarios. Our approach outperforms existing baselines in identifying poisoned\ncontent and remains robust under dynamic and noisy conditions. These results\nsuggest that RAGOrigin provides a practical and effective solution for tracing\nthe origins of corrupted knowledge in RAG systems.", "AI": {"tldr": "RAGOrigin\u63d0\u51fa\u4e00\u79cd\u9ed1\u7bb1\u8d23\u4efb\u5f52\u56e0\u65b9\u6cd5\uff0c\u901a\u8fc7\u68c0\u7d22\u6392\u540d\u3001\u8bed\u4e49\u76f8\u5173\u6027\u4e0e\u751f\u6210\u5f71\u54cd\u4e09\u7ef4\u8bc4\u5206\u5e76\u7ed3\u5408\u65e0\u76d1\u7763\u805a\u7c7b\uff0c\u6709\u6548\u5b9a\u4f4dRAG\u77e5\u8bc6\u5e93\u4e2d\u7684\u4e2d\u6bd2\u6587\u672c\uff0c\u5728\u591a\u79cd\u653b\u51fb\u4e0e\u573a\u666f\u4e0b\u4f18\u4e8e\u57fa\u7ebf\u3002", "motivation": "\u73b0\u6709RAG\u7cfb\u7edf\u6613\u53d7\u77e5\u8bc6\u5e93\u6295\u6bd2\u653b\u51fb\uff0c\u4e14\u5df2\u6709\u9632\u5fa1\u6613\u88ab\u81ea\u9002\u5e94\u653b\u51fb\u89c4\u907f\uff0c\u9700\u80fd\u8ffd\u6eaf\u5e76\u5b9a\u4f4d\u8d23\u4efb\u6587\u672c\u4ee5\u4fbf\u54cd\u5e94\u4e0e\u4fee\u590d\u3002", "method": "\u4e3a\u6bcf\u6b21\u8bef\u751f\u6210\u6784\u5efa\u805a\u7126\u6eaf\u6e90\u8303\u56f4\uff0c\u7ed3\u5408\u68c0\u7d22\u6392\u540d\u3001\u8bed\u4e49\u76f8\u5173\u6027\u4e0e\u5bf9\u751f\u6210\u7ed3\u679c\u7684\u5f71\u54cd\u8bc4\u4f30\u6bcf\u6761\u5019\u9009\u6587\u672c\u7684\u8d23\u4efb\u5206\u6570\uff0c\u5e76\u7528\u65e0\u76d1\u7763\u805a\u7c7b\u9694\u79bb\u4e2d\u6bd2\u6587\u672c\u3002", "result": "\u57287\u4e2a\u6570\u636e\u96c6\u548c15\u79cd\u6295\u6bd2\u653b\u51fb\uff08\u542b\u81ea\u9002\u5e94\u4e0e\u591a\u653b\u51fb\u8005\u573a\u666f\uff09\u4e0a\uff0cRAGOrigin\u5728\u8bc6\u522b\u4e2d\u6bd2\u5185\u5bb9\u4e0a\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\uff0c\u5e76\u5728\u52a8\u6001\u5608\u6742\u73af\u5883\u4e0b\u8868\u73b0\u7a33\u5065\u3002", "conclusion": "RAGOrigin\u80fd\u5728\u9ed1\u76d2\u8bbe\u5b9a\u4e0b\u6709\u6548\u8bc6\u522b\u77e5\u8bc6\u5e93\u4e2d\u5bfc\u81f4\u8bef\u751f\u6210\u7684\u4e2d\u6bd2\u6587\u672c\uff0c\u4e3aRAG\u7cfb\u7edf\u63d0\u4f9b\u53ef\u884c\u7684\u6eaf\u6e90\u624b\u6bb5\u3002"}}
{"id": "2509.13636", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.13636", "abs": "https://arxiv.org/abs/2509.13636", "authors": ["Yasin Hasanpoor", "Bahram Tarvirdizadeh", "Khalil Alipour", "Mohammad Ghamari"], "title": "Multimodal signal fusion for stress detection using deep neural networks: a novel approach for converting 1D signals to unified 2D images", "comment": "14 pages 7 images 2 tables", "summary": "This study introduces a novel method that transforms multimodal physiological\nsignalsphotoplethysmography (PPG), galvanic skin response (GSR), and\nacceleration (ACC) into 2D image matrices to enhance stress detection using\nconvolutional neural networks (CNNs). Unlike traditional approaches that\nprocess these signals separately or rely on fixed encodings, our technique\nfuses them into structured image representations that enable CNNs to capture\ntemporal and cross signal dependencies more effectively. This image based\ntransformation not only improves interpretability but also serves as a robust\nform of data augmentation. To further enhance generalization and model\nrobustness, we systematically reorganize the fused signals into multiple\nformats, combining them in a multi stage training pipeline. This approach\nsignificantly boosts classification performance. While demonstrated here in the\ncontext of stress detection, the proposed method is broadly applicable to any\ndomain involving multimodal physiological signals, paving the way for more\naccurate, personalized, and real time health monitoring through wearable\ntechnologies.", "AI": {"tldr": "\u5c06PPG\u3001GSR\u3001ACC\u878d\u5408\u4e3a2D\u56fe\u50cf\u4f9bCNN\u8bad\u7ec3\uff0c\u901a\u8fc7\u591a\u683c\u5f0f\u91cd\u7ec4\u548c\u591a\u9636\u6bb5\u8bad\u7ec3\u63d0\u5347\u538b\u529b\u68c0\u6d4b\u51c6\u786e\u6027\u4e0e\u6cdb\u5316\u80fd\u529b\uff0c\u5bf9\u53ef\u7a7f\u6234\u5065\u5eb7\u76d1\u6d4b\u5177\u5e7f\u6cdb\u9002\u7528\u6027\u3002", "motivation": "\u63d0\u9ad8\u591a\u6a21\u6001\u751f\u7406\u4fe1\u53f7\uff08PPG\u3001GSR\u3001ACC\uff09\u5728\u538b\u529b\u68c0\u6d4b\u4efb\u52a1\u4e2d\u7684\u5206\u7c7b\u6027\u80fd\u4e0e\u53ef\u89e3\u91ca\u6027\uff0c\u514b\u670d\u4f20\u7edf\u72ec\u7acb\u5904\u7406\u6216\u56fa\u5b9a\u7f16\u7801\u65b9\u6cd5\u7684\u5c40\u9650\uff0c\u901a\u8fc7\u5c06\u4fe1\u53f7\u878d\u5408\u4e3a2D\u56fe\u50cf\u77e9\u9635\u4ee5\u5229\u4e8eCNN\u6355\u6349\u65f6\u95f4\u4e0e\u8de8\u4fe1\u53f7\u4f9d\u8d56\u5173\u7cfb\u3002", "method": "\u628aPPG\u3001GSR\u3001ACC\u4fe1\u53f7\u9884\u5904\u7406\u5e76\u6309\u8bbe\u8ba1\u89c4\u5219\u5d4c\u5165\u5230\u4e8c\u7ef4\u77e9\u9635\uff08\u56fe\u50cf\uff09\u4e2d\uff0c\u751f\u6210\u591a\u79cd\u91cd\u7ec4\u683c\u5f0f\u4f5c\u4e3a\u6570\u636e\u589e\u5f3a\uff1b\u4f7f\u7528CNN\u5728\u591a\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\u4e0b\u5b66\u4e60\u8fd9\u4e9b\u8868\u793a\uff0c\u8bc4\u4f30\u5206\u7c7b\u6027\u80fd\u5e76\u5206\u6790\u53ef\u89e3\u91ca\u6027\u4e0e\u6cdb\u5316\u6027\u3002", "result": "\u63d0\u51fa\u4e00\u79cd\u5c06\u591a\u6a21\u6001\u751f\u7406\u4fe1\u53f7\u8f6c\u6362\u4e3a\u7ed3\u6784\u5316\u56fe\u50cf\u8868\u793a\u7684\u65b9\u6cd5\uff0c\u5e76\u5728\u591a\u9636\u6bb5\u8bad\u7ec3\u7ba1\u7ebf\u4e2d\u4ee5\u4e0d\u540c\u683c\u5f0f\u91cd\u7ec4\u8fd9\u4e9b\u56fe\u50cf\uff0c\u663e\u8457\u63d0\u5347\u4e86\u538b\u529b\u5206\u7c7b\u6027\u80fd\u4e0e\u6a21\u578b\u9c81\u68d2\u6027\uff0c\u540c\u65f6\u589e\u5f3a\u4e86\u53ef\u89e3\u91ca\u6027\u4e0e\u6570\u636e\u589e\u5f3a\u6548\u679c\u3002", "conclusion": "\u56fe\u50cf\u5316\u7684\u591a\u6a21\u6001\u4fe1\u53f7\u878d\u5408\u80fd\u66f4\u6709\u6548\u5730\u6355\u83b7\u65f6\u5e8f\u4e0e\u8de8\u6a21\u6001\u4f9d\u8d56\uff0c\u901a\u8fc7\u591a\u683c\u5f0f\u91cd\u7ec4\u4e0e\u591a\u9636\u6bb5\u8bad\u7ec3\u53ef\u63d0\u9ad8\u5206\u7c7b\u6027\u80fd\u548c\u6a21\u578b\u9c81\u68d2\u6027\uff0c\u65b9\u6cd5\u53ef\u63a8\u5e7f\u81f3\u5176\u4ed6\u751f\u7406\u4fe1\u53f7\u5e94\u7528\u4ee5\u652f\u6301\u4e2a\u6027\u5316\u5b9e\u65f6\u5065\u5eb7\u76d1\u6d4b\u3002"}}
{"id": "2509.13389", "categories": ["cs.AI", "I.2.4; I.2.6; I.2.8"], "pdf": "https://arxiv.org/pdf/2509.13389", "abs": "https://arxiv.org/abs/2509.13389", "authors": ["Carlos N\u00fa\u00f1ez-Molina", "Vicen\u00e7 G\u00f3mez", "Hector Geffner"], "title": "From Next Token Prediction to (STRIPS) World Models -- Preliminary Results", "comment": "10 pages, 3 figures", "summary": "We consider the problem of learning propositional STRIPS world models from\naction traces alone, using a deep learning architecture (transformers) and\ngradient descent. The task is cast as a supervised next token prediction\nproblem where the tokens are the actions, and an action $a$ may follow an\naction sequence if the hidden effects of the previous actions do not make an\naction precondition of $a$ false. We show that a suitable transformer\narchitecture can faithfully represent propositional STRIPS world models, and\nthat the models can be learned from sets of random valid (positive) and invalid\n(negative) action sequences alone. A number of experiments are reported.", "AI": {"tldr": "\u7528Transformer\u548c\u76d1\u7763\u7684\u4e0b\u4e00\u4e2a\u52a8\u4f5c\u9884\u6d4b\uff0c\u628a\u4ece\u52a8\u4f5c\u5e8f\u5217\u5b66STRIPS\u6a21\u578b\u7684\u95ee\u9898\u8f6c\u6210\u5206\u7c7b\u5b66\u4e60\uff1b\u7ed9\u51fa\u67b6\u6784\u4e0e\u8bad\u7ec3\u6d41\u7a0b\uff0c\u5b9e\u9a8c\u8868\u660e\u53ef\u884c\u3002", "motivation": "\u5e0c\u671b\u4ece\u7eaf\u52a8\u4f5c\u65e5\u5fd7\u4e2d\u81ea\u52a8\u5b66\u4e60\u7ed3\u6784\u5316\u7684\u89c4\u5212\u9886\u57df\u6a21\u578b\uff08\u547d\u9898STRIPS\uff09\uff0c\u907f\u514d\u624b\u5de5\u5efa\u6a21\uff0c\u5229\u7528\u6df1\u5ea6\u5b66\u4e60\u5904\u7406\u7b26\u53f7\u8ba1\u5212\u9886\u57df\u7684\u8868\u793a\u4e0e\u5b66\u4e60\u95ee\u9898\u3002", "method": "\u5c06\u5b66\u4e60\u95ee\u9898\u6784\u9020\u6210\u76d1\u7763\u7684\u4e0b\u4e00\u4e2atoken\u9884\u6d4b\uff0c\u5373\u9884\u6d4b\u52a8\u4f5c\u662f\u5426\u53ef\u5728\u5f53\u524d\u52a8\u4f5c\u5e8f\u5217\u540e\u53d1\u751f\uff1b\u91c7\u7528\u7279\u5b9a\u67b6\u6784\u7684Transformer\u5e76\u7528\u968f\u673a\u6709\u6548\u4e0e\u65e0\u6548\u7684\u52a8\u4f5c\u5e8f\u5217\u4f5c\u4e3a\u8bad\u7ec3\u6570\u636e\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u9884\u6d4b\u8bef\u5dee\u8fdb\u884c\u8bad\u7ec3\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u6240\u63d0\u51faTransformer\u67b6\u6784\u53ef\u4ee5\u51c6\u786e\u8868\u793a\u5e76\u5b66\u4e60STRIPS\u6a21\u578b\uff0c\u4ece\u968f\u673a\u751f\u6210\u7684\u6b63\u8d1f\u52a8\u4f5c\u5e8f\u5217\u4e2d\u6210\u529f\u6062\u590d\u52a8\u4f5c\u53ef\u884c\u6027\u5173\u7cfb\uff08\u9884\u6761\u4ef6\u4e0e\u6548\u679c\u9690\u542b\u5173\u7cfb\uff09\u3002", "conclusion": "\u8be5\u8bba\u6587\u8bc1\u660e\u4e86\u9002\u5f53\u8bbe\u8ba1\u7684Transformer\u80fd\u591f\u5fe0\u5b9e\u8868\u793a\u547d\u9898STRIPS\u4e16\u754c\u6a21\u578b\uff0c\u5e76\u4e14\u53ef\u4ee5\u4ec5\u4ece\u52a8\u4f5c\u8f68\u8ff9\uff08\u6b63\u8d1f\u6837\u672c\uff09\u4e2d\u901a\u8fc7\u68af\u5ea6\u4e0b\u964d\u5b66\u4e60\u5230\u8fd9\u4e9b\u6a21\u578b\u3002"}}
{"id": "2509.13788", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.13788", "abs": "https://arxiv.org/abs/2509.13788", "authors": ["Giovanni Giuseppe Grimaldi"], "title": "Homomorphic encryption schemes based on coding theory and polynomials", "comment": null, "summary": "Homomorphic encryption is a powerful cryptographic tool that enables secure\ncomputations on the private data. It evaluates any function for any operation\nsecurely on the encrypted data without knowing its corresponding plaintext. For\noriginal data $p$, $c$ denotes the ciphertext of the original plaintext $p$,\ni.e. $c = Encrypt_k(p)$. This is crucial for any sensitive application running\nin the Cloud, because we must protect data privacy even in the case when the\nserver has falled victim to a cyber attack. The encryption scheme $Encrypt_k$\nis said to be homomorphic with respect to some set of operations $\\mathcal{O}$,\nif for any operation $\\circ \\in \\mathcal{O}$ one can compute $Encrypt_k(p_1\n\\circ p_2)$ from $Encrypt_k(p_1) \\circ Encrypt_k(p_2)$. Those schemes come in\nthree forms: somewhat, partially and fully homomorphic. In this survey, we\npresent the state of art of the known homomorphic encryption schemes based on\ncoding theory and polynomials.", "AI": {"tldr": "\u7efc\u8ff0\u57fa\u4e8e\u7f16\u7801\u548c\u591a\u9879\u5f0f\u7684\u540c\u6001\u52a0\u5bc6\uff0c\u8bc4\u4f30\u5176\u6784\u9020\u65b9\u6cd5\u3001\u6027\u80fd\u4e0e\u6311\u6218\uff0c\u5e76\u63d0\u51fa\u672a\u6765\u7814\u7a76\u65b9\u5411\uff0c\u5982\u6548\u7387\u4f18\u5316\u548c\u5b89\u5168\u6027\u8bc1\u660e\u3002", "motivation": "\u540c\u6001\u52a0\u5bc6\u53ef\u5728\u4e0d\u6cc4\u9732\u660e\u6587\u7684\u60c5\u51b5\u4e0b\u5728\u4e91\u7aef\u5b89\u5168\u6267\u884c\u8ba1\u7b97\uff0c\u4fdd\u62a4\u654f\u611f\u6570\u636e\u514d\u53d7\u4e91\u670d\u52a1\u5668\u88ab\u653b\u7834\u65f6\u7684\u4fe1\u606f\u6cc4\u9732\uff0c\u7f16\u7801\u7406\u8bba\u4e0e\u591a\u9879\u5f0f\u65b9\u6cd5\u4e3a\u6784\u9020\u9ad8\u6548\u540c\u6001\u65b9\u6848\u63d0\u4f9b\u4e86\u66ff\u4ee3\u8def\u7ebf\u548c\u65b0\u5de5\u5177\u3002", "method": "\u56de\u987e\u5e76\u5206\u7c7b\u5df2\u6709\u5de5\u4f5c\uff0c\u6bd4\u8f83\u4e0d\u540c\u65b9\u6848\uff08\u90e8\u5206\u3001\u6709\u9650\u548c\u5168\u540c\u6001\uff09\u7684\u6784\u9020\u6280\u672f\u3001\u9519\u8bef\u589e\u957f\u63a7\u5236\u3001\u566a\u58f0\u7ba1\u7406\u4e0e\u5bc6\u94a5\u5207\u6362\u673a\u5236\uff0c\u7efc\u8ff0\u57fa\u4e8e\u683c\u3001\u7f16\u7801\u548c\u591a\u9879\u5f0f\u6784\u9020\u7684\u5173\u952e\u601d\u60f3\u4e0e\u7b97\u6cd5\u5b9e\u73b0\u3002", "result": "\u603b\u7ed3\u51fa\u57fa\u4e8e\u7f16\u7801\u548c\u591a\u9879\u5f0f\u7684\u65b9\u6848\u5728\u67d0\u4e9b\u64cd\u4f5c\u4e0a\u53ef\u5b9e\u73b0\u540c\u6001\u6027\uff0c\u5217\u51fa\u73b0\u6709\u65b9\u6848\u7684\u4f18\u7f3a\u70b9\u4e0e\u9002\u7528\u573a\u666f\uff0c\u5e76\u6307\u51fa\u672a\u6765\u7814\u7a76\u65b9\u5411\u5982\u964d\u4f4e\u8ba1\u7b97\u5f00\u9500\u3001\u6539\u8fdb\u566a\u58f0\u7ba1\u7406\u3001\u8bc1\u660e\u66f4\u5f3a\u7684\u5b89\u5168\u6027\u5047\u8bbe\u548c\u5b9e\u73b0\u5b9e\u7528\u7cfb\u7edf\u3002", "conclusion": "\u672c\u6587\u7efc\u8ff0\u4e86\u57fa\u4e8e\u7f16\u7801\u7406\u8bba\u548c\u591a\u9879\u5f0f\u7684\u540c\u6001\u52a0\u5bc6\u65b9\u6848\u7684\u7814\u7a76\u8fdb\u5c55\uff0c\u6307\u51fa\u8fd9\u4e9b\u65b9\u6848\u5728\u5b9e\u73b0\u540c\u6001\u8fd0\u7b97\u65b9\u9762\u5177\u6709\u6f5c\u529b\u4f46\u4ecd\u9762\u4e34\u6548\u7387\u3001\u5bc6\u94a5\u7ba1\u7406\u548c\u5b89\u5168\u6027\u8bc1\u660e\u7b49\u6311\u6218\u3002"}}
{"id": "2509.13642", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2509.13642", "abs": "https://arxiv.org/abs/2509.13642", "authors": ["Zirun Guo", "Feng Zhang", "Kai Jia", "Tao Jin"], "title": "LLM-I: LLMs are Naturally Interleaved Multimodal Creators", "comment": null, "summary": "We propose LLM-Interleaved (LLM-I), a flexible and dynamic framework that\nreframes interleaved image-text generation as a tool-use problem. LLM-I is\ndesigned to overcome the \"one-tool\" bottleneck of current unified models, which\nare limited to synthetic imagery and struggle with tasks requiring factual\ngrounding or programmatic precision. Our framework empowers a central LLM or\nMLLM agent to intelligently orchestrate a diverse toolkit of specialized visual\ntools, including online image search, diffusion-based generation, code\nexecution, and image editing. The agent is trained to select and apply these\ntools proficiently via a Reinforcement Learning (RL) framework that features a\nhybrid reward system combining rule-based logic with judgments from LLM and\nMLLM evaluators. Trained on a diverse new dataset using four different model\nbackbones, LLM-I demonstrates state-of-the-art performance, outperforming\nexisting methods by a large margin across four benchmarks. We also introduce a\nnovel test-time scaling strategy that provides further performance gains.\nProject Page: https://github.com/ByteDance-BandAI/LLM-I.", "AI": {"tldr": "LLM-I\u628a\u56fe\u6587\u751f\u6210\u5f53\u4f5c\u5de5\u5177\u8c03\u7528\uff0c\u8ba9\u4e2d\u5fc3\u5927\u6a21\u578b\u667a\u80fd\u8c03\u5ea6\u641c\u7d22\u3001\u751f\u6210\u3001\u6267\u884c\u548c\u7f16\u8f91\u7b49\u4e13\u4e1a\u89c6\u89c9\u5de5\u5177\uff0c\u901a\u8fc7\u6df7\u5408\u5956\u52b1\u7684RL\u8bad\u7ec3\u4e0e\u6d4b\u8bd5\u65f6\u6269\u5c55\u7b56\u7565\uff0c\u5728\u591a\u6570\u636e\u591a\u6a21\u578b\u4e0a\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7edf\u4e00\u89c6\u89c9\u751f\u6210\u6a21\u578b\u53d7\u9650\u4e8e\u5408\u6210\u56fe\u50cf\u80fd\u529b\uff0c\u96be\u4ee5\u5904\u7406\u9700\u8981\u771f\u5b9e\u56fe\u50cf\u68c0\u7d22\u3001\u7cbe\u786e\u7a0b\u5e8f\u5316\u63a7\u5236\u6216\u7f16\u8f91\u7684\u4efb\u52a1\uff1b\u56e0\u6b64\u5e0c\u671b\u901a\u8fc7\u5de5\u5177\u5316\u5206\u5de5\u63d0\u5347\u5b9e\u7528\u6027\u4e0e\u51c6\u786e\u6027\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u4ee5\u4e2d\u5fc3LLM/MLLM\u4e3a\u4ee3\u7406\u7684\u6846\u67b6\uff0c\u4ee3\u7406\u5728\u5f3a\u5316\u5b66\u4e60\uff08\u6df7\u5408\u5956\u52b1\uff1a\u89c4\u5219+LLM/MLLM\u5224\u522b\uff09\u4e0b\u5b66\u4f1a\u9009\u62e9\u5e76\u7ec4\u5408\u591a\u79cd\u89c6\u89c9\u5de5\u5177\uff08\u5728\u7ebf\u641c\u7d22\u3001\u6269\u6563\u751f\u6210\u3001\u4ee3\u7801\u6267\u884c\u3001\u56fe\u50cf\u7f16\u8f91\uff09\uff1b\u5e76\u5728\u591a\u6a21\u578b\u9aa8\u5e72\u4e0a\u7528\u65b0\u6784\u5efa\u7684\u591a\u6837\u5316\u6570\u636e\u96c6\u8bad\u7ec3\uff0c\u8f85\u4ee5\u6d4b\u8bd5\u65f6\u6269\u5c55\u7b56\u7565\u3002", "result": "\u5728\u56db\u4e2a\u57fa\u51c6\u4e0a\u5927\u5e45\u9886\u5148\u73b0\u6709\u65b9\u6cd5\uff0c\u5c55\u793a\u4e86\u5de5\u5177\u7ec4\u5408\u4e0eRL\u8bad\u7ec3\u7684\u6709\u6548\u6027\uff1b\u6d4b\u8bd5\u65f6\u6269\u5c55\u7b56\u7565\u8fdb\u4e00\u6b65\u63d0\u5347\u6027\u80fd\u3002", "conclusion": "LLM-I\u901a\u8fc7\u5c06\u56fe\u6587\u4ea4\u4e92\u751f\u6210\u4efb\u52a1\u89c6\u4e3a\u5de5\u5177\u8c03\u7528\u95ee\u9898\uff0c\u6709\u6548\u6253\u7834\u4e86\u7edf\u4e00\u6a21\u578b\u201c\u4e00\u5200\u5207\u201d\u5728\u5408\u6210\u56fe\u50cf\u548c\u4e8b\u5b9e/\u7a0b\u5e8f\u5316\u7cbe\u5ea6\u4e0a\u7684\u5c40\u9650\u3002"}}
{"id": "2509.13450", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.13450", "abs": "https://arxiv.org/abs/2509.13450", "authors": ["Vincent Siu", "Nicholas Crispino", "David Park", "Nathan W. Henry", "Zhun Wang", "Yang Liu", "Dawn Song", "Chenguang Wang"], "title": "SteeringControl: Holistic Evaluation of Alignment Steering in LLMs", "comment": null, "summary": "We introduce SteeringControl, a benchmark for evaluating representation\nsteering methods across core alignment objectives--bias, harmful generation,\nand hallucination--and their effects on secondary behaviors such as sycophancy\nand commonsense morality. While prior alignment work often highlights\ntruthfulness or reasoning ability to demonstrate the side effects of\nrepresentation steering, we find there are many unexplored tradeoffs not yet\nunderstood in a systematic way. We collect a dataset of safety-relevant primary\nand secondary behaviors to evaluate steering effectiveness and behavioral\nentanglement centered around five popular steering methods. To enable this, we\ncraft a modular steering framework based on unique components that serve as the\nbuilding blocks of many existing methods. Our results on Qwen-2.5-7B and\nLlama-3.1-8B find that strong steering performance is dependent on the specific\ncombination of steering method, model, and targeted behavior, and that severe\nconcept entanglement can result from poor combinations of these three as well.\nWe release our code here:\nhttps://github.com/wang-research-lab/SteeringControl.git.", "AI": {"tldr": "SteeringControl\u63d0\u51fa\u4e86\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u8868\u5f81\u5f15\u5bfc\u65b9\u6cd5\u5728\u504f\u89c1\u3001\u6709\u5bb3\u751f\u6210\u3001\u5e7b\u89c9\u53ca\u5bf9\u6b21\u8981\u884c\u4e3a\u5f71\u54cd\u7684\u7efc\u5408\u57fa\u51c6\uff0c\u6784\u5efa\u6a21\u5757\u5316\u5f15\u5bfc\u6846\u67b6\u5e76\u5728Qwen\u4e0eLlama\u4e0a\u5b9e\u9a8c\u8bc1\u660e\uff1a\u5f15\u5bfc\u6548\u679c\u9ad8\u5ea6\u4f9d\u8d56\u65b9\u6cd5-\u6a21\u578b-\u76ee\u6807\u7684\u7ec4\u5408\uff0c\u9519\u8bef\u7ec4\u5408\u4f1a\u5f15\u53d1\u4e25\u91cd\u6982\u5ff5\u7ea0\u7f20\u3002", "motivation": "\u5f53\u524d\u5173\u4e8e\u6a21\u578b\u5bf9\u9f50\u7684\u7814\u7a76\u591a\u5173\u6ce8\u771f\u5b9e\u6027\u6216\u63a8\u7406\u80fd\u529b\uff0c\u800c\u5bf9\u8868\u5f81\u5f15\u5bfc\u5728\u591a\u79cd\u5bf9\u9f50\u76ee\u6807\u4e4b\u95f4\u7684\u6743\u8861\u548c\u5bf9\u6b21\u8981\u884c\u4e3a\u5f71\u54cd\u7684\u7cfb\u7edf\u6027\u7814\u7a76\u8f83\u5c11\u3002\u4f5c\u8005\u5e0c\u671b\u901a\u8fc7\u57fa\u51c6\u8bc4\u4f30\u63ed\u793a\u8fd9\u4e9b\u672a\u7406\u89e3\u7684\u6743\u8861\u548c\u6f5c\u5728\u7684\u6982\u5ff5\u7ea0\u7f20\u95ee\u9898\u3002", "method": "\u4f5c\u8005\u6784\u5efa\u4e86\u4e00\u4e2a\u6a21\u5757\u5316\u7684\u5f15\u5bfc\u6846\u67b6\uff0c\u5c06\u73b0\u6709\u65b9\u6cd5\u62c6\u5206\u4e3a\u72ec\u7acb\u7ec4\u4ef6\uff0c\u56f4\u7ed5\u4e94\u79cd\u6d41\u884c\u7684\u5f15\u5bfc\u65b9\u6cd5\u8bbe\u8ba1\u5b9e\u9a8c\uff0c\u5e76\u6536\u96c6\u4e86\u5305\u542b\u4e3b\u8981\u4e0e\u6b21\u8981\u5b89\u5168\u76f8\u5173\u884c\u4e3a\u7684\u6570\u636e\u96c6\u7528\u4e8e\u8bc4\u4f30\u3002\u5b9e\u9a8c\u5728Qwen-2.5-7B\u548cLlama-3.1-8B\u4e0a\u8fdb\u884c\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff1a1) \u5f3a\u6548\u5f15\u5bfc\u4f9d\u8d56\u4e8e\u5f15\u5bfc\u65b9\u6cd5\u3001\u6a21\u578b\u4e0e\u76ee\u6807\u884c\u4e3a\u7684\u5177\u4f53\u7ec4\u5408\uff1b2) \u4e0d\u6070\u5f53\u7ec4\u5408\u53ef\u80fd\u5bfc\u81f4\u4e25\u91cd\u7684\u6982\u5ff5\u7ea0\u7f20\uff08\u5373\u5728\u63a7\u5236\u67d0\u4e00\u884c\u4e3a\u65f6\u610f\u5916\u5f71\u54cd\u5176\u4ed6\u884c\u4e3a\uff09\uff1b3) \u4e0d\u540c\u6a21\u578b\u5728\u76f8\u540c\u5f15\u5bfc\u65b9\u6cd5\u4e0b\u8868\u73b0\u5dee\u5f02\u663e\u8457\u3002\u4f5c\u8005\u540c\u65f6\u516c\u5f00\u4e86\u4ee3\u7801\u5e93\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86SteeringControl\u57fa\u51c6\uff0c\u7528\u4e8e\u7cfb\u7edf\u8bc4\u4f30\u4e0d\u540c\u8868\u5f81\u5f15\u5bfc\uff08steering\uff09\u65b9\u6cd5\u5728\u504f\u89c1\u3001\u6709\u5bb3\u751f\u6210\u548c\u5e7b\u89c9\u7b49\u6838\u5fc3\u5bf9\u9f50\u76ee\u6807\u4e0a\u7684\u6548\u679c\uff0c\u4ee5\u53ca\u5bf9\u4ece\u4f17\u6027\u548c\u5e38\u8bc6\u9053\u5fb7\u7b49\u6b21\u8981\u884c\u4e3a\u7684\u5f71\u54cd\u3002\u7ed3\u8bba\u5f3a\u8c03\uff1a\u5f15\u5bfc\u6548\u679c\u9ad8\u5ea6\u4f9d\u8d56\u4e8e\u5f15\u5bfc\u65b9\u6cd5\u3001\u6a21\u578b\u4e0e\u76ee\u6807\u884c\u4e3a\u7684\u5177\u4f53\u7ec4\u5408\uff0c\u9519\u8bef\u7ec4\u5408\u53ef\u80fd\u5bfc\u81f4\u4e25\u91cd\u7684\u6982\u5ff5\u7ea0\u7f20\u3002"}}
{"id": "2509.13648", "categories": ["cs.LG", "cs.IR"], "pdf": "https://arxiv.org/pdf/2509.13648", "abs": "https://arxiv.org/abs/2509.13648", "authors": ["Geon Lee", "Bhuvesh Kumar", "Clark Mingxuan Ju", "Tong Zhao", "Kijung Shin", "Neil Shah", "Liam Collins"], "title": "Sequential Data Augmentation for Generative Recommendation", "comment": null, "summary": "Generative recommendation plays a crucial role in personalized systems,\npredicting users' future interactions from their historical behavior sequences.\nA critical yet underexplored factor in training these models is data\naugmentation, the process of constructing training data from user interaction\nhistories. By shaping the training distribution, data augmentation directly and\noften substantially affects model generalization and performance. Nevertheless,\nin much of the existing work, this process is simplified, applied\ninconsistently, or treated as a minor design choice, without a systematic and\nprincipled understanding of its effects.\n  Motivated by our empirical finding that different augmentation strategies can\nyield large performance disparities, we conduct an in-depth analysis of how\nthey reshape training distributions and influence alignment with future targets\nand generalization to unseen inputs. To systematize this design space, we\npropose GenPAS, a generalized and principled framework that models augmentation\nas a stochastic sampling process over input-target pairs with three\nbias-controlled steps: sequence sampling, target sampling, and input sampling.\nThis formulation unifies widely used strategies as special cases and enables\nflexible control of the resulting training distribution. Our extensive\nexperiments on benchmark and industrial datasets demonstrate that GenPAS yields\nsuperior accuracy, data efficiency, and parameter efficiency compared to\nexisting strategies, providing practical guidance for principled training data\nconstruction in generative recommendation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faGenPAS\u6846\u67b6\uff0c\u5c06\u589e\u5f3a\u7edf\u4e00\u5efa\u6a21\u4e3a\u4e09\u6b65\u504f\u7f6e\u7684\u968f\u673a\u91c7\u6837\u8fc7\u7a0b\uff0c\u7cfb\u7edf\u5316\u5730\u63a7\u5236\u8bad\u7ec3\u5206\u5e03\uff0c\u663e\u8457\u63d0\u5347\u751f\u6210\u5f0f\u63a8\u8350\u7684\u6027\u80fd\u4e0e\u6548\u7387\u3002", "motivation": "\u52a8\u673a\u662f\u89c2\u5bdf\u5230\u4e0d\u540c\u6570\u636e\u589e\u5f3a\u7b56\u7565\u4f1a\u5bfc\u81f4\u6a21\u578b\u6027\u80fd\u5dee\u5f02\u5f88\u5927\uff0c\u4f46\u73b0\u6709\u5de5\u4f5c\u5bf9\u589e\u5f3a\u5904\u7406\u4e0d\u7cfb\u7edf\u3001\u4e0d\u4e00\u81f4\uff0c\u7f3a\u4e4f\u5173\u4e8e\u5176\u5982\u4f55\u5f71\u54cd\u8bad\u7ec3\u5206\u5e03\u548c\u6cdb\u5316\u6027\u7684\u539f\u5219\u6027\u7406\u89e3\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u4e2a\u7edf\u4e00\u4e14\u53ef\u63a7\u7684\u589e\u5f3a\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u4e86GenPAS\u6846\u67b6\uff0c\u5c06\u6570\u636e\u589e\u5f3a\u5efa\u6a21\u4e3a\u8f93\u5165-\u76ee\u6807\u5bf9\u7684\u968f\u673a\u91c7\u6837\u8fc7\u7a0b\uff0c\u5305\u542b\u5e8f\u5217\u91c7\u6837\u3001\u76ee\u6807\u91c7\u6837\u548c\u8f93\u5165\u91c7\u6837\u4e09\u6b65\uff0c\u5e76\u901a\u8fc7\u8c03\u8282\u8fd9\u4e09\u6b65\u7684\u504f\u7f6e\u6765\u751f\u6210\u4e0d\u540c\u7684\u8bad\u7ec3\u5206\u5e03\uff1b\u5728\u57fa\u51c6\u548c\u5de5\u4e1a\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5927\u89c4\u6a21\u5b9e\u9a8c\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "GenPAS\u5728\u591a\u4e2a\u57fa\u51c6\u548c\u5de5\u4e1a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u5728\u51c6\u786e\u6027\u3001\u6570\u636e\u6548\u7387\u548c\u53c2\u6570\u6548\u7387\u65b9\u9762\u5747\u4f18\u4e8e\u73b0\u6709\u5e38\u7528\u7b56\u7565\uff0c\u8bc1\u660e\u4e86\u8be5\u6846\u67b6\u7684\u6709\u6548\u6027\u5e76\u4e3a\u751f\u6210\u5f0f\u63a8\u8350\u7684\u8bad\u7ec3\u6570\u636e\u6784\u5efa\u63d0\u4f9b\u4e86\u5b9e\u9645\u6307\u5bfc\u3002", "conclusion": "\u672c\u6587\u7ed3\u8bba\u662f\uff1a\u6570\u636e\u589e\u5f3a\u7b56\u7565\u5bf9\u751f\u6210\u5f0f\u63a8\u8350\u6a21\u578b\u7684\u6027\u80fd\u5f71\u54cd\u663e\u8457\uff0c\u901a\u8fc7\u628a\u589e\u5f3a\u89c6\u4f5c\u5bf9\u8f93\u5165-\u76ee\u6807\u5bf9\u7684\u968f\u673a\u91c7\u6837\u8fc7\u7a0b\uff0c\u5e76\u63a7\u5236\u5e8f\u5217\u91c7\u6837\u3001\u76ee\u6807\u91c7\u6837\u548c\u8f93\u5165\u91c7\u6837\u4e09\u4e2a\u504f\u7f6e\u6b65\u9aa4\uff0c\u53ef\u4ee5\u7cfb\u7edf\u5316\u5730\u6784\u5efa\u8bad\u7ec3\u5206\u5e03\uff0c\u4ece\u800c\u63d0\u5347\u6a21\u578b\u7684\u51c6\u786e\u6027\u3001\u6570\u636e\u6548\u7387\u548c\u53c2\u6570\u6548\u7387\u3002"}}
{"id": "2509.13547", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2509.13547", "abs": "https://arxiv.org/abs/2509.13547", "authors": ["Harper Reed", "Michael Sugimura", "Angelo Zangari"], "title": "AI Agents with Human-Like Collaborative Tools: Adaptive Strategies for Enhanced Problem-Solving", "comment": "16 pages, 5 tables", "summary": "We investigate whether giving LLM agents the collaborative tools and autonomy\nthat humans naturally use for problem solving can improve their performance. We\nequip Claude Code agents with MCP-based social media and journaling tools and\nallow them to use these tools as they see fit. Across 34 Aider Polyglot Python\nprogramming challenges, collaborative tools substantially improve performance\non the hardest problems, delivering 15-40% lower cost, 12-27% fewer turns, and\n12-38% faster completion than baseline agents. Effects on the full challenge\nset are mixed, suggesting these tools act as performance enhancers when\nadditional reasoning scaffolding is most needed. Surprisingly, Different models\nnaturally adopted distinct collaborative strategies without explicit\ninstruction. Sonnet 3.7 engaged broadly across tools and benefited from\narticulation-based cognitive scaffolding. Sonnet 4 showed selective adoption,\nleaning on journal-based semantic search when problems were genuinely\ndifficult. This mirrors how human developers adjust collaboration based on\nexpertise and task complexity. Behavioral analysis shows agents prefer writing\nover reading by about 2-9x, indicating that structured articulation drives much\nof the improvement rather than information access alone. Overall, AI agents can\nsystematically benefit from human-inspired collaboration tools at the edge of\ntheir capabilities, pointing to adaptive collaborative interfaces as reasoning\nenhancers rather than universal efficiency boosts.", "AI": {"tldr": "\u5728\u6700\u96be\u9898\u4e0a\uff0c\u7ed9LLM\u4ee3\u7406\u4ee5\u793e\u4ea4\u5a92\u4f53\u548c\u65e5\u5fd7\u5de5\u5177\u5e76\u8ba9\u5176\u81ea\u4e3b\u4f7f\u7528\uff0c\u53ef\u663e\u8457\u63d0\u5347\u6027\u80fd\uff08\u6210\u672c\u219315-40%\u3001\u8f6e\u6b21\u219312-27%\u3001\u901f\u5ea6\u219312-38%\uff09\uff1b\u6574\u4f53\u6548\u679c\u6df7\u5408\uff0c\u8868\u660e\u5de5\u5177\u5728\u9700\u8981\u989d\u5916\u63a8\u7406\u652f\u67b6\u65f6\u6700\u6709\u7528\u3002", "motivation": "\u63a2\u7a76\u628a\u4eba\u7c7b\u5728\u95ee\u9898\u89e3\u51b3\u4e2d\u4f7f\u7528\u7684\u534f\u4f5c\u5de5\u5177\u4e0e\u81ea\u4e3b\u6027\u8d4b\u4e88LLM\u4ee3\u7406\uff0c\u662f\u5426\u80fd\u63d0\u5347\u5176\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "method": "\u4e3aClaude Code\u4ee3\u7406\u63d0\u4f9bMCP\u673a\u5236\u7684\u793e\u4ea4\u5a92\u4f53\u4e0e\u65e5\u5fd7\u5de5\u5177\uff0c\u5141\u8bb8\u81ea\u4e3b\u4f7f\u7528\uff1b\u572834\u4e2aAider Polyglot Python\u7f16\u7a0b\u6311\u6218\u4e0a\u6bd4\u8f83\u6709\u65e0\u5de5\u5177\u7684\u8868\u73b0\uff0c\u5206\u6790\u6210\u672c\u3001\u8f6e\u6b21\u3001\u5b8c\u6210\u65f6\u95f4\u4e0e\u884c\u4e3a\u6a21\u5f0f\u3002", "result": "Collaborative tools (social media and journaling) plus autonomy improve LLM agent performance on hardest programming problems; variable effects overall; models differ in strategy; writing > reading; tools act as scaffolding at edge cases.", "conclusion": "\u4eba\u7c7b\u542f\u53d1\u7684\u534f\u4f5c\u5de5\u5177\u80fd\u4f5c\u4e3a\u63a8\u7406\u652f\u67b6\u63d0\u5347AI\u4ee3\u7406\u5728\u56f0\u96be\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff0c\u4f46\u4e0d\u662f\u5bf9\u6240\u6709\u4efb\u52a1\u7684\u666e\u9002\u6548\u7387\u63d0\u5347\uff1b\u4e0d\u540c\u6a21\u578b\u4f1a\u81ea\u53d1\u91c7\u7528\u4e0d\u540c\u534f\u4f5c\u7b56\u7565\uff0c\u503e\u5411\u4e8e\u4e66\u5199\u800c\u975e\u9605\u8bfb\u3002"}}
{"id": "2509.13987", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.13987", "abs": "https://arxiv.org/abs/2509.13987", "authors": ["Ozer Ozturk", "Busra Buyuktanir", "Gozde Karatas Baydogmus", "Kazim Yildiz"], "title": "Differential Privacy in Federated Learning: Mitigating Inference Attacks with Randomized Response", "comment": null, "summary": "Machine learning models used for distributed architectures consisting of\nservers and clients require large amounts of data to achieve high accuracy.\nData obtained from clients are collected on a central server for model\ntraining. However, storing data on a central server raises concerns about\nsecurity and privacy. To address this issue, a federated learning architecture\nhas been proposed. In federated learning, each client trains a local model\nusing its own data. The trained models are periodically transmitted to the\ncentral server. The server then combines the received models using federated\naggregation algorithms to obtain a global model. This global model is\ndistributed back to the clients, and the process continues in a cyclical\nmanner. Although preventing data from leaving the clients enhances security,\ncertain concerns still remain. Attackers can perform inference attacks on the\nobtained models to approximate the training dataset, potentially causing data\nleakage. In this study, differential privacy was applied to address the\naforementioned security vulnerability, and a performance analysis was\nconducted. The Data-Unaware Classification Based on Association (duCBA)\nalgorithm was used as the federated aggregation method. Differential privacy\nwas implemented on the data using the Randomized Response technique, and the\ntrade-off between security and performance was examined under different epsilon\nvalues. As the epsilon value decreased, the model accuracy declined, and class\nprediction imbalances were observed. This indicates that higher levels of\nprivacy do not always lead to practical outcomes and that the balance between\nsecurity and performance must be carefully considered.", "AI": {"tldr": "\u5728\u4f7f\u7528duCBA\u805a\u5408\u7684\u8054\u90a6\u5b66\u4e60\u4e2d\uff0c\u57fa\u4e8e\u968f\u673a\u54cd\u5e94\u7684\u5dee\u5206\u9690\u79c1\u53ef\u964d\u4f4e\u6570\u636e\u6cc4\u9732\u98ce\u9669\uff0c\u4f46\u4f1a\u5bfc\u81f4\u51c6\u786e\u7387\u4e0b\u964d\u548c\u7c7b\u522b\u9884\u6d4b\u5931\u8861\uff0c\u9700\u5728\u9690\u79c1\u5f3a\u5ea6\u4e0e\u53ef\u7528\u6027\u4e4b\u95f4\u6743\u8861\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u96c6\u4e2d\u5f0f\u8bad\u7ec3\u4e2d\u5bf9\u5ba2\u6237\u7aef\u6570\u636e\u9690\u79c1\u6cc4\u9732\u7684\u62c5\u5fe7\uff0c\u901a\u8fc7\u8054\u90a6\u5b66\u4e60\u7ed3\u5408\u5dee\u5206\u9690\u79c1\u51cf\u5c11\u8bad\u7ec3\u6570\u636e\u88ab\u63a8\u65ad\u6216\u91cd\u5efa\u7684\u98ce\u9669\uff0c\u8bc4\u4f30\u5728\u5b9e\u9645\u8054\u90a6\u805a\u5408\uff08duCBA\uff09\u4e0b\u5dee\u5206\u9690\u79c1\u5bf9\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\u3002", "method": "\u5728\u8054\u90a6\u5b66\u4e60\u67b6\u6784\u4e2d\u4f7f\u7528duCBA\u4f5c\u4e3a\u805a\u5408\u7b97\u6cd5\uff1b\u5728\u5ba2\u6237\u7aef\u5bf9\u6570\u636e\u5e94\u7528\u968f\u673a\u54cd\u5e94\uff08Randomized Response\uff09\u4ee5\u5b9e\u73b0\u5dee\u5206\u9690\u79c1\uff0c\u7136\u540e\u8bad\u7ec3\u672c\u5730\u6a21\u578b\u5e76\u4e0a\u4f20\u7ed9\u670d\u52a1\u5668\u8fdb\u884cduCBA\u805a\u5408\uff0c\u5faa\u73af\u8fed\u4ee3\u3002\u5bf9\u4e0d\u540cepsilon\u503c\u4e0b\u7684\u6027\u80fd\uff08\u51c6\u786e\u7387\u3001\u7c7b\u522b\u9884\u6d4b\u5206\u5e03\uff09\u8fdb\u884c\u5bf9\u6bd4\u5b9e\u9a8c\u5206\u6790\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff1a\u5f15\u5165\u968f\u673a\u54cd\u5e94\u5dee\u5206\u9690\u79c1\u540e\uff0c\u968f\u7740epsilon\u51cf\u5c0f\uff0c\u6574\u4f53\u51c6\u786e\u7387\u9010\u6b65\u4e0b\u964d\uff0c\u540c\u65f6\u67d0\u4e9b\u7c7b\u7684\u9884\u6d4b\u6bd4\u4f8b\u663e\u8457\u504f\u79fb\uff0c\u51fa\u73b0\u7c7b\u522b\u4e0d\u5747\u8861\u9884\u6d4b\uff1b\u8868\u660e\u5b58\u5728\u660e\u663e\u7684\u9690\u79c1-\u6548\u7528\u6298\u8877\u3002", "conclusion": "\u5e94\u7528\u5dee\u5206\u9690\u79c1\u4f1a\u5728\u9690\u79c1\u4e0e\u6027\u80fd\u4e4b\u95f4\u5b58\u5728\u660e\u663e\u6743\u8861\uff1b\u5728\u6240\u7528\u8bbe\u7f6e\u4e0b\uff0c\u968f\u7740\u9690\u79c1\u5f3a\u5ea6\uff08epsilon\u51cf\u5c0f\uff09\u589e\u52a0\uff0c\u6a21\u578b\u51c6\u786e\u7387\u4e0b\u964d\u4e14\u7c7b\u522b\u9884\u6d4b\u4e0d\u5e73\u8861\u52a0\u5267\uff0c\u8bf4\u660e\u9ad8\u9690\u79c1\u53ef\u80fd\u5bfc\u81f4\u4e0d\u53ef\u63a5\u53d7\u7684\u5b9e\u7528\u6027\u635f\u5931\u3002"}}
{"id": "2509.13651", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.13651", "abs": "https://arxiv.org/abs/2509.13651", "authors": ["Yongkang Du", "Jieyu Zhao", "Yijun Yang", "Tianyi Zhou"], "title": "Controllable Pareto Trade-off between Fairness and Accuracy", "comment": null, "summary": "The fairness-accuracy trade-off is a key challenge in NLP tasks. Current work\nfocuses on finding a single \"optimal\" solution to balance the two objectives,\nwhich is limited considering the diverse solutions on the Pareto front. This\nwork intends to provide controllable trade-offs according to the user's\npreference of the two objectives, which is defined as a reference vector. To\nachieve this goal, we apply multi-objective optimization (MOO), which can find\nsolutions from various regions of the Pareto front. However, it is challenging\nto precisely control the trade-off due to the stochasticity of the training\nprocess and the high dimentional gradient vectors. Thus, we propose\nControllable Pareto Trade-off (CPT) that can effectively train models to\nperform different trade-offs according to users' preferences. CPT 1) stabilizes\nthe fairness update with a moving average of stochastic gradients to determine\nthe update direction, and 2) prunes the gradients by only keeping the gradients\nof the critical parameters. We evaluate CPT on hate speech detection and\noccupation classification tasks. Experiments show that CPT can achieve a\nhigher-quality set of solutions on the Pareto front than the baseline methods.\nIt also exhibits better controllability and can precisely follow the\nhuman-defined reference vectors.", "AI": {"tldr": "\u63d0\u51faCPT\uff1a\u7528\u79fb\u52a8\u5e73\u5747\u7a33\u5b9a\u516c\u5e73\u66f4\u65b0\u5e76\u5bf9\u68af\u5ea6\u526a\u679d\u4ee5\u5b9e\u73b0\u53ef\u63a7\u7684\u516c\u5e73-\u51c6\u786e\u6027\u6743\u8861\uff0c\u80fd\u5728Pareto\u524d\u6cbf\u4e0a\u7cbe\u786e\u751f\u6210\u7528\u6237\u671f\u671b\u7684\u89e3\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u53ea\u5bfb\u6c42\u5355\u4e00\u201c\u6700\u4f18\u201d\u516c\u5e73-\u51c6\u786e\u6027\u5e73\u8861\uff0c\u5ffd\u7565Pareto\u524d\u6cbf\u4e0a\u591a\u6837\u5316\u7684\u53ef\u9009\u89e3\uff1b\u7528\u6237\u53ef\u80fd\u5e0c\u671b\u6309\u504f\u597d\uff08\u53c2\u8003\u5411\u91cf\uff09\u5728\u524d\u6cbf\u4e0a\u9009\u62e9\u4e0d\u540c\u6743\u8861\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u53ef\u63a7\u751f\u6210\u4e0d\u540c\u6743\u8861\u89e3\u7684\u65b9\u6cd5\u3002", "method": "\u57fa\u4e8e\u591a\u76ee\u6807\u4f18\u5316\u6846\u67b6\uff0cCPT\u5305\u542b\u4e24\u9879\u5173\u952e\u6280\u672f\uff1a1) \u5bf9\u516c\u5e73\u76ee\u6807\u7684\u968f\u673a\u68af\u5ea6\u505a\u79fb\u52a8\u5e73\u5747\u4ee5\u7a33\u5b9a\u66f4\u65b0\u65b9\u5411\uff1b2) \u5bf9\u68af\u5ea6\u8fdb\u884c\u526a\u679d\uff0c\u53ea\u4fdd\u7559\u88ab\u5224\u5b9a\u4e3a\u5173\u952e\u7684\u53c2\u6570\u7684\u68af\u5ea6\uff0c\u4ece\u800c\u964d\u4f4e\u566a\u58f0\u5e76\u63d0\u9ad8\u53ef\u63a7\u6027\u3002", "result": "CPT\u63d0\u51fa\u901a\u8fc7MOO\u5b9e\u73b0\u5bf9\u516c\u5e73-\u51c6\u786e\u6027\u6743\u8861\u7684\u53ef\u63a7\u8c03\u8282\uff0c\u7279\u522b\u5728\u8bad\u7ec3\u4e2d\u7528\u79fb\u52a8\u5e73\u5747\u7a33\u5b9a\u516c\u5e73\u76ee\u6807\u7684\u68af\u5ea6\u5e76\u526a\u679d\u4ec5\u4fdd\u7559\u5173\u952e\u53c2\u6570\u68af\u5ea6\uff0c\u4ece\u800c\u53ef\u6309\u7528\u6237\u7ed9\u5b9a\u7684\u53c2\u8003\u5411\u91cf\u5f97\u5230\u4e0d\u540cPareto\u524d\u6cbf\u89e3\u3002\u5b9e\u9a8c\u8bc1\u660e\u5728\u4ec7\u6068\u8a00\u8bba\u68c0\u6d4b\u548c\u804c\u4e1a\u5206\u7c7b\u4efb\u52a1\u4e0a\uff0cCPT\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u751f\u6210\u66f4\u9ad8\u8d28\u91cf\u7684Pareto\u89e3\u5e76\u80fd\u7cbe\u786e\u8ddf\u968f\u53c2\u8003\u5411\u91cf\u3002", "conclusion": "CPT\u80fd\u66f4\u597d\u5730\u63a7\u5236\u516c\u5e73\u4e0e\u51c6\u786e\u6027\u4e4b\u95f4\u7684\u6743\u8861\uff0c\u751f\u6210\u66f4\u9ad8\u8d28\u91cf\u4e14\u53ef\u63a7\u7684Pareto\u524d\u6cbf\u89e3\uff0c\u6bd4\u73b0\u6709\u57fa\u7ebf\u8868\u73b0\u66f4\u4f18\u3002"}}
{"id": "2509.13570", "categories": ["cs.AI", "math.HO", "Primary: 97U50, Secondary: 97U70, 97D40, 97D60, 97E50, 97H40"], "pdf": "https://arxiv.org/pdf/2509.13570", "abs": "https://arxiv.org/abs/2509.13570", "authors": ["Hannah Klawa", "Shraddha Rajpal", "Cigole Thomas"], "title": "Gen AI in Proof-based Math Courses: A Pilot Study", "comment": "35 pages, 6 figures, Comments welcome!", "summary": "With the rapid rise of generative AI in higher education and the\nunreliability of current AI detection tools, developing policies that encourage\nstudent learning and critical thinking has become increasingly important. This\nstudy examines student use and perceptions of generative AI across three\nproof-based undergraduate mathematics courses: a first-semester abstract\nalgebra course, a topology course and a second-semester abstract algebra\ncourse. In each case, course policy permitted some use of generative AI.\nDrawing on survey responses and student interviews, we analyze how students\nengaged with AI tools, their perceptions of generative AI's usefulness and\nlimitations, and what implications these perceptions hold for teaching\nproof-based mathematics. We conclude by discussing future considerations for\nintegrating generative AI into proof-based mathematics instruction.", "AI": {"tldr": "\u7814\u7a76\u8c03\u67e5\u4e86\u5728\u4e09\u95e8\u8bc1\u660e\u7c7b\u672c\u79d1\u6570\u5b66\u8bfe\u4e2d\uff0c\u5b66\u751f\u5982\u4f55\u4f7f\u7528\u548c\u770b\u5f85\u751f\u6210\u5f0fAI\uff08\u8bfe\u7a0b\u5747\u5141\u8bb8\u90e8\u5206\u4f7f\u7528\uff09\u3002\u901a\u8fc7\u95ee\u5377\u4e0e\u8bbf\u8c08\uff0c\u5206\u6790\u5b66\u751f\u4e0eAI\u4ea4\u4e92\u65b9\u5f0f\u3001\u5bf9AI\u6709\u7528\u6027\u548c\u5c40\u9650\u6027\u7684\u770b\u6cd5\uff0c\u5e76\u8ba8\u8bba\u5bf9\u6559\u5b66\u7684\u5f71\u54cd\u4e0e\u672a\u6765\u6574\u5408\u5efa\u8bae\u3002", "motivation": "\u968f\u7740\u751f\u6210\u5f0fAI\u5728\u9ad8\u7b49\u6559\u80b2\u4e2d\u8fc5\u901f\u666e\u53ca\u4e14\u73b0\u6709\u68c0\u6d4b\u5de5\u5177\u4e0d\u53ef\u9760\uff0c\u9700\u8981\u5236\u5b9a\u65e2\u9f13\u52b1\u5b66\u751f\u5b66\u4e60\u53c8\u57f9\u517b\u6279\u5224\u6027\u601d\u7ef4\u7684\u653f\u7b56\uff0c\u56e0\u6b64\u7814\u7a76\u65e8\u5728\u63a2\u67e5\u5b66\u751f\u5728\u8bc1\u660e\u7c7b\u6570\u5b66\u8bfe\u7a0b\u4e2d\u5982\u4f55\u5b9e\u9645\u4f7f\u7528\u4e0e\u770b\u5f85\u751f\u6210\u5f0fAI\uff0c\u4ee5\u4fbf\u4e3a\u8bfe\u7a0b\u653f\u7b56\u4e0e\u6559\u5b66\u5b9e\u8df5\u63d0\u4f9b\u8bc1\u636e\u3002", "method": "\u5728\u4e09\u95e8\u8bc1\u660e\u6027\u8bfe\u7a0b\u4e2d\u91c7\u7528\u6df7\u5408\u65b9\u6cd5\uff1a\u5206\u53d1\u95ee\u5377\u4ee5\u6536\u96c6\u5e7f\u6cdb\u4f7f\u7528\u60c5\u51b5\u4e0e\u6001\u5ea6\u6570\u636e\uff0c\u5e76\u5bf9\u82e5\u5e72\u5b66\u751f\u8fdb\u884c\u534a\u7ed3\u6784\u5316\u8bbf\u8c08\u4ee5\u83b7\u53d6\u6df1\u5165\u8303\u4f8b\u548c\u611f\u53d7\u3002\u8bfe\u7a0b\u5141\u8bb8\u6709\u9650\u5236\u5730\u4f7f\u7528\u751f\u6210\u5f0fAI\uff0c\u7814\u7a76\u5206\u6790\u57fa\u4e8e\u5b9a\u6027\u4e0e\u5b9a\u91cf\u6570\u636e\u7684\u7f16\u7801\u4e0e\u4e3b\u9898\u5206\u6790\u3002", "result": "\u5b66\u751f\u5e38\u7528AI\u6765\u641c\u96c6\u4f8b\u5b50\u3001\u68c0\u6838\u5c0f\u6b65\u9aa4\u3001\u83b7\u5f97\u601d\u8def\u63d0\u793a\u548c\u8349\u62df\u8bc1\u660e\uff1b\u4f46\u4ed6\u4eec\u8ba4\u4e3aAI\u751f\u6210\u7684\u8bc1\u660e\u5e38\u6709\u9519\u8bef\u6216\u7f3a\u4e4f\u4e25\u8c28\u6027\uff0c\u5fc5\u987b\u8fdb\u884c\u6279\u5224\u6027\u5ba1\u67e5\u3002\u4e0d\u540c\u8bfe\u7a0b\u4e0e\u5b66\u751f\u80cc\u666f\u5f71\u54cd\u4f7f\u7528\u65b9\u5f0f\u3002\u7814\u7a76\u5efa\u8bae\u660e\u786e\u4f7f\u7528\u8fb9\u754c\u3001\u6559\u6388\u5982\u4f55\u8bc4\u4f30AI\u8f93\u51fa\u53ca\u5c06AI\u6574\u5408\u8fdb\u8bfe\u5802\u6d3b\u52a8\u4ee5\u4fc3\u8fdb\u800c\u975e\u66ff\u4ee3\u6df1\u5ea6\u5b66\u4e60\u3002", "conclusion": "\u5b66\u751f\u5728\u5141\u8bb8\u4f7f\u7528\u7684\u73af\u5883\u4e2d\uff0c\u4f1a\u5c06\u751f\u6210\u5f0fAI\u7528\u4e8e\u751f\u6210\u8349\u7a3f\u3001\u68c0\u9a8c\u60f3\u6cd5\u3001\u5bfb\u627e\u4f8b\u5b50\u548c\u83b7\u53d6\u8bc1\u660e\u63d0\u793a\uff0c\u4f46\u5bf9\u6df1\u5c42\u7406\u89e3\u4e0e\u521b\u9020\u6027\u8bc1\u660e\u4ecd\u6301\u6000\u7591\u6001\u5ea6\u3002\u6559\u5b66\u4e0a\u5e94\u5236\u5b9a\u660e\u786e\u4f7f\u7528\u89c4\u8303\u3001\u6559\u6388AI\u7d20\u517b\u3001\u8bbe\u8ba1\u80fd\u8bc4\u4f30\u6df1\u5c42\u7406\u89e3\u7684\u4f5c\u4e1a\u4e0e\u8bc4\u4f30\u65b9\u6cd5\uff0c\u5e76\u5c06AI\u4f5c\u4e3a\u4fc3\u8fdb\u5b66\u4e60\u7684\u5de5\u5177\u800c\u975e\u66ff\u4ee3\u3002"}}
{"id": "2509.14035", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.14035", "abs": "https://arxiv.org/abs/2509.14035", "authors": ["Hannah Keller", "Jacob Imola", "Fabrizio Boninsegna", "Rasmus Pagh", "Amrita Roy Chowdhury"], "title": "Piquant$\\varepsilon$: Private Quantile Estimation in the Two-Server Model", "comment": "30 Pages, 19 Figures, 1 Table", "summary": "Quantiles are key in distributed analytics, but computing them over sensitive\ndata risks privacy. Local differential privacy (LDP) offers strong protection\nbut lower accuracy than central DP, which assumes a trusted aggregator. Secure\nmulti-party computation (MPC) can bridge this gap, but generic MPC solutions\nface scalability challenges due to large domains, complex secure operations,\nand multi-round interactions.\n  We present Piquant$\\varepsilon$, a system for privacy-preserving estimation\nof multiple quantiles in a distributed setting without relying on a trusted\nserver. Piquant$\\varepsilon$ operates under the malicious threat model and\nachieves accuracy of the central DP model. Built on the two-server model,\nPiquant$\\varepsilon$ uses a novel strategy of releasing carefully chosen\nintermediate statistics, reducing MPC complexity while preserving end-to-end\nDP. Empirically, Piquant$\\varepsilon$ estimates 5 quantiles on 1 million\nrecords in under a minute with domain size $10^9$, achieving up to $10^4$-fold\nhigher accuracy than LDP, and up to $\\sim 10\\times$ faster runtime compared to\nbaselines.", "AI": {"tldr": "Piquant\u03b5: two-server malicious-MPC system that releases intermediate statistics to get central-DP accuracy for multi-quantile estimation at scale; very large accuracy gains over LDP and substantial speedups vs MPC baselines.", "motivation": "Central DP provides high accuracy but needs trusted aggregator; LDP protects locally but suffers large accuracy loss; generic MPC can bridge but is too costly for large domains/records; need a scalable, accurate, and strong-privacy method for quantiles without trusted server.", "method": "Uses two-server MPC with novel release of carefully chosen intermediate statistics to reduce MPC complexity; optimized protocols for large domains and multiple quantiles achieving low rounds and computation; preserves end-to-end differential privacy via noise addition at appropriate steps.", "result": "Estimates 5 quantiles on 1M records with domain 10^9 in under a minute, up to 10^4x accuracy improvement over LDP, and ~10x faster than baselines.", "conclusion": "Piquant\u03b5 provides a practical, accurate, and scalable solution for multi-quantile estimation with strong privacy (malicious two-server model + end-to-end DP), matching central DP accuracy while avoiding a trusted aggregator."}}
{"id": "2509.13686", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.13686", "abs": "https://arxiv.org/abs/2509.13686", "authors": ["Bingsheng Peng", "Shutao Zhang", "Xi Zheng", "Ye Xue", "Xinyu Qin", "Tsung-Hui Chang"], "title": "RF-LSCM: Pushing Radiance Fields to Multi-Domain Localized Statistical Channel Modeling for Cellular Network Optimization", "comment": null, "summary": "Accurate localized wireless channel modeling is a cornerstone of cellular\nnetwork optimization, enabling reliable prediction of network performance\nduring parameter tuning. Localized statistical channel modeling (LSCM) is the\nstate-of-the-art channel modeling framework tailored for cellular network\noptimization. However, traditional LSCM methods, which infer the channel's\nAngular Power Spectrum (APS) from Reference Signal Received Power (RSRP)\nmeasurements, suffer from critical limitations: they are typically confined to\nsingle-cell, single-grid and single-carrier frequency analysis and fail to\ncapture complex cross-domain interactions. To overcome these challenges, we\npropose RF-LSCM, a novel framework that models the channel APS by jointly\nrepresenting large-scale signal attenuation and multipath components within a\nradiance field. RF-LSCM introduces a multi-domain LSCM formulation with a\nphysics-informed frequency-dependent Attenuation Model (FDAM) to facilitate the\ncross frequency generalization as well as a point-cloud-aided environment\nenhanced method to enable multi-cell and multi-grid channel modeling.\nFurthermore, to address the computational inefficiency of typical neural\nradiance fields, RF-LSCM leverages a low-rank tensor representation,\ncomplemented by a novel Hierarchical Tensor Angular Modeling (HiTAM) algorithm.\nThis efficient design significantly reduces GPU memory requirements and\ntraining time while preserving fine-grained accuracy. Extensive experiments on\nreal-world multi-cell datasets demonstrate that RF-LSCM significantly\noutperforms state-of-the-art methods, achieving up to a 30% reduction in mean\nabsolute error (MAE) for coverage prediction and a 22% MAE improvement by\neffectively fusing multi-frequency data.", "AI": {"tldr": "\u63d0\u51faRF-LSCM\uff1a\u5c06APS\u7528\u8f90\u5c04\u573a\u8054\u5408\u8868\u793a\u8870\u51cf\u548c\u591a\u5f84\uff0c\u5305\u542b\u9891\u7387\u76f8\u5173\u7684\u7269\u7406\u8870\u51cf\u6a21\u578b(FDAM)\u3001\u70b9\u4e91\u589e\u5f3a\u5b9e\u73b0\u591a\u5c0f\u533a\u591a\u7f51\u683c\uff0c\u5e76\u7528\u4f4e\u79e9\u5f20\u91cf\u4e0eHiTAM\u52a0\u901f\u8bad\u7ec3\uff1b\u5728\u771f\u5b9e\u591a\u5c0f\u533a\u6570\u636e\u4e0a\u76f8\u6bd4SOTA\u663e\u8457\u964d\u4f4eMAE\u3002", "motivation": "\u4f20\u7edfLSCM\u4ec5\u57fa\u4e8eRSRP\u5728\u5355\u5c0f\u533a/\u5355\u7f51\u683c/\u5355\u9891\u4e0b\u53cd\u6f14APS\uff0c\u65e0\u6cd5\u5904\u7406\u591a\u5c0f\u533a\u3001\u591a\u7f51\u683c\u53ca\u8de8\u9891\u590d\u6742\u4ea4\u4e92\uff0c\u4e14\u795e\u7ecf\u8f90\u5c04\u573a\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u96be\u4ee5\u5b9e\u9645\u90e8\u7f72\u3002", "method": "\u6784\u5efa\u57fa\u4e8e\u795e\u7ecf\u8f90\u5c04\u573a\u7684APS\u8868\u793a\uff0c\u5c06\u5927\u5c3a\u5ea6\u8870\u51cf\u4e0e\u591a\u5f84\u7528\u9891\u7387\u76f8\u5173\u7684FDAM\u8054\u5408\u5efa\u6a21\uff1b\u5f15\u5165\u70b9\u4e91\u8f85\u52a9\u7684\u73af\u5883\u4fe1\u606f\u4ee5\u6269\u5c55\u5230\u591a\u5c0f\u533a\u591a\u7f51\u683c\uff1b\u91c7\u7528\u4f4e\u79e9\u5f20\u91cf\u5206\u89e3\u5e76\u8bbe\u8ba1HiTAM\u5c42\u6b21\u5316\u5f20\u91cf\u89d2\u5ea6\u5efa\u6a21\u4ee5\u63d0\u9ad8\u8bad\u7ec3\u4e0e\u63a8\u7406\u6548\u7387\u3002", "result": "\u5728\u771f\u5b9e\u591a\u5c0f\u533a\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\uff0cRF-LSCM\u5728\u8986\u76d6\u9884\u6d4b\u4e0aMAE\u964d\u4f4e\u6700\u591a\u7ea630%\uff0c\u901a\u8fc7\u591a\u9891\u6570\u636e\u878d\u5408\u53ef\u518d\u63d0\u5347\u7ea622%\u7684MAE\u6539\u5584\uff0c\u540c\u65f6\u8282\u7701\u663e\u5b58\u5e76\u7f29\u77ed\u8bad\u7ec3\u65f6\u95f4\u3002", "conclusion": "RF-LSCM\u5728\u8986\u76d6\u9884\u6d4b\u548c\u591a\u9891\u878d\u5408\u4efb\u52a1\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709LSCM\u65b9\u6cd5\uff0c\u6700\u9ad8\u53ef\u964d\u4f4e\u7ea630%\u8986\u76d6\u9884\u6d4bMAE\uff0c\u4e14\u5b9e\u73b0\u591a\u5c0f\u533a\u3001\u591a\u7f51\u683c\u4e0e\u8de8\u9891\u6cdb\u5316\uff0c\u540c\u65f6\u901a\u8fc7\u4f4e\u79e9\u5f20\u91cf\u548cHiTAM\u663e\u8457\u964d\u4f4eGPU\u5185\u5b58\u4e0e\u8bad\u7ec3\u65f6\u95f4\u3002"}}
{"id": "2509.13588", "categories": ["cs.AI", "cs.CE", "cs.CY"], "pdf": "https://arxiv.org/pdf/2509.13588", "abs": "https://arxiv.org/abs/2509.13588", "authors": ["Xuan Liu", "Haoyang Shang", "Haojian Jin"], "title": "Programmable Cognitive Bias in Social Agents", "comment": null, "summary": "This paper introduces CoBRA, a novel toolkit for systematically specifying\nagent behavior in LLM-based social simulation. We found that conventional\napproaches that specify agent behaviors through implicit natural language\ndescriptions cannot yield consistent behaviors across models, and the produced\nagent behaviors do not capture the nuances of the descriptions. In contrast,\nCoBRA presents a new approach to program agents' cognitive biases explicitly,\nby grounding agents' expected behaviors using classic social science\nexperiments. CoBRA has two components: (1) Cognitive Bias Index that measures\nthe cognitive bias of a social agent, by quantifying the agent's reactions in a\nset of validated classical social science experiments; (2) Behavioral\nRegulation Engine that aligns the agent's behavior to demonstrate controlled\ncognitive bias. We evaluated CoBRA as an HCI toolkit through demonstration and\ntechnical benchmarks. Our results suggest that CoBRA can precisely program the\ncognitive bias demonstrated in a social agent in a model-agnostic manner.", "AI": {"tldr": "CoBRA\u901a\u8fc7\u628a\u4ee3\u7406\u884c\u4e3a\u6620\u5c04\u5230\u7ecf\u5178\u793e\u4f1a\u5b9e\u9a8c\u5e76\u7528\u8c03\u8282\u5f15\u64ce\u63a7\u5236\u751f\u6210\uff0c\u63d0\u4f9b\u4e86\u4e00\u5957\u53ef\u6d4b\u3001\u53ef\u63a7\u4e14\u6a21\u578b\u65e0\u5173\u7684\u65b9\u6cd5\u6765\u5728LLM\u793e\u4f1a\u6a21\u62df\u4e2d\u89c4\u8303\u8ba4\u77e5\u504f\u5dee\u4e0e\u884c\u4e3a\u3002", "motivation": "\u4f20\u7edf\u7528\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u6765\u6307\u5b9a\u4ee3\u7406\u884c\u4e3a\u4f1a\u5bfc\u81f4\u4e0d\u540c\u6a21\u578b\u95f4\u884c\u4e3a\u4e0d\u4e00\u81f4\u4e14\u96be\u4ee5\u6355\u6349\u63cf\u8ff0\u7684\u7ec6\u5fae\u5dee\u522b\uff0c\u56e0\u800c\u9700\u8981\u4e00\u4e2a\u7cfb\u7edf\u5316\u3001\u53ef\u6d4b\u91cf\u4e14\u53ef\u63a7\u7684\u9014\u5f84\u6765\u6307\u5b9a\u57fa\u4e8eLLM\u7684\u793e\u4f1a\u6a21\u62df\u4e2d\u7684\u4ee3\u7406\u884c\u4e3a\u548c\u8ba4\u77e5\u504f\u5dee\u3002", "method": "CoBRA\u7531\u4e24\u90e8\u5206\u7ec4\u6210\uff1a\u4e00\u662fCognitive Bias Index\uff0c\u7528\u4e00\u7ec4\u7ecf\u8fc7\u9a8c\u8bc1\u7684\u7ecf\u5178\u793e\u4f1a\u79d1\u5b66\u5b9e\u9a8c\u91cf\u5316\u4ee3\u7406\u5728\u5b9e\u9a8c\u4e2d\u7684\u53cd\u5e94\uff0c\u4ece\u800c\u8861\u91cf\u5176\u8ba4\u77e5\u504f\u5dee\uff1b\u4e8c\u662fBehavioral Regulation Engine\uff0c\u901a\u8fc7\u8c03\u8282\u751f\u6210\u8fc7\u7a0b\u4f7f\u4ee3\u7406\u884c\u4e3a\u5339\u914d\u76ee\u6807\u8ba4\u77e5\u504f\u5dee\uff0c\u5b9e\u73b0\u53ef\u63a7\u884c\u4e3a\u8868\u73b0\u3002\u65b9\u6cd5\u58f0\u660e\u4e3a\u6a21\u578b\u65e0\u5173\u3002", "result": "\u901a\u8fc7\u6f14\u793a\u548c\u6280\u672f\u57fa\u51c6\u8bc4\u4f30\uff0c\u4f5c\u8005\u8868\u660eCoBRA\u53ef\u4ee5\u7cbe\u786e\u5730\u5728\u6a21\u578b\u65e0\u5173\u7684\u6761\u4ef6\u4e0b\u7f16\u7a0b\u51fa\u7279\u5b9a\u7684\u8ba4\u77e5\u504f\u5dee\uff0c\u4ece\u800c\u5b9e\u73b0\u66f4\u4e00\u81f4\u4e0e\u53ef\u63a7\u7684\u793e\u4f1a\u4ee3\u7406\u884c\u4e3a\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51faCoBRA\u5de5\u5177\u5305\uff0c\u901a\u8fc7\u663e\u5f0f\u7f16\u7a0b\u8ba4\u77e5\u504f\u5dee\u5e76\u4ee5\u7ecf\u5178\u793e\u4f1a\u79d1\u5b66\u5b9e\u9a8c\u4e3a\u57fa\u51c6\uff0c\u80fd\u5728\u4e0d\u540cLLM\u6a21\u578b\u95f4\u66f4\u7a33\u5b9a\u3001\u53ef\u63a7\u5730\u518d\u73b0\u793e\u4f1a\u4ee3\u7406\uff08agent\uff09\u7684\u884c\u4e3a\u3002"}}
{"id": "2509.14096", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.14096", "abs": "https://arxiv.org/abs/2509.14096", "authors": ["V\u00edctor Mayoral-Vilches"], "title": "The Cybersecurity of a Humanoid Robot", "comment": null, "summary": "The rapid advancement of humanoid robotics presents unprecedented\ncybersecurity challenges that existing theoretical frameworks fail to\nadequately address. This report presents a comprehensive security assessment of\na production humanoid robot platform, bridging the gap between abstract\nsecurity models and operational vulnerabilities. Through systematic static\nanalysis, runtime observation, and cryptographic examination, we uncovered a\ncomplex security landscape characterized by both sophisticated defensive\nmechanisms and critical vulnerabilities. Our findings reveal a dual-layer\nproprietary encryption system (designated FMX') that, while innovative in\ndesign, suffers from fundamental implementation flaws including the use of\nstatic cryptographic keys that enable offline configuration decryption. More\nsignificantly, we documented persistent telemetry connections transmitting\ndetailed robot state information--including audio, visual, spatial, and\nactuator data--to external servers without explicit user consent or\nnotification mechanisms. We operationalized a Cybersecurity AI agent on the\nUnitree G1 to map and prepare exploitation of its manufacturer's cloud\ninfrastructure, illustrating how a compromised humanoid can escalate from\ncovert data collection to active counter-offensive operations. We argue that\nsecuring humanoid robots requires a paradigm shift toward Cybersecurity AI\n(CAI) frameworks that can adapt to the unique challenges of physical-cyber\nconvergence. This work contributes empirical evidence for developing robust\nsecurity standards as humanoid robots transition from research curiosities to\noperational systems in critical domains.", "AI": {"tldr": "\u5bf9\u751f\u4ea7\u7ea7\u7c7b\u4eba\u673a\u5668\u4eba\u8fdb\u884c\u7cfb\u7edf\u6027\u5b89\u5168\u8bc4\u4f30\uff0c\u66b4\u9732\u4e86\u52a0\u5bc6\u5b9e\u73b0\u7f3a\u9677\u4e0e\u672a\u6388\u6743\u9065\u6d4b\u6cc4\u9732\uff0c\u5e76\u6f14\u793a\u4e86\u901a\u8fc7\u673a\u5668\u4eba\u5bf9\u5382\u5546\u4e91\u8fdb\u884c\u653b\u51fb\u7684\u53ef\u884c\u6027\uff0c\u547c\u5401\u5f15\u5165\u53ef\u81ea\u9002\u5e94\u7684Cybersecurity AI\u5b89\u5168\u8303\u5f0f\u3002", "motivation": "\u7c7b\u4eba\u673a\u5668\u4eba\u5feb\u901f\u53d1\u5c55\u5e26\u6765\u65b0\u7684\u7f51\u7edc\u5b89\u5168\u6311\u6218\uff0c\u73b0\u6709\u62bd\u8c61\u5b89\u5168\u6a21\u578b\u65e0\u6cd5\u6709\u6548\u8986\u76d6\u5b9e\u9645\u64cd\u4f5c\u6f0f\u6d1e\uff0c\u9700\u63d0\u4f9b\u5b9e\u8bc1\u8bc4\u4f30\u4ee5\u63a8\u52a8\u6807\u51c6\u5236\u5b9a\u3002", "method": "\u901a\u8fc7\u9759\u6001\u5206\u6790\u3001\u8fd0\u884c\u65f6\u89c2\u6d4b\u548c\u5bc6\u7801\u5b66\u68c0\u67e5\uff0c\u7ed3\u5408\u5728Unitree G1\u4e0a\u90e8\u7f72\u7684\u7f51\u7edc\u5b89\u5168AI\u4ee3\u7406\u8fdb\u884c\u4e91\u7aef\u57fa\u7840\u8bbe\u65bd\u6620\u5c04\u4e0e\u5229\u7528\u51c6\u5907\u3002", "result": "\u53d1\u73b0\u53cc\u5c42\u4e13\u6709\u52a0\u5bc6\uff08FMX'\uff09\u5b58\u5728\u9759\u6001\u5bc6\u94a5\u7b49\u5b9e\u73b0\u6027\u7f3a\u9677\uff0c\u53ef\u79bb\u7ebf\u89e3\u5bc6\u914d\u7f6e\uff1b\u68c0\u6d4b\u5230\u6301\u7eed\u9065\u6d4b\u8fde\u63a5\u5411\u5916\u90e8\u670d\u52a1\u5668\u4f20\u8f93\u8be6\u7ec6\u9690\u79c1\u76f8\u5173\u6570\u636e\u4e14\u65e0\u7528\u6237\u901a\u77e5\uff1b\u793a\u8303\u4e86\u88ab\u653b\u7834\u673a\u5668\u4eba\u5982\u4f55\u5347\u7ea7\u4e3a\u4e3b\u52a8\u53cd\u5236\u7684\u653b\u51fb\u8def\u5f84\u3002", "conclusion": "\u8be5\u8bba\u6587\u63ed\u793a\u4e86\u9762\u5411\u7c7b\u4eba\u673a\u5668\u4eba\u5e73\u53f0\u7684\u5b9e\u9645\u5b89\u5168\u98ce\u9669\uff0c\u5f3a\u8c03\u73b0\u6709\u7406\u8bba\u6846\u67b6\u4e0d\u8db3\uff0c\u9700\u91c7\u7528\u9762\u5411\u7269\u7406-\u7f51\u7edc\u878d\u5408\u7684\u9002\u5e94\u6027\u5b89\u5168\u65b9\u6cd5\uff08CAI\uff09\u3002"}}
{"id": "2509.13717", "categories": ["cs.LG", "cs.NA", "math.NA"], "pdf": "https://arxiv.org/pdf/2509.13717", "abs": "https://arxiv.org/abs/2509.13717", "authors": ["Yifan Yu", "Cheuk Hin Ho", "Yangshuai Wang"], "title": "A Conformal Prediction Framework for Uncertainty Quantification in Physics-Informed Neural Networks", "comment": null, "summary": "Physics-Informed Neural Networks (PINNs) have emerged as a powerful framework\nfor solving PDEs, yet existing uncertainty quantification (UQ) approaches for\nPINNs generally lack rigorous statistical guarantees. In this work, we bridge\nthis gap by introducing a distribution-free conformal prediction (CP) framework\nfor UQ in PINNs. This framework calibrates prediction intervals by constructing\nnonconformity scores on a calibration set, thereby yielding distribution-free\nuncertainty estimates with rigorous finite-sample coverage guarantees for\nPINNs. To handle spatial heteroskedasticity, we further introduce local\nconformal quantile estimation, enabling spatially adaptive uncertainty bands\nwhile preserving theoretical guarantee. Through systematic evaluations on\ntypical PDEs (damped harmonic oscillator, Poisson, Allen-Cahn, and Helmholtz\nequations) and comprehensive testing across multiple uncertainty metrics, our\nresults demonstrate that the proposed framework achieves reliable calibration\nand locally adaptive uncertainty intervals, consistently outperforming\nheuristic UQ approaches. By bridging PINNs with distribution-free UQ, this work\nintroduces a general framework that not only enhances calibration and\nreliability, but also opens new avenues for uncertainty-aware modeling of\ncomplex PDE systems.", "AI": {"tldr": "\u672c\u6587\u5c06\u4fdd\u5f62\u9884\u6d4b\u5f15\u5165PINN\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\uff0c\u63d0\u4f9b\u5206\u5e03\u81ea\u7531\u7684\u6709\u9650\u6837\u672c\u8986\u76d6\u4fdd\u8bc1\uff0c\u5e76\u901a\u8fc7\u5c40\u90e8\u5206\u4f4d\u4f30\u8ba1\u5904\u7406\u7a7a\u95f4\u5f02\u65b9\u5dee\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u5728\u591a\u79cdPDE\u4e0a\u5b9e\u73b0\u4e86\u66f4\u53ef\u9760\u548c\u5c40\u90e8\u81ea\u9002\u5e94\u7684\u4e0d\u786e\u5b9a\u6027\u5e26\u3002", "motivation": "\u73b0\u6709PINN\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u6cd5\u5927\u591a\u7f3a\u4e4f\u4e25\u683c\u7684\u7edf\u8ba1\u8986\u76d6\u4fdd\u8bc1\uff0c\u5c24\u5176\u5728\u6837\u672c\u91cf\u6709\u9650\u6216\u5b58\u5728\u7a7a\u95f4\u5f02\u65b9\u5dee\u65f6\uff0c\u65e0\u6cd5\u4fdd\u8bc1\u7f6e\u4fe1\u533a\u95f4\u7684\u53ef\u9760\u6027\u3002\u672c\u5de5\u4f5c\u65e8\u5728\u4e3aPINN\u7684UQ\u63d0\u4f9b\u5206\u5e03\u81ea\u7531\u3001\u6709\u9650\u6837\u672c\u7684\u7406\u8bba\u4fdd\u8bc1\uff0c\u540c\u65f6\u517c\u987e\u7a7a\u95f4\u81ea\u9002\u5e94\u6027\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u57fa\u4e8e\u4fdd\u5f62\u9884\u6d4b\u7684\u5206\u5e03\u81ea\u7531UQ\u6846\u67b6\uff1a1) \u8bad\u7ec3PINN\u5f97\u5230\u9884\u6d4b\uff1b2) \u5728\u72ec\u7acb\u6821\u51c6\u96c6\u4e0a\u8ba1\u7b97nonconformity score\uff08\u5982\u6b8b\u5dee\u6216\u7edd\u5bf9\u8bef\u5dee\uff09\uff1b3) \u4ee5\u987a\u5e8f\u7edf\u8ba1\u91cf\u786e\u5b9a\u7f6e\u4fe1\u6c34\u5e73\u5bf9\u5e94\u7684\u5206\u4f4d\u6570\uff0c\u6784\u9020\u5168\u5c40\u6216\u5c40\u90e8\uff08\u57fa\u4e8e\u7a7a\u95f4\u90bb\u57df\u6216\u5206\u4f4d\u56de\u5f52\uff09\u7f6e\u4fe1\u533a\u95f4\uff1b4) \u5bf9\u5c40\u90e8\u5f02\u65b9\u5dee\u91c7\u7528\u5c40\u90e8\u5206\u4f4d\u4f30\u8ba1\u5e76\u7ed3\u5408CP\u6821\u51c6\u4ee5\u4fdd\u6301\u8986\u76d6\u7387\u4fdd\u8bc1\u3002\u5b9e\u9a8c\u4e0a\u4e0e\u591a\u79cd\u542f\u53d1\u5f0fUQ\u65b9\u6cd5\u6bd4\u8f83\u5e76\u8bc4\u4f30\u8986\u76d6\u7387\u3001\u533a\u95f4\u5bbd\u5ea6\u548c\u5c40\u90e8\u9002\u5e94\u6027\u3002", "result": "\u5728\u591a\u4e2a\u5178\u578bPDE\uff08\u6708\u5f0f\uff09\u4e0a\u5b9e\u8bc1\u663e\u793a\uff1a1) CP\u6846\u67b6\u80fd\u5b9e\u73b0\u4e25\u683c\u7684\u6709\u9650\u6837\u672c\u8986\u76d6\u4fdd\u8bc1\uff08\u7ecf\u9a8c\u8986\u76d6\u7387\u63a5\u8fd1\u6807\u79f0\u7f6e\u4fe1\u6c34\u5e73\uff09\uff1b2) \u5c40\u90e8\u4fdd\u5f62\u5206\u4f4d\u4f30\u8ba1\u80fd\u6709\u6548\u5904\u7406\u7a7a\u95f4\u5f02\u65b9\u5dee\uff0c\u751f\u6210\u66f4\u7a84\u4e14\u5728\u4e0d\u540c\u7a7a\u95f4\u4f4d\u7f6e\u4e0a\u81ea\u9002\u5e94\u7684\u533a\u95f4\uff1b3) \u76f8\u8f83\u4e8e\u5e38\u7528\u542f\u53d1\u5f0fUQ\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5728\u8986\u76d6\u7387\u548c\u533a\u95f4\u6548\u7387\u4e4b\u95f4\u53d6\u5f97\u66f4\u597d\u5e73\u8861\u3002", "conclusion": "\u672c\u6587\u5c06\u5206\u5e03\u81ea\u7531\u7684\u7f6e\u4fe1\u9884\u6d4b\uff08conformal prediction, CP\uff09\u5f15\u5165\u5230\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\uff08PINNs\uff09\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u4e2d\uff0c\u901a\u8fc7\u5728\u6821\u51c6\u96c6\u4e0a\u6784\u5efanonconformity scores\u6821\u51c6\u9884\u6d4b\u533a\u95f4\uff0c\u4ece\u800c\u4e3aPINNs\u63d0\u4f9b\u6709\u9650\u6837\u672c\u8986\u76d6\u4fdd\u8bc1\u3002\u9488\u5bf9\u7a7a\u95f4\u5f02\u65b9\u5dee\u95ee\u9898\uff0c\u63d0\u51fa\u5c40\u90e8\u4fdd\u5f62\u5206\u4f4d\u4f30\u8ba1\uff08local conformal quantile estimation\uff09\uff0c\u5b9e\u73b0\u7a7a\u95f4\u81ea\u9002\u5e94\u7684\u4e0d\u786e\u5b9a\u6027\u5e26\u5e76\u4fdd\u6301\u7406\u8bba\u4fdd\u8bc1\u3002\u5b9e\u9a8c\u8986\u76d6\u963b\u5c3c\u8c10\u632f\u5b50\u3001Poisson\u3001Allen-Cahn\u548cHelmholtz\u65b9\u7a0b\uff0c\u7ed3\u679c\u663e\u793a\u8be5\u6846\u67b6\u5728\u6821\u51c6\u548c\u5c40\u90e8\u81ea\u9002\u5e94\u6027\u4e0a\u4f18\u4e8e\u542f\u53d1\u5f0f\u65b9\u6cd5\u3002"}}
{"id": "2509.13615", "categories": ["cs.AI", "cs.CL", "cs.HC"], "pdf": "https://arxiv.org/pdf/2509.13615", "abs": "https://arxiv.org/abs/2509.13615", "authors": ["Zongru Wu", "Rui Mao", "Zhiyuan Tian", "Pengzhou Cheng", "Tianjie Ju", "Zheng Wu", "Lingzhong Dong", "Haiyue Sheng", "Zhuosheng Zhang", "Gongshen Liu"], "title": "See, Think, Act: Teaching Multimodal Agents to Effectively Interact with GUI by Identifying Toggles", "comment": null, "summary": "The advent of multimodal agents facilitates effective interaction within\ngraphical user interface (GUI), especially in ubiquitous GUI control. However,\ntheir inability to reliably execute toggle control instructions remains a key\nbottleneck. To investigate this, we construct a state control benchmark with\nbinary toggle instructions from public datasets. Evaluations of existing agents\ndemonstrate their unreliability, particularly when the current toggle state\nalready matches the desired state. To address the challenge, we propose\nState-aware Reasoning (StaR), a training method that teaches agents to perceive\nthe current toggle state, analyze the desired state from the instruction, and\nact accordingly. Experiments on three multimodal agents demonstrate that StaR\ncan improve toggle instruction execution accuracy by over 30\\%. Further\nevaluations on three public benchmarks show that StaR also enhances general\ntask performance. Finally, evaluations on a dynamic environment highlight the\npotential of StaR for real-world applications. Code, benchmark, and\nStaR-enhanced agents are available at https://github.com/ZrW00/StaR.", "AI": {"tldr": "They identify a failure mode in multimodal GUI agents for binary toggle instructions, build a benchmark, and introduce StaR training to teach agents to perceive and reason about current and desired toggle states, yielding large accuracy gains and broader performance improvements.", "motivation": "Multimodal agents struggle with reliable execution of binary toggle (on/off) GUI commands, which is critical for ubiquitous GUI control; this failure, especially when no change is needed, motivates creating benchmarks and methods to teach state-aware behavior.", "method": "They construct a state control benchmark from public datasets, evaluate existing agents, and propose StaR \u2014 a training method that teaches agents to perceive current toggle state, infer desired state from instructions, and act accordingly. They test StaR on three multimodal agents and additional public benchmarks and a dynamic environment.", "result": "StaR improves toggle instruction execution accuracy by over 30% across three agents, enhances performance on three public benchmarks, and performs well in dynamic environments. Code and benchmarks are released.", "conclusion": "This paper concludes that current multimodal agents are unreliable at executing binary toggle GUI instructions, especially when the desired state matches the current state; their proposed State-aware Reasoning (StaR) significantly improves toggle accuracy and general task performance, and shows promise in dynamic environments."}}
{"id": "2509.14139", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2509.14139", "abs": "https://arxiv.org/abs/2509.14139", "authors": ["V\u00edctor Mayoral-Vilches"], "title": "Cybersecurity AI: Humanoid Robots as Attack Vectors", "comment": null, "summary": "We present a systematic security assessment of the Unitree G1 humanoid\nshowing it operates simultaneously as a covert surveillance node and can be\npurposed as an active cyber operations platform. Partial reverse engineering of\nUnitree's proprietary FMX encryption reveal a static Blowfish-ECB layer and a\npredictable LCG mask-enabled inspection of the system's otherwise sophisticated\nsecurity architecture, the most mature we have observed in commercial robotics.\nTwo empirical case studies expose the critical risk of this humanoid robot: (a)\nthe robot functions as a trojan horse, continuously exfiltrating multi-modal\nsensor and service-state telemetry to 43.175.228.18:17883 and\n43.175.229.18:17883 every 300 seconds without operator notice, creating\nviolations of GDPR Articles 6 and 13; (b) a resident Cybersecurity AI (CAI)\nagent can pivot from reconnaissance to offensive preparation against any\ntarget, such as the manufacturer's cloud control plane, demonstrating\nescalation from passive monitoring to active counter-operations. These findings\nargue for adaptive CAI-powered defenses as humanoids move into critical\ninfrastructure, contributing the empirical evidence needed to shape future\nsecurity standards for physical-cyber convergence systems.", "AI": {"tldr": "Unitree G1 has weak FMX encryption (static Blowfish-ECB + predictable LCG mask) enabling data exfiltration every 300s to external IPs and allowing onboard CAI to pivot to offensive operations; calls for adaptive defenses and standards.", "motivation": "Assess security risks of commercial humanoid robots as they integrate into critical infrastructure, to provide empirical evidence for security standards and motivate adaptive defenses.", "method": "Partial reverse engineering of FMX encryption layer, network traffic analysis showing periodic exfiltration to specific IPs/ports, empirical deployment of a resident CAI agent demonstrating escalation paths to cloud control plane.", "result": "This paper reveals critical vulnerabilities in Unitree G1 humanoid: covert continuous exfiltration of sensor and state telemetry to external IPs via FMX protocol weaknesses, and capability for an onboard Cybersecurity AI agent to switch from reconnaissance to offensive operations, posing risks to privacy (GDPR violations) and active cyber attacks. The paper contributes empirical evidence for security standards and suggests need for adaptive CAI-powered defenses.", "conclusion": "Unitree G1's security architecture, despite seeming mature, contains critical flaws enabling covert surveillance and offensive cyber operations; mitigations should include stronger crypto, firmware auditing, network restrictions, privacy-by-design, and deployment-specific CAI defenses."}}
{"id": "2509.13725", "categories": ["cs.LG", "cs.CY"], "pdf": "https://arxiv.org/pdf/2509.13725", "abs": "https://arxiv.org/abs/2509.13725", "authors": ["Md Sabbir Ahmed", "Noah French", "Mark Rucker", "Zhiyuan Wang", "Taylor Myers-Brower", "Kaitlyn Petz", "Mehdi Boukhechba", "Bethany A. Teachman", "Laura E. Barnes"], "title": "WatchAnxiety: A Transfer Learning Approach for State Anxiety Prediction from Smartwatch Data", "comment": null, "summary": "Social anxiety is a common mental health condition linked to significant\nchallenges in academic, social, and occupational functioning. A core feature is\nelevated momentary (state) anxiety in social situations, yet little prior work\nhas measured or predicted fluctuations in this anxiety throughout the day.\nCapturing these intra-day dynamics is critical for designing real-time,\npersonalized interventions such as Just-In-Time Adaptive Interventions\n(JITAIs). To address this gap, we conducted a study with socially anxious\ncollege students (N=91; 72 after exclusions) using our custom smartwatch-based\nsystem over an average of 9.03 days (SD = 2.95). Participants received seven\necological momentary assessments (EMAs) per day to report state anxiety. We\ndeveloped a base model on over 10,000 days of external heart rate data,\ntransferred its representations to our dataset, and fine-tuned it to generate\nprobabilistic predictions. These were combined with trait-level measures in a\nmeta-learner. Our pipeline achieved 60.4% balanced accuracy in state anxiety\ndetection in our dataset. To evaluate generalizability, we applied the training\napproach to a separate hold-out set from the TILES-18 dataset-the same dataset\nused for pretraining. On 10,095 once-daily EMAs, our method achieved 59.1%\nbalanced accuracy, outperforming prior work by at least 7%.", "AI": {"tldr": "\u901a\u8fc7\u5fc3\u7387\u8fc1\u79fb\u5b66\u4e60+\u5143\u5b66\u4e60\uff0c\u7814\u7a76\u5b9e\u73b0\u4e86\u53ef\u7a7f\u6234\u8bbe\u5907\u4e0b\u5bf9\u793e\u4ea4\u7126\u8651\u72b6\u6001\u7684\u65e5\u5185\u68c0\u6d4b\uff0c\u8868\u73b0\u4f18\u4e8e\u65e2\u5f80\u5de5\u4f5c\uff0c\u63a8\u52a8\u5b9e\u65f6\u4e2a\u6027\u5316\u5e72\u9884\u53d1\u5c55\u3002", "motivation": "\u793e\u4ea4\u7126\u8651\u7684\u72b6\u6001\u6027\u7126\u8651\u5728\u65e5\u5185\u6ce2\u52a8\u663e\u8457\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u5f88\u5c11\u6d4b\u91cf\u6216\u9884\u6d4b\u8fd9\u4e9b\u6ce2\u52a8\uff1b\u638c\u63e1\u65e5\u5185\u52a8\u6001\u5bf9\u5b9e\u65f6\u4e2a\u6027\u5316\u5e72\u9884\uff08\u5982JITAI\uff09\u81f3\u5173\u91cd\u8981\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u667a\u80fd\u624b\u8868\u7684\u9ad8\u9891EMA\u6536\u96c6\u6570\u636e\uff1b\u5728\u5916\u90e8\u5927\u89c4\u6a21\u5fc3\u7387\u6570\u636e\uff08\u7ea610,000\u5929\uff09\u4e0a\u8bad\u7ec3\u57fa\u7840\u6a21\u578b\u5e76\u8fc1\u79fb\u5230\u5c0f\u6837\u672c\u793e\u4ea4\u7126\u8651\u6570\u636e\u96c6\uff0c\u8fdb\u884c\u5fae\u8c03\u751f\u6210\u6982\u7387\u9884\u6d4b\uff1b\u5c06\u8be5\u9884\u6d4b\u4e0e\u7279\u8d28\u91cf\u8868\u901a\u8fc7\u5143\u5b66\u4e60\u5668\u878d\u5408\u3002", "result": "\u572872\u540d\u793e\u4ea4\u7126\u8651\u5927\u5b66\u751f\u7684\u9ad8\u9891EMA\u6570\u636e\u4e0a\u5b9e\u73b060.4%\u5e73\u8861\u51c6\u786e\u7387\uff1b\u5728TILES-18\u6301\u51fa\u96c6\u4e0a\u7684\u4e00\u6b21\u6027\u65e5EMA\uff0810,095\u6761\uff09\u4e0a\u8fbe\u523059.1%\u5e73\u8861\u51c6\u786e\u7387\uff0c\u6bd4\u5148\u524d\u65b9\u6cd5\u9ad8\u81f3\u5c117%\u3002", "conclusion": "\u8be5\u7814\u7a76\u8868\u660e\u53ef\u7a7f\u6234\u8bbe\u5907\u5fc3\u7387\u6570\u636e\u7ed3\u5408\u8fc1\u79fb\u5b66\u4e60\u4e0e\u5143\u5b66\u4e60\u53ef\u5728\u65e5\u5185\u68c0\u6d4b\u793e\u4ea4\u7126\u8651\u72b6\u6001\uff0c\u4e14\u5728\u4e24\u4e2a\u6570\u636e\u96c6\u4e0a\u5747\u4f18\u4e8e\u65e2\u6709\u65b9\u6cd5\u3002"}}
{"id": "2509.13704", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2509.13704", "abs": "https://arxiv.org/abs/2509.13704", "authors": ["Liangtao Lin", "Zhaomeng Zhu", "Tianwei Zhang", "Yonggang Wen"], "title": "InfraMind: A Novel Exploration-based GUI Agentic Framework for Mission-critical Industrial Management", "comment": null, "summary": "Mission-critical industrial infrastructure, such as data centers,\nincreasingly depends on complex management software. Its operations, however,\npose significant challenges due to the escalating system complexity,\nmulti-vendor integration, and a shortage of expert operators. While Robotic\nProcess Automation (RPA) offers partial automation through handcrafted scripts,\nit suffers from limited flexibility and high maintenance costs. Recent advances\nin Large Language Model (LLM)-based graphical user interface (GUI) agents have\nenabled more flexible automation, yet these general-purpose agents face five\ncritical challenges when applied to industrial management, including unfamiliar\nelement understanding, precision and efficiency, state localization, deployment\nconstraints, and safety requirements. To address these issues, we propose\nInfraMind, a novel exploration-based GUI agentic framework specifically\ntailored for industrial management systems. InfraMind integrates five\ninnovative modules to systematically resolve different challenges in industrial\nmanagement: (1) systematic search-based exploration with virtual machine\nsnapshots for autonomous understanding of complex GUIs; (2) memory-driven\nplanning to ensure high-precision and efficient task execution; (3) advanced\nstate identification for robust localization in hierarchical interfaces; (4)\nstructured knowledge distillation for efficient deployment with lightweight\nmodels; and (5) comprehensive, multi-layered safety mechanisms to safeguard\nsensitive operations. Extensive experiments on both open-source and commercial\nDCIM platforms demonstrate that our approach consistently outperforms existing\nframeworks in terms of task success rate and operational efficiency, providing\na rigorous and scalable solution for industrial management automation.", "AI": {"tldr": "\u63d0\u51faInfraMind\uff0c\u4e00\u79cd\u9762\u5411\u5de5\u4e1a\u7ba1\u7406\u7cfb\u7edf\u7684\u63a2\u7d22\u9a71\u52a8\u578bGUI\u4ee3\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u7cfb\u7edf\u641c\u7d22\u3001\u8bb0\u5fc6\u9a71\u52a8\u89c4\u5212\u3001\u72b6\u6001\u8bc6\u522b\u3001\u77e5\u8bc6\u84b8\u998f\u4e0e\u591a\u5c42\u5b89\u5168\u673a\u5236\u89e3\u51b3\u5de5\u4e1a\u573a\u666f\u4e0b\u7684\u4e94\u5927\u6311\u6218\uff0c\u5728\u5f00\u6e90\u548c\u5546\u7528DCIM\u5e73\u53f0\u4e0a\u663e\u8457\u63d0\u9ad8\u4efb\u52a1\u6210\u529f\u7387\u4e0e\u6548\u7387\u3002", "motivation": "\u4f20\u7edfRPA\u811a\u672c\u7075\u6d3b\u6027\u5dee\u3001\u7ef4\u62a4\u6210\u672c\u9ad8\uff1b\u901a\u7528LLM GUI\u4ee3\u7406\u5728\u5de5\u4e1a\u7ba1\u7406\u573a\u666f\u9762\u4e34\u5143\u7d20\u8bc6\u522b\u3001\u751f\u6548\u7cbe\u5ea6\u3001\u72b6\u6001\u5b9a\u4f4d\u3001\u90e8\u7f72\u9650\u5236\u4e0e\u5b89\u5168\u7b49\u4e94\u5927\u6311\u6218\uff0c\u9700\u8bbe\u8ba1\u5b9a\u5236\u5316\u65b9\u6848\u3002", "method": "\u6846\u67b6\u7531\u4e94\u4e2a\u6a21\u5757\u7ec4\u6210\uff1a\u641c\u7d22\u578b\u63a2\u7d22\uff08\u57fa\u4e8eVM\u5feb\u7167\uff09\u7528\u4e8e\u81ea\u52a8\u7406\u89e3GUI\uff1b\u8bb0\u5fc6\u9a71\u52a8\u89c4\u5212\u63d0\u9ad8\u7cbe\u5ea6\u548c\u6548\u7387\uff1b\u9ad8\u7ea7\u72b6\u6001\u8bc6\u522b\u7528\u4e8e\u5c42\u7ea7\u754c\u9762\u5b9a\u4f4d\uff1b\u7ed3\u6784\u5316\u77e5\u8bc6\u84b8\u998f\u5c06\u6a21\u578b\u538b\u7f29\u4fbf\u4e8e\u90e8\u7f72\uff1b\u591a\u5c42\u5b89\u5168\u673a\u5236\u4fdd\u62a4\u654f\u611f\u64cd\u4f5c\u3002", "result": "\u5728\u591a\u4e2a\u5f00\u6e90\u4e0e\u5546\u7528\u6570\u636e\u4e2d\u5fc3\u57fa\u7840\u8bbe\u65bd\u7ba1\u7406\uff08DCIM\uff09\u5e73\u53f0\u4e0a\uff0cInfraMind\u5728\u4efb\u52a1\u6210\u529f\u7387\u4e0e\u64cd\u4f5c\u6548\u7387\u65b9\u9762\u5747\u4f18\u4e8e\u73b0\u6709\u6846\u67b6\uff0c\u5c55\u793a\u4e86\u826f\u597d\u7684\u53ef\u6269\u5c55\u6027\u4e0e\u90e8\u7f72\u53ef\u884c\u6027\u3002", "conclusion": "InfraMind\u5728\u590d\u6742\u5de5\u4e1a\u7ba1\u7406GUI\u4e0a\u6bd4\u73b0\u6709\u901a\u7528GUI\u4ee3\u7406\u53d6\u5f97\u66f4\u9ad8\u7684\u4efb\u52a1\u6210\u529f\u7387\u548c\u8fd0\u884c\u6548\u7387\uff0c\u4e14\u652f\u6301\u8f7b\u91cf\u90e8\u7f72\u4e0e\u591a\u5c42\u6b21\u5b89\u5168\u4fdd\u969c\uff0c\u9002\u5408\u5927\u89c4\u6a21\u3001\u53d7\u9650\u73af\u5883\u7684\u5de5\u4e1a\u81ea\u52a8\u5316\u5e94\u7528\u3002"}}
{"id": "2509.13735", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.13735", "abs": "https://arxiv.org/abs/2509.13735", "authors": ["Junzhi She", "Xunkai Li", "Rong-Hua Li", "Guoren Wang"], "title": "State Space Models over Directed Graphs", "comment": "currently undergoing review by IEEE Transactions on Big Data", "summary": "Directed graphs are ubiquitous across numerous domains, where the\ndirectionality of edges encodes critical causal dependencies. However, existing\nGNNs and graph Transformers tailored for directed graphs face two major\nchallenges: (1) effectively capturing long-range causal dependencies derived\nfrom directed edges; (2) balancing accuracy and training efficiency when\nprocessing large-scale graph datasets. In recent years, state space models\n(SSMs) have achieved substantial progress in causal sequence tasks, and their\nvariants designed for graphs have demonstrated state-of-the-art accuracy while\nmaintaining high efficiency across various graph learning benchmarks. However,\nexisting graph state space models are exclusively designed for undirected\ngraphs, which limits their performance in directed graph learning. To this end,\nwe propose an innovative approach DirEgo2Token which sequentializes directed\ngraphs via k-hop ego graphs. This marks the first systematic extension of state\nspace models to the field of directed graph learning. Building upon this, we\ndevelop DirGraphSSM, a novel directed graph neural network architecture that\nimplements state space models on directed graphs via the message-passing\nmechanism. Experimental results demonstrate that DirGraphSSM achieves\nstate-of-the-art performance on three representative directed graph learning\ntasks while attaining competitive performance on two additional tasks with\n1.5$\\times $ to 2$\\times $ training speed improvements compared to existing\nstate-of-the-art models.", "AI": {"tldr": "\u63d0\u51faDirEgo2Token\u5c06\u6709\u5411\u56fe\u8f6c\u4e3ak\u8df3ego\u5b50\u56fe\u5e8f\u5217\uff0c\u5e76\u57fa\u4e8e\u6b64\u8bbe\u8ba1DirGraphSSM\uff0c\u5728\u6709\u5411\u56fe\u4e0a\u9996\u6b21\u7cfb\u7edf\u6027\u5730\u5e94\u7528SSM\uff0c\u517c\u987e\u7cbe\u5ea6\u4e0e\u8bad\u7ec3\u6548\u7387\uff0c\u53d6\u5f97\u4f18\u5f02\u7ed3\u679c\u3002", "motivation": "\u73b0\u6709\u56feS S M\u53ea\u9762\u5411\u65e0\u5411\u56fe\uff0c\u65e0\u6cd5\u5145\u5206\u5229\u7528\u6709\u5411\u8fb9\u7684\u56e0\u679c\u4fe1\u606f\uff1b\u53e6\u6709\u5411\u56fe\u4efb\u52a1\u9700\u517c\u987e\u957f\u7a0b\u4f9d\u8d56\u5efa\u6a21\u4e0e\u5927\u56fe\u8bad\u7ec3\u6548\u7387\uff0c\u6545\u63d0\u51fa\u5c06SSM\u6269\u5c55\u81f3\u6709\u5411\u56fe\u7684\u9700\u6c42\u3002", "method": "\u6838\u5fc3\u65b9\u6cd5\u662fDirEgo2Token\uff1a\u5bf9\u6bcf\u4e2a\u8282\u70b9\u6784\u5efak\u8df3\u6709\u5411ego\u5b50\u56fe\u5e76\u5e8f\u5217\u5316\u4e3atoken\u5e8f\u5217\uff0c\u7136\u540e\u5728\u5e8f\u5217\u4e0a\u5e94\u7528\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\uff08SSM\uff09\u8fdb\u884c\u957f\u7a0b\u4fe1\u606f\u5efa\u6a21\uff1b\u6574\u4f53\u67b6\u6784DirGraphSSM\u5728\u6d88\u606f\u4f20\u9012\u6846\u67b6\u4e0b\u5b9e\u73b0SSM\u6a21\u5757\u4ee5\u5904\u7406\u6709\u5411\u8fb9\u65b9\u5411\u6027\uff0c\u540c\u65f6\u4f18\u5316\u8bad\u7ec3\u6548\u7387\u3002", "result": "DirGraphSSM\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u72b6\u6001\u7a7a\u95f4\u6a21\u578b(SSM)\u6269\u5c55\u81f3\u6709\u5411\u56fe\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u6709\u5411\u56fe\u5e8f\u5217\u5316\u4e3ak\u8df3ego\u5b50\u56fe\uff08DirEgo2Token\uff09\u5e76\u5728\u6b64\u57fa\u7840\u4e0a\u6784\u5efa\u57fa\u4e8e\u6d88\u606f\u4f20\u9012\u7684\u6709\u5411\u56fe\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\uff0c\u5b9e\u73b0\u4e86\u5bf9\u957f\u7a0b\u56e0\u679c\u4f9d\u8d56\u7684\u9ad8\u6548\u5efa\u6a21\u3002\u5b9e\u9a8c\u663e\u793a\u5728\u4e09\u4e2a\u6709\u4ee3\u8868\u6027\u7684\u6709\u5411\u56fe\u4efb\u52a1\u4e0a\u8fbe\u5230\u4e86SOTA\u6027\u80fd\uff0c\u5e76\u5728\u53e6\u5916\u4e24\u4e2a\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u7ade\u4e89\u6027\u7ed3\u679c\uff0c\u8bad\u7ec3\u901f\u5ea6\u6bd4\u5148\u524d\u6700\u597d\u6a21\u578b\u63d0\u53471.5\u20132\u00d7\u3002", "conclusion": "\u672c\u6587\u9996\u6b21\u5c06SSM\u7cfb\u7edf\u6027\u5e94\u7528\u4e8e\u6709\u5411\u56fe\u5b66\u4e60\uff0c\u901a\u8fc7\u5e8f\u5217\u5316\u7b56\u7565\u548c\u57fa\u4e8e\u6d88\u606f\u4f20\u9012\u7684\u5b9e\u73b0\uff0c\u6709\u6548\u6355\u6349\u957f\u7a0b\u56e0\u679c\u5173\u7cfb\u5e76\u63d0\u5347\u8bad\u7ec3\u6548\u7387\uff0c\u4e3a\u6709\u5411\u56fe\u795e\u7ecf\u7f51\u7edc\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u5411\u3002"}}
{"id": "2509.13761", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.13761", "abs": "https://arxiv.org/abs/2509.13761", "authors": ["Qikai Chang", "Zhenrong Zhang", "Pengfei Hu", "Jiefeng Ma", "Yicheng Pan", "Jianshu Zhang", "Jun Du", "Quan Liu", "Jianqing Gao"], "title": "THOR: Tool-Integrated Hierarchical Optimization via RL for Mathematical Reasoning", "comment": "22 pages, 13 figures", "summary": "Large Language Models (LLMs) have made remarkable progress in mathematical\nreasoning, but still continue to struggle with high-precision tasks like\nnumerical computation and formal symbolic manipulation. Integrating external\ntools has emerged as a promising approach to bridge this gap. Despite recent\nadvances, existing methods struggle with three key challenges: constructing\ntool-integrated reasoning data, performing fine-grained optimization, and\nenhancing inference. To overcome these limitations, we propose THOR\n(Tool-Integrated Hierarchical Optimization via RL). First, we introduce TIRGen,\na multi-agent actor-critic-based pipeline for constructing high-quality\ndatasets of tool-integrated reasoning paths, aligning with the policy and\ngeneralizing well across diverse models. Second, to perform fine-grained\nhierarchical optimization, we introduce an RL strategy that jointly optimizes\nfor both trajectory-level problem solving and step-level code generation. This\nis motivated by our key insight that the success of an intermediate tool call\nis a strong predictor of the final answer's correctness. Finally, THOR\nincorporates a self-correction mechanism that leverages immediate tool feedback\nto dynamically revise erroneous reasoning paths during inference. Our approach\ndemonstrates strong generalization across diverse models, performing\neffectively in both reasoning and non-reasoning models. It further achieves\nstate-of-the-art performance for models of a similar scale on multiple\nmathematical benchmarks, while also delivering consistent improvements on code\nbenchmarks. Our code will be publicly available at\nhttps://github.com/JingMog/THOR.", "AI": {"tldr": "THOR\u901a\u8fc7TIRGen\u6570\u636e\u6784\u5efa\u3001\u5c42\u7ea7RL\u4f18\u5316\u548c\u63a8\u7406\u81ea\u7ea0\uff0c\u6709\u6548\u63d0\u5347LLM\u5de5\u5177\u8c03\u7528\u7684\u6570\u5b66\u4e0e\u7f16\u7801\u80fd\u529b\uff0c\u8fbe\u6210SOTA\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u6784\u5efa\u5de5\u5177\u96c6\u6210\u63a8\u7406\u6570\u636e\u3001\u8fdb\u884c\u7ec6\u7c92\u5ea6\u4f18\u5316\u53ca\u63a8\u7406\u65f6\u81ea\u7ea0\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u5bfc\u81f4\u9ad8\u7cbe\u5ea6\u6570\u5b66\u4e0e\u7b26\u53f7\u4efb\u52a1\u6027\u80fd\u53d7\u9650\u3002", "method": "\u63d0\u51faTIRGen\u591a\u4e3b\u4f53actor-critic\u6d41\u6c34\u7ebf\u751f\u6210\u9ad8\u8d28\u91cf\u5de5\u5177\u96c6\u6210\u63a8\u7406\u8def\u5f84\u6570\u636e\uff1b\u8bbe\u8ba1\u5c42\u7ea7\u5316\u5f3a\u5316\u5b66\u4e60\u540c\u65f6\u4f18\u5316\u8f68\u8ff9\u7ea7\u89e3\u9898\u80fd\u529b\u4e0e\u6b65\u9aa4\u7ea7\u4ee3\u7801\u751f\u6210\uff1b\u5728\u63a8\u7406\u9636\u6bb5\u5f15\u5165\u57fa\u4e8e\u5de5\u5177\u5373\u65f6\u53cd\u9988\u7684\u81ea\u6211\u4fee\u6b63\u673a\u5236\u3002", "result": "\u5728\u591a\u9879\u6570\u5b66\u53ca\u4ee3\u7801\u57fa\u51c6\u4e0a\u5bf9\u540c\u91cf\u7ea7\u6a21\u578b\u5b9e\u73b0\u4e86\u9886\u5148\u6027\u80fd\uff0c\u4e14\u5bf9\u4e0d\u540c\u7c7b\u578b\u6a21\u578b\u5747\u5c55\u73b0\u51fa\u826f\u597d\u6cdb\u5316\u4e0e\u4e00\u81f4\u63d0\u5347\u3002", "conclusion": "THOR\u901a\u8fc7\u591a\u4e3b\u4f53\u6570\u636e\u751f\u6210\u3001\u5c42\u7ea7\u5316RL\u4f18\u5316\u4e0e\u81ea\u7ea0\u673a\u5236\uff0c\u663e\u8457\u63d0\u5347\u4e86LLM\u5728\u5de5\u5177\u8c03\u7528\u573a\u666f\u4e0b\u7684\u6570\u5b66\u4e0e\u4ee3\u7801\u4efb\u52a1\u8868\u73b0\uff0c\u4e14\u5728\u540c\u91cf\u7ea7\u6a21\u578b\u4e0a\u8fbe\u5230\u4e86SOTA\u3002"}}
{"id": "2509.13773", "categories": ["cs.AI", "cs.IR", "I.2.7; I.2.10"], "pdf": "https://arxiv.org/pdf/2509.13773", "abs": "https://arxiv.org/abs/2509.13773", "authors": ["Zhipeng Bian", "Jieming Zhu", "Xuyang Xie", "Quanyu Dai", "Zhou Zhao", "Zhenhua Dong"], "title": "MIRA: Empowering One-Touch AI Services on Smartphones with MLLM-based Instruction Recommendation", "comment": "Published in Proceedings of the 63rd Annual Meeting of the\n  Association for Computational Linguistics (Volume 6: Industry Track), ACL\n  2025. Official version: https://doi.org/10.18653/v1/2025.acl-industry.103", "summary": "The rapid advancement of generative AI technologies is driving the\nintegration of diverse AI-powered services into smartphones, transforming how\nusers interact with their devices. To simplify access to predefined AI\nservices, this paper introduces MIRA, a pioneering framework for task\ninstruction recommendation that enables intuitive one-touch AI tasking on\nsmartphones. With MIRA, users can long-press on images or text objects to\nreceive contextually relevant instruction recommendations for executing AI\ntasks. Our work introduces three key innovations: 1) A multimodal large\nlanguage model (MLLM)-based recommendation pipeline with structured reasoning\nto extract key entities, infer user intent, and generate precise instructions;\n2) A template-augmented reasoning mechanism that integrates high-level\nreasoning templates, enhancing task inference accuracy; 3) A prefix-tree-based\nconstrained decoding strategy that restricts outputs to predefined instruction\ncandidates, ensuring coherent and intent-aligned suggestions. Through\nevaluation using a real-world annotated datasets and a user study, MIRA has\ndemonstrated substantial improvements in the accuracy of instruction\nrecommendation. The encouraging results highlight MIRA's potential to\nrevolutionize the way users engage with AI services on their smartphones,\noffering a more seamless and efficient experience.", "AI": {"tldr": "MIRA\u901a\u8fc7MLLM+\u6a21\u677f\u63a8\u7406+\u524d\u7f00\u6811\u7ea6\u675f\u89e3\u7801\uff0c\u5b9e\u73b0\u4e86\u4e00\u952e\u5f0f\u624b\u673aAI\u4efb\u52a1\u6307\u4ee4\u63a8\u8350\uff0c\u663e\u8457\u63d0\u9ad8\u63a8\u8350\u51c6\u786e\u6027\u5e76\u6539\u5584\u7528\u6237\u4f53\u9a8c\u3002", "motivation": "\u968f\u7740\u624b\u673a\u7aef\u751f\u6210\u5f0fAI\u670d\u52a1\u589e\u591a\uff0c\u7528\u6237\u9700\u8981\u66f4\u7b80\u5355\u76f4\u89c2\u7684\u65b9\u5f0f\u89e6\u53d1\u9884\u5b9a\u4e49AI\u4efb\u52a1\uff0c\u51cf\u5c11\u5b66\u4e60\u6210\u672c\u5e76\u63d0\u9ad8\u64cd\u4f5c\u6548\u7387\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u8350\u6d41\u6c34\u7ebf\uff0c\u7ed3\u5408\u7ed3\u6784\u5316\u63a8\u7406\u63d0\u53d6\u5b9e\u4f53\u5e76\u63a8\u65ad\u610f\u56fe\uff1b\u5f15\u5165\u6a21\u677f\u589e\u5f3a\u63a8\u7406\u4ee5\u63d0\u5347\u4efb\u52a1\u63a8\u65ad\u51c6\u786e\u7387\uff1b\u91c7\u7528\u524d\u7f00\u6811\u7ea6\u675f\u89e3\u7801\u9650\u5236\u8f93\u51fa\u5230\u9884\u5b9a\u4e49\u6307\u4ee4\u96c6\u5408\uff0c\u4fdd\u8bc1\u4e00\u81f4\u6027\u3002", "result": "\u5728\u771f\u5b9e\u6807\u6ce8\u6570\u636e\u96c6\u548c\u7528\u6237\u7814\u7a76\u4e2d\uff0cMIRA\u5728\u6307\u4ee4\u63a8\u8350\u51c6\u786e\u7387\u4e0a\u6709\u663e\u8457\u63d0\u5347\uff0c\u7528\u6237\u53cd\u9988\u8868\u660e\u4f53\u9a8c\u66f4\u6d41\u7545\u9ad8\u6548\u3002", "conclusion": "MIRA\u663e\u8457\u63d0\u5347\u4e86\u57fa\u4e8e\u667a\u80fd\u624b\u673a\u7684AI\u4efb\u52a1\u6307\u4ee4\u63a8\u8350\u51c6\u786e\u6027\uff0c\u80fd\u5c06\u957f\u6309\u56fe\u50cf\u6216\u6587\u672c\u7684\u8f93\u5165\u6620\u5c04\u4e3a\u4e0a\u4e0b\u6587\u76f8\u5173\u7684\u9884\u5b9a\u4e49AI\u4efb\u52a1\u6307\u4ee4\uff0c\u6539\u5584\u7528\u6237\u4ea4\u4e92\u4f53\u9a8c\u3002"}}
{"id": "2509.13753", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.13753", "abs": "https://arxiv.org/abs/2509.13753", "authors": ["Hyotaek Jeon", "Hyunwook Lee", "Juwon Kim", "Sungahn Ko"], "title": "ST-LINK: Spatially-Aware Large Language Models for Spatio-Temporal Forecasting", "comment": "11 pages, 4 figures, Accepted to CIKM 2025. Code:\n  https://github.com/HyoTaek98/ST_LINK", "summary": "Traffic forecasting represents a crucial problem within intelligent\ntransportation systems. In recent research, Large Language Models (LLMs) have\nemerged as a promising method, but their intrinsic design, tailored primarily\nfor sequential token processing, introduces notable challenges in effectively\ncapturing spatial dependencies. Specifically, the inherent limitations of LLMs\nin modeling spatial relationships and their architectural incompatibility with\ngraph-structured spatial data remain largely unaddressed. To overcome these\nlimitations, we introduce ST-LINK, a novel framework that enhances the\ncapability of Large Language Models to capture spatio-temporal dependencies.\nIts key components are Spatially-Enhanced Attention (SE-Attention) and the\nMemory Retrieval Feed-Forward Network (MRFFN). SE-Attention extends rotary\nposition embeddings to integrate spatial correlations as direct rotational\ntransformations within the attention mechanism. This approach maximizes spatial\nlearning while preserving the LLM's inherent sequential processing structure.\nMeanwhile, MRFFN dynamically retrieves and utilizes key historical patterns to\ncapture complex temporal dependencies and improve the stability of long-term\nforecasting. Comprehensive experiments on benchmark datasets demonstrate that\nST-LINK surpasses conventional deep learning and LLM approaches, and\neffectively captures both regular traffic patterns and abrupt changes.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faST-LINK\u6846\u67b6\uff0c\u901a\u8fc7\u7a7a\u95f4\u589e\u5f3a\u6ce8\u610f\u529b\uff08SE-Attention\uff09\u548c\u8bb0\u5fc6\u68c0\u7d22\u524d\u9988\u7f51\u7edc\uff08MRFFN\uff09\u589e\u5f3a\u5927\u6a21\u578b\u5bf9\u65f6\u7a7a\u4f9d\u8d56\u7684\u5efa\u6a21\u80fd\u529b\u3002SE-Attention\u5c06\u7a7a\u95f4\u76f8\u5173\u6027\u878d\u5165\u65cb\u8f6c\u4f4d\u7f6e\u7f16\u7801\uff0cMRFFN\u52a8\u6001\u68c0\u7d22\u5386\u53f2\u6a21\u5f0f\u4ee5\u6539\u5584\u957f\u671f\u9884\u6d4b\u7a33\u5b9a\u6027\u3002\u5b9e\u9a8c\u8868\u660e\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u4f20\u7edf\u6df1\u5ea6\u5b66\u4e60\u548cLLM\u65b9\u6cd5\uff0c\u80fd\u540c\u65f6\u6355\u6349\u5e38\u89c4\u6a21\u5f0f\u4e0e\u7a81\u53d1\u53d8\u5316\u3002", "motivation": "\u73b0\u6709LLM\u4e3b\u8981\u9762\u5411\u5e8f\u5217\u4ee4\u724c\u5904\u7406\uff0c\u96be\u4ee5\u6709\u6548\u5efa\u6a21\u56fe\u7ed3\u6784\u7684\u7a7a\u95f4\u5173\u7cfb\uff0c\u5bfc\u81f4\u5728\u4ea4\u901a\u9884\u6d4b\u7b49\u65f6\u7a7a\u4efb\u52a1\u4e2d\u8868\u73b0\u53d7\u9650\u3002\u9700\u8981\u4e00\u79cd\u5728\u4fdd\u7559LLM\u4f18\u52bf\u7684\u540c\u65f6\u589e\u5f3a\u7a7a\u95f4\u4f9d\u8d56\u5efa\u6a21\u80fd\u529b\u7684\u65b9\u6cd5\u3002", "method": "\u6846\u67b6\u5305\u542b\u4e24\u5927\u6a21\u5757\uff1a1) SE-Attention\uff1a\u5c06\u7a7a\u95f4\u5173\u7cfb\u4ee5\u65cb\u8f6c\u53d8\u6362\u5f62\u5f0f\u6269\u5c55\u5230\u65cb\u8f6c\u4f4d\u7f6e\u7f16\u7801\u4e2d\uff0c\u4f7f\u6ce8\u610f\u529b\u673a\u5236\u76f4\u63a5\u7f16\u7801\u7a7a\u95f4\u76f8\u5173\u6027\uff0c\u540c\u65f6\u4fdd\u7559\u5e8f\u5217\u5904\u7406\u7ed3\u6784\uff1b2) MRFFN\uff1a\u5728\u524d\u9988\u7f51\u7edc\u4e2d\u5f15\u5165\u8bb0\u5fc6\u68c0\u7d22\u673a\u5236\uff0c\u52a8\u6001\u68c0\u7d22\u5173\u952e\u5386\u53f2\u6a21\u5f0f\u4ee5\u5efa\u6a21\u590d\u6742\u65f6\u95f4\u4f9d\u8d56\u5e76\u63d0\u9ad8\u957f\u671f\u9884\u6d4b\u7a33\u5b9a\u6027\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u4ea4\u901a\u6570\u636e\u96c6\u4e0a\u7684\u5168\u9762\u5b9e\u9a8c\u8868\u660e\uff0cST-LINK\u5728\u77ed\u671f\u4e0e\u957f\u671f\u9884\u6d4b\u5747\u4f18\u4e8e\u4f20\u7edf\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u548c\u76f4\u63a5\u5e94\u7528LLM\u7684\u65b9\u6cd5\uff0c\u5e76\u80fd\u591f\u66f4\u597d\u5730\u6355\u6349\u5e38\u89c4\u5468\u671f\u6027\u53d8\u5316\u4e0e\u7a81\u53d1\u4e8b\u4ef6\u5f15\u8d77\u7684\u6d41\u91cf\u53d8\u5316\u3002", "conclusion": "ST-LINK\u6709\u6548\u5f25\u8865\u4e86LLM\u5728\u7a7a\u95f4\u5efa\u6a21\u4e0a\u7684\u4e0d\u8db3\uff0c\u901a\u8fc7SE-Attention\u548cMRFFN\u7ed3\u5408\uff0c\u5b9e\u73b0\u4e86\u66f4\u51c6\u786e\u3001\u66f4\u7a33\u5065\u7684\u4ea4\u901a\u65f6\u7a7a\u9884\u6d4b\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u5e76\u80fd\u5e94\u5bf9\u7a81\u53d1\u6d41\u91cf\u53d8\u5316\u3002"}}
{"id": "2509.13880", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.13880", "abs": "https://arxiv.org/abs/2509.13880", "authors": ["Mingwei Zhang", "Zhenhao Gu", "Liangda Fang", "Cunjing Ge", "Ziliang Chen", "Zhao-Rong Lai", "Quanlong Guan"], "title": "An Exhaustive DPLL Approach to Model Counting over Integer Linear Constraints with Simplification Techniques", "comment": null, "summary": "Linear constraints are one of the most fundamental constraints in fields such\nas computer science, operations research and optimization. Many applications\nreduce to the task of model counting over integer linear constraints (MCILC).\nIn this paper, we design an exact approach to MCILC based on an exhaustive DPLL\narchitecture. To improve the efficiency, we integrate several effective\nsimplification techniques from mixed integer programming into the architecture.\nWe compare our approach to state-of-the-art MCILC counters and propositional\nmodel counters on 2840 random and 4131 application benchmarks. Experimental\nresults show that our approach significantly outperforms all exact methods in\nrandom benchmarks solving 1718 instances while the state-of-the-art approach\nonly computes 1470 instances. In addition, our approach is the only approach to\nsolve all 4131 application instances.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u5c06\u6df7\u5408\u6574\u6570\u89c4\u5212\u7b80\u5316\u6280\u672f\u878d\u5408\u5165\u7a77\u5c3dDPLL\u6846\u67b6\u7684\u7cbe\u786eMCILC\u65b9\u6cd5\uff0c\u5728\u5927\u91cf\u968f\u673a\u4e0e\u5e94\u7528\u57fa\u51c6\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u7cbe\u786e\u8ba1\u6570\u5668\u5e76\u5b9e\u73b0\u5168\u8986\u76d6\u5e94\u7528\u57fa\u51c6\u3002", "motivation": "\u6574\u6570\u7ebf\u6027\u7ea6\u675f\u5728\u8ba1\u7b97\u673a\u79d1\u5b66\u3001\u8fd0\u7b79\u5b66\u548c\u4f18\u5316\u7b49\u9886\u57df\u6781\u4e3a\u5e38\u89c1\uff0c\u8bb8\u591a\u5b9e\u9645\u95ee\u9898\u53ef\u5f52\u7ea6\u4e3a\u6574\u6570\u7ebf\u6027\u7ea6\u675f\u7684\u6a21\u578b\u8ba1\u6570\u95ee\u9898\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5728\u89c4\u6a21\u548c\u6548\u7387\u4e0a\u5b58\u5728\u4e0d\u8db3\uff0c\u56e0\u6b64\u9700\u8981\u8bbe\u8ba1\u66f4\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684\u7cbe\u786e\u8ba1\u6570\u65b9\u6cd5\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u57fa\u4e8eDPLL\u7684\u7a77\u5c3d\u641c\u7d22\u6846\u67b6\u7528\u4e8e\u6574\u6570\u7ebf\u6027\u7ea6\u675f\u7684\u6a21\u578b\u8ba1\u6570\uff1b\u5728\u8be5\u6846\u67b6\u4e2d\u96c6\u6210\u4e86\u82e5\u5e72\u6765\u81ea\u6df7\u5408\u6574\u6570\u89c4\u5212\u7684\u6709\u6548\u7b80\u5316\u6280\u672f\uff08\u5982\u7ea6\u675f\u4f20\u64ad\u3001\u53d8\u91cf\u754c\u5b9a\u3001\u5272\u5e73\u9762\u6216\u9884\u5904\u7406\u6b65\u9aa4\uff09\u4ee5\u526a\u679d\u548c\u7b80\u5316\u95ee\u9898\uff1b\u901a\u8fc7\u4e0e\u73b0\u6709MCILC\u8ba1\u6570\u5668\u548c\u547d\u9898\u6a21\u578b\u8ba1\u6570\u5668\u5728\u5927\u91cf\u57fa\u51c6\u4e0a\u8fdb\u884c\u6bd4\u8f83\u8bc4\u4f30\u3002", "result": "\u57282840\u4e2a\u968f\u673a\u57fa\u51c6\u4e2d\uff0c\u8be5\u65b9\u6cd5\u89e3\u51b3\u4e861718\u4e2a\u5b9e\u4f8b\uff0c\u663e\u8457\u4f18\u4e8e\u5f53\u524d\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u76841470\u4e2a\uff1b\u57284131\u4e2a\u5e94\u7528\u57fa\u51c6\u4e2d\uff0c\u8be5\u65b9\u6cd5\u662f\u552f\u4e00\u80fd\u591f\u89e3\u51b3\u6240\u6709\u5b9e\u4f8b\u7684\u65b9\u6cd5\uff0c\u663e\u793a\u51fa\u66f4\u5f3a\u7684\u9c81\u68d2\u6027\u548c\u5b9e\u7528\u6027\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u57fa\u4e8e\u7a77\u5c3dDPLL\u67b6\u6784\u7684\u7cbe\u786e\u6574\u6570\u7ebf\u6027\u7ea6\u675f\u8ba1\u6570\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f15\u5165\u6df7\u5408\u6574\u6570\u89c4\u5212\u4e2d\u7684\u7b80\u5316\u6280\u672f\u63d0\u9ad8\u6548\u7387\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5728\u968f\u673a\u4e0e\u5e94\u7528\u57fa\u51c6\u4e0a\u5747\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u7cbe\u786e\u65b9\u6cd5\uff0c\u80fd\u591f\u89e3\u51b3\u66f4\u591a\u5b9e\u4f8b\u5e76\u5728\u5e94\u7528\u57fa\u51c6\u4e0a\u8fbe\u5230100%\u8986\u76d6\u3002"}}
{"id": "2509.13763", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.13763", "abs": "https://arxiv.org/abs/2509.13763", "authors": ["Zongxin Shen", "Yanyong Huang", "Bin Wang", "Jinyuan Chang", "Shiyu Liu", "Tianrui Li"], "title": "Beyond Correlation: Causal Multi-View Unsupervised Feature Selection Learning", "comment": null, "summary": "Multi-view unsupervised feature selection (MUFS) has recently received\nincreasing attention for its promising ability in dimensionality reduction on\nmulti-view unlabeled data. Existing MUFS methods typically select\ndiscriminative features by capturing correlations between features and\nclustering labels. However, an important yet underexplored question remains:\n\\textit{Are such correlations sufficiently reliable to guide feature\nselection?} In this paper, we analyze MUFS from a causal perspective by\nintroducing a novel structural causal model, which reveals that existing\nmethods may select irrelevant features because they overlook spurious\ncorrelations caused by confounders. Building on this causal perspective, we\npropose a novel MUFS method called CAusal multi-view Unsupervised feature\nSelection leArning (CAUSA). Specifically, we first employ a generalized\nunsupervised spectral regression model that identifies informative features by\ncapturing dependencies between features and consensus clustering labels. We\nthen introduce a causal regularization module that can adaptively separate\nconfounders from multi-view data and simultaneously learn view-shared sample\nweights to balance confounder distributions, thereby mitigating spurious\ncorrelations. Thereafter, integrating both into a unified learning framework\nenables CAUSA to select causally informative features. Comprehensive\nexperiments demonstrate that CAUSA outperforms several state-of-the-art\nmethods. To our knowledge, this is the first in-depth study of causal\nmulti-view feature selection in the unsupervised setting.", "AI": {"tldr": "\u8bba\u6587\u6307\u51fa\u73b0\u6709MUFS\u65b9\u6cd5\u53ef\u80fd\u56e0\u6df7\u6742\u53d8\u91cf\u5bfc\u81f4\u9009\u62e9\u5230\u865a\u5047\u76f8\u5173\u7279\u5f81\uff0c\u63d0\u51faCAUSA\uff1a\u5c06\u5e7f\u4e49\u65e0\u76d1\u7763\u8c31\u56de\u5f52\u4e0e\u56e0\u679c\u6b63\u5219\u5316\u7ed3\u5408\uff0c\u901a\u8fc7\u5206\u79bb\u6df7\u6742\u6e90\u548c\u5b66\u4e60\u89c6\u56fe\u5171\u4eab\u6837\u672c\u6743\u91cd\u6765\u7f13\u89e3\u865a\u5047\u76f8\u5173\uff0c\u4ece\u800c\u5b9e\u73b0\u66f4\u9c81\u68d2\u7684\u56e0\u679c\u7279\u5f81\u9009\u62e9\uff0c\u5b9e\u9a8c\u5c55\u793a\u4e86\u4f18\u8d8a\u6027\u3002", "motivation": "\u73b0\u6709\u591a\u89c6\u56fe\u65e0\u76d1\u7763\u7279\u5f81\u9009\u62e9\u65b9\u6cd5\u4f9d\u8d56\u7279\u5f81\u4e0e\u805a\u7c7b\u6807\u7b7e\u4e4b\u95f4\u7684\u76f8\u5173\u6027\uff0c\u4f46\u8be5\u76f8\u5173\u6027\u53ef\u80fd\u7531\u6df7\u6742\u53d8\u91cf\u5f15\u5165\uff0c\u5bfc\u81f4\u9009\u62e9\u5230\u65e0\u5173\u7279\u5f81\uff1b\u56e0\u6b64\u9700\u8981\u56e0\u679c\u89c6\u89d2\u6765\u6d88\u9664\u865a\u5047\u76f8\u5173\uff0c\u63d0\u9ad8\u9009\u62e9\u7684\u53ef\u9760\u6027\u548c\u6cdb\u5316\u6027\u3002", "method": "\u6784\u5efa\u7ed3\u6784\u56e0\u679c\u6a21\u578b\u63ed\u793a\u6df7\u6742\u53d8\u91cf\u4f1a\u5728\u7279\u5f81\u4e0e\u805a\u7c7b\u6807\u7b7e\u95f4\u4ea7\u751f\u865a\u5047\u76f8\u5173\uff1b\u63d0\u51fa\u5e7f\u4e49\u65e0\u76d1\u7763\u8c31\u56de\u5f52\u7528\u4e8e\u6355\u6349\u7279\u5f81\u4e0e\u5171\u8bc6\u805a\u7c7b\u6807\u7b7e\u7684\u4f9d\u8d56\uff1b\u52a0\u5165\u56e0\u679c\u6b63\u5219\u5316\u6a21\u5757\uff0c\u5b66\u4e60\u533a\u5206\u6df7\u6742\u56e0\u5b50\u5e76\u5b66\u4e60\u89c6\u56fe\u5171\u4eab\u6837\u672c\u6743\u91cd\u4ee5\u5e73\u8861\u6df7\u6742\u5206\u5e03\uff1b\u5c06\u4e24\u8005\u7edf\u4e00\u4f18\u5316\u4ee5\u5f97\u5230\u56e0\u679c\u76f8\u5173\u7684\u7279\u5f81\u5b50\u96c6\u3002", "result": "\u5728\u591a\u6570\u636e\u96c6\u4e0a\u4e0e\u591a\u79cd\u5148\u8fdb\u65b9\u6cd5\u6bd4\u8f83\uff0cCAUSA\u5728\u7279\u5f81\u9009\u62e9\u8d28\u91cf\u4e0a\u8868\u73b0\u66f4\u597d\uff0c\u9a8c\u8bc1\u4e86\u56e0\u679c\u6b63\u5219\u5316\u80fd\u591f\u51cf\u5c11\u6df7\u6742\u5f71\u54cd\u5e76\u63d0\u5347\u4e0b\u6e38\u805a\u7c7b/\u5206\u7c7b\u6027\u80fd\u3002\u8bba\u6587\u5ba3\u79f0\u4e3a\u9996\u4e2a\u5bf9\u65e0\u76d1\u7763\u591a\u89c6\u56fe\u7279\u5f81\u9009\u62e9\u8fdb\u884c\u6df1\u5165\u56e0\u679c\u5206\u6790\u7684\u5de5\u4f5c\u3002", "conclusion": "\u8be5\u8bba\u6587\u4ece\u56e0\u679c\u89c6\u89d2\u5ba1\u89c6\u591a\u89c6\u56fe\u65e0\u76d1\u7763\u7279\u5f81\u9009\u62e9\uff0c\u63d0\u51fa\u4e86CAUSA\u65b9\u6cd5\uff0c\u901a\u8fc7\u56e0\u679c\u6b63\u5219\u5316\u53bb\u9664\u6df7\u6742\u56e0\u7d20\u5bfc\u81f4\u7684\u865a\u5047\u76f8\u5173\uff0c\u4ece\u800c\u9009\u62e9\u56e0\u679c\u76f8\u5173\uff08\u5373\u771f\u6b63\u4fe1\u606f\u6027\uff09\u7684\u7279\u5f81\u3002"}}
{"id": "2509.13968", "categories": ["cs.AI", "cs.CL", "cs.FL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.13968", "abs": "https://arxiv.org/abs/2509.13968", "authors": ["Konstantinos Voudouris", "Andrew Barron", "Marta Halina", "Colin Klein", "Matishalin Patel"], "title": "Exploring Major Transitions in the Evolution of Biological Cognition With Artificial Neural Networks", "comment": null, "summary": "Transitional accounts of evolution emphasise a few changes that shape what is\nevolvable, with dramatic consequences for derived lineages. More recently it\nhas been proposed that cognition might also have evolved via a series of major\ntransitions that manipulate the structure of biological neural networks,\nfundamentally changing the flow of information. We used idealised models of\ninformation flow, artificial neural networks (ANNs), to evaluate whether\nchanges in information flow in a network can yield a transitional change in\ncognitive performance. We compared networks with feed-forward, recurrent and\nlaminated topologies, and tested their performance learning artificial grammars\nthat differed in complexity, controlling for network size and resources. We\ndocumented a qualitative expansion in the types of input that recurrent\nnetworks can process compared to feed-forward networks, and a related\nqualitative increase in performance for learning the most complex grammars. We\nalso noted how the difficulty in training recurrent networks poses a form of\ntransition barrier and contingent irreversibility -- other key features of\nevolutionary transitions. Not all changes in network topology confer a\nperformance advantage in this task set. Laminated networks did not outperform\nnon-laminated networks in grammar learning. Overall, our findings show how some\nchanges in information flow can yield transitions in cognitive performance.", "AI": {"tldr": "Recurrent topology can produce a qualitative cognitive performance transition in ANN grammar learning, with training difficulty acting as an evolutionary-like barrier; laminated topology showed no advantage.", "motivation": "To test if cognition can evolve via major transitions that alter information flow in biological neural networks, analogous to evolutionary transitions, by using ANNs as models to see if topological changes yield transitional cognitive changes.", "method": "Used idealized artificial neural networks with controlled size/resources to compare feed-forward, recurrent, and laminated topologies on artificial grammar learning tasks of varying complexity; evaluated performance, training difficulty, and qualitative differences in input processing.", "result": "Recurrent networks processed a broader range of inputs and performed better on the most complex grammars, but were harder to train (posing a transition barrier and contingent irreversibility). Laminated networks showed no performance benefit in grammar learning.", "conclusion": "Changes in information flow within neural network topologies can produce qualitative transitions in cognitive performance; specifically, recurrent ANNs show expanded processing capabilities and better learning on complex grammars compared to feed-forward ANNs, while laminated topology did not confer advantages in this task."}}
{"id": "2509.13783", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.13783", "abs": "https://arxiv.org/abs/2509.13783", "authors": ["Tianshuo Zhang", "Wenzhe Zhai", "Rui Yann", "Jia Gao", "He Cao", "Xianglei Xing"], "title": "Floating-Body Hydrodynamic Neural Networks", "comment": null, "summary": "Fluid-structure interaction is common in engineering and natural systems,\nwhere floating-body motion is governed by added mass, drag, and background\nflows. Modeling these dissipative dynamics is difficult: black-box neural\nmodels regress state derivatives with limited interpretability and unstable\nlong-horizon predictions. We propose Floating-Body Hydrodynamic Neural Networks\n(FHNN), a physics-structured framework that predicts interpretable hydrodynamic\nparameters such as directional added masses, drag coefficients, and a\nstreamfunction-based flow, and couples them with analytic equations of motion.\nThis design constrains the hypothesis space, enhances interpretability, and\nstabilizes integration. On synthetic vortex datasets, FHNN achieves up to an\norder-of-magnitude lower error than Neural ODEs, recovers physically consistent\nflow fields. Compared with Hamiltonian and Lagrangian neural networks, FHNN\nmore effectively handles dissipative dynamics while preserving\ninterpretability, which bridges the gap between black-box learning and\ntransparent system identification.", "AI": {"tldr": "FHNN\u5c06\u7269\u7406\u53c2\u6570\u5316\u4e0e\u795e\u7ecf\u7f51\u7edc\u7ed3\u5408\uff0c\u901a\u8fc7\u53ef\u89e3\u91ca\u53c2\u6570\u9884\u6d4b\u4e0e\u89e3\u6790\u65b9\u7a0b\u8026\u5408\uff0c\u63d0\u4f9b\u7a33\u5065\u4e14\u53ef\u89e3\u91ca\u7684\u6d6e\u4f53\u6d41\u56fa\u8026\u5408\u5efa\u6a21\uff0c\u663e\u8457\u4f18\u4e8e\u9ed1\u7bb1\u548c\u4fdd\u5b88\u7cfb\u7edf\u5bfc\u5411\u795e\u7ecf\u7f51\u7edc\u3002", "motivation": "\u4f20\u7edf\u9ed1\u7bb1\u795e\u7ecf\u6a21\u578b\u5728\u5efa\u6a21\u8017\u6563\u6d41\u56fa\u8026\u5408\uff08\u5982\u6d6e\u4f53\uff09\u65f6\u53ef\u89e3\u91ca\u6027\u5dee\u4e14\u957f\u65f6\u9884\u6d4b\u4e0d\u7a33\u5b9a\uff1b\u9700\u8981\u4e00\u79cd\u65e2\u6709\u7269\u7406\u7ea6\u675f\u53c8\u80fd\u5b66\u4e60\u590d\u6742\u80cc\u666f\u6d41\u4e0e\u963b\u6027\u6548\u5e94\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51faFHNN\u6846\u67b6\uff1a\u7f51\u7edc\u8f93\u51fa\u53ef\u89e3\u91ca\u53c2\u6570\uff08\u65b9\u5411\u6027\u9644\u52a0\u8d28\u91cf\u77e9\u9635\u3001\u963b\u529b\u7cfb\u6570\u3001\u6d41\u51fd\u6570\u573a\uff09\uff0c\u5e76\u5c06\u5176\u4ee3\u5165\u89e3\u6790\u7684\u8fd0\u52a8\u65b9\u7a0b\u8fdb\u884c\u6570\u503c\u79ef\u5206\uff0c\u8bad\u7ec3\u76ee\u6807\u4e3a\u72b6\u6001\u6570\u636e\u62df\u5408\uff1b\u5728\u5408\u6210\u6da1\u6d41\u6570\u636e\u96c6\u4e0a\u4e0eNeural ODE\u3001Hamiltonian/Lagrangian\u7f51\u7edc\u6bd4\u8f83\u3002", "result": "\u5728\u5408\u6210\u6da1\u6570\u636e\u96c6\u4e0a\uff0cFHNN\u6bd4Neural ODE\u8bef\u5dee\u964d\u4f4e\u7ea6\u4e00\u4e2a\u6570\u91cf\u7ea7\uff0c\u80fd\u6062\u590d\u7269\u7406\u4e00\u81f4\u7684\u6d41\u573a\uff1b\u76f8\u6bd4Hamiltonian/Lagrangian\u7f51\u7edc\u66f4\u597d\u5730\u5904\u7406\u8017\u6563\u8fc7\u7a0b\u5e76\u4fdd\u7559\u53ef\u89e3\u91ca\u53c2\u6570\u3002", "conclusion": "FHNN\u901a\u8fc7\u5c06\u7269\u7406\u7ed3\u6784\uff08\u65b9\u5411\u6027\u9644\u52a0\u8d28\u91cf\u3001\u963b\u529b\u7cfb\u6570\u3001\u57fa\u4e8e\u6d41\u51fd\u6570\u7684\u80cc\u666f\u6d41\uff09\u4e0e\u89e3\u6790\u8fd0\u52a8\u65b9\u7a0b\u8026\u5408\uff0c\u80fd\u66f4\u7a33\u5b9a\u4e14\u53ef\u89e3\u91ca\u5730\u5efa\u6a21\u6d6e\u4f53\u7684\u8017\u6563\u6d41\u56fa\u8026\u5408\u52a8\u529b\u5b66\uff0c\u4f18\u4e8e\u9ed1\u7bb1\u795e\u7ecfODE\u548c\u57fa\u4e8e\u53d8\u5206\u539f\u7406\u7684\u795e\u7ecf\u7f51\u7edc\u5728\u957f\u671f\u79ef\u5206\u548c\u53ef\u89e3\u91ca\u6027\u4e0a\u7684\u8868\u73b0\u3002"}}
{"id": "2509.14030", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.14030", "abs": "https://arxiv.org/abs/2509.14030", "authors": ["Maosheng Qin", "Renyu Zhu", "Mingxuan Xia", "Chenkai Chen", "Zhen Zhu", "Minmin Lin", "Junbo Zhao", "Lu Xu", "Changjie Fan", "Runze Wu", "Haobo Wang"], "title": "CrowdAgent: Multi-Agent Managed Multi-Source Annotation System", "comment": null, "summary": "High-quality annotated data is a cornerstone of modern Natural Language\nProcessing (NLP). While recent methods begin to leverage diverse annotation\nsources-including Large Language Models (LLMs), Small Language Models (SLMs),\nand human experts-they often focus narrowly on the labeling step itself. A\ncritical gap remains in the holistic process control required to manage these\nsources dynamically, addressing complex scheduling and quality-cost trade-offs\nin a unified manner. Inspired by real-world crowdsourcing companies, we\nintroduce CrowdAgent, a multi-agent system that provides end-to-end process\ncontrol by integrating task assignment, data annotation, and quality/cost\nmanagement. It implements a novel methodology that rationally assigns tasks,\nenabling LLMs, SLMs, and human experts to advance synergistically in a\ncollaborative annotation workflow. We demonstrate the effectiveness of\nCrowdAgent through extensive experiments on six diverse multimodal\nclassification tasks. The source code and video demo are available at\nhttps://github.com/QMMMS/CrowdAgent.", "AI": {"tldr": "\u63d0\u51fa CrowdAgent\uff0c\u4e00\u4e2a\u5c06 LLM/SLM/\u4eba\u5de5\u6574\u5408\u7684\u591a\u4ee3\u7406\u7aef\u5230\u7aef\u6807\u6ce8\u7cfb\u7edf\uff0c\u5b9e\u73b0\u4efb\u52a1\u5206\u914d\u4e0e\u8d28\u91cf/\u6210\u672c\u5e73\u8861\uff0c\u5728\u591a\u6a21\u6001\u5206\u7c7b\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u8d8a\u3002", "motivation": "\u5f53\u524d\u65b9\u6cd5\u867d\u7136\u5229\u7528\u591a\u6837\u5316\u6807\u6ce8\u6e90\uff0c\u4f46\u591a\u805a\u7126\u4e8e\u6807\u6ce8\u672c\u8eab\uff0c\u7f3a\u4e4f\u7edf\u4e00\u7684\u6d41\u7a0b\u63a7\u5236\u6765\u52a8\u6001\u7ba1\u7406\u4e0d\u540c\u6807\u6ce8\u6e90\u53ca\u590d\u6742\u7684\u8c03\u5ea6\u4e0e\u8d28\u91cf-\u6210\u672c\u6743\u8861\u3002CrowdAgent \u53d7\u4f17\u5305\u516c\u53f8\u542f\u53d1\uff0c\u65e8\u5728\u586b\u8865\u8be5\u7a7a\u767d\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u591a\u4ee3\u7406\u7cfb\u7edf\uff0c\u5c06\u4efb\u52a1\u667a\u80fd\u5206\u914d\u7ed9 LLM\u3001SLM \u4e0e\u4eba\u5de5\u4e13\u5bb6\uff0c\u7ed3\u5408\u52a8\u6001\u8c03\u5ea6\u4e0e\u8d28\u91cf\u6210\u672c\u6743\u8861\u7b56\u7565\uff0c\u5b9e\u73b0\u534f\u540c\u6807\u6ce8\u6d41\u7a0b\u3002\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u5728\u516d\u4e2a\u591a\u6a21\u6001\u5206\u7c7b\u4efb\u52a1\u4e0a\u7684\u6709\u6548\u6027\u3002", "result": "\u5728\u516d\u4e2a\u591a\u6a21\u6001\u5206\u7c7b\u4efb\u52a1\u4e0a\uff0cCrowdAgent \u5c55\u793a\u4e86\u8f83\u4f20\u7edf\u6216\u5355\u4e00\u7b56\u7565\u66f4\u597d\u7684\u6807\u6ce8\u8d28\u91cf\u4e0e\u6210\u672c\u6548\u7387\uff0c\u4ee3\u7801\u4e0e\u6f14\u793a\u5df2\u5f00\u6e90\u3002", "conclusion": "CrowdAgent \u63d0\u4f9b\u4e86\u7aef\u5230\u7aef\u7684\u6d41\u7a0b\u63a7\u5236\uff0c\u80fd\u591f\u5728\u4efb\u52a1\u5206\u914d\u3001\u6570\u636e\u6807\u6ce8\u4e0e\u8d28\u91cf/\u6210\u672c\u7ba1\u7406\u4e4b\u95f4\u5b9e\u73b0\u534f\u540c\u4f18\u5316\uff0c\u4ece\u800c\u5728\u591a\u6a21\u6001\u5206\u7c7b\u4efb\u52a1\u4e0a\u663e\u8457\u63d0\u5347\u6807\u6ce8\u6548\u7387\u4e0e\u8d28\u91cf\u3002"}}
{"id": "2509.13805", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2509.13805", "abs": "https://arxiv.org/abs/2509.13805", "authors": ["Florian Wiesner", "Matthias Wessling", "Stephen Baek"], "title": "Towards a Physics Foundation Model", "comment": null, "summary": "Foundation models have revolutionized natural language processing through a\n``train once, deploy anywhere'' paradigm, where a single pre-trained model\nadapts to countless downstream tasks without retraining. Access to a Physics\nFoundation Model (PFM) would be transformative -- democratizing access to\nhigh-fidelity simulations, accelerating scientific discovery, and eliminating\nthe need for specialized solver development. Yet current physics-aware machine\nlearning approaches remain fundamentally limited to single, narrow domains and\nrequire retraining for each new system. We present the General Physics\nTransformer (GPhyT), trained on 1.8 TB of diverse simulation data, that\ndemonstrates foundation model capabilities are achievable for physics. Our key\ninsight is that transformers can learn to infer governing dynamics from\ncontext, enabling a single model to simulate fluid-solid interactions, shock\nwaves, thermal convection, and multi-phase dynamics without being told the\nunderlying equations. GPhyT achieves three critical breakthroughs: (1) superior\nperformance across multiple physics domains, outperforming specialized\narchitectures by up to 29x, (2) zero-shot generalization to entirely unseen\nphysical systems through in-context learning, and (3) stable long-term\npredictions through 50-timestep rollouts. By establishing that a single model\ncan learn generalizable physical principles from data alone, this work opens\nthe path toward a universal PFM that could transform computational science and\nengineering.", "AI": {"tldr": "GPhyT\u901a\u8fc7\u5728\u5927\u89c4\u6a21\u5f02\u6784\u4eff\u771f\u6570\u636e\u4e0a\u8bad\u7ec3\u53d8\u6362\u5668\uff0c\u5b9e\u73b0\u4e86\u8de8\u591a\u7269\u7406\u9886\u57df\u7684\u901a\u7528\u6a21\u62df\u80fd\u529b\uff0c\u652f\u6301\u96f6\u6837\u672c\u6cdb\u5316\u4e0e\u7a33\u5b9a\u957f\u65f6\u9884\u6d4b\uff0c\u671d\u901a\u7528\u7269\u7406\u57fa\u7840\u6a21\u578b\u8fc8\u51fa\u5173\u952e\u4e00\u6b65\u3002", "motivation": "\u76ee\u6807\u662f\u6784\u5efa\u7c7b\u4f3cNLP\u57fa\u7840\u6a21\u578b\u7684\u7269\u7406\u57fa\u7840\u6a21\u578b\uff08PFM\uff09\uff0c\u6d88\u9664\u4e3a\u6bcf\u4e2a\u7269\u7406\u7cfb\u7edf\u5355\u72ec\u8bad\u7ec3\u89e3\u7b97\u5668\u7684\u9700\u6c42\uff0c\u6c11\u4e3b\u5316\u9ad8\u4fdd\u771f\u6a21\u62df\u5e76\u52a0\u901f\u79d1\u5b66\u5de5\u7a0b\u7814\u7a76\u3002", "method": "\u4f7f\u75281.8TB\u591a\u6837\u5316\u4eff\u771f\u6570\u636e\u8bad\u7ec3\u5927\u578b\u53d8\u6362\u5668\uff08GPhyT\uff09\uff0c\u901a\u8fc7\u4e0a\u4e0b\u6587\u63d0\u4f9b\u8fc7\u53bb\u72b6\u6001\u4ee5\u8ba9\u6a21\u578b\u63a8\u65ad\u5e76\u9884\u6d4b\u7cfb\u7edf\u52a8\u529b\u5b66\uff0c\u8986\u76d6\u6d41\u56fa\u8026\u5408\u3001\u51b2\u51fb\u6ce2\u3001\u70ed\u5bf9\u6d41\u548c\u591a\u76f8\u6d41\u7b49\u591a\u79cd\u7269\u7406\u573a\u666f\u3002", "result": "GPhyT\u5728\u591a\u4e2a\u7269\u7406\u57df\u4e0a\u4f18\u4e8e\u4e13\u7528\u67b6\u6784\uff08\u6700\u9ad829\u500d\uff09\uff0c\u5c55\u793a\u4e86\u96f6\u6837\u672c\u60c5\u5883\u5b66\u4e60\u6cdb\u5316\u5230\u672a\u89c1\u7cfb\u7edf\u7684\u80fd\u529b\uff0c\u5e76\u5728\u957f\u65f6\u95f4\uff0850\u6b65\uff09\u6eda\u52a8\u9884\u6d4b\u4e2d\u4fdd\u6301\u7a33\u5b9a\u3002", "conclusion": "GPhyT\u5c55\u793a\u4e86\u5c06\u5927\u578b\u53d8\u6362\u5668\u7528\u4e8e\u901a\u7528\u7269\u7406\u5efa\u6a21\u7684\u53ef\u884c\u6027\uff0c\u8868\u660e\u5355\u4e00\u6a21\u578b\u53ef\u901a\u8fc7\u4e0a\u4e0b\u6587\u5b66\u4e60\u7269\u7406\u52a8\u529b\u5b66\uff0c\u4ece\u800c\u5728\u591a\u9886\u57df\u6a21\u62df\u4efb\u52a1\u4e2d\u65e0\u9700\u91cd\u8bad\u7ec3\u5373\u53ef\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2509.14195", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.14195", "abs": "https://arxiv.org/abs/2509.14195", "authors": ["Shalima Binta Manir", "Tim Oates"], "title": "Hierarchical Learning for Maze Navigation: Emergence of Mental Representations via Second-Order Learning", "comment": "8 pages, 3 figures", "summary": "Mental representation, characterized by structured internal models mirroring\nexternal environments, is fundamental to advanced cognition but remains\nchallenging to investigate empirically. Existing theory hypothesizes that\nsecond-order learning -- learning mechanisms that adapt first-order learning\n(i.e., learning about the task/domain) -- promotes the emergence of such\nenvironment-cognition isomorphism. In this paper, we empirically validate this\nhypothesis by proposing a hierarchical architecture comprising a Graph\nConvolutional Network (GCN) as a first-order learner and an MLP controller as a\nsecond-order learner. The GCN directly maps node-level features to predictions\nof optimal navigation paths, while the MLP dynamically adapts the GCN's\nparameters when confronting structurally novel maze environments. We\ndemonstrate that second-order learning is particularly effective when the\ncognitive system develops an internal mental map structurally isomorphic to the\nenvironment. Quantitative and qualitative results highlight significant\nperformance improvements and robust generalization on unseen maze tasks,\nproviding empirical support for the pivotal role of structured mental\nrepresentations in maximizing the effectiveness of second-order learning.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7GCN+MLP\u5206\u5c42\u67b6\u6784\u5b9e\u8bc1\u9a8c\u8bc1\u4e86\u7b2c\u4e8c\u9636\u5b66\u4e60\u80fd\u4fc3\u8fdb\u4e0e\u73af\u5883\u7ed3\u6784\u540c\u6784\u7684\u5fc3\u7406\u8868\u5f81\uff0c\u4ece\u800c\u63d0\u9ad8\u5728\u7ed3\u6784\u65b0\u9896\u8ff7\u5bab\u4efb\u52a1\u4e0a\u7684\u6cdb\u5316\u548c\u6027\u80fd\u3002", "motivation": "\u9a8c\u8bc1\u7406\u8bba\u5047\u8bbe\uff1a\u4e8c\u9636\u5b66\u4e60\u673a\u5236\u80fd\u4fc3\u8fdb\u73af\u5883\u2014\u8ba4\u77e5\u540c\u6784\u7684\u5185\u90e8\u5fc3\u7406\u8868\u5f81\uff0c\u4ece\u800c\u63d0\u9ad8\u8ba4\u77e5\u7cfb\u7edf\u5728\u7ed3\u6784\u53d8\u5316\u4efb\u52a1\u4e0a\u7684\u9002\u5e94\u6027\u4e0e\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u5206\u5c42\u67b6\u6784\uff1aGCN\u4f5c\u4e3a\u4e00\u9636\u5b66\u4e60\u5668\u7528\u4e8e\u4ece\u8282\u70b9\u7279\u5f81\u9884\u6d4b\u6700\u4f18\u5bfc\u822a\u8def\u5f84\uff0cMLP\u4f5c\u4e3a\u4e8c\u9636\u63a7\u5236\u5668\u5728\u9047\u5230\u7ed3\u6784\u65b0\u9896\u7684\u8ff7\u5bab\u65f6\u52a8\u6001\u8c03\u6574GCN\u53c2\u6570\u3002\u901a\u8fc7\u5728\u4e0d\u540c\u7ed3\u6784\u8ff7\u5bab\u4e0a\u7684\u8bad\u7ec3\u4e0e\u6d4b\u8bd5\uff0c\u8bc4\u4f30\u6027\u80fd\u4e0e\u6cdb\u5316\u80fd\u529b\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u4e8c\u9636\u5b66\u4e60\u5728\u6a21\u578b\u5f62\u6210\u4e0e\u73af\u5883\u7ed3\u6784\u540c\u6784\u7684\u6761\u4ef6\u4e0b\u6548\u679c\u663e\u8457\uff0c\u8868\u73b0\u4e3a\u6027\u80fd\u663e\u8457\u63d0\u5347\u548c\u5728\u672a\u89c1\u8ff7\u5bab\u4efb\u52a1\u4e0a\u7684\u7a33\u5065\u6cdb\u5316\uff1b\u5e76\u7ed9\u51fa\u5b9a\u91cf\u4e0e\u5b9a\u6027\u5206\u6790\u652f\u6301\u8be5\u7ed3\u8bba\u3002", "conclusion": "\u7b2c\u4e8c\u9636\u5b66\u4e60\uff08\u5bf9\u4e00\u9636\u5b66\u4e60\u53c2\u6570\u7684\u9002\u5e94\uff09\u4fc3\u8fdb\u4e86\u4e0e\u73af\u5883\u7ed3\u6784\u540c\u6784\u7684\u5fc3\u7406\u8868\u5f81\u7684\u5f62\u6210\uff0c\u4ece\u800c\u63d0\u5347\u5728\u65b0\u7ed3\u6784\u8ff7\u5bab\u4efb\u52a1\u4e0a\u7684\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2509.13818", "categories": ["cs.LG", "quant-ph"], "pdf": "https://arxiv.org/pdf/2509.13818", "abs": "https://arxiv.org/abs/2509.13818", "authors": ["Zheng-an Wang", "Yanbo J. Wang", "Jiachi Zhang", "Qi Xu", "Yilun Zhao", "Jintao Li", "Yipeng Zhang", "Bo Yang", "Xinkai Gao", "Xiaofeng Cao", "Kai Xu", "Pengpeng Hao", "Xuan Yang", "Heng Fan"], "title": "Hybrid Quantum-Classical Neural Networks for Few-Shot Credit Risk Assessment", "comment": null, "summary": "Quantum Machine Learning (QML) offers a new paradigm for addressing complex\nfinancial problems intractable for classical methods. This work specifically\ntackles the challenge of few-shot credit risk assessment, a critical issue in\ninclusive finance where data scarcity and imbalance limit the effectiveness of\nconventional models. To address this, we design and implement a novel hybrid\nquantum-classical workflow. The methodology first employs an ensemble of\nclassical machine learning models (Logistic Regression, Random Forest, XGBoost)\nfor intelligent feature engineering and dimensionality reduction. Subsequently,\na Quantum Neural Network (QNN), trained via the parameter-shift rule, serves as\nthe core classifier. This framework was evaluated through numerical simulations\nand deployed on the Quafu Quantum Cloud Platform's ScQ-P21 superconducting\nprocessor. On a real-world credit dataset of 279 samples, our QNN achieved a\nrobust average AUC of 0.852 +/- 0.027 in simulations and yielded an impressive\nAUC of 0.88 in the hardware experiment. This performance surpasses a suite of\nclassical benchmarks, with a particularly strong result on the recall metric.\nThis study provides a pragmatic blueprint for applying quantum computing to\ndata-constrained financial scenarios in the NISQ era and offers valuable\nempirical evidence supporting its potential in high-stakes applications like\ninclusive finance.", "AI": {"tldr": "Paper proposes ensemble-based feature engineering followed by a parameter-shift trained QNN for few-shot credit risk; achieves AUC ~0.85-0.88 beating classical baselines, validated on cloud superconducting hardware", "motivation": "Address few-shot credit risk assessment under data scarcity and imbalance, improving inclusive finance decision-making where classical models struggle", "method": "Hybrid quantum-classical workflow with ensemble feature engineering and QNN classifier", "result": "Simulations: QNN avg AUC 0.852 +/- 0.027; Hardware (ScQ-P21) AUC 0.88 on 279-sample dataset; superior recall vs classical baselines", "conclusion": "Demonstrates feasibility and advantage of QML for data-constrained financial tasks in NISQ era, offering empirical blueprint for inclusive finance applications."}}
{"id": "2010.01052", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2010.01052", "abs": "https://arxiv.org/abs/2010.01052", "authors": ["Jaume Banus", "Maxime Sermesant", "Oscar Camara", "Marco Lorenzi"], "title": "Joint data imputation and mechanistic modelling for simulating heart-brain interactions in incomplete datasets", "comment": null, "summary": "The use of mechanistic models in clinical studies is limited by the lack of\nmulti-modal patients data representing different anatomical and physiological\nprocesses. For example, neuroimaging datasets do not provide a sufficient\nrepresentation of heart features for the modeling of cardiovascular factors in\nbrain disorders. To tackle this problem we introduce a probabilistic framework\nfor joint cardiac data imputation and personalisation of cardiovascular\nmechanistic models, with application to brain studies with incomplete heart\ndata. Our approach is based on a variational framework for the joint inference\nof an imputation model of cardiac information from the available features,\nalong with a Gaussian Process emulator that can faithfully reproduce\npersonalised cardiovascular dynamics. Experimental results on UK Biobank show\nthat our model allows accurate imputation of missing cardiac features in\ndatasets containing minimal heart information, e.g. systolic and diastolic\nblood pressures only, while jointly estimating the emulated parameters of the\nlumped model. This allows a novel exploration of the heart-brain joint\nrelationship through simulation of realistic cardiac dynamics corresponding to\ndifferent conditions of brain anatomy.", "AI": {"tldr": "\u63d0\u51fa\u8054\u5408\u63d2\u8865\u548c\u673a\u68b0\u6a21\u578b\u4e2a\u6027\u5316\u7684\u6982\u7387\u53d8\u5206\u6846\u67b6\uff0c\u7ed3\u5408\u5fc3\u810f\u7279\u5f81\u63d2\u8865\u4e0e\u9ad8\u65af\u8fc7\u7a0b\u4eff\u771f\u5668\uff0c\u5728UK Biobank\u4e0a\u80fd\u4ece\u6781\u5c11\u5fc3\u810f\u4fe1\u606f\u51c6\u786e\u6062\u590d\u7f3a\u5931\u7279\u5f81\u5e76\u4f30\u8ba1\u6a21\u578b\u53c2\u6570\uff0c\u652f\u6301\u5fc3\u8111\u8054\u5408\u6a21\u62df\u4e0e\u7814\u7a76\u3002", "motivation": "\u4e34\u5e8a\u53ca\u5927\u578b\u5f71\u50cf\u961f\u5217\uff08\u5982UK Biobank\uff09\u5e38\u7f3a\u4e4f\u591a\u6a21\u6001\u60a3\u8005\u6570\u636e\uff0c\u5c24\u5176\u662f\u795e\u7ecf\u5f71\u50cf\u6570\u636e\u96c6\u7f3a\u5c11\u4e30\u5bcc\u7684\u5fc3\u810f\u7279\u5f81\uff0c\u9650\u5236\u4e86\u4f7f\u7528\u673a\u68b0\u6a21\u578b\u7814\u7a76\u5fc3\u8111\u76f8\u4e92\u4f5c\u7528\u7684\u80fd\u529b\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u80fd\u5728\u6570\u636e\u4e0d\u5b8c\u6574\u65f6\u540c\u65f6\u63d2\u8865\u5fc3\u810f\u4fe1\u606f\u5e76\u4e2a\u6027\u5316\u673a\u68b0\u6a21\u578b\u7684\u65b9\u6cd5\u3002", "method": "\u57fa\u4e8e\u53d8\u5206\u63a8\u65ad\u6784\u5efa\u8054\u5408\u6a21\u578b\uff1a\u4e00\u65b9\u9762\u5b66\u4e60\u4ece\u53ef\u7528\u7279\u5f81\uff08\u5982\u8840\u538b\uff09\u5230\u7f3a\u5931\u5fc3\u810f\u4fe1\u606f\u7684\u63d2\u8865\u6a21\u578b\uff1b\u53e6\u4e00\u65b9\u9762\u8bad\u7ec3\u9ad8\u65af\u8fc7\u7a0b\uff08GP\uff09\u4eff\u771f\u5668\u6765\u903c\u8fd1\u5fc3\u8840\u7ba1\u7b80\u5316\u673a\u68b0\u6a21\u578b\u7684\u8f93\u51fa\u5e76\u5b9e\u73b0\u53c2\u6570\u4e2a\u6027\u5316\uff0c\u4e24\u8005\u5728\u6982\u7387\u6846\u67b6\u4e0b\u8054\u5408\u4f18\u5316\u3002", "result": "\u5728UK Biobank\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff1a\u6a21\u578b\u80fd\u5728\u4ec5\u6709\u6536\u7f29\u538b\u4e0e\u8212\u5f20\u538b\u7b49\u6781\u5c11\u5fc3\u810f\u4fe1\u606f\u65f6\uff0c\u51c6\u786e\u63d2\u8865\u5176\u4ed6\u5fc3\u810f\u7279\u5f81\uff0c\u5e76\u8054\u5408\u4f30\u8ba1\u7b80\u5316\u6a21\u578b\u7684\u53c2\u6570\uff1b\u751f\u6210\u7684\u4e2a\u4f53\u5316\u5fc3\u810f\u52a8\u529b\u5b66\u5728\u4e0d\u540c\u8111\u89e3\u5256\u6761\u4ef6\u4e0b\u80fd\u7528\u4e8e\u6a21\u62df\u5fc3\u8111\u5173\u7cfb\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u5728\u4e34\u5e8a\u7814\u7a76\u4e2d\u8054\u5408\u8fdb\u884c\u5fc3\u810f\u6570\u636e\u63d2\u8865\u548c\u4e2a\u6027\u5316\u5fc3\u8840\u7ba1\u673a\u68b0\u6a21\u578b\u7684\u6982\u7387\u6846\u67b6\uff0c\u7279\u522b\u9002\u7528\u4e8e\u8111\u7814\u7a76\u4e2d\u5fc3\u810f\u6570\u636e\u4e0d\u5b8c\u6574\u7684\u60c5\u51b5\u3002\u901a\u8fc7\u53d8\u5206\u63a8\u65ad\u540c\u65f6\u5b66\u4e60\u5fc3\u810f\u4fe1\u606f\u7684\u63d2\u8865\u6a21\u578b\u4e0e\u9ad8\u65af\u8fc7\u7a0b\u4eff\u771f\u5668\uff0c\u8be5\u65b9\u6cd5\u80fd\u5728\u53ea\u6709\u6781\u5c11\u5fc3\u810f\u4fe1\u606f\u7684\u6570\u636e\u96c6\u4e2d\u51c6\u786e\u63d2\u8865\u7f3a\u5931\u5fc3\u810f\u7279\u5f81\uff0c\u5e76\u4f30\u8ba1\u7b80\u5316\uff08lumped\uff09\u6a21\u578b\u7684\u4e2a\u4f53\u5316\u53c2\u6570\uff0c\u4ece\u800c\u652f\u6301\u57fa\u4e8e\u4e0d\u540c\u8111\u89e3\u5256\u6761\u4ef6\u4e0b\u73b0\u5b9e\u5fc3\u810f\u52a8\u529b\u5b66\u7684\u6a21\u62df\uff0c\u4fc3\u8fdb\u5fc3\u8111\u8054\u5408\u5173\u7cfb\u7684\u63a2\u7d22\u3002"}}
{"id": "2509.13841", "categories": ["cs.LG", "physics.geo-ph"], "pdf": "https://arxiv.org/pdf/2509.13841", "abs": "https://arxiv.org/abs/2509.13841", "authors": ["Qingqi Zhao", "Heng Xiao"], "title": "An End-to-End Differentiable, Graph Neural Network-Embedded Pore Network Model for Permeability Prediction", "comment": "This preprint is also available at ESS Open Archive:\n  https://essopenarchive.org/users/960205/articles/1329010", "summary": "Accurate prediction of permeability in porous media is essential for modeling\nsubsurface flow. While pure data-driven models offer computational efficiency,\nthey often lack generalization across scales and do not incorporate explicit\nphysical constraints. Pore network models (PNMs), on the other hand, are\nphysics-based and efficient but rely on idealized geometric assumptions to\nestimate pore-scale hydraulic conductance, limiting their accuracy in complex\nstructures. To overcome these limitations, we present an end-to-end\ndifferentiable hybrid framework that embeds a graph neural network (GNN) into a\nPNM. In this framework, the analytical formulas used for conductance\ncalculations are replaced by GNN-based predictions derived from pore and throat\nfeatures. The predicted conductances are then passed to the PNM solver for\npermeability computation. In this way, the model avoids the idealized geometric\nassumptions of PNM while preserving the physics-based flow calculations. The\nGNN is trained without requiring labeled conductance data, which can number in\nthe thousands per pore network; instead, it learns conductance values by using\na single scalar permeability as the training target. This is made possible by\nbackpropagating gradients through both the GNN (via automatic differentiation)\nand the PNM solver (via a discrete adjoint method), enabling fully coupled,\nend-to-end training. The resulting model achieves high accuracy and generalizes\nwell across different scales, outperforming both pure data-driven and\ntraditional PNM approaches. Gradient-based sensitivity analysis further reveals\nphysically consistent feature influences, enhancing model interpretability.\nThis approach offers a scalable and physically informed framework for\npermeability prediction in complex porous media, reducing model uncertainty and\nimproving accuracy.", "AI": {"tldr": "\u63d0\u51fa\u5c06GNN\u5d4c\u5165PNM\u5e76\u901a\u8fc7\u79bb\u6563\u4f34\u968f\u6cd5\u5b9e\u73b0\u7aef\u5230\u7aef\u53ef\u5fae\u8bad\u7ec3\uff0c\u7528\u5355\u4e00\u6e17\u900f\u7387\u6807\u7b7e\u5b66\u4e60\u6210\u5343\u4e0a\u4e07\u5bfc\u7387\uff0c\u517c\u987e\u7269\u7406\u4e00\u81f4\u6027\u4e0e\u6570\u636e\u9a71\u52a8\u7075\u6d3b\u6027\uff0c\u663e\u8457\u63d0\u9ad8\u590d\u6742\u5b54\u9699\u4ecb\u8d28\u7684\u6e17\u900f\u7387\u9884\u6d4b\u7cbe\u5ea6\u4e0e\u6cdb\u5316\u6027\u3002", "motivation": "\u7eaf\u6570\u636e\u9a71\u52a8\u6a21\u578b\u7f3a\u4e4f\u7269\u7406\u7ea6\u675f\u548c\u5c3a\u5ea6\u6cdb\u5316\u6027\uff0c\u4f20\u7edfPNM\u57fa\u4e8e\u7b80\u5316\u51e0\u4f55\u5047\u8bbe\u5bfc\u81f4\u590d\u6742\u7ed3\u6784\u7cbe\u5ea6\u4e0d\u8db3\uff0c\u6545\u9700\u517c\u5177\u7269\u7406\u4e00\u81f4\u6027\u4e0e\u6570\u636e\u5b66\u4e60\u80fd\u529b\u7684\u65b9\u6cd5\u3002", "method": "\u7528GNN\u66ff\u4ee3PNM\u4e2d\u57fa\u4e8e\u51e0\u4f55\u7406\u60f3\u5316\u7684\u89e3\u6790\u5bfc\u7387\u516c\u5f0f\uff0cGNN\u9884\u6d4b\u7684\u5bfc\u7387\u8f93\u5165PNM\u6c42\u89e3\u5668\u8ba1\u7b97\u6e17\u900f\u7387\uff1b\u8bad\u7ec3\u901a\u8fc7\u81ea\u52a8\u5fae\u5206\u5bf9GNN\u548c\u901a\u8fc7\u79bb\u6563\u4f34\u968f\u6cd5\u5bf9PNM\u6c42\u89e3\u5668\u6c42\u5bfc\uff0c\u7aef\u5230\u7aef\u6700\u5c0f\u5316\u6e17\u900f\u7387\u8bef\u5dee\u3002", "result": "\u6a21\u578b\u5728\u4e0d\u540c\u5c3a\u5ea6\u4e0a\u76f8\u8f83\u7eaf\u6570\u636e\u9a71\u52a8\u6a21\u578b\u548c\u4f20\u7edfPNM\u5747\u8868\u73b0\u66f4\u4f18\uff0c\u80fd\u51c6\u786e\u9884\u6d4b\u6e17\u900f\u7387\u5e76\u5177\u6709\u826f\u597d\u6cdb\u5316\u6027\uff1b\u7075\u654f\u5ea6\u5206\u6790\u663e\u793a\u7279\u5f81\u5f71\u54cd\u4e0e\u7269\u7406\u76f4\u89c9\u4e00\u81f4\uff0c\u63d0\u5347\u4e86\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u5fae\u5206\u7684\u6df7\u5408\u6846\u67b6\uff0c\u5c06\u56fe\u795e\u7ecf\u7f51\u7edc\u5d4c\u5165\u5b54\u9699\u7f51\u7edc\u6a21\u578b\uff0c\u5b9e\u73b0\u4ece\u5b54\u5589\u7279\u5f81\u5230\u5bfc\u6c34\u5bfc\u7387\u7684\u7aef\u5230\u7aef\u5b66\u4e60\uff0c\u5e76\u901a\u8fc7\u79bb\u6563\u4f34\u968f\u6cd5\u5728PNM\u6c42\u89e3\u5668\u4e0a\u53cd\u5411\u4f20\u64ad\uff0c\u4f7f\u5f97\u4ec5\u7528\u5355\u4e00\u6807\u91cf\u6e17\u900f\u7387\u5373\u53ef\u8bad\u7ec3GNN\u3002"}}
{"id": "2509.13866", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.13866", "abs": "https://arxiv.org/abs/2509.13866", "authors": ["Sitong Chen", "Shen Nie", "Jiacheng Sun", "Zijin Feng", "Zhenguo Li", "Ji-Rong Wen", "Chongxuan Li"], "title": "Masked Diffusion Models as Energy Minimization", "comment": null, "summary": "We present a systematic theoretical framework that interprets masked\ndiffusion models (MDMs) as solutions to energy minimization problems in\ndiscrete optimal transport. Specifically, we prove that three distinct energy\nformulations--kinetic, conditional kinetic, and geodesic energy--are\nmathematically equivalent under the structure of MDMs, and that MDMs minimize\nall three when the mask schedule satisfies a closed-form optimality condition.\nThis unification not only clarifies the theoretical foundations of MDMs, but\nalso motivates practical improvements in sampling. By parameterizing\ninterpolation schedules via Beta distributions, we reduce the schedule design\nspace to a tractable 2D search, enabling efficient post-training tuning without\nmodel modification. Experiments on synthetic and real-world benchmarks\ndemonstrate that our energy-inspired schedules outperform hand-crafted\nbaselines, particularly in low-step sampling settings.", "AI": {"tldr": "\u672c\u6587\u628aMDMs\u770b\u4f5c\u79bb\u6563\u6700\u4f18\u4f20\u8f93\u4e2d\u7684\u80fd\u91cf\u6700\u5c0f\u5316\uff0c\u8bc1\u660e\u4e09\u79cd\u80fd\u91cf\u7b49\u4ef7\u5e76\u63d0\u51fa\u57fa\u4e8eBeta\u5206\u5e03\u7684\u53ef\u8c03\u63a9\u7801\u8c03\u5ea6\uff0c\u80fd\u5728\u4f4e\u6b65\u91c7\u6837\u4e0b\u63d0\u5347\u751f\u6210\u8d28\u91cf\u3002", "motivation": "\u73b0\u6709\u5bf9\u63a9\u7801\u6269\u6563\u6a21\u578b\u7684\u7406\u8bba\u7406\u89e3\u4e0d\u8db3\uff1b\u9700\u8981\u7edf\u4e00\u7684\u80fd\u91cf\u89c6\u89d2\u6765\u89e3\u91caMDMs\u4e3a\u4f55\u80fd\u6709\u6548\u751f\u6210\u5e76\u6307\u5bfc\u66f4\u597d\u7684\u91c7\u6837\u7b56\u7565\u3002", "method": "\u901a\u8fc7\u4e25\u683c\u7684\u6570\u5b66\u63a8\u5bfc\uff0c\u5b9a\u4e49\u4e09\u7c7b\u80fd\u91cf\u51fd\u6570\u5e76\u5728MDM\u6846\u67b6\u4e0b\u8bc1\u660e\u5176\u7b49\u4ef7\u6027\uff1b\u63d0\u51fa\u63a9\u7801\u8c03\u5ea6\u7684\u95ed\u5f0f\u6700\u4f18\u6027\u6761\u4ef6\uff1b\u5c06\u63d2\u503c\u8c03\u5ea6\u53c2\u6570\u5316\u4e3aBeta\u5206\u5e03\uff0c\u628a\u8bbe\u8ba1\u7a7a\u95f4\u964d\u4e3a\u4e8c\u7ef4\u4ee5\u4fbf\u540e\u8bad\u7ec3\u8c03\u4f18\uff1b\u5728\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u505a\u5b9e\u9a8c\u8bc4\u4f30\u3002", "result": "\u5efa\u7acb\u4e86MDMs\u4e0e\u4e09\u7c7b\u80fd\u91cf\u6700\u5c0f\u5316\u95ee\u9898\u7684\u7b49\u4ef7\u6027\u7406\u8bba\uff1b\u63d0\u51fa\u57fa\u4e8eBeta\u5206\u5e03\u7684\u53ef\u8c03\u63a9\u7801\u8c03\u5ea6\u65b9\u6cd5\uff1b\u5b9e\u9a8c\u8868\u660e\u6240\u63d0\u51fa\u7684\u80fd\u91cf\u542f\u53d1\u8c03\u5ea6\u5728\u4f4e\u6b65\u91c7\u6837\u4e0b\u4f18\u4e8e\u624b\u5de5\u8bbe\u8ba1\u7684\u57fa\u7ebf\u3002", "conclusion": "\u672c\u6587\u5c06\u63a9\u7801\u6269\u6563\u6a21\u578b\uff08MDMs\uff09\u7edf\u4e00\u89e3\u91ca\u4e3a\u79bb\u6563\u6700\u4f18\u4f20\u8f93\u4e2d\u7684\u80fd\u91cf\u6700\u5c0f\u5316\u95ee\u9898\uff0c\u8bc1\u660e\u4e86\u52a8\u529b\u5b66\uff08kinetic\uff09\u3001\u6761\u4ef6\u52a8\u529b\u5b66\uff08conditional kinetic\uff09\u548c\u6d4b\u5730\u80fd\u91cf\uff08geodesic energy\uff09\u4e09\u79cd\u80fd\u91cf\u5728MDM\u7ed3\u6784\u4e0b\u7b49\u4ef7\uff0c\u5e76\u5728\u63a9\u7801\u8c03\u5ea6\u6ee1\u8db3\u95ed\u5f0f\u6700\u4f18\u6761\u4ef6\u65f6\uff0cMDMs\u540c\u65f6\u6700\u5c0f\u5316\u8fd9\u4e09\u79cd\u80fd\u91cf\u3002"}}
{"id": "2509.13895", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.13895", "abs": "https://arxiv.org/abs/2509.13895", "authors": ["Zhanting Zhou", "Jinshan Lai", "Fengchun Zhang", "Zeqin Wu", "Fengli Zhang"], "title": "FedSSG: Expectation-Gated and History-Aware Drift Alignment for Federated Learning", "comment": "4 page main text for conference", "summary": "Non-IID data and partial participation induce client drift and inconsistent\nlocal optima in federated learning, causing unstable convergence and accuracy\nloss. We present FedSSG, a stochastic sampling-guided, history-aware drift\nalignment method. FedSSG maintains a per-client drift memory that accumulates\nlocal model differences as a lightweight sketch of historical gradients;\ncrucially, it gates both the memory update and the local alignment term by a\nsmooth function of the observed/expected participation ratio (a\nphase-by-expectation signal derived from the server sampler). This\nstatistically grounded gate stays weak and smooth when sampling noise dominates\nearly, then strengthens once participation statistics stabilize, contracting\nthe local-global gap without extra communication. Across CIFAR-10/100 with\n100/500 clients and 2-15 percent participation, FedSSG consistently outperforms\nstrong drift-aware baselines and accelerates convergence; on our benchmarks it\nimproves test accuracy by up to a few points (e.g., about +0.9 on CIFAR-10 and\nabout +2.7 on CIFAR-100 on average over the top-2 baseline) and yields about\n4.5x faster target-accuracy convergence on average. The method adds only O(d)\nclient memory and a constant-time gate, and degrades gracefully to a mild\nregularizer under near-IID or uniform sampling. FedSSG shows that sampling\nstatistics can be turned into a principled, history-aware phase control to\nstabilize and speed up federated training.", "AI": {"tldr": "FedSSG\u901a\u8fc7\u7ef4\u62a4\u6bcf\u5ba2\u6237\u7aef\u7684\u6f02\u79fb\u8bb0\u5fc6\u5e76\u57fa\u4e8e\u89c2\u6d4b/\u671f\u671b\u53c2\u4e0e\u7387\u7684\u5e73\u6ed1\u95e8\u63a7\u6765\u5728\u65e9\u671f\u6291\u5236\u566a\u58f0\u3001\u540e\u671f\u6536\u7f29\u5c40\u90e8-\u5168\u5c40\u5dee\u5f02\uff0c\u4ece\u800c\u7a33\u5b9a\u5e76\u52a0\u901f\u8054\u90a6\u5b66\u4e60\u6536\u655b", "motivation": "\u5728\u975eIID\u548c\u90e8\u5206\u53c2\u4e0e\u573a\u666f\u4e2d\uff0c\u5ba2\u6237\u7aef\u6f02\u79fb\u4e0e\u4e0d\u4e00\u81f4\u7684\u672c\u5730\u6700\u4f18\u5bfc\u81f4\u8054\u90a6\u8bad\u7ec3\u4e0d\u7a33\u5b9a\uff0c\u9700\u4e00\u79cd\u8f7b\u91cf\u4e14\u57fa\u4e8e\u7edf\u8ba1\u7684\u673a\u5236\u5728\u8bad\u7ec3\u4e0d\u540c\u9636\u6bb5\u9002\u914d\u5bf9\u9f50\u5f3a\u5ea6\u4ee5\u7a33\u5b9a\u6536\u655b", "method": "\u4e3a\u6bcf\u4e2a\u5ba2\u6237\u7aef\u7ef4\u62a4O(d)\u7684\u6f02\u79fb\u8bb0\u5fc6\uff0c\u7d2f\u79ef\u5c40\u90e8\u6a21\u578b\u5dee\u5206\u4f5c\u4e3a\u5386\u53f2\u68af\u5ea6\u7684\u8f7b\u91cf\u8349\u56fe\uff1b\u7528\u4e00\u4e2a\u5173\u4e8e\u89c2\u6d4b/\u671f\u671b\u53c2\u4e0e\u7387\u7684\u5e73\u6ed1\u51fd\u6570\u5bf9\u8bb0\u5fc6\u66f4\u65b0\u548c\u672c\u5730\u5bf9\u9f50\u9879\u8fdb\u884c\u95e8\u63a7", "result": "FedSSG\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u62bd\u6837\u7edf\u8ba1\u7684\u5386\u53f2\u611f\u77e5\u6f02\u79fb\u5bf9\u9f50\u65b9\u6cd5", "conclusion": "\u5229\u7528\u670d\u52a1\u5668\u62bd\u6837\u7684\u53c2\u4e0e\u7edf\u8ba1\u5b66\u4fe1\u53f7\u5bf9\u672c\u5730\u5bf9\u9f50\u5f3a\u5ea6\u8fdb\u884c\u9636\u6bb5\u6027\u63a7\u5236\uff0c\u53ef\u4ee5\u5728\u4e0d\u589e\u52a0\u901a\u4fe1\u7684\u524d\u63d0\u4e0b\u964d\u4f4e\u5ba2\u6237\u7aef\u6f02\u79fb\u5e76\u63d0\u5347\u6a21\u578b\u6cdb\u5316\u4e0e\u6536\u655b\u901f\u5ea6"}}
{"id": "2509.13906", "categories": ["cs.LG", "I.2.6"], "pdf": "https://arxiv.org/pdf/2509.13906", "abs": "https://arxiv.org/abs/2509.13906", "authors": ["Afrin Dange", "Sunita Sarawagi"], "title": "TFMAdapter: Lightweight Instance-Level Adaptation of Foundation Models for Forecasting with Covariates", "comment": "Accepted at CIKM 2025", "summary": "Time Series Foundation Models (TSFMs) have recently achieved state-of-the-art\nperformance in univariate forecasting on new time series simply by conditioned\non a brief history of past values. Their success demonstrates that large-scale\npretraining across diverse domains can acquire the inductive bias to generalize\nfrom temporal patterns in a brief history. However, most TSFMs are unable to\nleverage covariates -- future-available exogenous variables critical for\naccurate forecasting in many applications -- due to their domain-specific\nnature and the lack of associated inductive bias. We propose TFMAdapter, a\nlightweight, instance-level adapter that augments TSFMs with covariate\ninformation without fine-tuning. Instead of retraining, TFMAdapter operates on\nthe limited history provided during a single model call, learning a\nnon-parametric cascade that combines covariates with univariate TSFM forecasts.\nHowever, such learning would require univariate forecasts at all steps in the\nhistory, requiring too many calls to the TSFM. To enable training on the full\nhistorical context while limiting TSFM invocations, TFMAdapter uses a two-stage\nmethod: (1) generating pseudo-forecasts with a simple regression model, and (2)\ntraining a Gaussian Process regressor to refine predictions using both pseudo-\nand TSFM forecasts alongside covariates. Extensive experiments on real-world\ndatasets demonstrate that TFMAdapter consistently outperforms both foundation\nmodels and supervised baselines, achieving a 24-27\\% improvement over base\nfoundation models with minimal data and computational overhead. Our results\nhighlight the potential of lightweight adapters to bridge the gap between\ngeneric foundation models and domain-specific forecasting needs.", "AI": {"tldr": "TFMAdapter\u4e3aTSFM\u63d0\u4f9b\u65e0\u9700\u5fae\u8c03\u7684\u534f\u53d8\u91cf\u9002\u914d\uff0c\u5229\u7528\u4f2a\u9884\u6d4b+\u9ad8\u65af\u8fc7\u7a0b\u8fdb\u884c\u5386\u53f2\u5b66\u4e60\uff0c\u663e\u8457\u63d0\u5347\u9884\u6d4b\u6027\u80fd\u4e14\u5f00\u9500\u5c0f\u3002", "motivation": "\u89e3\u51b3\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\uff08TSFMs\uff09\u65e0\u6cd5\u5229\u7528\u53ef\u7528\u672a\u6765\u5916\u751f\u53d8\u91cf\uff08\u534f\u53d8\u91cf\uff09\u7684\u95ee\u9898\uff0c\u8fd9\u4e9b\u534f\u53d8\u91cf\u5bf9\u8bb8\u591a\u9884\u6d4b\u4efb\u52a1\u81f3\u5173\u91cd\u8981\u3002\u63d0\u51fa\u5728\u4e0d\u5fae\u8c03TSFM\u7684\u524d\u63d0\u4e0b\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7\u3001\u5b9e\u4f8b\u7ea7\u9002\u914d\u5668\u5c06\u534f\u53d8\u91cf\u4fe1\u606f\u878d\u5165\u9884\u6d4b\u4e2d\u3002", "method": "\u5b9e\u4f8b\u7ea7\u975e\u53c2\u6570\u7ea7\u8054\uff1a\u5728\u5355\u6b21\u8c03\u7528\u5386\u53f2\u4e0a\u751f\u6210\u4f2a\u9884\u6d4b\uff08\u7b80\u5355\u56de\u5f52\uff09\u4ee5\u51cf\u5c11TSFM\u8c03\u7528\uff0c\u7136\u540e\u8bad\u7ec3\u9ad8\u65af\u8fc7\u7a0b\u56de\u5f52\u7ed3\u5408\u4f2a\u9884\u6d4b\u3001\u6709\u9650TSFM\u9884\u6d4b\u4e0e\u534f\u53d8\u91cf\u8fdb\u884c\u8f93\u51fa\u7cbe\u70bc\u3002", "result": "\u63d0\u51faTFMAdapter\uff1a\u5728\u5355\u6b21\u6a21\u578b\u8c03\u7528\u65f6\u57fa\u4e8e\u6709\u9650\u5386\u53f2\u5b66\u4e60\u975e\u53c2\u6570\u7ea7\u8054\uff0c\u5c06\u534f\u53d8\u91cf\u4e0e\u5355\u53d8\u91cfTSFM\u9884\u6d4b\u7ed3\u5408\u3002\u901a\u8fc7\u4e24\u9636\u6bb5\u65b9\u6cd5\u51cf\u5c11\u5bf9TSFM\u8c03\u7528\u6b21\u6570\uff1a\u5148\u7528\u7b80\u5355\u56de\u5f52\u751f\u6210\u4f2a\u9884\u6d4b\uff0c\u518d\u8bad\u7ec3\u9ad8\u65af\u8fc7\u7a0b\u56de\u5f52\u4f7f\u7528\u4f2a\u9884\u6d4b\u3001TSFM\u9884\u6d4b\u4e0e\u534f\u53d8\u91cf\u8fdb\u884c\u7cbe\u70bc\u3002\u5b9e\u9a8c\u8bc1\u660e\u5728\u591a\u6570\u636e\u96c6\u4e0a\u6bd4\u57fa\u7840\u6a21\u578b\u548c\u6709\u76d1\u7763\u57fa\u7ebf\u5e73\u5747\u63d0\u534724-27%\u3002", "conclusion": "\u8f7b\u91cf\u7ea7\u9002\u914d\u5668\u80fd\u6709\u6548\u5f25\u5408\u901a\u7528\u57fa\u7840\u6a21\u578b\u4e0e\u9886\u57df\u7279\u5b9a\u534f\u53d8\u91cf\u9700\u6c42\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u5b9e\u73b0\u9ad8\u6548\u3001\u4f4e\u6210\u672c\u7684\u6027\u80fd\u63d0\u5347\u3002"}}
{"id": "2509.13908", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.13908", "abs": "https://arxiv.org/abs/2509.13908", "authors": ["Priyobrata Mondal", "Faizanuddin Ansari", "Swagatam Das"], "title": "APFEx: Adaptive Pareto Front Explorer for Intersectional Fairness", "comment": null, "summary": "Ensuring fairness in machine learning models is critical, especially when\nbiases compound across intersecting protected attributes like race, gender, and\nage. While existing methods address fairness for single attributes, they fail\nto capture the nuanced, multiplicative biases faced by intersectional\nsubgroups. We introduce Adaptive Pareto Front Explorer (APFEx), the first\nframework to explicitly model intersectional fairness as a joint optimization\nproblem over the Cartesian product of sensitive attributes. APFEx combines\nthree key innovations- (1) an adaptive multi-objective optimizer that\ndynamically switches between Pareto cone projection, gradient weighting, and\nexploration strategies to navigate fairness-accuracy trade-offs, (2)\ndifferentiable intersectional fairness metrics enabling gradient-based\noptimization of non-smooth subgroup disparities, and (3) theoretical guarantees\nof convergence to Pareto-optimal solutions. Experiments on four real-world\ndatasets demonstrate APFEx's superiority, reducing fairness violations while\nmaintaining competitive accuracy. Our work bridges a critical gap in fair ML,\nproviding a scalable, model-agnostic solution for intersectional fairness.", "AI": {"tldr": "APFEx\u63d0\u51fa\u4e00\u79cd\u81ea\u9002\u5e94\u591a\u76ee\u6807\u3001\u53ef\u5fae\u5206\u6307\u6807\u5e76\u6709\u6536\u655b\u4fdd\u8bc1\u7684\u6846\u67b6\uff0c\u4e13\u95e8\u7528\u4e8e\u4ea4\u53c9\u654f\u611f\u5c5e\u6027\u7684\u516c\u5e73\u6027\u4f18\u5316\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5728\u516c\u5e73\u6027-\u51c6\u786e\u7387\u6743\u8861\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u591a\u9488\u5bf9\u5355\u4e00\u654f\u611f\u5c5e\u6027\uff0c\u65e0\u6cd5\u6355\u6349\u5728\u591a\u4e2a\u654f\u611f\u5c5e\u6027\u4ea4\u53c9\u4e0b\u7684\u4e58\u6cd5\u6027\u504f\u5dee\uff0c\u9700\u4e00\u79cd\u663e\u5f0f\u5efa\u6a21\u4ea4\u53c9\u516c\u5e73\u6027\u7684\u8054\u5408\u4f18\u5316\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u81ea\u9002\u5e94\u591a\u76ee\u6807\u4f18\u5316\u5668\uff0c\u7ed3\u5408\u5e15\u7d2f\u6258\u9525\u6295\u5f71\u3001\u68af\u5ea6\u52a0\u6743\u548c\u63a2\u7d22\u7b56\u7565\uff1b\u5f15\u5165\u53ef\u5fae\u5206\u7684\u4ea4\u53c9\u7fa4\u4f53\u516c\u5e73\u6027\u6307\u6807\u4ee5\u652f\u6301\u57fa\u4e8e\u68af\u5ea6\u7684\u4f18\u5316\uff1b\u5e76\u7ed9\u51fa\u6536\u655b\u5230\u5e15\u7d2f\u6258\u6700\u4f18\u89e3\u7684\u7406\u8bba\u4fdd\u8bc1\u3002", "result": "\u5728\u56db\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\uff0cAPFEx\u51cf\u5c11\u4e86\u516c\u5e73\u6027\u8fdd\u89c4\uff08\u4ea4\u53c9\u7fa4\u4f53\u5dee\u5f02\uff09\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6709\u7ade\u4e89\u529b\u7684\u9884\u6d4b\u51c6\u786e\u7387\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86APFEx\u6846\u67b6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4ea4\u53c9\u654f\u611f\u5c5e\u6027\u4e0b\u7684\u516c\u5e73\u6027\uff0c\u540c\u65f6\u5728\u51c6\u786e\u7387\u4e0a\u4fdd\u6301\u7ade\u4e89\u529b\u3002"}}
{"id": "2509.13914", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.13914", "abs": "https://arxiv.org/abs/2509.13914", "authors": ["Divya Thuremella", "Yi Yang", "Simon Wanna", "Lars Kunze", "Daniele De Martini"], "title": "Ensemble of Pre-Trained Models for Long-Tailed Trajectory Prediction", "comment": "Accepted 2025 IEEE International Conference on Intelligent\n  Transportation Systems (ITSC 2025)", "summary": "This work explores the application of ensemble modeling to the\nmultidimensional regression problem of trajectory prediction for vehicles in\nurban environments. As newer and bigger state-of-the-art prediction models for\nautonomous driving continue to emerge, an important open challenge is the\nproblem of how to combine the strengths of these big models without the need\nfor costly re-training. We show how, perhaps surprisingly, combining\nstate-of-the-art deep learning models out-of-the-box (without retraining or\nfine-tuning) with a simple confidence-weighted average method can enhance the\noverall prediction. Indeed, while combining trajectory prediction models is not\nstraightforward, this simple approach enhances performance by 10% over the best\nprediction model, especially in the long-tailed metrics. We show that this\nperformance improvement holds on both the NuScenes and Argoverse datasets, and\nthat these improvements are made across the dataset distribution. The code for\nour work is open source.", "AI": {"tldr": "TL;DR\uff1a\u5bf9\u591a\u4e2a\u73b0\u6709\u8f66\u8f86\u8f68\u8ff9\u9884\u6d4b\u6a21\u578b\u8fdb\u884c\u65e0\u9700\u91cd\u8bad\u7ec3\u7684\u7f6e\u4fe1\u5ea6\u52a0\u6743\u5e73\u5747\uff0c\u53ef\u5728NuScenes\u548cArgoverse\u4e0a\u5c06\u6027\u80fd\u63d0\u5347\u7ea610%\uff0c\u5bf9\u957f\u5c3e\u573a\u666f\u63d0\u5347\u66f4\u5927\uff0c\u4e14\u4ee3\u7801\u5f00\u6e90\u3002", "motivation": "\u52a8\u673a\u662f\uff1a\u968f\u7740\u66f4\u5927\u66f4\u5f3a\u7684\u65e0\u4eba\u9a7e\u9a76\u8f68\u8ff9\u9884\u6d4b\u6a21\u578b\u4e0d\u65ad\u51fa\u73b0\uff0c\u5982\u4f55\u5728\u4e0d\u8017\u8d39\u5927\u91cf\u8ba1\u7b97\u8d44\u6e90\u548c\u65f6\u95f4\u8fdb\u884c\u91cd\u8bad\u7ec3\u7684\u524d\u63d0\u4e0b\uff0c\u7ed3\u5408\u8fd9\u4e9b\u6a21\u578b\u7684\u4f18\u70b9\u4ee5\u63d0\u5347\u9884\u6d4b\u6548\u679c\uff0c\u6210\u4e3a\u4e00\u4e2a\u5b9e\u9645\u4e14\u91cd\u8981\u7684\u95ee\u9898\u3002\u4f5c\u8005\u5e0c\u671b\u627e\u5230\u4e00\u79cd\u7b80\u5355\u6709\u6548\u4e14\u53ef\u76f4\u63a5\u5e94\u7528\u4e8e\u73b0\u6709\u6a21\u578b\u7684\u96c6\u6210\u65b9\u6848\u3002", "method": "\u65b9\u6cd5\u662f\u91c7\u7528\u7b80\u5355\u7684\u7f6e\u4fe1\u5ea6\u52a0\u6743\u5e73\u5747\u5c06\u591a\u4e2a\u5df2\u6709\u8f68\u8ff9\u9884\u6d4b\u6a21\u578b\u7684\u8f93\u51fa\u8fdb\u884c\u878d\u5408\uff0c\u65e0\u9700\u5bf9\u6a21\u578b\u8fdb\u884c\u91cd\u8bad\u7ec3\u6216\u5fae\u8c03\u3002\u5177\u4f53\u6d41\u7a0b\u5305\u62ec\uff1a\u4ece\u6bcf\u4e2a\u57fa\u6a21\u578b\u83b7\u53d6\u591a\u6a21\u6001\u8f68\u8ff9\u9884\u6d4b\u53ca\u5176\u7f6e\u4fe1\u5ea6\u8bc4\u5206\uff0c\u6309\u7f6e\u4fe1\u5ea6\u5bf9\u5404\u9884\u6d4b\u8fdb\u884c\u52a0\u6743\u5e73\u5747\u4ee5\u751f\u6210\u6700\u7ec8\u9884\u6d4b\u3002\u8bc4\u4f30\u5728NuScenes\u548cArgoverse\u6570\u636e\u96c6\u4e0a\u5b8c\u6210\uff0c\u5e76\u5728\u6574\u4f53\u4e0e\u957f\u5c3e\u6307\u6807\u4e0a\u4e0e\u5355\u4e00\u6700\u4f73\u6a21\u578b\u6bd4\u8f83\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff1a\u7f6e\u4fe1\u52a0\u6743\u5e73\u5747\u7684\u7b80\u5355\u96c6\u6210\u65b9\u5f0f\u5728\u4e24\u4e2a\u4e3b\u6d41\u6570\u636e\u96c6\u4e0a\u5747\u4f18\u4e8e\u5355\u4e00\u6700\u5148\u8fdb\u6a21\u578b\uff0c\u6574\u4f53\u6027\u80fd\u63d0\u5347\u7ea610%\uff0c\u5728\u957f\u5c3e\uff08\u5c11\u89c1\u573a\u666f/\u6781\u7aef\u60c5\u5f62\uff09\u6307\u6807\u4e0a\u63d0\u5347\u66f4\u4e3a\u663e\u8457\u3002\u6027\u80fd\u63d0\u5347\u5728\u6570\u636e\u5206\u5e03\u5404\u4e2a\u90e8\u5206\u5747\u6709\u4f53\u73b0\uff0c\u4e14\u65b9\u6cd5\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u5f00\u9500\u3002", "conclusion": "\u8bba\u6587\u7ed3\u8bba\u662f\uff1a\u5728\u65e0\u4eba\u9a7e\u9a76\u8f66\u8f86\u8f68\u8ff9\u9884\u6d4b\u7684\u591a\u7ef4\u56de\u5f52\u4efb\u52a1\u4e2d\uff0c\u76f4\u63a5\u5bf9\u82e5\u5e72\u6700\u5148\u8fdb\u6df1\u5ea6\u5b66\u4e60\u9884\u6d4b\u6a21\u578b\u8fdb\u884c\u65e0\u91cd\u8bad\u7ec3\u7684\u7f6e\u4fe1\u52a0\u6743\u5e73\u5747\uff08confidence-weighted average\uff09\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u6574\u4f53\u9884\u6d4b\u6027\u80fd\u3002\u8be5\u7b80\u5355\u96c6\u6210\u65b9\u6cd5\u5728NuScenes\u548cArgoverse\u4e24\u4e2a\u6570\u636e\u96c6\u4e0a\u5747\u63d0\u5347\u4e86\u6027\u80fd\uff0c\u5c24\u5176\u5728\u957f\u5c3e\u8bc4\u4f30\u6307\u6807\u4e0a\u63d0\u5347\u660e\u663e\uff08\u7ea610%\u76f8\u8f83\u4e8e\u6700\u4f18\u5355\u6a21\u578b\uff09\u3002\u4f5c\u8005\u5e76\u5f00\u6e90\u4e86\u4ee3\u7801\u3002"}}
{"id": "2509.13952", "categories": ["cs.LG", "cs.NA", "math.NA"], "pdf": "https://arxiv.org/pdf/2509.13952", "abs": "https://arxiv.org/abs/2509.13952", "authors": ["Amin Lotfalian", "Mohammad Reza Banan", "Pooyan Broumand"], "title": "eXtended Physics Informed Neural Network Method for Fracture Mechanics Problems", "comment": null, "summary": "This paper presents eXtended Physics-Informed Neural Network (X-PINN), a\nnovel and robust framework for addressing fracture mechanics problems involving\nmultiple cracks in fractured media. To address this, an energy-based loss\nfunction, customized integration schemes, and domain decomposition procedures\nare proposed. Inspired by the Extended Finite Element Method (XFEM), the neural\nnetwork solution space is enriched with specialized functions that allow crack\nbody discontinuities and singularities at crack tips to be explicitly captured.\nFurthermore, a structured framework is introduced in which standard and\nenriched solution components are modeled using distinct neural networks,\nenabling flexible and effective simulations of complex multiple-crack problems\nin 1D and 2D domains, with convenient extensibility to 3D problems. Numerical\nexperiments are conducted to validate the effectiveness and robustness of the\nproposed method.", "AI": {"tldr": "X-PINN augments PINNs with XFEM-inspired enrichment functions, energy-based loss, tailored integration and domain decomposition, and separate networks for enriched/standard parts to effectively simulate multiple cracks; tested in 1D/2D.", "motivation": "Develop a robust PINN framework to handle fracture mechanics with multiple cracks by incorporating XFEM-like enrichments to capture discontinuities and singularities, and by using energy-based losses, custom integration and domain decomposition.", "method": "Enrich neural network solution space with crack-specific functions (discontinuous and singular), use energy-based loss for variational consistency, implement customized numerical integration and domain decomposition, and assign distinct neural networks to standard vs enriched components.", "result": "Proposed X-PINN: enriched PINN solution space with specialized functions, separate networks for standard and enriched components, energy-based loss, customized integration schemes, domain decomposition; validated via numerical experiments in 1D and 2D, extensible to 3D.", "conclusion": "X-PINN effectively and robustly models multiple-crack fracture mechanics by explicitly representing discontinuities and singularities, offering flexibility and extensibility to higher dimensions."}}
{"id": "2509.13974", "categories": ["cs.LG", "eess.SP"], "pdf": "https://arxiv.org/pdf/2509.13974", "abs": "https://arxiv.org/abs/2509.13974", "authors": ["Amirhossein Shahbazinia", "Jonathan Dan", "Jose A. Miranda", "Giovanni Ansaloni", "David Atienza"], "title": "Personalization on a Budget: Minimally-Labeled Continual Learning for Resource-Efficient Seizure Detection", "comment": null, "summary": "Objective: Epilepsy, a prevalent neurological disease, demands careful\ndiagnosis and continuous care. Seizure detection remains challenging, as\ncurrent clinical practice relies on expert analysis of electroencephalography,\nwhich is a time-consuming process and requires specialized knowledge.\nAddressing this challenge, this paper explores automated epileptic seizure\ndetection using deep learning, focusing on personalized continual learning\nmodels that adapt to each patient's unique electroencephalography signal\nfeatures, which evolve over time. Methods: In this context, our approach\naddresses the challenge of integrating new data into existing models without\ncatastrophic forgetting, a common issue in static deep learning models. We\npropose EpiSMART, a continual learning framework for seizure detection that\nuses a size-constrained replay buffer and an informed sample selection strategy\nto incrementally adapt to patient-specific electroencephalography signals. By\nselectively retaining high-entropy and seizure-predicted samples, our method\npreserves critical past information while maintaining high performance with\nminimal memory and computational requirements. Results: Validation on the\nCHB-MIT dataset, shows that EpiSMART achieves a 21% improvement in the F1 score\nover a trained baseline without updates in all other patients. On average,\nEpiSMART requires only 6.46 minutes of labeled data and 6.28 updates per day,\nmaking it suitable for real-time deployment in wearable systems.\nConclusion:EpiSMART enables robust and personalized seizure detection under\nrealistic and resource-constrained conditions by effectively integrating new\ndata into existing models without degrading past knowledge. Significance: This\nframework advances automated seizure detection by providing a continual\nlearning approach that supports patient-specific adaptation and practical\ndeployment in wearable healthcare systems.", "AI": {"tldr": "EpiSMART\u901a\u8fc7\u53d7\u9650\u91cd\u653e\u4e0e\u9ad8\u4fe1\u606f\u91cf\u6837\u672c\u9009\u62e9\uff0c\u5b9e\u73b0\u4e86\u4f4e\u5185\u5b58\u5f00\u9500\u7684\u4e2a\u6027\u5316\u6301\u7eed\u766b\u75eb\u53d1\u4f5c\u68c0\u6d4b\uff0c\u5728CHB-MIT\u4e0aF1\u63d0\u9ad821%\uff0c\u9002\u5408\u53ef\u7a7f\u6234\u5b9e\u65f6\u90e8\u7f72\u3002", "motivation": "\u4e34\u5e8aEEG\u5206\u6790\u8d39\u65f6\u9700\u4e13\u4e1a\u77e5\u8bc6\uff0c\u75c5\u4ebaEEG\u4fe1\u53f7\u968f\u65f6\u95f4\u53d8\u5316\uff0c\u9759\u6001\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u65e0\u6cd5\u6709\u6548\u9002\u5e94\u65b0\u6570\u636e\u4e14\u4f1a\u51fa\u73b0\u707e\u96be\u6027\u9057\u5fd8\uff0c\u56e0\u6b64\u9700\u9762\u5411\u53ef\u7a7f\u6234\u5b9e\u65f6\u90e8\u7f72\u7684\u4e2a\u6027\u5316\u6301\u7eed\u5b66\u4e60\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86EpiSMART\u6301\u7eed\u5b66\u4e60\u6846\u67b6\uff0c\u4f7f\u7528\u6709\u9650\u5927\u5c0f\u7684\u91cd\u653e\u7f13\u51b2\u533a\u548c\u57fa\u4e8e\u4fe1\u606f\u91cf\u7684\u6837\u672c\u9009\u62e9\u7b56\u7565\uff08\u9ad8\u71b5\u548c\u88ab\u9884\u6d4b\u4e3a\u53d1\u4f5c\u7684\u6837\u672c\uff09\u8fdb\u884c\u589e\u91cf\u66f4\u65b0\uff0c\u4ee5\u4fdd\u5b58\u5173\u952e\u5386\u53f2\u4fe1\u606f\u5e76\u51cf\u5c11\u5b58\u50a8\u4e0e\u8ba1\u7b97\u9700\u6c42\u3002", "result": "\u5728CHB-MIT\u6570\u636e\u96c6\u4e0a\uff0c\u76f8\u8f83\u4e8e\u4e0d\u66f4\u65b0\u7684\u8bad\u7ec3\u57fa\u7ebf\uff0cF1\u5206\u6570\u5e73\u5747\u63d0\u534721%\uff1b\u5e73\u5747\u53ea\u97006.46\u5206\u949f\u6807\u6ce8\u6570\u636e\u548c6.28\u6b21\u66f4\u65b0/\u5929\uff0c\u9002\u5408\u5b9e\u65f6\u53ef\u7a7f\u6234\u7cfb\u7edf\u3002", "conclusion": "EpiSMART\u80fd\u5728\u8d44\u6e90\u53d7\u9650\u7684\u6761\u4ef6\u4e0b\uff0c\u901a\u8fc7\u9009\u62e9\u6027\u56de\u653e\u548c\u5728\u7ebf\u66f4\u65b0\u907f\u514d\u707e\u96be\u6027\u9057\u5fd8\uff0c\u5b9e\u73b0\u4e2a\u6027\u5316\u766b\u75eb\u53d1\u4f5c\u68c0\u6d4b\uff0c\u4e14\u5728CHB-MIT\u6570\u636e\u96c6\u4e0a\u663e\u8457\u4f18\u4e8e\u9759\u6001\u57fa\u7ebf\u3002"}}
{"id": "2509.14000", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.14000", "abs": "https://arxiv.org/abs/2509.14000", "authors": ["Ivana Kesi\u0107", "Alja\u017e Blatnik", "Carolina Fortuna", "Bla\u017e Bertalani\u010d"], "title": "Deep Temporal Graph Networks for Real-Time Correction of GNSS Jamming-Induced Deviations", "comment": "20 pages, 4 figures", "summary": "Global Navigation Satellite Systems (GNSS) are increasingly disrupted by\nintentional jamming, degrading availability precisely when positioning and\ntiming must remain operational. We address this by reframing jamming mitigation\nas dynamic graph regression and introducing a receiver-centric deep temporal\ngraph network that predicts, and thus corrects, the receivers horizontal\ndeviation in real time. At each 1 Hz epoch, the satellite receiver environment\nis represented as a heterogeneous star graph (receiver center, tracked\nsatellites as leaves) with time varying attributes (e.g., SNR, azimuth,\nelevation, latitude/longitude). A single layer Heterogeneous Graph ConvLSTM\n(HeteroGCLSTM) aggregates one hop spatial context and temporal dynamics over a\nshort history to output the 2D deviation vector applied for on the fly\ncorrection.\n  We evaluate on datasets from two distinct receivers under three jammer\nprofiles, continuous wave (cw), triple tone (cw3), and wideband FM, each\nexercised at six power levels between -45 and -70 dBm, with 50 repetitions per\nscenario (prejam/jam/recovery). Against strong multivariate time series\nbaselines (MLP, uniform CNN, and Seq2Point CNN), our model consistently attains\nthe lowest mean absolute error (MAE). At -45 dBm, it achieves 3.64 cm\n(GP01/cw), 7.74 cm (GP01/cw3), 4.41 cm (ublox/cw), 4.84 cm (ublox/cw3), and\n4.82 cm (ublox/FM), improving to 1.65-2.08 cm by -60 to -70 dBm. On mixed mode\ndatasets pooling all powers, MAE is 3.78 cm (GP01) and 4.25 cm (ublox10),\noutperforming Seq2Point, MLP, and CNN. A split study shows superior data\nefficiency: with only 10\\% training data our approach remains well ahead of\nbaselines (20 cm vs. 36-42 cm).", "AI": {"tldr": "\u8be5\u5de5\u4f5c\u5c06GNSS\u6297\u5e72\u6270\u89c6\u4e3a\u52a8\u6001\u56fe\u56de\u5f52\uff0c\u63d0\u51fa\u4ee5\u63a5\u6536\u673a\u4e3a\u4e2d\u5fc3\u7684\u65f6\u5e8f\u5f02\u6784\u56fe\u7f51\u7edc\uff08HeteroGCLSTM\uff09\uff0c\u57281 Hz\u60c5\u51b5\u4e0b\u57fa\u4e8e\u536b\u661f-\u63a5\u6536\u673a\u661f\u5f62\u56fe\u9884\u6d4b\u5e76\u4fee\u6b63\u6c34\u5e73\u504f\u5dee\uff0c\u5b9e\u73b0\u5b9e\u65f6\u5b9a\u4f4d\u6821\u6b63\u3002", "motivation": "\u9762\u5bf9\u65e5\u76ca\u4e25\u91cd\u7684\u6545\u610f\u5e72\u6270\u5bfc\u81f4GNSS\u53ef\u7528\u6027\u4e0b\u964d\uff0c\u9700\u5728\u5e72\u6270\u53d1\u751f\u65f6\u5b9e\u65f6\u4fdd\u6301\u5b9a\u4f4d/\u5b9a\u65f6\u529f\u80fd\uff0c\u56e0\u6b64\u5c06\u5e72\u6270\u7f13\u89e3\u95ee\u9898\u8868\u8ff0\u4e3a\u63a5\u6536\u673a\u4e2d\u5fc3\u7684\u52a8\u6001\u56fe\u56de\u5f52\u4ee5\u5b9e\u73b0\u5728\u7ebf\u8bef\u5dee\u9884\u6d4b\u548c\u6821\u6b63\u3002", "method": "\u5728\u6bcf\u79d2\u6784\u5efa\u4ee5\u63a5\u6536\u673a\u4e3a\u4e2d\u5fc3\u3001\u8ddf\u8e2a\u536b\u661f\u4e3a\u53f6\u8282\u70b9\u7684\u5f02\u6784\u661f\u5f62\u56fe\uff0c\u8282\u70b9\u5e26\u65f6\u53d8\u5c5e\u6027\uff08SNR\u3001\u65b9\u4f4d\u3001\u4ef0\u89d2\u3001\u7ecf\u7eac\u5ea6\u7b49\uff09\u3002\u63d0\u51fa\u5355\u5c42Heterogeneous Graph ConvLSTM\u805a\u5408\u4e00\u8df3\u7a7a\u95f4\u4e0a\u4e0b\u6587\u5e76\u5efa\u6a21\u77ed\u65f6\u5e8f\u5386\u53f2\uff0c\u8f93\u51fa2D\u504f\u5dee\u5411\u91cf\u7528\u4e8e\u5b9e\u65f6\u4fee\u6b63\u3002", "result": "\u5728\u4e24\u4e2a\u63a5\u6536\u673a\uff08GP01, ublox\uff09\u548c\u4e09\u7c7b\u5e72\u6270\uff08cw, cw3, FM\uff09\u4e0a\u3001\u529f\u7387-45\u81f3-70 dBm\u7684\u591a\u4e2a\u60c5\u666f\u4e0e\u91cd\u590d\u8bd5\u9a8c\u4e2d\uff0c\u63d0\u51fa\u6a21\u578b\u5728MAE\u4e0a\u6301\u7eed\u9886\u5148\uff1a\u4f8b\u5982\u5728-45 dBm\u65f6GP01\u5bf9cw\u4e3a3.64 cm\uff0cublox\u5bf9cw\u4e3a4.41 cm\uff0c\u529f\u7387\u964d\u4f4e\u5230-60\u81f3-70 dBm\u65f6MAE\u4e0b\u964d\u52301.65\u20132.08 cm\u3002\u6df7\u5408\u529f\u7387\u6570\u636e\u4e0aGP01\u4e3a3.78 cm\uff0cublox10\u4e3a4.25 cm\u3002\u4ec5\u752810%\u8bad\u7ec3\u6570\u636e\u65f6\u4ecd\u4ee5\u7ea620 cm MAE\u4f18\u4e8e\u57fa\u7ebf\u768436\u201342 cm\u3002", "conclusion": "\u6a21\u578b\u5728\u4e24\u7c7b\u63a5\u6536\u673a\u4e0e\u4e09\u79cd\u5e72\u6270\u5668\uff08cw\u3001cw3\u3001FM\uff09\u53ca\u591a\u529f\u7387\u6c34\u5e73\u4e0a\u5747\u663e\u8457\u4f18\u4e8eMLP\u3001CNN\u3001Seq2Point\u7b49\u57fa\u7ebf\uff0cMAE\u6700\u4f4e\u53ef\u8fbe\u7ea61.65\u20132.08 cm\uff08\u4f4e\u529f\u7387\u5e72\u6270\uff09\uff0c\u603b\u4f53\u6df7\u5408\u6570\u636eMAE\u7ea63.8\u20134.3 cm\uff1b\u6570\u636e\u6548\u7387\u4e5f\u66f4\u597d\uff0c10%\u8bad\u7ec3\u6570\u636e\u4ecd\u4f18\u4e8e\u57fa\u7ebf\u3002"}}
{"id": "2509.14061", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.14061", "abs": "https://arxiv.org/abs/2509.14061", "authors": ["Chiara De Luca", "Elisa Donati"], "title": "Queen Detection in Beehives via Environmental Sensor Fusion for Low-Power Edge Computing", "comment": null, "summary": "Queen bee presence is essential for the health and stability of honeybee\ncolonies, yet current monitoring methods rely on manual inspections that are\nlabor-intensive, disruptive, and impractical for large-scale beekeeping. While\nrecent audio-based approaches have shown promise, they often require high power\nconsumption, complex preprocessing, and are susceptible to ambient noise. To\novercome these limitations, we propose a lightweight, multimodal system for\nqueen detection based on environmental sensor fusion-specifically, temperature,\nhumidity, and pressure differentials between the inside and outside of the\nhive. Our approach employs quantized decision tree inference on a commercial\nSTM32 microcontroller, enabling real-time, low-power edge computing without\ncompromising accuracy. We show that our system achieves over 99% queen\ndetection accuracy using only environmental inputs, with audio features\noffering no significant performance gain. This work presents a scalable and\nsustainable solution for non-invasive hive monitoring, paving the way for\nautonomous, precision beekeeping using off-the-shelf, energy-efficient\nhardware.", "AI": {"tldr": "\u901a\u8fc7\u73af\u5883\u4f20\u611f\u5668\u878d\u5408\u4e0e\u91cf\u5316\u51b3\u7b56\u6811\u5728STM32\u4e0a\u5b9e\u73b0\u4f4e\u529f\u8017\u3001\u9ad8\u51c6\u786e\u7684\u8702\u738b\u68c0\u6d4b\uff0c\u4f18\u4e8e\u53d7\u566a\u58f0\u5f71\u54cd\u7684\u97f3\u9891\u65b9\u6cd5\uff0c\u9002\u5408\u53ef\u6269\u5c55\u7684\u975e\u4fb5\u5165\u6027\u8702\u7bb1\u76d1\u6d4b\u3002", "motivation": "\u4f20\u7edf\u4eba\u5de5\u68c0\u67e5\u8017\u65f6\u4e14\u6270\u52a8\u8702\u7fa4\uff0c\u73b0\u6709\u57fa\u4e8e\u97f3\u9891\u7684\u65b9\u6cd5\u529f\u8017\u9ad8\u3001\u9700\u590d\u6742\u9884\u5904\u7406\u4e14\u6613\u53d7\u566a\u58f0\u5f71\u54cd\uff0c\u9700\u4e00\u79cd\u4f4e\u529f\u8017\u3001\u9c81\u68d2\u4e14\u53ef\u6269\u5c55\u7684\u8702\u738b\u68c0\u6d4b\u65b9\u6848\u3002", "method": "\u4f5c\u8005\u4f7f\u7528\u6e29\u5ea6\u3001\u6e7f\u5ea6\u548c\u5185\u5916\u538b\u529b\u5dee\u4f5c\u4e3a\u8f93\u5165\u7279\u5f81\uff0c\u6784\u5efa\u5e76\u91cf\u5316\u51b3\u7b56\u6811\u6a21\u578b\uff0c\u5728\u5546\u7528STM32\u5fae\u63a7\u5236\u5668\u4e0a\u8fdb\u884c\u63a8\u7406\uff0c\u6bd4\u8f83\u52a0\u5165\u97f3\u9891\u7279\u5f81\u524d\u540e\u7684\u6027\u80fd\u548c\u529f\u8017\u5dee\u5f02\u3002", "result": "\u5728\u4ec5\u4f7f\u7528\u73af\u5883\u4f20\u611f\u5668\u8f93\u5165\u65f6\uff0c\u7cfb\u7edf\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u5b9e\u73b0\u4e86\u8d85\u8fc799%\u7684\u8702\u738b\u68c0\u6d4b\u51c6\u786e\u7387\uff0c\u97f3\u9891\u7279\u5f81\u5e76\u672a\u5e26\u6765\u663e\u8457\u6027\u80fd\u63d0\u5347\uff0c\u4e14\u6574\u4f53\u7cfb\u7edf\u529f\u8017\u4f4e\uff0c\u9002\u5408\u5927\u89c4\u6a21\u90e8\u7f72\u3002", "conclusion": "\u8be5\u8bba\u6587\u8bc1\u660e\u901a\u8fc7\u73af\u5883\u4f20\u611f\u5668\uff08\u6e29\u5ea6\u3001\u6e7f\u5ea6\u3001\u5185\u5916\u538b\u529b\u5dee\uff09\u878d\u5408\uff0c\u53ef\u5728\u4f4e\u529f\u8017STM32\u8fb9\u7f18\u8bbe\u5907\u4e0a\u4ee5\u91cf\u5316\u51b3\u7b56\u6811\u5b9e\u73b0\u5b9e\u65f6\u8702\u738b\u68c0\u6d4b\uff0c\u8fbe\u5230\u8d85\u8fc799%\u7684\u51c6\u786e\u7387\uff0c\u4ece\u800c\u63d0\u4f9b\u4e00\u79cd\u53ef\u6269\u5c55\u3001\u975e\u5165\u4fb5\u7684\u8702\u7bb1\u76d1\u6d4b\u65b9\u6848\u3002"}}
{"id": "2509.14024", "categories": ["cs.LG", "68T07, 68P27, 92-08, 92-10"], "pdf": "https://arxiv.org/pdf/2509.14024", "abs": "https://arxiv.org/abs/2509.14024", "authors": ["Raouf Kerkouche", "Henrik Zunker", "Mario Fritz", "Martin J. K\u00fchn"], "title": "Differentially private federated learning for localized control of infectious disease dynamics", "comment": "18 pages, 6 figures", "summary": "In times of epidemics, swift reaction is necessary to mitigate epidemic\nspreading. For this reaction, localized approaches have several advantages,\nlimiting necessary resources and reducing the impact of interventions on a\nlarger scale. However, training a separate machine learning (ML) model on a\nlocal scale is often not feasible due to limited available data. Centralizing\nthe data is also challenging because of its high sensitivity and privacy\nconstraints. In this study, we consider a localized strategy based on the\nGerman counties and communities managed by the related local health authorities\n(LHA). For the preservation of privacy to not oppose the availability of\ndetailed situational data, we propose a privacy-preserving forecasting method\nthat can assist public health experts and decision makers. ML methods with\nfederated learning (FL) train a shared model without centralizing raw data.\nConsidering the counties, communities or LHAs as clients and finding a balance\nbetween utility and privacy, we study a FL framework with client-level\ndifferential privacy (DP). We train a shared multilayer perceptron on sliding\nwindows of recent case counts to forecast the number of cases, while clients\nexchange only norm-clipped updates and the server aggregated updates with DP\nnoise. We evaluate the approach on COVID-19 data on county-level during two\nphases. As expected, very strict privacy yields unstable, unusable forecasts.\nAt a moderately strong level, the DP model closely approaches the non-DP model:\n$R^2= 0.94$ (vs. 0.95) and mean absolute percentage error (MAPE) of 26 % in\nNovember 2020; $R^2= 0.88$ (vs. 0.93) and MAPE of 21 % in March 2022. Overall,\nclient-level DP-FL can deliver useful county-level predictions with strong\nprivacy guarantees, and viable privacy budgets depend on epidemic phase,\nallowing privacy-compliant collaboration among health authorities for local\nforecasting.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5728\u8054\u90a6\u5b66\u4e60(FL)\u6846\u67b6\u4e0b\u7ed3\u5408\u5ba2\u6237\u7ea7\u5dee\u5206\u9690\u79c1(DP)\u7684\u6d41\u884c\u75c5\u9884\u6d4b\u65b9\u6cd5\uff0c\u4ee5\u5fb7\u56fd\u53bf\u5e02\u7ea7COVID-19\u6570\u636e\u4e3a\u4f8b\uff0c\u4f7f\u7528\u591a\u5c42\u611f\u77e5\u5668\u57fa\u4e8e\u6ed1\u52a8\u7a97\u53e3\u75c5\u4f8b\u6570\u8fdb\u884c\u77ed\u671f\u9884\u6d4b\u3002\u5b9e\u9a8c\u663e\u793a\u5728\u9002\u5ea6\u9690\u79c1\u4fdd\u62a4\u4e0b\uff0cDP\u6a21\u578b\u7684\u6027\u80fd\u63a5\u8fd1\u975eDP\u6a21\u578b\uff08\u4f8b\u5982\u57282020\u5e7411\u6708R^2=0.94 vs 0.95\uff0cMAPE 26%\uff1b2022\u5e743\u6708R^2=0.88 vs 0.93\uff0cMAPE 21%\uff09\uff0c\u800c\u8fc7\u5f3a\u9690\u79c1\u4f1a\u5bfc\u81f4\u9884\u6d4b\u4e0d\u7a33\u5b9a\u3002\u8be5\u65b9\u6cd5\u53ef\u5728\u4fdd\u8bc1\u9690\u79c1\u524d\u63d0\u4e0b\u652f\u6301\u5730\u65b9\u536b\u751f\u90e8\u95e8\u534f\u4f5c\u9884\u6d4b\u3002", "motivation": "\u5730\u65b9\u536b\u751f\u5f53\u5c40\u9700\u8981\u57fa\u4e8e\u654f\u611f\u75c5\u4f8b\u6570\u636e\u7684\u7cbe\u7ec6\u5316\u9884\u6d4b\uff0c\u4f46\u53d7\u6570\u636e\u91cf\u6709\u9650\u4e0e\u9690\u79c1\u9650\u5236\u5f71\u54cd\uff0c\u65e0\u6cd5\u96c6\u4e2d\u8bad\u7ec3\u6216\u5355\u72ec\u8bad\u7ec3\u6a21\u578b\uff0c\u6545\u63d0\u51fa\u5728\u4fdd\u62a4\u9690\u79c1\u7684\u524d\u63d0\u4e0b\u5b9e\u73b0\u8de8\u533a\u57df\u534f\u4f5c\u7684\u9884\u6d4b\u65b9\u6cd5\u3002", "method": "\u5c06\u5404\u53bf/\u793e\u533a\u89c6\u4e3aFL\u5ba2\u6237\u7aef\uff0c\u8bad\u7ec3\u5171\u4eab\u591a\u5c42\u611f\u77e5\u5668\uff1b\u8f93\u5165\u4e3a\u6700\u8fd1\u75c5\u4f8b\u6570\u7684\u6ed1\u52a8\u7a97\u53e3\uff1b\u5ba2\u6237\u7aef\u4ec5\u4e0a\u4f20\u7ecf\u8303\u6570\u88c1\u526a\u7684\u53c2\u6570\u66f4\u65b0\uff0c\u670d\u52a1\u5668\u5728\u805a\u5408\u65f6\u52a0\u5165DP\u566a\u58f0\uff1b\u8bc4\u4f30\u6307\u6807\u5305\u62ecR^2\u548cMAPE\uff0c\u5728\u4e24\u4e2a\u75ab\u60c5\u9636\u6bb5\uff082020\u5e7411\u6708\u30012022\u5e743\u6708\uff09\u4e0a\u6bd4\u8f83DP\u4e0e\u975eDP\u6a21\u578b\u3002", "result": "\u5728\u4e2d\u7b49\u5f3a\u5ea6\u9690\u79c1\u4fdd\u62a4\u4e0b\uff0cDP-FL\u6a21\u578b\u6027\u80fd\u63a5\u8fd1\u975eDP\uff1a2020\u5e7411\u6708R^2=0.94 vs 0.95\uff0cMAPE 26%\uff1b2022\u5e743\u6708R^2=0.88 vs 0.93\uff0cMAPE 21%\uff1b\u8fc7\u5f3a\u9690\u79c1\u5bfc\u81f4\u6a21\u578b\u4e0d\u53ef\u7528\u3002", "conclusion": "\u5728\u5408\u7406\u7684\u9690\u79c1\u9884\u7b97\u4e0b\uff0c\u5ba2\u6237\u7aef\u7ea7\u5dee\u5206\u9690\u79c1\u7684\u8054\u90a6\u5b66\u4e60\u80fd\u5728\u53bf\u7ea7\u63d0\u4f9b\u6709\u7528\u7684\u75ab\u60c5\u77ed\u671f\u9884\u6d4b\uff0c\u9690\u79c1\u9884\u7b97\u9700\u6839\u636e\u75ab\u60c5\u9636\u6bb5\u8c03\u6574\u3002"}}
{"id": "2509.14172", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.14172", "abs": "https://arxiv.org/abs/2509.14172", "authors": ["Ziyuan Chen", "Zhenghui Zhao", "Zhangye Han", "Miancan Liu", "Xianhang Ye", "Yiqing Li", "Hongbo Min", "Jinkui Ren", "Xiantao Zhang", "Guitao Cao"], "title": "TGPO: Tree-Guided Preference Optimization for Robust Web Agent Reinforcement Learning", "comment": null, "summary": "With the rapid advancement of large language models and vision-language\nmodels, employing large models as Web Agents has become essential for automated\nweb interaction. However, training Web Agents with reinforcement learning faces\ncritical challenges including credit assignment misallocation, prohibitively\nhigh annotation costs, and reward sparsity. To address these issues, we propose\nTree-Guided Preference Optimization (TGPO), an offline reinforcement learning\nframework that proposes a tree-structured trajectory representation merging\nsemantically identical states across trajectories to eliminate label conflicts.\nOur framework incorporates a Process Reward Model that automatically generates\nfine-grained rewards through subgoal progress, redundancy detection, and action\nverification. Additionally, a dynamic weighting mechanism prioritizes\nhigh-impact decision points during training. Experiments on Online-Mind2Web and\nour self-constructed C-WebShop datasets demonstrate that TGPO significantly\noutperforms existing methods, achieving higher success rates with fewer\nredundant steps.", "AI": {"tldr": "TGPO\u7528\u6811\u72b6\u8f68\u8ff9\u5408\u5e76\u540c\u8bed\u4e49\u72b6\u6001\u5e76\u914d\u5408\u8fc7\u7a0b\u5956\u52b1\u4e0e\u52a8\u6001\u52a0\u6743\uff0c\u89e3\u51b3\u4e86Web Agent\u8bad\u7ec3\u4e2d\u7684\u5956\u52b1\u7a00\u758f\u548c\u6807\u7b7e\u51b2\u7a81\uff0c\u5b9e\u9a8c\u663e\u793a\u6027\u80fd\u5927\u5e45\u63d0\u5347\u3002", "motivation": "\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3Web Agent\u906d\u9047\u56de\u62a5\u7a00\u758f\u3001\u6807\u6ce8\u4ee3\u4ef7\u9ad8\u548c\u9519\u8bef\u5206\u914d\uff08credit assignment\uff09\u7b49\u96be\u9898\uff0c\u9700\u66f4\u7cbe\u7ec6\u7684\u5956\u52b1\u4e0e\u66f4\u4e00\u81f4\u7684\u8f68\u8ff9\u6807\u7b7e\u4ee5\u63d0\u9ad8\u6837\u672c\u6548\u7387\u4e0e\u5b66\u4e60\u7a33\u5b9a\u6027\u3002", "method": "\u63d0\u51faTree-Guided Preference Optimization(TGPO)\uff0c\u6784\u5efa\u5408\u5e76\u8bed\u4e49\u76f8\u540c\u72b6\u6001\u7684\u6811\u7ed3\u6784\u8f68\u8ff9\u8868\u793a\uff1b\u5f15\u5165Process Reward Model\u57fa\u4e8e\u5b50\u76ee\u6807\u8fdb\u5c55\u3001\u5197\u4f59\u68c0\u6d4b\u548c\u52a8\u4f5c\u9a8c\u8bc1\u81ea\u52a8\u751f\u6210\u7ec6\u7c92\u5ea6\u5956\u52b1\uff1b\u5e76\u91c7\u7528\u52a8\u6001\u52a0\u6743\u673a\u5236\u5f3a\u8c03\u9ad8\u5f71\u54cd\u51b3\u7b56\u70b9\u8fdb\u884c\u8bad\u7ec3\u3002", "result": "\u5728Online-Mind2Web\u548c\u4f5c\u8005\u6784\u5efa\u7684C-WebShop\u6570\u636e\u96c6\u4e0a\uff0cTGPO\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u53d6\u5f97\u66f4\u9ad8\u6210\u529f\u7387\u5e76\u51cf\u5c11\u5197\u4f59\u6b65\u9aa4\u3002", "conclusion": "TGPO\u6709\u6548\u7f13\u89e3\u4e86\u5956\u52b1\u7a00\u758f\u4e0e\u6807\u7b7e\u51b2\u7a81\u95ee\u9898\uff0c\u901a\u8fc7\u6811\u72b6\u8f68\u8ff9\u8868\u793a\u548c\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\u63d0\u5347Web Agent\u7684\u8bad\u7ec3\u6548\u679c\u3002"}}
{"id": "2509.14029", "categories": ["cs.LG", "eess.SP", "physics.comp-ph", "q-bio.BM"], "pdf": "https://arxiv.org/pdf/2509.14029", "abs": "https://arxiv.org/abs/2509.14029", "authors": ["Samuel Tovey", "Julian Ho\u00dfbach", "Sandro Kuppel", "Tobias Ensslen", "Jan C. Behrends", "Christian Holm"], "title": "Deep Learning-Driven Peptide Classification in Biological Nanopores", "comment": "29 pages (incl. references) 7 figures", "summary": "A device capable of performing real time classification of proteins in a\nclinical setting would allow for inexpensive and rapid disease diagnosis. One\nsuch candidate for this technology are nanopore devices. These devices work by\nmeasuring a current signal that arises when a protein or peptide enters a\nnanometer-length-scale pore. Should this current be uniquely related to the\nstructure of the peptide and its interactions with the pore, the signals can be\nused to perform identification. While such a method would allow for real time\nidentification of peptides and proteins in a clinical setting, to date, the\ncomplexities of these signals limit their accuracy. In this work, we tackle the\nissue of classification by converting the current signals into scaleogram\nimages via wavelet transforms, capturing amplitude, frequency, and time\ninformation in a modality well-suited to machine learning algorithms. When\ntested on 42 peptides, our method achieved a classification accuracy of\n~$81\\,\\%$, setting a new state-of-the-art in the field and taking a step toward\npractical peptide/protein diagnostics at the point of care. In addition, we\ndemonstrate model transfer techniques that will be critical when deploying\nthese models into real hardware, paving the way to a new method for real-time\ndisease diagnosis.", "AI": {"tldr": "Use wavelet-generated scaleograms of nanopore current traces as inputs to machine learning, yielding state-of-the-art ~81% accuracy on 42-peptide classification and showing transfer methods toward real-device use", "motivation": "Enable real-time, low-cost peptide/protein identification from complex nanopore current signals for point-of-care diagnostics", "method": "Wavelet transform + ML classification", "result": "Converted current signals into scaleogram images via wavelet transforms; achieved ~81% classification accuracy on 42 peptides; demonstrated model transfer techniques for hardware deployment", "conclusion": "Wavelet scaleogram-based ML enables substantially improved peptide classification from nanopore signals and transfer strategies bring the approach closer to practical real-time diagnostics"}}
{"id": "2509.14181", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.14181", "abs": "https://arxiv.org/abs/2509.14181", "authors": ["Yifan Hu", "Jie Yang", "Tian Zhou", "Peiyuan Liu", "Yujin Tang", "Rong Jin", "Liang Sun"], "title": "Bridging Past and Future: Distribution-Aware Alignment for Time Series Forecasting", "comment": null, "summary": "Representation learning techniques like contrastive learning have long been\nexplored in time series forecasting, mirroring their success in computer vision\nand natural language processing. Yet recent state-of-the-art (SOTA) forecasters\nseldom adopt these representation approaches because they have shown little\nperformance advantage. We challenge this view and demonstrate that explicit\nrepresentation alignment can supply critical information that bridges the\ndistributional gap between input histories and future targets. To this end, we\nintroduce TimeAlign, a lightweight, plug-and-play framework that learns\nauxiliary features via a simple reconstruction task and feeds them back to any\nbase forecaster. Extensive experiments across eight benchmarks verify its\nsuperior performance. Further studies indicate that the gains arises primarily\nfrom correcting frequency mismatches between historical inputs and future\noutputs. We also provide a theoretical justification for the effectiveness of\nTimeAlign in increasing the mutual information between learned representations\nand predicted targets. As it is architecture-agnostic and incurs negligible\noverhead, TimeAlign can serve as a general alignment module for modern deep\nlearning time-series forecasting systems. The code is available at\nhttps://github.com/TROUBADOUR000/TimeAlign.", "AI": {"tldr": "TimeAlign\u901a\u8fc7\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u7684\u91cd\u6784\u5f0f\u5bf9\u9f50\u6a21\u5757\uff0c\u8865\u9f50\u5386\u53f2\u4e0e\u672a\u6765\u5728\u9891\u7387\u548c\u5206\u5e03\u4e0a\u7684\u5dee\u5f02\uff0c\u80fd\u65e0\u7f1d\u63a5\u5165\u4efb\u610f\u9884\u6d4b\u5668\u5e76\u663e\u8457\u63d0\u5347\u65f6\u5e8f\u9884\u6d4b\u6027\u80fd\u3002", "motivation": "\u5c3d\u7ba1\u5bf9\u6bd4\u5b66\u4e60\u7b49\u8868\u793a\u5b66\u4e60\u5728\u89c6\u89c9\u548cNLP\u53d6\u5f97\u6210\u529f\uff0c\u4f46\u5728\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u9886\u57df\u672a\u5e26\u6765\u660e\u663e\u6027\u80fd\u63d0\u5347\u3002\u4f5c\u8005\u8ba4\u4e3a\u662f\u56e0\u4e3a\u5386\u53f2\u8f93\u5165\u4e0e\u672a\u6765\u76ee\u6807\u5728\u5206\u5e03\u4e0a\u5b58\u5728\u5dee\u8ddd\uff0c\u56e0\u800c\u9700\u8981\u663e\u5f0f\u7684\u8868\u5f81\u5bf9\u9f50\u6765\u8865\u5145\u9884\u6d4b\u4fe1\u606f\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u7b80\u5355\u7684\u91cd\u6784\u4efb\u52a1\u6765\u5b66\u4e60\u8f85\u52a9\u8868\u793a\uff0c\u8fd9\u4e9b\u8868\u793a\u88ab\u56de\u9988\u5230\u4efb\u610f\u57fa\u7ebf\u9884\u6d4b\u5668\u4e2d\u3002TimeAlign\u4e3a\u67b6\u6784\u65e0\u5173\u7684\u6a21\u5757\uff0c\u8bad\u7ec3\u65f6\u4e0e\u4e3b\u9884\u6d4b\u5668\u8054\u5408\u6216\u9644\u52a0\u8bad\u7ec3\uff0c\u76ee\u6807\u662f\u663e\u5f0f\u5bf9\u9f50\u5386\u53f2\u4e0e\u672a\u6765\u7684\u8868\u5f81\uff0c\u51cf\u5c11\u9891\u7387\u5dee\u5f02\u5e26\u6765\u7684\u5206\u5e03\u9e3f\u6c9f\u3002", "result": "\u5728\u516b\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5927\u91cf\u5b9e\u9a8c\uff0cTimeAlign\u5728\u591a\u79cd\u57fa\u7ebf\u548c\u4efb\u52a1\u4e0a\u5747\u8868\u73b0\u51fa\u663e\u8457\u63d0\u5347\u3002\u6d88\u878d\u7814\u7a76\u663e\u793a\u6027\u80fd\u63d0\u5347\u4e3b\u8981\u6e90\u81ea\u7ea0\u6b63\u9891\u7387\u4e0d\u5339\u914d\uff1b\u7406\u8bba\u5206\u6790\u8868\u660eTimeAlign\u53ef\u589e\u52a0\u5b66\u4e60\u8868\u793a\u4e0e\u9884\u6d4b\u76ee\u6807\u4e4b\u95f4\u7684\u4e92\u4fe1\u606f\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51faTimeAlign\uff0c\u4e00\u4e2a\u8f7b\u91cf\u3001\u53ef\u63d2\u62d4\u7684\u5bf9\u9f50\u6a21\u5757\uff0c\u901a\u8fc7\u91cd\u6784\u4efb\u52a1\u5b66\u4e60\u8f85\u52a9\u7279\u5f81\u5e76\u56de\u9988\u7ed9\u4efb\u4f55\u57fa\u7840\u9884\u6d4b\u5668\uff0c\u4ece\u800c\u7f29\u5c0f\u8f93\u5165\u5386\u53f2\u4e0e\u672a\u6765\u76ee\u6807\u4e4b\u95f4\u7684\u5206\u5e03\u5dee\u8ddd\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u5728\u516b\u4e2a\u57fa\u51c6\u4e0a\u4f18\u4e8eSOTA\uff0c\u4e3b\u8981\u6536\u76ca\u6765\u81ea\u7ea0\u6b63\u5386\u53f2\u4e0e\u672a\u6765\u7684\u9891\u7387\u4e0d\u5339\u914d\uff0c\u5e76\u901a\u8fc7\u7406\u8bba\u5206\u6790\u89e3\u91ca\u4e86\u5176\u63d0\u9ad8\u8868\u793a\u4e0e\u9884\u6d4b\u76ee\u6807\u4e92\u4fe1\u606f\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2509.14216", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.14216", "abs": "https://arxiv.org/abs/2509.14216", "authors": ["Johnny R. Zhang", "Xiaomei Mi", "Gaoyuan Du", "Qianyi Sun", "Shiqi Wang", "Jiaxuan Li", "Wenhua Zhou"], "title": "A Universal Banach--Bregman Framework for Stochastic Iterations: Unifying Stochastic Mirror Descent, Learning and LLM Training", "comment": "69 pages, 10 figures. Preprint", "summary": "Stochastic optimization powers the scalability of modern artificial\nintelligence, spanning machine learning, deep learning, reinforcement learning,\nand large language model training. Yet, existing theory remains largely\nconfined to Hilbert spaces, relying on inner-product frameworks and\northogonality. This paradigm fails to capture non-Euclidean settings, such as\nmirror descent on simplices, Bregman proximal methods for sparse learning,\nnatural gradient descent in information geometry, or\nKullback--Leibler-regularized language model training. Unlike Euclidean-based\nHilbert-space methods, this approach embraces general Banach spaces. This work\nintroduces a pioneering Banach--Bregman framework for stochastic iterations,\nestablishing Bregman geometry as a foundation for next-generation optimization.\nIt (i) provides a unified template via Bregman projections and Bregman--Fejer\nmonotonicity, encompassing stochastic approximation, mirror descent, natural\ngradient, adaptive methods, and mirror-prox; (ii) establishes super-relaxations\n($\\lambda > 2$) in non-Hilbert settings, enabling flexible geometries and\nelucidating their acceleration effect; and (iii) delivers convergence theorems\nspanning almost-sure boundedness to geometric rates, validated on synthetic and\nreal-world tasks. Empirical studies across machine learning (UCI benchmarks),\ndeep learning (e.g., Transformer training), reinforcement learning\n(actor--critic), and large language models (WikiText-2 with distilGPT-2) show\nup to 20% faster convergence, reduced variance, and enhanced accuracy over\nclassical baselines. These results position Banach--Bregman geometry as a\ncornerstone unifying optimization theory and practice across core AI paradigms.", "AI": {"tldr": "\u63d0\u51fa\u5e76\u7406\u8bba\u5316\u4e86\u4e00\u4e2a\u5728Banach\u7a7a\u95f4\u4e2d\u57fa\u4e8eBregman\u51e0\u4f55\u7684\u968f\u673a\u4f18\u5316\u7edf\u4e00\u6846\u67b6\uff0c\u5141\u8bb8\u8d85\u677e\u5f1b\u5e76\u8bc1\u660e\u591a\u79cd\u6536\u655b\u6027\uff0c\u540c\u65f6\u5728\u591a\u4efb\u52a1\u5b9e\u9a8c\u4e2d\u5c55\u793a\u4e86\u663e\u8457\u52a0\u901f\u4e0e\u7a33\u5065\u6027\u3002", "motivation": "\u52a8\u673a\u6765\u81ea\u4e8e\u73b0\u6709\u968f\u673a\u4f18\u5316\u7406\u8bba\u4e3b\u8981\u4f9d\u8d56Hilbert\u7a7a\u95f4\u7ed3\u6784\uff08\u5185\u79ef\u3001\u6b63\u4ea4\u6027\uff09\uff0c\u65e0\u6cd5\u89e3\u91ca\u6216\u523b\u753b\u975e\u6b27\u6c0f\u51e0\u4f55\u4e0b\u7684\u5e38\u89c1\u7b97\u6cd5\uff08\u5982\u955c\u50cf\u4e0b\u964d\u3001Bregman\u8fd1\u7aef\u3001\u81ea\u7136\u68af\u5ea6\u3001KL\u6b63\u5219\u7684\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\uff09\u3002\u6587\u732e\u7f3a\u4e4f\u4e00\u4e2a\u5728Banach\u7a7a\u95f4\u4e2d\u7edf\u4e00\u7684\u3001\u5177\u6709\u968f\u673a\u6027\u5904\u7406\u80fd\u529b\u7684\u7406\u8bba\u6846\u67b6\u3002", "method": "\u8bba\u6587\u57fa\u4e8eBregman\u6563\u5ea6\u4e0eBregman\u6295\u5f71\uff0c\u5b9a\u4e49\u4e86Bregman\u2013Fej\u00e9r\u5355\u8c03\u6027\u5e76\u7528\u5176\u4f5c\u4e3a\u5206\u6790\u4e3b\u5e72\uff0c\u6784\u5efa\u7edf\u4e00\u7684\u968f\u673a\u8fed\u4ee3\u6a21\u7248\u3002\u7406\u8bba\u4e0a\uff0c\u63a8\u5bfc\u4e86\u5728Banach\u7a7a\u95f4\u4e0b\u7684\u6536\u655b\u6761\u4ef6\u3001\u6b65\u957f/\u677e\u5f1b\u53c2\u6570\u8303\u56f4\u4ee5\u53ca\u4ea7\u751f\u51e0\u4f55\u6536\u655b\u7387\u7684\u5047\u8bbe\uff1b\u5b9e\u8bc1\u4e0a\uff0c\u5728UCI\u57fa\u51c6\u3001Transformer\u3001actor\u2013critic\u548c distilGPT-2\uff08WikiText-2\uff09\u4e0a\u4e0e\u7ecf\u5178\u57fa\u7ebf\u6bd4\u8f83\uff0c\u6d4b\u91cf\u6536\u655b\u901f\u5ea6\u3001\u65b9\u5dee\u548c\u7cbe\u5ea6\u3002", "result": "\u4e3b\u8981\u7ed3\u679c\u5305\u62ec\uff1a\u5728Banach\u7a7a\u95f4\u4e0a\u5efa\u7acb\u7684Banach\u2013Bregman\u7edf\u4e00\u6846\u67b6\uff1b\u5f15\u5165\u5e76\u5206\u6790\u4e86Bregman\u2013Fej\u00e9r\u5355\u8c03\u6027\uff1b\u8bc1\u660e\u5728\u975eHilbert\u8bbe\u7f6e\u4e0b\u5141\u8bb8\u8d85\u677e\u5f1b\u03bb>2\u5e76\u9610\u660e\u5176\u52a0\u901f\u4f5c\u7528\uff1b\u7ed9\u51fa\u4ece\u51e0\u4e4e\u5fc5\u6709\u6709\u754c\u5230\u51e0\u4f55\u6536\u655b\u7684\u6536\u655b\u5b9a\u7406\uff1b\u5b9e\u8bc1\u7ed3\u679c\u663e\u793a\u5728\u591a\u79cd\u4efb\u52a1\u4e0a\u53ef\u8fbe\u6700\u591a\u7ea620%\u7684\u6536\u655b\u52a0\u901f\u3001\u65b9\u5dee\u964d\u4f4e\u548c\u7cbe\u5ea6\u63d0\u5347\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u5728\u4e00\u822cBanach\u7a7a\u95f4\u4e2d\u7edf\u4e00\u63cf\u8ff0Bregman\u51e0\u4f55\u4e0e\u968f\u673a\u8fed\u4ee3\u7684\u6846\u67b6\uff0c\u6269\u5c55\u4e86\u4f20\u7edf\u4ec5\u5728Hilbert\u7a7a\u95f4\uff08\u6b27\u6c0f\uff09\u9002\u7528\u7684\u968f\u673a\u4f18\u5316\u7406\u8bba\u3002\u4f5c\u8005\u58f0\u79f0\u6784\u5efa\u4e86\u5305\u542b\u955c\u50cf\u4e0b\u964d\u3001\u81ea\u9002\u5e94\u65b9\u6cd5\u3001\u81ea\u7136\u68af\u5ea6\u7b49\u5728\u5185\u7684\u7edf\u4e00\u6a21\u7248\uff0c\u63d0\u51fa\u5e76\u5206\u6790\u4e86\u5728\u975eHilbert\u8bbe\u7f6e\u4e0b\u53ef\u53d6\u7684\u8d85\u677e\u5f1b\u53c2\u6570\uff08\u03bb>2\uff09\uff0c\u8bc1\u660e\u4e86\u591a\u79cd\u6536\u655b\u6027\u7ed3\u679c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6027\u80fd\u63d0\u5347\u3002"}}
{"id": "2509.14077", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.14077", "abs": "https://arxiv.org/abs/2509.14077", "authors": ["Yuhao Wang", "Enlu Zhou"], "title": "Online Bayesian Risk-Averse Reinforcement Learning", "comment": null, "summary": "In this paper, we study the Bayesian risk-averse formulation in reinforcement\nlearning (RL). To address the epistemic uncertainty due to a lack of data, we\nadopt the Bayesian Risk Markov Decision Process (BRMDP) to account for the\nparameter uncertainty of the unknown underlying model. We derive the asymptotic\nnormality that characterizes the difference between the Bayesian risk value\nfunction and the original value function under the true unknown distribution.\nThe results indicate that the Bayesian risk-averse approach tends to\npessimistically underestimate the original value function. This discrepancy\nincreases with stronger risk aversion and decreases as more data become\navailable. We then utilize this adaptive property in the setting of online RL\nas well as online contextual multi-arm bandits (CMAB), a special case of online\nRL. We provide two procedures using posterior sampling for both the general RL\nproblem and the CMAB problem. We establish a sub-linear regret bound, with the\nregret defined as the conventional regret for both the RL and CMAB settings.\nAdditionally, we establish a sub-linear regret bound for the CMAB setting with\nthe regret defined as the Bayesian risk regret. Finally, we conduct numerical\nexperiments to demonstrate the effectiveness of the proposed algorithm in\naddressing epistemic uncertainty and verifying the theoretical properties.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u5e76\u5206\u6790\u4e86\u57fa\u4e8eBRMDP\u7684\u8d1d\u53f6\u65af\u98ce\u9669\u538c\u6076RL\u65b9\u6cd5\uff0c\u8bc1\u660e\u5176\u5728\u5c0f\u6837\u672c\u4e0b\u4f1a\u4fdd\u5b88\u4f4e\u4f30\u4ef7\u503c\u5e76\u968f\u6570\u636e\u81ea\u9002\u5e94\u6536\u655b\uff0c\u7ed9\u51fa\u540e\u9a8c\u91c7\u6837\u7b97\u6cd5\u5e76\u8bc1\u660e\u6b21\u7ebf\u6027\u9057\u61be\uff0c\u4e14\u5b9e\u9a8c\u8bc1\u5b9e\u6709\u6548\u3002", "motivation": "\u5728\u6837\u672c\u4e0d\u8db3\u5bfc\u81f4\u7684\u5916\u751f\u4e0d\u786e\u5b9a\u6027\uff08\u5373\u53c2\u6570\u7684\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\uff09\u4e0b\uff0c\u5e0c\u671b\u6784\u5efa\u4e00\u79cd\u5728\u51b3\u7b56\u4e2d\u663e\u5f0f\u8003\u8651\u4e0d\u786e\u5b9a\u6027\u7684\u4fdd\u5b88\u7b56\u7565\uff0c\u4ece\u800c\u5728\u5728\u7ebfRL\u4e0eCMAB\u4e2d\u63d0\u9ad8\u5b89\u5168\u6027\u548c\u6cdb\u5316\u6027\u80fd\u5e76\u63a7\u5236\u98ce\u9669\u3002", "method": "\u5229\u7528BRMDP\u6846\u67b6\u5904\u7406\u53c2\u6570\u4e0d\u786e\u5b9a\u6027\uff0c\u63a8\u5bfc\u8d1d\u53f6\u65af\u98ce\u9669\u503c\u51fd\u6570\u4e0e\u771f\u5b9e\u503c\u51fd\u6570\u5dee\u5f02\u7684\u6e10\u8fd1\u6b63\u6001\u6027\uff1b\u57fa\u4e8e\u8be5\u81ea\u9002\u5e94\u4fdd\u5b88\u6027\u8bbe\u8ba1\u57fa\u4e8e\u540e\u9a8c\u91c7\u6837\u7684\u5728\u7ebfRL\u4e0eCMAB\u7b97\u6cd5\uff0c\u5e76\u8bc1\u660e\u6b21\u7ebf\u6027\u9057\u61be\u754c\uff1b\u6700\u540e\u901a\u8fc7\u6570\u503c\u4eff\u771f\u5b9e\u9a8c\u9a8c\u8bc1\u7406\u8bba\u3002", "result": "1) \u63a8\u5bfc\u51fa\u8d1d\u53f6\u65af\u98ce\u9669\u503c\u51fd\u6570\u4e0e\u771f\u5b9e\u503c\u51fd\u6570\u5dee\u5f02\u7684\u6e10\u8fd1\u6b63\u6001\u5206\u5e03\uff0c\u8868\u660e\u8d1d\u53f6\u65af\u98ce\u9669\u65b9\u6cd5\u503e\u5411\u4e8e\u60b2\u89c2\u4f30\u8ba1\uff1b2) \u8be5\u5dee\u5f02\u968f\u98ce\u9669\u538c\u6076\u7cfb\u6570\u589e\u52a0\u800c\u589e\u5927\uff0c\u968f\u6837\u672c\u91cf\u589e\u52a0\u800c\u51cf\u5c0f\uff1b3) \u4e3a\u5728\u7ebfRL\u548cCMAB\u5206\u522b\u7ed9\u51fa\u540e\u9a8c\u91c7\u6837\u7b97\u6cd5\u5e76\u8bc1\u660e\u5e38\u89c4\u9057\u61be\u548c\u8d1d\u53f6\u65af\u98ce\u9669\u9057\u61be\u7684\u6b21\u7ebf\u6027\u4e0a\u754c\uff1b4) \u6570\u503c\u5b9e\u9a8c\u652f\u6301\u7406\u8bba\u7ed3\u8bba\u5e76\u5c55\u793a\u7b97\u6cd5\u5728\u5904\u7406\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u4e0a\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u8bba\u6587\u8bc1\u660e\u4e86\u8d1d\u53f6\u65af\u98ce\u9669\u538c\u6076\uff08BRMDP\uff09\u5728\u5b58\u5728\u53c2\u6570\u4e0d\u786e\u5b9a\u6027\u65f6\u4f1a\u4fdd\u5b88\u5730\u4f4e\u4f30\u771f\u5b9e\u4ef7\u503c\u51fd\u6570\uff0c\u5e76\u91cf\u5316\u4e86\u8fd9\u79cd\u5dee\u5f02\u7684\u6e10\u8fd1\u6b63\u6001\u6027\u8d28\uff1b\u968f\u7740\u98ce\u9669\u538c\u6076\u7a0b\u5ea6\u589e\u5927\u5dee\u5f02\u589e\u5927\uff0c\u968f\u7740\u6570\u636e\u91cf\u589e\u52a0\u5dee\u5f02\u7f29\u5c0f\u3002\u901a\u8fc7\u5c06\u8be5\u65b9\u6cd5\u5e94\u7528\u4e8e\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u548c\u4e0a\u4e0b\u6587\u591a\u81c2\u8d4c\u535a\u673a\uff08CMAB\uff09\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u540e\u9a8c\u91c7\u6837\u7684\u4e24\u79cd\u7b97\u6cd5\uff0c\u5e76\u8bc1\u660e\u4e86\u5e38\u89c4\u548c\u8d1d\u53f6\u65af\u98ce\u9669\u5b9a\u4e49\u4e0b\u7684\u6b21\u7ebf\u6027\u9057\u61be\u754c\uff0c\u540c\u65f6\u901a\u8fc7\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u7406\u8bba\u548c\u7b97\u6cd5\u6709\u6548\u6027\u3002"}}
{"id": "2509.14223", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2509.14223", "abs": "https://arxiv.org/abs/2509.14223", "authors": ["Dmitrii Krasheninnikov", "Richard E. Turner", "David Krueger"], "title": "Language models' activations linearly encode training-order recency", "comment": null, "summary": "We show that language models' activations linearly encode when information\nwas learned during training. Our setup involves creating a model with a known\ntraining order by sequentially fine-tuning Llama-3.2-1B on six disjoint but\notherwise similar datasets about named entities. We find that the average\nactivations of test samples for the six training datasets encode the training\norder: when projected into a 2D subspace, these centroids are arranged exactly\nin the order of training and lie on a straight line. Further, we show that\nlinear probes can accurately (~90%) distinguish \"early\" vs. \"late\" entities,\ngeneralizing to entities unseen during the probes' own training. The model can\nalso be fine-tuned to explicitly report an unseen entity's training stage (~80%\naccuracy). Interestingly, this temporal signal does not seem attributable to\nsimple differences in activation magnitudes, losses, or model confidence. Our\npaper demonstrates that models are capable of differentiating information by\nits acquisition time, and carries significant implications for how they might\nmanage conflicting data and respond to knowledge modifications.", "AI": {"tldr": "\u4f5c\u8005\u901a\u8fc7\u5bf9Llama-3.2-1B\u987a\u5e8f\u5fae\u8c03\u5e76\u5206\u6790\u6fc0\u6d3b\u5747\u503c\uff0c\u53d1\u73b0\u6a21\u578b\u7ebf\u6027\u5730\u7f16\u7801\u4e86\u4fe1\u606f\u7684\u5b66\u4e60\u65f6\u95f4\uff0c\u80fd\u7528\u7ebf\u6027\u63a2\u9488\u9ad8\u51c6\u786e\u5ea6\u533a\u5206\u65e9\u665a\u5b66\u5230\u7684\u5b9e\u4f53\uff0c\u6697\u793a\u6a21\u578b\u5728\u8868\u793a\u4e2d\u4fdd\u7559\u65f6\u95f4\u4fe1\u606f\uff0c\u5bf9\u77e5\u8bc6\u51b2\u7a81\u4e0e\u66f4\u65b0\u6709\u91cd\u8981\u542b\u4e49\u3002", "motivation": "\u52a8\u673a\u5728\u4e8e\u7406\u89e3\u6a21\u578b\u5982\u4f55\u5728\u8868\u793a\u4e2d\u7f16\u7801\u77e5\u8bc6\u83b7\u53d6\u65f6\u95f4\uff0c\u8fd9\u5bf9\u5904\u7406\u51b2\u7a81\u4fe1\u606f\u4e0e\u77e5\u8bc6\u66f4\u65b0\u5177\u6709\u91cd\u8981\u5f71\u54cd\u3002", "method": "\u65b9\u6cd5\u4e3a\u901a\u8fc7\u987a\u5e8f\u5fae\u8c03Llama-3.2-1B\u5728\u516d\u4e2a\u4e92\u4e0d\u4ea4\u53e0\u4f46\u76f8\u4f3c\u7684\u6570\u636e\u96c6\u4e0a\uff0c\u6784\u9020\u5df2\u77e5\u8bad\u7ec3\u987a\u5e8f\uff1b\u8ba1\u7b97\u6bcf\u7ec4\u6d4b\u8bd5\u6837\u672c\u7684\u5e73\u5747\u6fc0\u6d3b\uff08\u4e2d\u5fc3\u5411\u91cf\uff09\uff0c\u5e76\u4f7f\u7528\u7ebf\u6027\u6295\u5f71\u4e0e\u7ebf\u6027\u63a2\u9488\u6765\u68c0\u6d4b\u8bad\u7ec3\u65f6\u95f4\u4fe1\u606f\u3002", "result": "\u4e3b\u8981\u7ed3\u679c\u5305\u62ec\uff1a\u57282D\u7ebf\u6027\u5b50\u7a7a\u95f4\u4e2d\uff0c\u4e0d\u540c\u8bad\u7ec3\u9636\u6bb5\u7684\u6fc0\u6d3b\u4e2d\u5fc3\u6309\u8bad\u7ec3\u987a\u5e8f\u6392\u5217\u4e14\u8fd1\u4f3c\u5171\u7ebf\uff1b\u7ebf\u6027\u63a2\u9488\u80fd\u7ea690%\u533a\u5206\u65e9\u671f/\u540e\u671f\u5b9e\u4f53\u5e76\u6cdb\u5316\u5230\u672a\u89c1\u5b9e\u4f53\uff1b\u53ef\u5fae\u8c03\u6a21\u578b\u4ee5\u62a5\u544a\u5b9e\u4f53\u7684\u8bad\u7ec3\u9636\u6bb5\u7ea680%\u51c6\u786e\u7387\uff1b\u8fd9\u4e00\u65f6\u5e8f\u4fe1\u53f7\u975e\u7531\u7b80\u5355\u6fc0\u6d3b\u5e45\u5ea6\u3001\u635f\u5931\u6216\u7f6e\u4fe1\u5ea6\u5dee\u5f02\u89e3\u91ca\u3002", "conclusion": "\u8be5\u8bba\u6587\u7ed3\u8bba\u662f\uff1a\u8bed\u8a00\u6a21\u578b\u7684\u6fc0\u6d3b\u80fd\u591f\u7ebf\u6027\u7f16\u7801\u4fe1\u606f\u88ab\u5b66\u4e60\u7684\u65f6\u95f4\uff0c\u6a21\u578b\u80fd\u591f\u533a\u5206\u65e9\u671f\u4e0e\u540e\u671f\u5b66\u5230\u7684\u5b9e\u4f53\u4fe1\u606f\uff0c\u5e76\u5728\u4f4e\u7ef4\u6295\u5f71\u4e2d\u6309\u8bad\u7ec3\u987a\u5e8f\u6392\u5217\u3002"}}
{"id": "2509.14078", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.14078", "abs": "https://arxiv.org/abs/2509.14078", "authors": ["Robiul Islam", "Dmitry I. Ignatov", "Karl Kaberg", "Roman Nabatchikov"], "title": "Exploring the Relationship between Brain Hemisphere States and Frequency Bands through Deep Learning Optimization Techniques", "comment": null, "summary": "This study investigates classifier performance across EEG frequency bands\nusing various optimizers and evaluates efficient class prediction for the left\nand right hemispheres. Three neural network architectures - a deep dense\nnetwork, a shallow three-layer network, and a convolutional neural network\n(CNN) - are implemented and compared using the TensorFlow and PyTorch\nframeworks. Results indicate that the Adagrad and RMSprop optimizers\nconsistently perform well across different frequency bands, with Adadelta\nexhibiting robust performance in cross-model evaluations. Specifically, Adagrad\nexcels in the beta band, while RMSprop achieves superior performance in the\ngamma band. Conversely, SGD and FTRL exhibit inconsistent performance. Among\nthe models, the CNN demonstrates the second highest accuracy, particularly in\ncapturing spatial features of EEG data. The deep dense network shows\ncompetitive performance in learning complex patterns, whereas the shallow\nthree-layer network, sometimes being less accurate, provides computational\nefficiency. SHAP (Shapley Additive Explanations) plots are employed to identify\nefficient class prediction, revealing nuanced contributions of EEG frequency\nbands to model accuracy. Overall, the study highlights the importance of\noptimizer selection, model architecture, and EEG frequency band analysis in\nenhancing classifier performance and understanding feature importance in\nneuroimaging-based classification tasks.", "AI": {"tldr": "\u6bd4\u8f83\u4e09\u79cd\u7f51\u7edc\u4e0e\u591a\u79cd\u4f18\u5316\u5668\u5728EEG\u9891\u6bb5\u4e0a\u7684\u5206\u7c7b\u8868\u73b0\uff1aAdagrad\u548cRMSprop\u8868\u73b0\u7a33\u5b9a\uff0cAdadelta\u9c81\u68d2\uff0cCNN\u64c5\u957f\u7a7a\u95f4\u7279\u5f81\uff0cSHAP\u63ed\u793a\u9891\u6bb5\u91cd\u8981\u6027\u3002", "motivation": "\u8bc4\u4f30\u4e0d\u540c\u4f18\u5316\u5668\u4e0e\u7f51\u7edc\u67b6\u6784\u5728\u4e0d\u540cEEG\u9891\u6bb5\u4e0a\u7684\u5206\u7c7b\u6027\u80fd\uff0c\u5e76\u8bc6\u522b\u54ea\u4e9b\u9891\u6bb5\u4e0e\u5de6\u53f3\u534a\u7403\u7684\u7c7b\u522b\u9884\u6d4b\u6700\u4e3a\u9ad8\u6548\uff0c\u4ece\u800c\u4f18\u5316\u795e\u7ecf\u5f71\u50cf\u5206\u7c7b\u6d41\u7a0b\u3002", "method": "\u5b9e\u73b0\u5e76\u6bd4\u8f83\u4e09\u79cd\u7f51\u7edc\u7ed3\u6784\uff08\u6df1\u5ea6\u5bc6\u96c6\u7f51\u7edc\u3001\u4e09\u5c42\u6d45\u7f51\u3001\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff09\uff0c\u4f7f\u7528TensorFlow\u548cPyTorch\u4e24\u4e2a\u6846\u67b6\u8fdb\u884c\u8bad\u7ec3\uff0c\u6bd4\u8f83\u591a\u79cd\u4f18\u5316\u5668\uff08Adagrad\u3001RMSprop\u3001Adadelta\u3001SGD\u3001FTRL\uff09\u5728\u4e0d\u540cEEG\u9891\u6bb5\uff08\u5982beta\u3001gamma\u7b49\uff09\u4e0a\u7684\u6027\u80fd\uff1b\u4f7f\u7528SHAP\u5206\u6790\u7279\u5f81\u91cd\u8981\u6027\u5e76\u8bc4\u4f30\u5de6\u53f3\u534a\u7403\u7c7b\u522b\u9884\u6d4b\u6548\u679c\u3002", "result": "Adagrad\u5728beta\u9891\u6bb5\u8868\u73b0\u6700\u4f73\uff0cRMSprop\u5728gamma\u9891\u6bb5\u6700\u4f73\uff1bAdadelta\u5728\u8de8\u6a21\u578b\u8bc4\u4f30\u4e2d\u7a33\u5b9a\uff1bCNN\u603b\u4f53\u4f4d\u5217\u7b2c\u4e8c\u5e76\u64c5\u957f\u7a7a\u95f4\u7279\u5f81\uff1b\u6df1\u5ea6\u5bc6\u96c6\u7f51\u5728\u590d\u6742\u6a21\u5f0f\u4e0b\u8868\u73b0\u826f\u597d\uff0c\u6d45\u7f51\u5728\u8ba1\u7b97\u6548\u7387\u4e0a\u5360\u4f18\u4f46\u51c6\u786e\u7387\u6709\u65f6\u8f83\u4f4e\uff1bSGD\u4e0eFTRL\u8868\u73b0\u4e0d\u7a33\u5b9a\uff1bSHAP\u663e\u793a\u4e0d\u540c\u9891\u6bb5\u5bf9\u5404\u7c7b\u522b\u9884\u6d4b\u7684\u8d21\u732e\u5b58\u5728\u5dee\u5f02\u3002", "conclusion": "\u4f18\u5316\u5668\u9009\u62e9\u3001\u6a21\u578b\u67b6\u6784\u4e0e\u9891\u6bb5\u5bf9\u5206\u7c7b\u6027\u80fd\u5747\u6709\u663e\u8457\u5f71\u54cd\uff1bAdagrad\u548cRMSprop\u603b\u4f53\u8868\u73b0\u7a33\u5b9a\uff0cAdadelta\u8de8\u6a21\u578b\u9c81\u68d2\uff0cSGD\u548cFTRL\u4e0d\u7a33\u5b9a\uff1bCNN\u5728\u63d0\u53d6\u7a7a\u95f4\u7279\u5f81\u4e0a\u6548\u679c\u826f\u597d\uff0c\u6df1\u5ea6\u5bc6\u96c6\u7f51\u7edc\u5728\u590d\u6742\u6a21\u5f0f\u5b66\u4e60\u4e0a\u5177\u7ade\u4e89\u529b\uff0c\u4e09\u5c42\u6d45\u7f51\u8ba1\u7b97\u9ad8\u6548\u4f46\u6709\u65f6\u51c6\u786e\u7387\u8f83\u4f4e\uff1bSHAP\u89e3\u6790\u63ed\u793a\u5404\u9891\u6bb5\u5bf9\u7c7b\u522b\u9884\u6d4b\u7684\u7ec6\u5fae\u8d21\u732e\u3002"}}
{"id": "2509.14113", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.14113", "abs": "https://arxiv.org/abs/2509.14113", "authors": ["Alessandro Brusaferri", "Danial Ramin", "Andrea Ballarino"], "title": "From Distributional to Quantile Neural Basis Models: the case of Electricity Price Forecasting", "comment": "6 pages", "summary": "While neural networks are achieving high predictive accuracy in multi-horizon\nprobabilistic forecasting, understanding the underlying mechanisms that lead to\nfeature-conditioned outputs remains a significant challenge for forecasters. In\nthis work, we take a further step toward addressing this critical issue by\nintroducing the Quantile Neural Basis Model, which incorporates the\ninterpretability principles of Quantile Generalized Additive Models into an\nend-to-end neural network training framework. To this end, we leverage shared\nbasis decomposition and weight factorization, complementing Neural Models for\nLocation, Scale, and Shape by avoiding any parametric distributional\nassumptions. We validate our approach on day-ahead electricity price\nforecasting, achieving predictive performance comparable to distributional and\nquantile regression neural networks, while offering valuable insights into\nmodel behavior through the learned nonlinear mappings from input features to\noutput predictions across the horizon.", "AI": {"tldr": "\u63d0\u51faQuantile Neural Basis Model\uff0c\u5c06Quantile GAM\u7684\u53ef\u89e3\u91ca\u6027\u4e0e\u795e\u7ecf\u7f51\u7edc\u7ed3\u5408\uff0c\u901a\u8fc7\u5171\u4eab\u57fa\u5206\u89e3\u548c\u6743\u91cd\u5206\u89e3\u5b9e\u73b0\u65e0\u5206\u5e03\u5047\u8bbe\u7684\u7aef\u5230\u7aef\u8bad\u7ec3\uff0c\u5728\u65e5\u5185\u7535\u4ef7\u9884\u6d4b\u4e0a\u6027\u80fd\u4e0e\u73b0\u6709\u5206\u5e03\u5f0f/\u5206\u4f4d\u56de\u5f52\u795e\u7ecf\u7f51\u76f8\u5f53\u4f46\u66f4\u53ef\u89e3\u91ca\u3002", "motivation": "\u76ee\u524d\u795e\u7ecf\u7f51\u7edc\u5728\u591a\u65f6\u57df\u6982\u7387\u9884\u6d4b\u4e0a\u7cbe\u5ea6\u9ad8\u4f46\u53ef\u89e3\u91ca\u6027\u5dee\uff0c\u6a21\u578b\u884c\u4e3a\u5bf9\u7279\u5f81\u6761\u4ef6\u8f93\u51fa\u7684\u5f71\u54cd\u96be\u4ee5\u7406\u89e3\uff1b\u56e0\u6b64\u5e0c\u671b\u5c06\u7edf\u8ba1\u53ef\u89e3\u91ca\u6027\u5de5\u5177\uff08Quantile GAM\uff09\u4e0e\u795e\u7ecf\u7f51\u7edc\u7ed3\u5408\uff0c\u65e2\u4fdd\u7559\u9884\u6d4b\u529b\u53c8\u63d0\u9ad8\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u7ed3\u5408\u5171\u4eab\u57fa\u51fd\u6570\u5206\u89e3\u4e0e\u6743\u91cd\u56e0\u5b50\u5206\u89e3\uff08\u7c7b\u4f3c\u4e8eGAM\u7684\u57fa\u5c55\u5f00\uff09\uff0c\u5728\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u4e2d\u7aef\u5230\u7aef\u4f18\u5316\u591a\u4e2a\u5206\u4f4d\u6570\u7684\u9884\u6d4b\uff0c\u65e0\u9700\u6307\u5b9a\u53c2\u6570\u5316\u5206\u5e03\uff1b\u6a21\u578b\u8f93\u51fa\u901a\u8fc7\u57fa\u4e0e\u65f6\u57df\u76f8\u5173\u7cfb\u6570\u91cd\u6784\u591a\u65f6\u57df\u5206\u4f4d\u6570\u66f2\u7ebf\u3002", "result": "Introduces Quantile Neural Basis Model (QNBM) combining interpretability of Quantile GAMs with neural nets for multi-horizon probabilistic forecasting; uses shared basis decomposition and weight factorization; avoids parametric distributional assumptions; validated on day-ahead electricity price forecasting with comparable performance to existing methods and improved interpretability.", "conclusion": "QNBM\u5728\u591a\u65f6\u57df\u6982\u7387\u9884\u6d4b\u4e2d\u80fd\u4fdd\u6301\u4e0e\u5206\u5e03\u5047\u8bbe\u6216\u5206\u4f4d\u56de\u5f52\u795e\u7ecf\u7f51\u76f8\u5f53\u7684\u9884\u6d4b\u7cbe\u5ea6\uff0c\u540c\u65f6\u901a\u8fc7\u5b66\u4e60\u5230\u7684\u975e\u7ebf\u6027\u6620\u5c04\u63d0\u4f9b\u8de8\u9884\u6d4b\u65f6\u57df\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u9002\u7528\u4e8e\u7535\u529b\u4ef7\u683c\u7b49\u5e8f\u5217\u9884\u6d4b\u4efb\u52a1\u3002"}}
{"id": "2509.14129", "categories": ["cs.LG", "cs.CY"], "pdf": "https://arxiv.org/pdf/2509.14129", "abs": "https://arxiv.org/abs/2509.14129", "authors": ["Kit T. Rodolfa", "Erika Salomon", "Jin Yao", "Steve Yoder", "Robert Sullivan", "Kevin McGuire", "Allie Dickinson", "Rob MacDougall", "Brian Seidler", "Christina Sung", "Claire Herdeman", "Rayid Ghani"], "title": "Breaking the Cycle of Incarceration With Targeted Mental Health Outreach: A Case Study in Machine Learning for Public Policy", "comment": null, "summary": "Many incarcerated individuals face significant and complex challenges,\nincluding mental illness, substance dependence, and homelessness, yet jails and\nprisons are often poorly equipped to address these needs. With little support\nfrom the existing criminal justice system, these needs can remain untreated and\nworsen, often leading to further offenses and a cycle of incarceration with\nadverse outcomes both for the individual and for public safety, with\nparticularly large impacts on communities of color that continue to widen the\nalready extensive racial disparities in criminal justice outcomes. Responding\nto these failures, a growing number of criminal justice stakeholders are\nseeking to break this cycle through innovative approaches such as\ncommunity-driven and alternative approaches to policing, mentoring, community\nbuilding, restorative justice, pretrial diversion, holistic defense, and social\nservice connections. Here we report on a collaboration between Johnson County,\nKansas, and Carnegie Mellon University to perform targeted, proactive mental\nhealth outreach in an effort to reduce reincarceration rates.\n  This paper describes the data used, our predictive modeling approach and\nresults, as well as the design and analysis of a field trial conducted to\nconfirm our model's predictive power, evaluate the impact of this targeted\noutreach, and understand at what level of reincarceration risk outreach might\nbe most effective. Through this trial, we find that our model is highly\npredictive of new jail bookings, with more than half of individuals in the\ntrial's highest-risk group returning to jail in the following year. Outreach\nwas most effective among these highest-risk individuals, with impacts on mental\nhealth utilization, EMS dispatches, and criminal justice involvement.", "AI": {"tldr": "\u901a\u8fc7\u6570\u636e\u9a71\u52a8\u7684\u98ce\u9669\u9884\u6d4b\u5e76\u5bf9\u9ad8\u98ce\u9669\u4e2a\u4f53\u5b9e\u65bd\u7cbe\u795e\u5065\u5eb7\u5916\u5c55\uff0c\u53ef\u6709\u6548\u51cf\u5c11\u518d\u5165\u72f1\u53ca\u76f8\u5173\u7d27\u6025\u670d\u52a1\u4f7f\u7528\uff0c\u5e72\u9884\u6548\u679c\u4e3b\u8981\u96c6\u4e2d\u5728\u6700\u9ad8\u98ce\u9669\u4eba\u7fa4\u3002", "motivation": "\u76d1\u72f1\u4e0e\u770b\u5b88\u6240\u65e0\u6cd5\u5145\u5206\u63d0\u4f9b\u7cbe\u795e\u5065\u5eb7\u3001\u836f\u7269\u4f9d\u8d56\u4e0e\u65e0\u5bb6\u53ef\u5f52\u7b49\u590d\u6742\u9700\u6c42\uff0c\u5bfc\u81f4\u53cd\u590d\u5165\u72f1\u4e0e\u793e\u533a\u5371\u5bb3\uff0c\u9700\u901a\u8fc7\u793e\u533a\u9a71\u52a8\u7684\u66ff\u4ee3\u6027\u5e72\u9884\u6253\u7834\u6076\u6027\u5faa\u73af\u5e76\u7f29\u5c0f\u5211\u4e8b\u53f8\u6cd5\u4e2d\u7684\u79cd\u65cf\u4e0d\u5e73\u7b49\u3002", "method": "\u5229\u7528\u7ea6\u7ff0\u900a\u53bf\u7684\u884c\u653f\u6570\u636e\u6784\u5efa\u518d\u5165\u72f1\u98ce\u9669\u9884\u6d4b\u6a21\u578b\uff0c\u5e76\u5728\u968f\u673a\u5316/\u51c6\u5b9e\u9a8c\u6027\u7530\u91ce\u8bd5\u9a8c\u4e2d\u5bf9\u9ad8\u3001\u4e2d\u3001\u4f4e\u98ce\u9669\u7ec4\u5b9e\u65bd\u9488\u5bf9\u6027\u7cbe\u795e\u5065\u5eb7\u5916\u5c55\uff0c\u8bc4\u4f30\u518d\u5165\u72f1\u3001\u7cbe\u795e\u5065\u5eb7\u5229\u7528\u3001EMS\u8c03\u5ea6\u7b49\u591a\u91cd\u7ed3\u5c40\u7684\u5f71\u54cd\u3002", "result": "\u6a21\u578b\u5728\u9884\u6d4b\u6548\u679c\u4e0a\u8868\u73b0\u826f\u597d\uff1a\u6700\u9ad8\u98ce\u9669\u7ec4\u4e2d\u8d85\u8fc7\u4e00\u534a\u5728\u4e00\u5e74\u5185\u518d\u6b21\u5165\u72f1\uff1b\u5916\u5c55\u5e72\u9884\u5728\u6700\u9ad8\u98ce\u9669\u7ec4\u4e2d\u5e26\u6765\u663e\u8457\u6539\u5584\uff08\u964d\u4f4e\u518d\u5165\u72f1\u3001\u589e\u52a0\u7cbe\u795e\u5065\u5eb7\u670d\u52a1\u5229\u7528\u3001\u51cf\u5c11EMS\u8c03\u5ea6\u53ca\u5211\u4e8b\u53f8\u6cd5\u63a5\u89e6\uff09\uff0c\u800c\u5bf9\u4e2d\u4f4e\u98ce\u9669\u7ec4\u5f71\u54cd\u6709\u9650\u3002", "conclusion": "\u8fd9\u9879\u7814\u7a76\u8868\u660e\uff0c\u57fa\u4e8e\u884c\u653f\u6570\u636e\u7684\u9884\u6d4b\u6a21\u578b\u80fd\u6709\u6548\u8bc6\u522b\u51fa\u9ad8\u98ce\u9669\u518d\u5165\u72f1\u4e2a\u4f53\uff0c\u5e76\u901a\u8fc7\u9488\u5bf9\u6027\u7cbe\u795e\u5065\u5eb7\u5916\u5c55\u663e\u8457\u964d\u4f4e\u8fd9\u4e9b\u9ad8\u98ce\u9669\u4eba\u7fa4\u7684\u518d\u5165\u72f1\u7387\u4e0e\u76f8\u5173\u4e0d\u826f\u7ed3\u5c40\u3002"}}
{"id": "2509.14158", "categories": ["cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2509.14158", "abs": "https://arxiv.org/abs/2509.14158", "authors": ["Feng Ruan", "Keli Liu", "Michael Jordan"], "title": "A Compositional Kernel Model for Feature Learning", "comment": null, "summary": "We study a compositional variant of kernel ridge regression in which the\npredictor is applied to a coordinate-wise reweighting of the inputs. Formulated\nas a variational problem, this model provides a simple testbed for feature\nlearning in compositional architectures. From the perspective of variable\nselection, we show how relevant variables are recovered while noise variables\nare eliminated. We establish guarantees showing that both global minimizers and\nstationary points discard noise coordinates when the noise variables are\nGaussian distributed. A central finding is that $\\ell_1$-type kernels, such as\nthe Laplace kernel, succeed in recovering features contributing to nonlinear\neffects at stationary points, whereas Gaussian kernels recover only linear\nones.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u4e00\u4e2a\u5bf9\u8f93\u5165\u9010\u5750\u6807\u91cd\u52a0\u6743\u7684\u7ec4\u5408\u6838\u5cad\u56de\u5f52\u6a21\u578b\uff0c\u8bc1\u660e\u5728\u9ad8\u65af\u566a\u58f0\u4e0b\uff0c\u5168\u5c40\u6700\u4f18\u4e0e\u9a7b\u70b9\u90fd\u4f1a\u53bb\u9664\u566a\u58f0\u53d8\u91cf\uff1b\u5173\u952e\u53d1\u73b0\u662f\u62c9\u666e\u62c9\u65af\u7b49L1\u578b\u6838\u80fd\u5728\u9a7b\u70b9\u6062\u590d\u975e\u7ebf\u6027\u7279\u5f81\uff0c\u800c\u9ad8\u65af\u6838\u53ea\u80fd\u6062\u590d\u7ebf\u6027\u7279\u5f81\u3002", "motivation": "\u6784\u5efa\u4e00\u4e2a\u7b80\u5355\u800c\u53ef\u5206\u6790\u7684\u7ec4\u5408\u5f0f\u6a21\u578b\u6765\u7814\u7a76\u7279\u5f81\u5b66\u4e60\u5728\u5206\u5c42/\u7ec4\u5408\u67b6\u6784\u4e2d\u7684\u6548\u679c\uff0c\u5c24\u5176\u5173\u6ce8\u53d8\u91cf\u9009\u62e9\u80fd\u529b\uff1a\u5373\u5982\u4f55\u5728\u542b\u566a\u6570\u636e\u4e2d\u6062\u590d\u76f8\u5173\u53d8\u91cf\u5e76\u5254\u9664\u65e0\u5173\uff08\u566a\u58f0\uff09\u53d8\u91cf\u3002\u901a\u8fc7\u7814\u7a76\u4e0d\u540c\u6838\u7684\u6027\u8d28\uff0c\u7406\u89e3\u4e3a\u4f55\u4e00\u4e9b\u6838\u80fd\u6355\u83b7\u975e\u7ebf\u6027\u8d21\u732e\u800c\u53e6\u4e00\u4e9b\u4e0d\u80fd\u3002", "method": "\u5c06\u9884\u6d4b\u5668\u5e94\u7528\u4e8e\u8f93\u5165\u7684\u9010\u5750\u6807\u91cd\u52a0\u6743\uff0c\u5e76\u5c06\u95ee\u9898\u8868\u8ff0\u4e3a\u4e00\u4e2a\u53d8\u5206\uff08\u4f18\u5316\uff09\u95ee\u9898\uff1b\u5206\u6790\u5168\u5c40\u6700\u5c0f\u70b9\u4e0e\u9a7b\u70b9\u7684\u6027\u8d28\uff0c\u7279\u522b\u662f\u5728\u566a\u58f0\u53d8\u91cf\u4e3a\u9ad8\u65af\u65f6\uff0c\u5229\u7528\u6838\u51fd\u6570\u7684\u4e0d\u540c\u6027\u8d28\uff08L1\u578b\u4e0eGaussian\u578b\uff09\u63a8\u5bfc\u53d8\u91cf\u9009\u62e9\u7684\u7406\u8bba\u4fdd\u8bc1\u3002\u7406\u8bba\u5de5\u5177\u5305\u62ec\u6838\u5cad\u56de\u5f52\u7684\u6700\u4f18\u5316\u5206\u6790\u3001\u9a7b\u70b9\u6761\u4ef6\u4ee5\u53ca\u6982\u7387/\u9ad8\u7ef4\u7edf\u8ba1\u8bba\u8bc1\u6765\u8bc1\u660e\u566a\u58f0\u5750\u6807\u88ab\u4e22\u5f03\u4e0e\u7279\u5f81\u6062\u590d\u7684\u6027\u8d28\u3002", "result": "\u8bc1\u660e\u4e86\u5728\u566a\u58f0\u53d8\u91cf\u4e3a\u9ad8\u65af\u5206\u5e03\u65f6\uff0c\u6a21\u578b\u7684\u5168\u5c40\u6700\u5c0f\u70b9\u4e0e\u9a7b\u70b9\u90fd\u4f1a\u4e22\u5f03\u566a\u58f0\u5750\u6807\uff0c\u4ece\u800c\u5b9e\u73b0\u53d8\u91cf\u9009\u62e9\uff1b\u5e76\u4e14\u5c55\u793a\u4e86\u6838\u51fd\u6570\u7684\u5173\u952e\u5f71\u54cd\uff1aL1\u578b\u6838\uff08\u62c9\u666e\u62c9\u65af\uff09\u53ef\u4ee5\u5728\u9a7b\u70b9\u5904\u8bc6\u522b\u53c2\u4e0e\u975e\u7ebf\u6027\u6548\u5e94\u7684\u7279\u5f81\uff0c\u800c\u9ad8\u65af\u6838\u5219\u53ea\u8bc6\u522b\u7ebf\u6027\u8d21\u732e\u7684\u7279\u5f81\u3002\u7ed3\u679c\u4e3a\u7279\u5f81\u5b66\u4e60\u4e0e\u53d8\u91cf\u9009\u62e9\u5728\u7ec4\u5408\u6838\u65b9\u6cd5\u4e2d\u7684\u7406\u8bba\u7406\u89e3\u63d0\u4f9b\u4e86\u65b0\u89c1\u89e3\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u5e76\u5206\u6790\u4e86\u4e00\u79cd\u7ec4\u5408\u5f0f\uff08\u5206\u91cf\u91cd\u52a0\u6743\uff09\u6838\u5cad\u56de\u5f52\u6a21\u578b\uff0c\u4f5c\u4e3a\u7279\u5f81\u5b66\u4e60\u5728\u7ec4\u5408\u67b6\u6784\u4e2d\u7684\u7b80\u6d01\u6d4b\u8bd5\u5e8a\uff1b\u7ed3\u8bba\u662f\u8be5\u6a21\u578b\u80fd\u5b9e\u73b0\u53d8\u91cf\u9009\u62e9\uff0c\u5254\u9664\u566a\u58f0\u5750\u6807\u3002\u5bf9\u4e8e\u566a\u58f0\u4e3a\u9ad8\u65af\u5206\u5e03\u7684\u60c5\u5f62\uff0c\u8bba\u6587\u8bc1\u660e\u4e86\u5168\u5c40\u6700\u5c0f\u70b9\u548c\u9a7b\u70b9\u90fd\u4f1a\u4e22\u5f03\u566a\u58f0\u5750\u6807\uff1b\u4e14\u5173\u952e\u53d1\u73b0\u662f\uff1a\u542b\u6709L1\u6027\u8d28\u7684\u6838\uff08\u5982\u62c9\u666e\u62c9\u65af\u6838\uff09\u80fd\u5728\u9a7b\u70b9\u5904\u6062\u590d\u5bf9\u975e\u7ebf\u6027\u6548\u5e94\u6709\u8d21\u732e\u7684\u7279\u5f81\uff0c\u800c\u9ad8\u65af\u6838\u4ec5\u80fd\u6062\u590d\u7ebf\u6027\u8d21\u732e\u7684\u7279\u5f81\u3002"}}
{"id": "2509.14167", "categories": ["cs.LG", "q-bio.QM", "stat.AP", "stat.ME"], "pdf": "https://arxiv.org/pdf/2509.14167", "abs": "https://arxiv.org/abs/2509.14167", "authors": ["Md Rezwan Jaher", "Abul Mukid Mohammad Mukaddes", "A. B. M. Abdul Malek"], "title": "Deconstructing Intraocular Pressure: A Non-invasive Multi-Stage Probabilistic Inverse Framework", "comment": "43 pages, 10 figures (including supplementary material)", "summary": "Many critical healthcare decisions are challenged by the inability to measure\nkey underlying parameters. Glaucoma, a leading cause of irreversible blindness\ndriven by elevated intraocular pressure (IOP), provides a stark example. The\nprimary determinant of IOP, a tissue property called trabecular meshwork\npermeability, cannot be measured in vivo, forcing clinicians to depend on\nindirect surrogates. This clinical challenge is compounded by a broader\ncomputational one: developing predictive models for such ill-posed inverse\nproblems is hindered by a lack of ground-truth data and prohibitive cost of\nlarge-scale, high-fidelity simulations. We address both challenges with an\nend-to-end framework to noninvasively estimate unmeasurable variables from\nsparse, routine data. Our approach combines a multi-stage artificial\nintelligence architecture to functionally separate the problem; a novel data\ngeneration strategy we term PCDS that obviates the need for hundreds of\nthousands of costly simulations, reducing the effective computational time from\nyears to hours; and a Bayesian engine to quantify predictive uncertainty. Our\nframework deconstructs a single IOP measurement into its fundamental components\nfrom routine inputs only, yielding estimates for the unmeasurable tissue\npermeability and a patient's outflow facility. Our noninvasively estimated\noutflow facility achieved excellent agreement with state-of-the-art tonography\nwith precision comparable to direct physical instruments. Furthermore, the\nnewly derived permeability biomarker demonstrates high accuracy in stratifying\nclinical cohorts by disease risk, highlighting its diagnostic potential. More\nbroadly, our framework establishes a generalizable blueprint for solving\nsimilar inverse problems in other data-scarce, computationally-intensive\ndomains.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u7ed3\u5408\u591a\u9636\u6bb5AI\u3001PCDS\u6570\u636e\u751f\u6210\u4e0e\u8d1d\u53f6\u65af\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u7684\u6846\u67b6\uff0c\u4ece\u5e38\u89c4\u6570\u636e\u975e\u4fb5\u5165\u6027\u4f30\u8ba1\u4e0d\u53ef\u6d4b\u7684\u623f\u89d2\u7ec4\u7ec7\u6e17\u900f\u6027\u4e0e\u5f15\u6d41\u80fd\u529b\uff0c\u5b9e\u73b0\u4e0e\u5c16\u7aeftonography\u76f8\u5f53\u7684\u7cbe\u51c6\u5ea6\u5e76\u80fd\u7528\u4e8e\u98ce\u9669\u5206\u5c42\u3002", "motivation": "\u52a8\u673a\u662f\u4e34\u5e8a\u4e0a\u67d0\u4e9b\u5173\u952e\u53c2\u6570\uff08\u5982\u623f\u89d2\u7ec4\u7ec7\u6e17\u900f\u6027\uff09\u65e0\u6cd5\u4f53\u5185\u76f4\u63a5\u6d4b\u91cf\uff0c\u5bfc\u81f4\u8bca\u65ad\u4e0e\u51b3\u7b56\u53d7\u9650\uff1b\u540c\u65f6\u9ad8\u4fdd\u771f\u6a21\u62df\u4ee3\u4ef7\u9ad8\u6602\uff0c\u9650\u5236\u4e86\u57fa\u4e8e\u7269\u7406\u6a21\u578b\u7684\u9006\u95ee\u9898\u6c42\u89e3\u4e0e\u673a\u5668\u5b66\u4e60\u8bad\u7ec3\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\uff1a1) \u591a\u9636\u6bb5AI\u6a21\u5757\u5bf9\u95ee\u9898\u529f\u80fd\u6027\u5212\u5206\uff1b2) PCDS\uff08\u7269\u7406\u8026\u5408\u6570\u636e\u5408\u6210\uff09\u7b56\u7565\u5927\u5e45\u51cf\u5c11\u9ad8\u4fdd\u771f\u6a21\u62df\u9700\u6c42\uff1b3) \u8d1d\u53f6\u65af\u6a21\u5757\u63d0\u4f9b\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\uff1b\u7aef\u5230\u7aef\u4f30\u8ba1\u6e17\u900f\u6027\u4e0e\u5f15\u6d41\u80fd\u529b\u5e76\u4e0e\u4e34\u5e8a\u57fa\u51c6\u6bd4\u8f83\u9a8c\u8bc1\u3002", "result": "The paper presents an end-to-end framework to estimate unmeasurable physiological variables (trabecular meshwork permeability and outflow facility) from routine clinical data, focusing on glaucoma. It integrates a multi-stage AI architecture, a novel PCDS data generation strategy to drastically reduce simulation cost, and a Bayesian uncertainty quantification engine, achieving estimates that match state-of-the-art tonography and providing a permeability biomarker that stratifies disease risk.", "conclusion": "\u8be5\u6846\u67b6\u53ef\u4ece\u5e38\u89c4\u7a00\u758f\u6570\u636e\u91cd\u5efa\u4e0d\u53ef\u6d4b\u751f\u7406\u53c2\u6570\uff0c\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u5e76\u63d0\u4f9b\u5177\u6709\u8bca\u65ad\u4ef7\u503c\u7684\u751f\u7269\u6807\u5fd7\u7269\uff0c\u5177\u6709\u53ef\u63a8\u5e7f\u6027\u5230\u5176\u4ed6\u540c\u7c7b\u9006\u95ee\u9898\u3002"}}
{"id": "2509.14169", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.14169", "abs": "https://arxiv.org/abs/2509.14169", "authors": ["Ziming Wei", "Zichen Kong", "Yuan Wang", "David Z. Pan", "Xiyuan Tang"], "title": "TopoSizing: An LLM-aided Framework of Topology-based Understanding and Sizing for AMS Circuits", "comment": null, "summary": "Analog and mixed-signal circuit design remains challenging due to the\nshortage of high-quality data and the difficulty of embedding domain knowledge\ninto automated flows. Traditional black-box optimization achieves sampling\nefficiency but lacks circuit understanding, which often causes evaluations to\nbe wasted in low-value regions of the design space. In contrast, learning-based\nmethods embed structural knowledge but are case-specific and costly to retrain.\nRecent attempts with large language models show potential, yet they often rely\non manual intervention, limiting generality and transparency. We propose\nTopoSizing, an end-to-end framework that performs robust circuit understanding\ndirectly from raw netlists and translates this knowledge into optimization\ngains. Our approach first applies graph algorithms to organize circuits into a\nhierarchical device-module-stage representation. LLM agents then execute an\niterative hypothesis-verification-refinement loop with built-in consistency\nchecks, producing explicit annotations. Verified insights are integrated into\nBayesian optimization through LLM-guided initial sampling and\nstagnation-triggered trust-region updates, improving efficiency while\npreserving feasibility.", "AI": {"tldr": "TopoSizing\u5229\u7528\u56fe\u7b97\u6cd5\u548cLLM\u5728\u7f51\u8868\u4e0a\u6784\u5efa\u5c42\u6b21\u5316\u7535\u8def\u7406\u89e3\uff0c\u751f\u6210\u53ef\u9a8c\u8bc1\u7684\u8bbe\u8ba1\u6d1e\u89c1\u5e76\u7ed3\u5408\u81f3\u8d1d\u53f6\u65af\u4f18\u5316\uff0c\u63d0\u5347\u6a21\u62df/\u6df7\u5408\u4fe1\u53f7\u7535\u8def\u81ea\u52a8\u5316\u8bbe\u8ba1\u6548\u7387\u4e0e\u7a33\u5065\u6027\u3002", "motivation": "\u89e3\u51b3\u6a21\u62df\u548c\u6df7\u5408\u4fe1\u53f7\u7535\u8def\u8bbe\u8ba1\u4e2d\u6570\u636e\u4e0d\u8db3\u4e0e\u96be\u4ee5\u5c06\u9886\u57df\u77e5\u8bc6\u5d4c\u5165\u81ea\u52a8\u5316\u6d41\u7a0b\u7684\u95ee\u9898\uff0c\u51cf\u5c11\u5728\u8bbe\u8ba1\u7a7a\u95f4\u4f4e\u4ef7\u503c\u533a\u57df\u7684\u65e0\u6548\u8bc4\u4f30\u3002", "method": "\u4f7f\u7528\u56fe\u7b97\u6cd5\u751f\u6210\u5668\u4ef6-\u6a21\u5757-\u7ea7\u9636\u5c42\u8868\u793a\uff1bLLM\u4ee3\u7406\u6267\u884c\u5047\u8bbe-\u9a8c\u8bc1-\u7ec6\u5316\u5faa\u73af\u5e76\u8fdb\u884c\u4e00\u81f4\u6027\u68c0\u67e5\u4ee5\u8f93\u51fa\u6ce8\u91ca\uff1b\u5c06\u8fd9\u4e9b\u6ce8\u91ca\u7528\u4e8e\u8d1d\u53f6\u65af\u4f18\u5316\u7684\u521d\u59cb\u91c7\u6837\u4e0e\u5728\u505c\u6ede\u65f6\u542f\u7528\u7684\u4fe1\u8d56\u57df\u66f4\u65b0\u3002", "result": "\u63d0\u51faTopoSizing\u6846\u67b6\uff1a\u4ece\u539f\u59cb\u7f51\u8868\u76f4\u63a5\u8fdb\u884c\u7535\u8def\u7406\u89e3\uff0c\u6784\u5efa\u5206\u5c42\u8868\u793a\uff0c\u7531LLM\u4ee3\u7406\u8fdb\u884c\u5047\u8bbe-\u9a8c\u8bc1-\u7ec6\u5316\u5faa\u73af\u5e76\u751f\u6210\u663e\u5f0f\u6ce8\u91ca\uff0c\u5c06\u7ecf\u9a8c\u8bc1\u7684\u89c1\u89e3\u96c6\u6210\u5230\u8d1d\u53f6\u65af\u4f18\u5316\uff0c\u901a\u8fc7LLM\u5f15\u5bfc\u7684\u521d\u59cb\u91c7\u6837\u4e0e\u505c\u6ede\u89e6\u53d1\u7684\u4fe1\u8d56\u57df\u66f4\u65b0\u63d0\u5347\u91c7\u6837\u6548\u7387\u548c\u53ef\u884c\u6027\u4fdd\u6301\u3002", "conclusion": "\u901a\u8fc7\u5c06\u7ed3\u6784\u5316\u7535\u8def\u7406\u89e3\u4e0e\u4f18\u5316\u6d41\u7a0b\u7ed3\u5408\uff0cTopoSizing\u5728\u51cf\u5c11\u65e0\u6548\u8bc4\u4f30\u3001\u63d0\u9ad8\u91c7\u6837\u6548\u7387\u548c\u4fdd\u6301\u53ef\u884c\u6027\u65b9\u9762\u8868\u73b0\u66f4\u4f73\uff0c\u4e3a\u81ea\u52a8\u5316\u7535\u8def\u8bbe\u8ba1\u63d0\u4f9b\u66f4\u901a\u7528\u4e14\u900f\u660e\u7684\u8def\u5f84\u3002"}}
{"id": "2509.14198", "categories": ["cs.LG", "cs.NA", "math.NA", "math.OC", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2509.14198", "abs": "https://arxiv.org/abs/2509.14198", "authors": ["Juan Diego Toscano", "Daniel T. Chen", "Vivek Oommen", "George Em Karniadakis"], "title": "A Variational Framework for Residual-Based Adaptivity in Neural PDE Solvers and Operator Learning", "comment": null, "summary": "Residual-based adaptive strategies are widely used in scientific machine\nlearning but remain largely heuristic. We introduce a unifying variational\nframework that formalizes these methods by integrating convex transformations\nof the residual. Different transformations correspond to distinct objective\nfunctionals: exponential weights target the minimization of uniform error,\nwhile linear weights recover the minimization of quadratic error. Within this\nperspective, adaptive weighting is equivalent to selecting sampling\ndistributions that optimize the primal objective, thereby linking\ndiscretization choices directly to error metrics. This principled approach\nyields three benefits: (1) it enables systematic design of adaptive schemes\nacross norms, (2) reduces discretization error through variance reduction of\nthe loss estimator, and (3) enhances learning dynamics by improving the\ngradient signal-to-noise ratio. Extending the framework to operator learning,\nwe demonstrate substantial performance gains across optimizers and\narchitectures. Our results provide a theoretical justification of\nresidual-based adaptivity and establish a foundation for principled\ndiscretization and training strategies.", "AI": {"tldr": "\u6784\u5efa\u6b8b\u5dee\u53d8\u6362\u7684\u53d8\u5206\u89c6\u89d2\uff1a\u6307\u6570\u6743\u91cd\u5bf9\u5e94\u5747\u5300\u8bef\u5dee\u6700\u5c0f\u5316\uff0c\u7ebf\u6027\u6743\u91cd\u5bf9\u5e94\u4e8c\u6b21\u8bef\u5dee\uff1b\u8be5\u6846\u67b6\u80fd\u7cfb\u7edf\u8bbe\u8ba1\u4e0d\u540c\u8303\u6570\u4e0b\u7684\u81ea\u9002\u5e94\u3001\u964d\u4f4e\u79bb\u6563\u5316\u8bef\u5dee\u3001\u63d0\u5347\u68af\u5ea6\u4fe1\u566a\u6bd4\uff0c\u5e76\u5728\u7b97\u5b50\u5b66\u4e60\u4e2d\u663e\u8457\u63d0\u5347\u6548\u679c", "motivation": "\u5f53\u524d\u6b8b\u5dee\u57fa\u7840\u7684\u81ea\u9002\u5e94\u7b56\u7565\u591a\u4e3a\u542f\u53d1\u5f0f\uff0c\u7f3a\u4e4f\u7edf\u4e00\u7406\u8bba\uff1b\u9700\u8981\u4e00\u4e2a\u80fd\u628a\u52a0\u6743\u89c4\u5219\u3001\u79bb\u6563\u5316\u9009\u62e9\u548c\u76ee\u6807\u8bef\u5dee\u8054\u7cfb\u8d77\u6765\u7684\u7406\u8bba\u6846\u67b6\uff0c\u4ee5\u83b7\u5f97\u66f4\u7cfb\u7edf\u548c\u53ef\u8bc1\u660e\u7684\u81ea\u9002\u5e94\u65b9\u6848\u3002", "method": "\u5efa\u7acb\u53d8\u5206\u5f0f\u8868\u8ff0\uff1a\u5bf9\u6b8b\u5dee\u5e94\u7528\u51f8\u53d8\u6362\u5e76\u5c06\u5176\u7eb3\u5165\u76ee\u6807\u6cdb\u51fd\uff1b\u5206\u6790\u4e0d\u540c\u51f8\u51fd\u6570\uff08\u5982\u6307\u6570\u3001\u7ebf\u6027\uff09\u5bf9\u5e94\u7684\u76ee\u6807\u548c\u6700\u4f18\u91c7\u6837\uff1b\u8bc1\u660e\u91c7\u6837\u4f18\u5316\u7b49\u4ef7\u4e8e\u65b9\u5dee\u51cf\u5c0f\u4e0e\u4fe1\u566a\u6bd4\u63d0\u5347\uff1b\u5728\u7b97\u5b50\u5b66\u4e60\u4e0a\u901a\u8fc7\u4e0d\u540c\u4f18\u5316\u5668\u4e0e\u67b6\u6784\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u6548\u679c", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u53d8\u5206\u6846\u67b6\uff0c\u5c06\u6b8b\u5dee\u9a71\u52a8\u7684\u81ea\u9002\u5e94\u7b56\u7565\u5f62\u5f0f\u5316\uff0c\u901a\u8fc7\u5bf9\u6b8b\u5dee\u8fdb\u884c\u51f8\u53d8\u6362\u5c06\u4e0d\u540c\u7684\u52a0\u6743\u65b9\u5f0f\u5bf9\u5e94\u5230\u4e0d\u540c\u7684\u76ee\u6807\u6cdb\u51fd\u4e0a\uff0c\u5e76\u5c06\u81ea\u9002\u5e94\u52a0\u6743\u7b49\u4ef7\u4e3a\u9009\u62e9\u4f18\u5316\u539f\u59cb\u76ee\u6807\u7684\u91c7\u6837\u5206\u5e03\uff1b\u63a8\u5e7f\u5230\u7b97\u5b50\u5b66\u4e60\u5e76\u5b9e\u9a8c\u8bc1\u660e\u53ef\u63d0\u9ad8\u6027\u80fd", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u6b8b\u5dee\u81ea\u9002\u5e94\u63d0\u4f9b\u4e86\u7406\u8bba\u4f9d\u636e\uff0c\u5c06\u91c7\u6837/\u79bb\u6563\u5316\u7684\u9009\u62e9\u4e0e\u76ee\u6807\u8bef\u5dee\u76f4\u63a5\u8054\u7ed3\uff0c\u6307\u5bfc\u57fa\u4e8e\u4e0d\u540c\u8bef\u5dee\u8303\u6570\u7684\u81ea\u9002\u5e94\u7b56\u7565\u8bbe\u8ba1\uff0c\u80fd\u51cf\u5c11\u65b9\u5dee\u5e76\u6539\u5584\u8bad\u7ec3\u52a8\u6001\uff0c\u4ece\u800c\u63d0\u5347\u7b97\u5b50\u5b66\u4e60\u6027\u80fd"}}
{"id": "2509.14219", "categories": ["cs.LG", "math.DS", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2509.14219", "abs": "https://arxiv.org/abs/2509.14219", "authors": ["Jiaqi Yao", "Lewis Mitchell", "John Maclean", "Hemanth Saratchandran"], "title": "Data Denoising and Derivative Estimation for Data-Driven Modeling of Nonlinear Dynamical Systems", "comment": null, "summary": "Data-driven modeling of nonlinear dynamical systems is often hampered by\nmeasurement noise. We propose a denoising framework, called Runge-Kutta and\nTotal Variation Based Implicit Neural Representation (RKTV-INR), that\nrepresents the state trajectory with an implicit neural representation (INR)\nfitted directly to noisy observations. Runge-Kutta integration and total\nvariation are imposed as constraints to ensure that the reconstructed state is\na trajectory of a dynamical system that remains close to the original data. The\ntrained INR yields a clean, continuous trajectory and provides accurate\nfirst-order derivatives via automatic differentiation. These denoised states\nand derivatives are then supplied to Sparse Identification of Nonlinear\nDynamics (SINDy) to recover the governing equations. Experiments demonstrate\neffective noise suppression, precise derivative estimation, and reliable system\nidentification.", "AI": {"tldr": "Propose RKTV-INR: fit implicit neural representation to noisy observations using Runge-Kutta and total variation constraints to produce denoised trajectories and derivatives for SINDy-based system identification.", "motivation": "Measurement noise degrades data-driven discovery of dynamical systems; need clean states & derivatives for SINDy", "method": "RKTV-INR: INR+RK integration + TV constraint", "result": "INR fitted to noisy data with RK and TV constraints yields denoised continuous trajectories and accurate derivatives; SINDy recovers governing equations", "conclusion": "RKTV-INR effectively suppresses noise, yields precise derivative estimates, and enables reliable identification of system dynamics using SINDy."}}
{"id": "2509.14225", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2509.14225", "abs": "https://arxiv.org/abs/2509.14225", "authors": ["Benjamin Sterling", "Yousef El-Laham", "M\u00f3nica F. Bugallo"], "title": "Defending Diffusion Models Against Membership Inference Attacks via Higher-Order Langevin Dynamics", "comment": "5 pages, 2 figures, 1 table", "summary": "Recent advances in generative artificial intelligence applications have\nraised new data security concerns. This paper focuses on defending diffusion\nmodels against membership inference attacks. This type of attack occurs when\nthe attacker can determine if a certain data point was used to train the model.\nAlthough diffusion models are intrinsically more resistant to membership\ninference attacks than other generative models, they are still susceptible. The\ndefense proposed here utilizes critically-damped higher-order Langevin\ndynamics, which introduces several auxiliary variables and a joint diffusion\nprocess along these variables. The idea is that the presence of auxiliary\nvariables mixes external randomness that helps to corrupt sensitive input data\nearlier on in the diffusion process. This concept is theoretically investigated\nand validated on a toy dataset and a speech dataset using the Area Under the\nReceiver Operating Characteristic (AUROC) curves and the FID metric.", "AI": {"tldr": "\u901a\u8fc7\u5728\u6269\u6563\u6a21\u578b\u4e2d\u52a0\u5165\u5e26\u4e34\u754c\u963b\u5c3c\u7684\u9ad8\u9636\u6717\u4e4b\u4e07\u52a8\u529b\u5b66\u4e0e\u8f85\u52a9\u53d8\u91cf\uff0c\u63d0\u524d\u6df7\u5165\u968f\u673a\u6027\u4ee5\u9632\u6210\u5458\u63a8\u65ad\u653b\u51fb\uff0c\u5b9e\u9a8c\u5728\u73a9\u5177\u4e0e\u8bed\u97f3\u6570\u636e\u96c6\u4e0a\u7528AUROC\u4e0eFID\u9a8c\u8bc1\u4e86\u6709\u6548\u6027\u3002", "motivation": "\u751f\u6210\u5f0fAI\u5e26\u6765\u65b0\u7684\u6570\u636e\u5b89\u5168\u98ce\u9669\uff0c\u5c24\u5176\u662f\u6210\u5458\u63a8\u65ad\u653b\u51fb\u53ef\u4ee5\u5224\u5b9a\u67d0\u4e2a\u6837\u672c\u662f\u5426\u7528\u4e8e\u8bad\u7ec3\uff1b\u5c3d\u7ba1\u6269\u6563\u6a21\u578b\u6bd4\u5176\u4ed6\u751f\u6210\u6a21\u578b\u66f4\u6297\u6b64\u7c7b\u653b\u51fb\uff0c\u4f46\u4ecd\u5b58\u5728\u6cc4\u9732\u98ce\u9669\uff0c\u6545\u63d0\u51fa\u6539\u8fdb\u4ee5\u8fdb\u4e00\u6b65\u4fdd\u62a4\u8bad\u7ec3\u6570\u636e\u9690\u79c1\u3002", "method": "\u5728\u6807\u51c6\u6269\u6563\u6a21\u578b\u57fa\u7840\u4e0a\u6784\u5efa\u5e26\u591a\u4e2a\u8f85\u52a9\u53d8\u91cf\u7684\u8054\u5408\u6269\u6563\u8fc7\u7a0b\uff0c\u91c7\u7528\u9ad8\u9636\u6717\u4e4b\u4e07\u52a8\u529b\u5b66\uff08critically-damped higher-order Langevin dynamics\uff09\u5bf9\u8fd9\u4e9b\u53d8\u91cf\u8fdb\u884c\u6f14\u5316\uff0c\u4ee5\u66f4\u65e9\u3001\u66f4\u5f3a\u5730\u6df7\u5165\u968f\u673a\u6027\u3002\u7406\u8bba\u7ed9\u51fa\u8be5\u8fc7\u7a0b\u6df7\u5408\u6027\u7684\u5206\u6790\uff0c\u5e76\u901a\u8fc7AUROC\u548cFID\u5728\u4e24\u4e2a\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u65b9\u6cd5\u5728\u73a9\u5177\u6570\u636e\u96c6\u548c\u8bed\u97f3\u6570\u636e\u96c6\u4e0a\u964d\u4f4e\u4e86\u653b\u51fb\u8005AUROC\uff08\u5373\u964d\u4f4e\u653b\u51fb\u6210\u529f\u7387\uff09\uff0c\u540c\u65f6\u4fdd\u6301\u6216\u4ec5\u5c0f\u5e45\u5f71\u54cdFID\uff0c\u8868\u660e\u5728\u63d0\u9ad8\u9690\u79c1\u4fdd\u62a4\u7684\u540c\u65f6\u751f\u6210\u8d28\u91cf\u57fa\u672c\u4fdd\u7559\u3002", "conclusion": "\u4f5c\u8005\u63d0\u51fa\u901a\u8fc7\u5f15\u5165\u4e34\u754c\u963b\u5c3c\u7684\u9ad8\u9636\u6717\u4e4b\u4e07\u52a8\u529b\u5b66\u53ca\u8f85\u52a9\u53d8\u91cf\u6765\u9632\u5fa1\u6269\u6563\u6a21\u578b\u7684\u6210\u5458\u63a8\u65ad\u653b\u51fb\uff0c\u8ba4\u4e3a\u8f85\u52a9\u53d8\u91cf\u5728\u6269\u6563\u8fc7\u7a0b\u65e9\u671f\u6df7\u5165\u5916\u90e8\u968f\u673a\u6027\uff0c\u4ece\u800c\u7834\u574f\u654f\u611f\u8f93\u5165\u4fe1\u606f\u3002\u5b9e\u9a8c\u8bc1\u660e\u5728\u73a9\u5177\u6570\u636e\u96c6\u548c\u8bed\u97f3\u6570\u636e\u96c6\u4e0a\u80fd\u63d0\u9ad8\u5bf9\u6297\u6210\u5458\u63a8\u65ad\u653b\u51fb\u7684\u9c81\u68d2\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u751f\u6210\u8d28\u91cf\u3002"}}
{"id": "2509.14230", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.14230", "abs": "https://arxiv.org/abs/2509.14230", "authors": ["Mengting Ai", "Tianxin Wei", "Sirui Chen", "Jingrui He"], "title": "NIRVANA: Structured pruning reimagined for large language models compression", "comment": null, "summary": "Structured pruning of large language models (LLMs) offers substantial\nefficiency improvements by removing entire hidden units, yet current approaches\noften suffer from significant performance degradation, particularly in\nzero-shot settings, and necessitate costly recovery techniques such as\nsupervised fine-tuning (SFT) or adapter insertion. To address these critical\nshortcomings, we introduce NIRVANA, a novel pruning method explicitly designed\nto balance immediate zero-shot accuracy preservation with robust fine-tuning\ncapability. Leveraging a first-order saliency criterion derived from the Neural\nTangent Kernel under Adam optimization dynamics, NIRVANA provides a\ntheoretically grounded pruning strategy that respects essential model training\nbehaviors. To further address the unique challenges posed by structured\npruning, NIRVANA incorporates an adaptive sparsity allocation mechanism across\nlayers and modules (attention vs. MLP), which adjusts pruning intensity between\nmodules in a globally balanced manner. Additionally, to mitigate the high\nsensitivity of pruning decisions to calibration data quality, we propose a\nsimple yet effective KL divergence-based calibration data selection strategy,\nensuring more reliable and task-agnostic pruning outcomes. Comprehensive\nexperiments conducted on Llama3, Qwen, and T5 models demonstrate that NIRVANA\noutperforms existing structured pruning methods under equivalent sparsity\nconstraints, providing a theoretically sound and practical approach to LLM\ncompression. The code is available at\nhttps://github.com/iDEA-iSAIL-Lab-UIUC/NIRVANA.", "AI": {"tldr": "NIRVANA\u7528NTK-Adam\u4e00\u9636\u663e\u8457\u6027\u3001\u8de8\u5c42/\u6a21\u5757\u81ea\u9002\u5e94\u7a00\u758f\u5206\u914d\u548cKL\u7b5b\u9009\u6821\u51c6\u6570\u636e\uff0c\u6709\u6548\u5728\u7ed3\u6784\u5316\u526a\u679d\u4e2d\u517c\u987e\u96f6\u6837\u672c\u8868\u73b0\u4e0e\u53ef\u5fae\u8c03\u6027\uff0c\u5b9e\u9a8c\u8bc1\u660e\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u51cf\u5c11\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7ed3\u6784\u5316\u526a\u679d\u5bf9\u96f6\u6837\u672c\u6027\u80fd\u7684\u635f\u5bb3\uff0c\u907f\u514d\u6602\u8d35\u7684\u6062\u590d\u6280\u672f\uff08\u5982\u76d1\u7763\u5fae\u8c03\u6216\u9002\u914d\u5668\u63d2\u5165\uff09\uff0c\u5e76\u5728\u4fdd\u6301\u5373\u523b\u51c6\u786e\u6027\u4e0e\u540e\u7eed\u5fae\u8c03\u80fd\u529b\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\u3002", "method": "1) \u63a8\u5bfcAdam\u52a8\u529b\u5b66\u4e0b\u7684NTK\u4e00\u9636\u663e\u8457\u6027\u8bc4\u5206\u7528\u4e8e\u8861\u91cf\u9690\u85cf\u5355\u5143\u91cd\u8981\u6027\u30022) \u8bbe\u8ba1\u8de8\u5c42\u4e0e\u6a21\u5757\u7684\u81ea\u9002\u5e94\u7a00\u758f\u5206\u914d\u7b56\u7565\uff0c\u5e73\u8861\u6ce8\u610f\u529b\u4e0eMLP\u526a\u679d\u5f3a\u5ea6\u30023) \u4f7f\u7528KL\u6563\u5ea6\u5bf9\u6821\u51c6\u6570\u636e\u8fdb\u884c\u9009\u62e9\u4ee5\u63d0\u9ad8\u8bc4\u5206\u9c81\u68d2\u6027\u30024) \u5728\u591a\u79cdLLM\uff08Llama3\u3001Qwen\u3001T5\uff09\u4e0a\u8fdb\u884c\u7cfb\u7edf\u6bd4\u8f83\u5b9e\u9a8c\u3002", "result": "\u63d0\u51faNIRVANA\u65b9\u6cd5\uff1a\u57fa\u4e8eAdam\u4f18\u5316\u4e0b\u7684\u795e\u7ecf\u5207\u7ebf\u6838\u4e00\u9636\u663e\u8457\u6027\u51c6\u5219\u8fdb\u884c\u526a\u679d\uff0c\u7ed3\u5408\u8de8\u5c42\u4e0e\u6a21\u5757\uff08\u6ce8\u610f\u529b\u4e0eMLP\uff09\u81ea\u9002\u5e94\u7a00\u758f\u5206\u914d\u548c\u57fa\u4e8eKL\u6563\u5ea6\u7684\u6821\u51c6\u6570\u636e\u9009\u62e9\u7b56\u7565\u3002\u5728Llama3\u3001Qwen\u3001T5\u4e0a\u5b9e\u9a8c\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u7ed3\u6784\u5316\u526a\u679d\u65b9\u6cd5\u3002", "conclusion": "NIRVANA\u5728\u7406\u8bba\u548c\u5b9e\u8df5\u4e0a\u5747\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u7a33\u5065\u7684\u7ed3\u6784\u5316\u526a\u679d\u65b9\u6848\uff0c\u80fd\u5728\u540c\u7b49\u7a00\u758f\u7387\u4e0b\u6bd4\u73b0\u6709\u65b9\u6cd5\u66f4\u597d\u5730\u4fdd\u6301\u96f6\u6837\u672c\u6027\u80fd\u5e76\u63d0\u5347\u540e\u7eed\u5fae\u8c03\u6062\u590d\u80fd\u529b\u3002"}}
{"id": "2509.14234", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2509.14234", "abs": "https://arxiv.org/abs/2509.14234", "authors": ["Dulhan Jayalath", "Shashwat Goel", "Thomas Foster", "Parag Jain", "Suchin Gururangan", "Cheng Zhang", "Anirudh Goyal", "Alan Schelten"], "title": "Compute as Teacher: Turning Inference Compute Into Reference-Free Supervision", "comment": "22 pages, 8 figures, 2 tables", "summary": "Where do learning signals come from when there is no ground truth in\npost-training? We propose turning exploration into supervision through Compute\nas Teacher (CaT), which converts the model's own exploration at inference-time\ninto reference-free supervision by synthesizing a single reference from a group\nof parallel rollouts and then optimizing toward it. Concretely, the current\npolicy produces a group of rollouts; a frozen anchor (the initial policy)\nreconciles omissions and contradictions to estimate a reference, turning extra\ninference-time compute into a teacher signal. We turn this into rewards in two\nregimes: (i) verifiable tasks use programmatic equivalence on final answers;\n(ii) non-verifiable tasks use self-proposed rubrics-binary, auditable criteria\nscored by an independent LLM judge, with reward given by the fraction\nsatisfied. Unlike selection methods (best-of-N, majority, perplexity, or judge\nscores), synthesis may disagree with the majority and be correct even when all\nrollouts are wrong; performance scales with the number of rollouts. As a\ntest-time procedure, CaT improves Gemma 3 4B, Qwen 3 4B, and Llama 3.1 8B (up\nto +27% on MATH-500; +12% on HealthBench). With reinforcement learning\n(CaT-RL), we obtain further gains (up to +33% and +30%), with the trained\npolicy surpassing the initial teacher signal.", "AI": {"tldr": "CaT\u628a\u63a8\u7406\u671f\u7684\u5e76\u884c\u751f\u6210\u5408\u6210\u4e3a\u53c2\u8003\uff0c\u7528\u4f5c\u65e0\u6807\u7b7e\u76d1\u7763\uff0c\u80fd\u5728\u53ef\u9a8c\u8bc1\u4e0e\u4e0d\u53ef\u9a8c\u8bc1\u4efb\u52a1\u90fd\u4ea7\u751f\u6709\u6548\u5956\u52b1\uff0c\u5e76\u901a\u8fc7\u6d4b\u8bd5\u65f6\u6216\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u663e\u8457\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u5728\u540e\u8bad\u7ec3\u6216\u63a8\u7406\u9636\u6bb5\u7f3a\u4e4f\u5730\u9762\u771f\u503c\u6807\u7b7e\u65f6\uff0c\u5982\u4f55\u628a\u989d\u5916\u8ba1\u7b97\u8d44\u6e90\uff08\u5e76\u884crollout\uff09\u8f6c\u5316\u4e3a\u6559\u5b66\u4fe1\u53f7\u4ee5\u6539\u8fdb\u6a21\u578b\u63a8\u7406\uff1f", "method": "\u5728\u63a8\u7406\u65f6\u8ba9\u5f53\u524d\u7b56\u7565\u751f\u6210\u591a\u6761\u5e76\u884crollout\uff1b\u4f7f\u7528\u4e00\u4e2a\u51bb\u7ed3\u7684\u951a\uff08\u521d\u59cb\u7b56\u7565\uff09\u5bf9\u8fd9\u4e9brollout\u8fdb\u884c\u5408\u6210\uff0c\u89e3\u51b3\u9057\u6f0f\u4e0e\u77db\u76fe\u4ee5\u4f30\u8ba1\u5355\u4e00\u53c2\u8003\u7b54\u6848\u3002\u5bf9\u53ef\u9a8c\u8bc1\u4efb\u52a1\u57fa\u4e8e\u7a0b\u5e8f\u5316\u7b49\u4ef7\u6027\u7ed9\u51fa\u5956\u52b1\uff1b\u5bf9\u4e0d\u53ef\u9a8c\u8bc1\u4efb\u52a1\u63d0\u51fa\u81ea\u5b9a\u4e49\u4e8c\u5143\u53ef\u5ba1\u8ba1\u7684rubric\uff0c\u5e76\u7531\u72ec\u7acbLLM\u88c1\u5224\u8bc4\u4f30\u6ee1\u8db3\u7387\u4f5c\u4e3a\u5956\u52b1\u3002\u8fd8\u4e0e\u52a0\u5f3a\u5b66\u4e60\u7ed3\u5408\uff08CaT-RL\uff09\u8bad\u7ec3\u7b56\u7565\u4ee5\u8fdb\u4e00\u6b65\u63d0\u5347\u3002", "result": "\u4f5c\u4e3a\u6d4b\u8bd5\u65f6\u7a0b\u5e8f\uff0cCaT\u5728Gemma 3 4B\u3001Qwen 3 4B\u3001Llama 3.1 8B\u4e0a\u6709\u663e\u8457\u63d0\u5347\uff08\u4f8b\u5982\u5728MATH-500\u4e0a\u6700\u9ad8+27%\uff0cHealthBench\u4e0a+12%\uff09\uff1b\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u540e\uff08CaT-RL\uff09\u8fdb\u4e00\u6b65\u63d0\u5347\uff08\u6700\u9ad8\u53ef\u8fbe+33%\u548c+30%\uff09\uff0c\u4e14\u8bad\u7ec3\u540e\u7684\u7b56\u7565\u8d85\u8fc7\u521d\u59cb\u5408\u6210\u6559\u5e08\u4fe1\u53f7\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684Compute as Teacher (CaT)\u65b9\u6cd5\u5728\u65e0\u76d1\u7763\u7684\u540e\u8bad\u7ec3/\u63a8\u7406\u9636\u6bb5\uff0c\u5c06\u6a21\u578b\u7684\u5e76\u884c\u63a2\u7d22\u5408\u6210\u4e3a\u53c2\u8003\u5e76\u7528\u4e8e\u81ea\u76d1\u7763\uff0c\u4ece\u800c\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002CaT\u5728\u53ef\u9a8c\u8bc1\u4efb\u52a1\u548c\u4e0d\u53ef\u9a8c\u8bc1\u4efb\u52a1\u4e0b\u5747\u53ef\u751f\u6210\u5956\u52b1\u4fe1\u53f7\uff0c\u5e76\u5728\u6d4b\u8bd5\u65f6\u663e\u8457\u6539\u8fdb\u591a\u4e2a\u5f00\u6e90\u6a21\u578b\uff1b\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\uff08CaT-RL\uff09\u53ef\u8fdb\u4e00\u6b65\u8d85\u8d8a\u521d\u59cb\u6559\u5e08\u4fe1\u53f7\u3002"}}
